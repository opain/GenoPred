<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Estimating significance of prediction differences</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/united.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">GenoPred</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Estimating significance of prediction differences</h1>

</div>


<hr />
<p>This analysis was to compare different methods for estimating the statistical significance of prediction differences across polygenic scoring methods, and models in general.</p>
<p>Here I simulate data with one continuous outcome, and two correlated continuous sets of predictions The correlation between the predictors and the outcome is varied, and the correlation between the predictors themselves is varied.</p>
<p>As I do in my other analyses, I estimate the correlation between the predictors and the outcome to determine their predictive utility. Then I compare different methods by comparing the observed-predicted correlations. Several method comparing correlation are considered:</p>
<ul>
<li>Two-sample Z-test
<ul>
<li>Compares estimates from two populations and does not account for the correlation between predictors</li>
</ul></li>
<li>Permutation based
<ul>
<li>Randomises the phenotype, retaining the correlation between predictors, and then estimates the number times the difference in correlation is larger than the observed difference.</li>
</ul></li>
<li>Cox test
<ul>
<li>Method for comparing non-nested models</li>
</ul></li>
<li>Pearson and Filon’s (1898):
<ul>
<li>Method for comparing correlations between variables that are correlated and measured in a single sample</li>
<li>Implemented using cocor.dep.groups.overlap function in the cocor package</li>
<li>Other methods implemented by this function are highly concordant</li>
</ul></li>
<li>Fisher r-to-z :
<ul>
<li>Method for comparing correlations between variables that are independent and measures in different samples.</li>
<li>Implemented using psych package</li>
<li>Accounts for non-normal error of correlations</li>
</ul></li>
<li>Williams test :
<ul>
<li>Method for comparing correlations between variables that are dependent and measured in the same sample.</li>
<li>Implemented using psych package</li>
<li>Accounts for non-normal error of correlations</li>
</ul></li>
</ul>
<p>We will simulate the following scenarios:</p>
<ul>
<li>Estimates from two independent samples</li>
<li>Estimates from one sample, but predictors are uncorrelated</li>
<li>Estimates from one sample, and predictors are highly correlated</li>
</ul>
<hr />
<div id="estimates-from-two-independent-samples" class="section level1">
<h1><span class="header-section-number">1</span> Estimates from two independent samples</h1>
<pre class="r"><code>library(data.table)

set.seed(1)
# Sample 1
N&lt;-200
y1&lt;-rnorm(N)
x1&lt;-scale(y1+rnorm(N,0,3))
dat1&lt;-data.table(y1,x1)
cor(dat1)</code></pre>
<pre><code>##           y1        V1
## y1 1.0000000 0.2743249
## V1 0.2743249 1.0000000</code></pre>
<pre class="r"><code># Sample 2
N&lt;-200
y2&lt;-rnorm(N)
x2&lt;-scale(y2+rnorm(N,0,10))
dat2&lt;-data.table(y2,x2)
cor(dat2)</code></pre>
<pre><code>##            y2         V1
## y2 1.00000000 0.06274804
## V1 0.06274804 1.00000000</code></pre>
<pre class="r"><code>### Derive models using each predictor
mod1&lt;-lm(y1 ~ x1, data=dat1)
mod2&lt;-lm(y2 ~ x2, data=dat2)

dat1$pred1&lt;-predict(mod1, dat1)
dat2$pred2&lt;-predict(mod2, dat2)

dat_cor&lt;-data.frame(model1=&#39;x1&#39;,
                    model2=&#39;x2&#39;,
                    cor_x1_x2=NA,
                    cor_y_x1=coef(summary(mod1))[2,1],
                    cor_y_x1_se=coef(summary(mod1))[2,2],
                    cor_y_x2=coef(summary(mod2))[2,1],
                    cor_y_x2_se=coef(summary(mod2))[2,2],
                    cor_diff=coef(summary(mod1))[2,1]-coef(summary(mod2))[2,1])

### Test difference between predictors using a Z-test
dat_cor$cor_diff_Ztest_P&lt;-pnorm(-(dat_cor$cor_diff/sqrt((dat_cor$cor_y_x1_se^2)+(dat_cor$cor_y_x2_se^2)))) 

### Test difference between predictors using a permutation test
n_perm&lt;-500
diff&lt;-NULL
for(i in 1:n_perm){
  y1_sample&lt;-sample(y1)
  y2_sample&lt;-sample(y2)
  mod1_i&lt;-lm(y1_sample ~ x1, data=dat1)
  mod2_i&lt;-lm(y2_sample ~ x2, data=dat2)
  
  diff_i&lt;-coef(summary(mod1_i))[2,1]-coef(summary(mod2_i))[2,1]
  diff&lt;-c(diff,diff_i)
}

dat_cor$cor_diff_perm_P&lt;-sum(diff &gt; dat_cor$cor_diff[1])/n_perm

### Test difference between predictors using coxtest 
# Not possible as different samples

### Test difference between predictors using Fisher&#39;s Z transformation 
library(cocor)
dat_cor$cocor_fisherZ_P&lt;-cocor.indep.groups(r1.jk=dat_cor$cor_y_x1, r2.hm=dat_cor$cor_y_x2, n1=N, n2=N, alternative=&#39;greater&#39;)@fisher1925$p.value

library(psych)</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:scales&#39;:
## 
##     alpha, rescale</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>dat_cor$psych_fisherZ_P&lt;-paired.r(xy=dat_cor$cor_y_x1, xz=dat_cor$cor_y_x2, n=N, n2=N, twotailed=F)$p

dat_cor</code></pre>
<pre><code>##   model1 model2 cor_x1_x2  cor_y_x1 cor_y_x1_se   cor_y_x2 cor_y_x2_se
## 1     x1     x2        NA 0.2548745  0.06349504 0.06714255  0.07589417
##    cor_diff cor_diff_Ztest_P cor_diff_perm_P cocor_fisherZ_P psych_fisherZ_P
## 1 0.1877319       0.02890093           0.046      0.02747978      0.02747978</code></pre>
<p>The Fisher’s r-to-z transformation is a commonly used approach for comparing correlations from different samples. The two-sample z-test does not account for the non-normal error distribution of Pearson correlations. Results indicate the fisher r-to-z method is concordant with the two-sample z-test. The permutation-based approach is more conservative than other methods.</p>
<hr />
</div>
<div id="estimates-from-one-sample-but-predictors-are-uncorrelated" class="section level1">
<h1><span class="header-section-number">2</span> Estimates from one sample, but predictors are uncorrelated</h1>
<pre class="r"><code>library(data.table)
set.seed(1)
N&lt;-200
y&lt;-rnorm(N)
x1&lt;-as.numeric(scale(y+rnorm(N,0,3)))
x2&lt;-as.numeric(scale(y+rnorm(N,0,10)))
dat&lt;-data.table(y,x1,x2)
cor(dat)</code></pre>
<pre><code>##            y         x1         x2
## y  1.0000000 0.27432489 0.15351734
## x1 0.2743249 1.00000000 0.01848117
## x2 0.1535173 0.01848117 1.00000000</code></pre>
<pre class="r"><code>### Derive models using each predictor
mod1&lt;-lm(y ~ x1, data=dat)
mod2&lt;-lm(y ~ x2, data=dat)

dat$pred1&lt;-predict(mod1, dat)
dat$pred2&lt;-predict(mod2, dat)

dat_cor&lt;-data.frame(model1=&#39;x1&#39;,
                    model2=&#39;x2&#39;,
                    cor_x1_x2=cor(dat$x1,dat$x2),
                    cor_y_x1=coef(summary(mod1))[2,1],
                    cor_y_x1_se=coef(summary(mod1))[2,2],
                    cor_y_x2=coef(summary(mod2))[2,1],
                    cor_y_x2_se=coef(summary(mod2))[2,2],
                    cor_diff=coef(summary(mod1))[2,1]-coef(summary(mod2))[2,1])

### Test difference between predictors using a Z-test
dat_cor$cor_diff_Ztest_P&lt;-pnorm(-(dat_cor$cor_diff/sqrt((dat_cor$cor_y_x1_se^2)+(dat_cor$cor_y_x2_se^2)))) 

### Test difference between predictors using a permutation test
n_perm&lt;-500
diff&lt;-NULL
for(i in 1:n_perm){
  y_sample&lt;-sample(y)
  mod1_i&lt;-lm(y_sample ~ x1, data=dat)
  mod2_i&lt;-lm(y_sample ~ x2, data=dat)
  
  diff_i&lt;-coef(summary(mod1_i))[2,1]-coef(summary(mod2_i))[2,1]
  diff&lt;-c(diff,diff_i)
}

dat_cor$cor_diff_perm_P&lt;-sum(diff &gt; dat_cor$cor_diff[1])/n_perm

### Test difference between predictors using coxtest 
library(lmtest)</code></pre>
<pre><code>## Loading required package: zoo</code></pre>
<pre><code>## 
## Attaching package: &#39;zoo&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.Date, as.Date.numeric</code></pre>
<pre class="r"><code>dat_cor$cox_diff_P&lt;-coxtest(mod1, mod2)$P[2]

### Test difference between predictors using Pearson 
library(cocor)
dat_cor$pearson_diff_P&lt;-cocor.dep.groups.overlap(dat_cor$cor_y_x1, dat_cor$cor_y_x2, dat_cor$cor_x1_x2, N,alternative=&#39;greater&#39;)@pearson1898$p.value

### Test difference between predictors using Williams&#39;s Test
library(psych)
dat_cor$williams_diff_P&lt;-paired.r(xy=dat_cor$cor_y_x1, xz=dat_cor$cor_y_x2, yz=dat_cor$cor_x1_x2, n=N, twotailed=F)$p

dat_cor</code></pre>
<pre><code>##   model1 model2  cor_x1_x2  cor_y_x1 cor_y_x1_se  cor_y_x2 cor_y_x2_se cor_diff
## 1     x1     x2 0.01848117 0.2548745  0.06349504 0.1426325  0.06524537 0.112242
##   cor_diff_Ztest_P cor_diff_perm_P cox_diff_P pearson_diff_P williams_diff_P
## 1        0.1088132           0.112          0      0.1205402       0.1230892</code></pre>
<p>Apart fromt the coxtest method, results are similar across methods, with pearson and williams methods being highly concordant.</p>
<hr />
</div>
<div id="estimates-from-one-sample-and-predictors-are-highly-correlated" class="section level1">
<h1><span class="header-section-number">3</span> Estimates from one sample, and predictors are highly correlated</h1>
<pre class="r"><code>library(data.table)
set.seed(1)
N&lt;-200
y&lt;-rnorm(N)
set.seed(2)
x1&lt;-as.numeric(scale(y+rnorm(N,0,3)))
set.seed(3)
x2&lt;-as.numeric(scale(x1+rnorm(N,0,1)))
dat&lt;-data.table(y,x1,x2)
cor(dat)</code></pre>
<pre><code>##            y        x1        x2
## y  1.0000000 0.2813946 0.1928833
## x1 0.2813946 1.0000000 0.6928299
## x2 0.1928833 0.6928299 1.0000000</code></pre>
<pre class="r"><code>### Derive models using each predictor
mod1&lt;-lm(y ~ x1, data=dat)
mod2&lt;-lm(y ~ x2, data=dat)

dat$pred1&lt;-predict(mod1, dat)
dat$pred2&lt;-predict(mod2, dat)

dat_cor&lt;-data.frame(model1=&#39;x1&#39;,
                    model2=&#39;x2&#39;,
                    cor_x1_x2=cor(dat$x1,dat$x2),
                    cor_y_x1=coef(summary(mod1))[2,1],
                    cor_y_x1_se=coef(summary(mod1))[2,2],
                    cor_y_x2=coef(summary(mod2))[2,1],
                    cor_y_x2_se=coef(summary(mod2))[2,2],
                    cor_diff=coef(summary(mod1))[2,1]-coef(summary(mod2))[2,1])

### Test difference between predictors using a Z-test
dat_cor$cor_diff_Ztest_P&lt;-pnorm(-(dat_cor$cor_diff/sqrt((dat_cor$cor_y_x1_se^2)+(dat_cor$cor_y_x2_se^2)))) 

### Test difference between predictors using a permutation test
n_perm&lt;-500
diff&lt;-NULL
for(i in 1:n_perm){
  y_sample&lt;-sample(y)
  mod1_i&lt;-lm(y_sample ~ x1, data=dat)
  mod2_i&lt;-lm(y_sample ~ x2, data=dat)
  
  diff_i&lt;-coef(summary(mod1_i))[2,1]-coef(summary(mod2_i))[2,1]
  diff&lt;-c(diff,diff_i)
}

dat_cor$cor_diff_perm_P&lt;-sum(diff &gt; dat_cor$cor_diff[1])/n_perm

### Test difference between predictors using coxtest 
library(lmtest)
dat_cor$cox_diff_P&lt;-coxtest(mod1, mod2)$P[2]

### Test difference between predictors using Pearson 
library(cocor)
dat_cor$pearson_diff_P&lt;-cocor.dep.groups.overlap(dat_cor$cor_y_x1, dat_cor$cor_y_x2, dat_cor$cor_x1_x2, N,alternative=&#39;greater&#39;)@pearson1898$p.value

### Test difference between predictors using Williams&#39;s Test
library(psych)
dat_cor$williams_diff_P&lt;-paired.r(xy=dat_cor$cor_y_x1, xz=dat_cor$cor_y_x2, yz=dat_cor$cor_x1_x2, n=N, twotailed=F)$p

dat_cor</code></pre>
<pre><code>##   model1 model2 cor_x1_x2  cor_y_x1 cor_y_x1_se  cor_y_x2 cor_y_x2_se
## 1     x1     x2 0.6928299 0.2614429  0.06336002 0.1792073  0.06478817
##     cor_diff cor_diff_Ztest_P cor_diff_perm_P   cox_diff_P pearson_diff_P
## 1 0.08223559        0.1820774           0.068 2.185878e-06     0.06303985
##   williams_diff_P
## 1      0.06448287</code></pre>
<p>Again the coxtest method is very different from other methods. The two-sample Z test is now deviating from the other methods because it doesn’t account for the correlation between predictors. The results for the permutation, pearson and williams method are highly concordant.</p>
<p>The psych package is a solid package and the Williams method is recommended by Steiger who worked alot in this area. It is also faster than the permutation based approach. From here on use the Williams test to test for significant differences between correlations between outcomes and correlated predictors.</p>
<hr />
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
