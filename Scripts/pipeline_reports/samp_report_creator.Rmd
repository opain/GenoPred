---
title: "GenoPred Report"
params:
  name: ""
  config: ""
  cwd: ""
output:
  html_document:
    theme: cosmo
    fig_caption: yes
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = F, eval = T, message=F, warning=F)

# Set working directory to that upstream of this .Rmd file, so other files can be found easily.
knitr::opts_knit$set(root.dir = params$cwd)

library(data.table)
library(knitr)
library(ggplot2)
library(cowplot)
library(DT)

knit_hooks$set(optipng = hook_optipng)
knit_hooks$set(pngquant = hook_pngquant)

```

```{css}
/* Hero */
.gp-hero {
  display: flex; justify-content: space-between; align-items: center;
  padding: 18px 22px; margin-top: 25px;
  background: linear-gradient(135deg, rgba(43,108,176,.08), rgba(43,108,176,.02));
  border: 1px solid #e6ecf1; border-radius: 14px;
}
.gp-hero__brand { display: flex; align-items: center; gap: 14px; }
.gp-logo { height: 56px; width: auto; border-radius: 8px; }
.gp-title h1 { margin: 0; font-size: 1.8rem; color: var(--gp-primary); }
.gp-subtitle { margin: 2px 0 0; color: #5f6c7b; font-weight: 500; }

.gp-meta { text-align: right; color: #475a6b; font-size: 0.95rem; }
.gp-meta__label { color: #7b8794; font-weight: 600; margin-right: 6px; }
.gp-divider { margin: 18px 0 6px; border: 0; border-top: 1px solid #e2e8f0; }

/* Side TOC polish */
.tocify { border-radius: 12px; }

#header {
    display: none;
}

body {
  font-family: system-ui, -apple-system, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
}

h1 {
  font-size: 24px;
  font-weight: 600;
}

h2 {
  font-size: 22px;
  font-weight: 500;
}

h3 {
  font-size: 18px;
  font-weight: 500;
}

h4 {
  font-size: 16px;
  font-weight: 500;
}

p {
  font-weight: 400;
}

li {
  font-weight: 400;
}

pre code {
  white-space: pre;
  overflow-x: auto;
  display: block;
}

/* Style the tab buttons */
.nav-tabs > li > a {
  border-radius: 8px 8px 0 0;    /* rounded top corners */
  font-weight: 500;
}


```

```{r, results='asis', eval = T}
cat("
<div class='gp-hero'>
<div class='gp-hero__brand'>
<img src='", normalizePath("../docs/Images/logo/Horizontal.png"), "' alt='GenoPred' class='gp-logo'>
<div class='gp-title'>
<div style='font-size: 2rem; font-weight: 700; margin-top:1rem;'>
Sample Report for '", params$name, "' dataset
</div>
<p class='gp-subtitle'>Polygenic scoring & QC summary</p>
</div>
</div>
</div>
<hr class='gp-divider'>
", sep = '')
```

```{r, include = F}
# Load functions
source('../functions/misc.R')
source_all('../functions')

# Create a temporary directory
tmp_folder <- paste0(tempdir(), "/sub_dir.",params$name)
dir.create(tmp_folder, recursive = T)

# Read in outdir
outdir <- read_param(config = params$config, param = 'outdir', return_obj = F)

# Read in refdir
refdir <- read_param(config = params$config, param = 'refdir', return_obj = F)

# Read in target_list
target_list <- read_param(config = params$config, param = 'target_list')

# Read in gwas_list
gwas_list <- read_param(config = params$config, param = 'gwas_list')

# Read in gwas_list
gwas_groups <- read_param(config = params$config, param = 'gwas_groups')

# Read in score_list
score_list <- read_param(config = params$config, param = 'score_list')

# Identify PGS methods to be included
pgs_methods_list <- read_param(config = params$config, param = 'pgs_methods', return_obj = F)

# If testing, change CHROMS to chr value
testing <- read_param(config = params$config, param = 'testing', return_obj = F)

# Check ancestry probability threshold
ancestry_prob_thresh <- as.numeric(read_param(config = params$config, param = 'ancestry_prob_thresh', return_obj = F))

# Check external score overlap threshold
min_overlap <- read_param(config = params$config, param = 'min_overlap_external', return_obj = F)

if(!is.na(testing) && testing == 'NA'){
  testing<-NA
}
if(!is.na(testing)){
  CHROMS <- as.numeric(gsub('chr','',testing))
  cat0("Testing mode was used, restricting analyses to chromosome ", CHROMS,".\n\n")
  ancestry_prob_thresh <- 0.5
}

# Check whether target sample was specified
targ_incl <- !is.null(target_list)
  
# Check whether polygenic scoring was carried out
pgs_incl <- !all(c(is.null(gwas_list), is.null(score_list)))

```

```{r, results='asis', eval = T}
cat0("# {.tabset .tabset-fade} \n\n")
cat0("## Input processing {.tabset .tabset-fade} \n\n")
cat0("This section documents how input data were processed, including quality control steps and harmonisation against the reference panel.\n\n")
cat0("***\n\n")
```
  
```{r, results='asis', eval = targ_incl}
cat0("### Target data \n\n")

# Read in the .psam file to identify the number of samples
target_psam <- fread(paste0(outdir, '/', params$name, '/geno/', params$name, '.ref.chr', CHROMS[1], '.psam'))

# Read in the .psam file to identify the number of samples
ref_psam <- fread(paste0(refdir, '/ref.chr', CHROMS[1], '.psam'))

# Read in the format_target logs
format_target_logs <- list()
for(chr in CHROMS){
  format_target_logs[[paste0('chr', chr)]]<-readLines(paste0(outdir,'/',params$name,'/geno/',params$name,'.ref.chr',chr,'.format_target.log'))
}

# Count the number of variants in the target sample data that match reference variants
nvar_in_target_orig <-
  sum(sapply(format_target_logs, function(x)
    as.numeric(gsub('.* ','', gsub(' variants.', '', x[grepl('^Target data contains', x)])))))

nvar_in_target <-
  sum(sapply(format_target_logs, function(x)
    as.numeric(gsub('.* ','', gsub(' reference variants.', '', x[grepl('^Target contains', x) & grepl('reference variants.$', x)])))))

nvar_in_ref <-
  sum(sapply(format_target_logs, function(x)
    as.numeric(gsub('.* ','', gsub(' variants', '', x[grepl('^Reference data contains ', x) & !grepl('ambiguous', x)])))))

nvar_ambig_in_ref <-
  sum(sapply(format_target_logs, function(x)
    as.numeric(gsub('.* ','', gsub(' ambiguous variants', '', x[grepl('^Reference data contains ', x) & grepl('ambiguous', x)])))))

# Extract matching information
build <- format_target_logs[[1]][grepl('^GRCh', format_target_logs[[1]])]
build <- data.table(
  build = gsub(' .*','', build),
  match = as.numeric(gsub('% .*', '', gsub('.*: ', '', build)))
)
build <- build$build[build$match == max(build$match)]

target_restricted <- ifelse(any(grepl('Inserting missing reference variants.', format_target_logs[[1]])), F, T)

cat0("
**Uploaded target data:**\n
  - ", nrow(target_psam), " individuals.\n
  - ", target_list$type[target_list$name == params$name], " format.\n
  - Build ", build,".\n
  - ", nvar_in_target_orig, " variants.\n
\n")

cat0("
**Reference data:**\n
  - ", nrow(ref_psam), " individuals.\n
  - ", nvar_in_ref, " variants.\n
  - ", nvar_ambig_in_ref, " ambiguous variants.\n
\n")

cat0("
**After harmonisation:**\n
  - Target data contains ", nvar_in_target, " of ", nvar_in_ref, " reference variants (", round(nvar_in_target/nvar_in_ref*100, 1),"%).",
  if(target_restricted){
    "  - Reference data was restricted to target variants."
  }, "
\n")

cat0("***\n\n")

```

```{r, results='asis', eval = all(pgs_incl, !is.null(gwas_list))}

cat0("### GWAS sumstats {.tabset .tabset-fade} \n\n")

# Create a summary table for GWAS sumstats
sumstat_qc <- NULL
gwas_logs <- list()
for(gwas in gwas_list$name) {
    log <- readLines(paste0(outdir,'/reference/gwas_sumstat/', gwas, '/', gwas, '-cleaned.log'))
    
    orig_n <- as.numeric(gsub(' .*', '', gsub('GWAS contains ','', log[grepl('^GWAS contains ', log) & !grepl('ambiguous', log)])))
    final_n <- as.numeric(gsub(' .*', '', gsub('After removal of SNPs with SE == 0, ','', log[grepl('^After removal of SNPs with SE == 0, ', log)])))
    
    ambig_n <- as.numeric(gsub(' .*', '', gsub('GWAS contains ','', log[grepl('^GWAS contains ', log) & grepl('ambiguous', log)])))

    if(ambig_n == 0){
      strand_warning <- 'No ambiguous variants'
    } else {
      if(any(grepl('WARNING: ambiguous', log))){
        non_ambig_n <- orig_n - ambig_n
        flipped_n <- as.numeric(gsub(' .*', '', log[grepl('non-ambiguous variants were flipped', log)]))
  
        strand_warning <- paste0('Warning: ', flipped_n, ' of ', non_ambig_n, " non-ambiguous variants were strand flipped. Inclusion of ambiguous variants (N=", ambig_n, ") may therefore be unreliable.")
      } else {
        strand_warning <- 'No variants required flipping'
      }
    }

    sumstat_qc <- rbind(sumstat_qc, data.frame(
      name = gwas,
      label = gwas_list$label[gwas_list$name == gwas],
      population = gwas_list$population[gwas_list$name == gwas],
      orig_n = orig_n,
      final_n = final_n,
      strand_warning = strand_warning))
    
    gwas_logs[[gwas]] <- log
}
    
names(sumstat_qc) <- c('Name', 'Label', 'Population', 'N SNP\n(original)', 'N SNP\n(final)','Strand check')

datatable(sumstat_qc, 
          rownames = FALSE,
          options = list(
            dom = 't',
            ordering = FALSE,
            paging = FALSE,
            columnDefs = list(
              list(className = "dt-center", targets = '_all')
            ),
            scrollX = TRUE
          ),
          width = '100%',
          selection = 'none')

cat0("**Log files:** \n\n")

for(i in 1:length(gwas_logs)){
  cat0("#### ",names(gwas_logs)[i], " \n\n")

  cat("```", "\n")
  cat(gwas_logs[[i]][!grepl('#', gwas_logs[[i]])], sep = "\n")
  cat("\n```\n\n")
  
  cat0("***\n\n")

}
cat0("\n\n")

```

```{r, results='asis', eval = all(pgs_incl, !is.null(score_list))}

cat0("### External score files {.tabset .tabset-fade} \n\n")

# Create a summary table for score files
score_qc <- NULL
score_logs <- list()
for(score in score_list$name) {
    log <- readLines(paste0(outdir,'/reference/pgs_score_files/external/', score, '/ref-', score, '.log'))

    orig_n <- as.numeric(gsub(' .*', '', gsub('Score file contains ','', log[grepl('after removing duplicates.', log)])))
    nonzero_n <- as.numeric(gsub(' .*', '', gsub('Score file contains ','', log[grepl('effect size of zero.', log)])))
    final_n <- as.numeric(gsub(' .*', '', gsub('After matching variants to the reference, ','', log[grepl('^After matching variants to the reference, ', log)])))
    ambig_n <- as.numeric(gsub(' .*', '', gsub('Score file contains ','', log[grepl('ambiguous variants.$', log)])))

    if(ambig_n == 0){
      strand_warning <- 'No ambiguous variants'
    } else {
      if(any(grepl('WARNING: ambiguous', log))){
        non_ambig_n <- orig_n - ambig_n
        flipped_n <- as.numeric(gsub(' .*', '', log[grepl('non-ambiguous variants were flipped', log)]))
  
        strand_warning <- paste0(flipped_n, ' of ', non_ambig_n, " non-ambiguous variants were strand flipped")
      } else {
        strand_warning <- 'No variants required flipping'
      }
    }
      
    score_qc <- rbind(score_qc, data.frame(
      name = score,
      label = score_list$label[score_list$name == score],
      orig_n = orig_n,
      nonzero_n = nonzero_n,
      final_n = final_n,
      strand_warning = strand_warning,
      pass = all(!grepl('^Skipping', log))))
    
    score_logs[[score]] <- log
}

names(score_qc) <- c('Name', 'Label', 'NSNP\n(original)', 'NSNP\n(non-zero)', 'NSNP\n(final)', 'Strand check', 'Sufficient overlap')

if(nvar_ambig_in_ref == 0){
  score_qc$`Strand check` <- NULL
}

datatable(score_qc, 
          rownames = FALSE,
          options = list(
            dom = 't',
            ordering = FALSE,
            paging = FALSE,
            columnDefs = list(
              list(className = "dt-center", targets = '_all')
            ),
            scrollX = TRUE
          ),
          width = '100%',
          selection = 'none')

cat0("**Note.** The `Sufficient overlap` column indicates whether a sufficient proportion (", min_overlap*100, "%) of variants within the score file were present in the reference data.\n\n")

cat0("***\n\n")

cat0("**Log files:** \n\n")

for(i in 1:length(score_logs)){
  cat0("#### ",names(score_logs)[i], " \n\n")

  cat("```", "\n")
  cat(score_logs[[i]][!grepl('#', score_logs[[i]])], sep = "\n")
  cat("\n```\n\n")
  
  cat0("***\n\n")

}
cat0("\n\n")

```

```{r, results='asis', eval = targ_incl}

cat0("## Ancestry inference \n\n")

cat0("This section documents the target sample ancestry inference results.\n\n")

cat0("***\n\n")

# Read in ancestry classification log file  
ancestry_log <- readLines(paste0(outdir,'/',params$name,'/ancestry/', params$name,'.Ancestry.log'))

# Create table listing ancestry classifications
ancestry_log <- ancestry_log[(which(grepl('N per group based on model:', ancestry_log)) + 2):which(grepl('Unassigned', ancestry_log))]
target_classifications <- data.frame(
  Population = gsub(' .*','', gsub('^ ','', ancestry_log)),
  N = as.numeric(gsub('.* ','', gsub('^ ','', ancestry_log))))

cat0("- ", sum(target_classifications$N[target_classifications$Population != 'Unassigned']), " out of ", nrow(target_psam), " target individuals in the sample, were assigned to a reference population with a probability >", ancestry_prob_thresh*100, "%.\n")
cat0("- The number of individuals assigned to each population were:\n\n")

```

```{r, eval = targ_incl}

datatable(target_classifications, 
          rownames = FALSE,
          options = list(
            dom = 't', 
            ordering = FALSE,
            paging = FALSE,
            columnDefs = list(
              list(className = "dt-center", targets = "_all")  # Apply the class to all columns
            ),
            scrollX = TRUE
          ),
          selection = 'none',
          width = '35%')
      

```

```{r, results='asis', eval = targ_incl}
if(is.na(refdir)){
  cat0("Note. AFR = African, AMR = American, EAS = East Asian, EUR = European, CSA = Central and South Asian, MID = Middle Eastern.")
}

cat0("</br>\n\n")

cat0("**Target Principal Component Scores Compared to Reference Populations.**\n\n")
cat0(paste0("![](", normalizePath(outdir, mustWork = FALSE), '/', params$name, '/ancestry/', params$name, ".Ancestry.pc_plot.png)"))
cat0("**Note.** Black circles indicate target sample individuals.\n\n")

cat0("*** \n\n")

```

```{r, results='asis', eval = pgs_incl}

cat0("## Polygenic Scores {.tabset .tabset-fade} \n\n")

cat0("This section summarises the polygenic scores (PGS), showing the correlation between PGS, the number of PGS variants present in the target sample, and the distribution of PGS in the target sample. \n\n")

cat0("***\n\n")

```

```{r, results='asis', eval = pgs_incl}

cat0("### PGS correlation \n\n")
cat0("This section shows the correlation between PGS in the reference sample. This is intended as a sanity check that the PGS correlations are in the expected direction, thereby confirming the GWAS alleles are being interpreted correctly.\n\n")
cat0("***\n\n")

```

```{r, eval = pgs_incl, include = F}
# Identify pgs_scaling parameter
pgs_scaling <- read_param(config = params$config, param = 'pgs_scaling', return_obj = F)

if('continuous' %in% pgs_scaling){
  ref_pop <- 'TRANS'
} else {
  # Read in keep_list to determine populations available
  keep_list_i <- fread(paste0(outdir,'/',params$name,'/ancestry/keep_list.txt'))
  
  # Check whether output for a specific populations was requested in the config
  target_populations <- read_param(config = params$config, param = 'target_populations', return_obj = F)
  keep_list_i <- keep_list_i[keep_list_i$POP %in% target_populations,]
  
  ref_pop <- keep_list_i$POP[1]
}

# Read in the reference pgs
ref_pgs <- read_reference_pgs(config = params$config, population = ref_pop)

# Merge all PGS into single data.frame
for(gwas_i in names(ref_pgs)){
  for(method_i in names(ref_pgs[[gwas_i]])){
    names(ref_pgs[[gwas_i]][[method_i]])[3] <- paste(gwas_i,method_i, sep=':')
  }
}

ref_pgs <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2, by = c('FID','IID'), all.x = TRUE), unlist(ref_pgs, recursive=F))
ref_pgs$FID<-NULL
ref_pgs$IID<-NULL

# Calculate correlations
cormat<-cor(ref_pgs)
                
# Melt for plotting
melted_cormat <- reshape2::melt(cormat, na.rm = TRUE)

plot_obj<-ggplot(melted_cormat, aes(x = Var1, y = Var2, fill = value)) +
    geom_tile() +
    scale_fill_gradient2(low = "blue", mid = "white", high = "red",
                          midpoint = 0, limits = c(-1, 1),
                          name = "Pearson\nCorrelation\n") +
    geom_text(aes(label = round(value, 2)), color = "black", size = 4) +
    theme_minimal() +
    labs(x = "", y = "") +
    theme(text = element_text(size = 16), axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
    coord_fixed()

plot_file<-paste0(tempfile(),'.png')
plot_height <- 150+(70*ncol(ref_pgs))
plot_width <- 450+(70*ncol(ref_pgs))

if(plot_height < 400) {plot_height <- 400}
if(plot_width < 700) {plot_width <- 700}

png(plot_file, units = 'px', res = 100, width = plot_width, height = plot_height)
plot_obj
dev.off()

```

```{r, results='asis', eval = pgs_incl}

cat0(paste0("![](", plot_file,")\n\n"))
cat0("**Note.** Plot shows correlation between pseudovalidated PGS in ", ref_pop," population.\n\n")
cat0("***\n\n")

```

```{r, results='asis', eval = pgs_incl}

cat0("### PGS coverage \n\n")
cat0("This section summarises the polygenic score files, including both GWAS-derived and external scores. It reports the number of SNPs per score, the proportion present in the target sample, and the relative RÂ² accounting for missing variants. These metrics provide a check on score completeness, transferability, and the expected predictive utility in the target data.\n\n")
cat0("***\n\n")

```

```{r, eval = pgs_incl, include = F}
# List score files
score_files<-list_score_files(params$config)

# Identify pgs_scaling parameter
pgs_scaling <- read_param(config = params$config, param = 'pgs_scaling', return_obj = F)

# List populations
targ_pops <- NULL
if('continuous' %in% pgs_scaling){
  targ_pops <- c(targ_pops, 'TRANS')
}
if('discrete' %in% pgs_scaling){
  # Read in keep_list to determine populations available
  keep_list_i <- fread(paste0(outdir,'/',params$name,'/ancestry/keep_list.txt'))
  
  # Check whether output for a specific populations was requested in the config
  target_populations <- read_param(config = params$config, param = 'target_populations', return_obj = F)
  keep_list_i <- keep_list_i[keep_list_i$POP %in% target_populations,]
  
  targ_pops <- c(targ_pops, keep_list_i$POP)
}

missingness <- NULL
for (i in 1:nrow(score_files)) {
  missingness_j <- NULL
  for (j in targ_pops) {
    tmp <- data.table(population = j,
                                    fread(
                                      paste0(
                                        outdir,
                                        '/',
                                        params$name,
                                        '/pgs/',
                                        j,
                                        '/',
                                        score_files$method[i],
                                        '/',
                                        score_files$name[i],
                                        '/',
                                        params$name,
                                        '-',
                                        score_files$name[i],
                                        '-',
                                        j,
                                        '.missingness'
                                      )
                                    ))
    
    missingness_j <- rbind(missingness_j, tmp)
  }
  
  # Adjust the missingness for external score files to allow for variants not in the reference
  if(score_files$method[i] == 'external'){
    log <- readLines(
      paste0(
        outdir,
        '/reference/pgs_score_files/external/',
        score_files$name[i],
        '/ref-',
        score_files$name[i],
        '.log'
      )
    )
    log <- log[grepl('with effect size of zero.', log)]
    original <- as.numeric(gsub(' .*', '', gsub('Score file contains ', '', log)))
    original_missing <- original - missingness_j$n_nz
    missingness_j$mean_nz_miss <- ((missingness_j$n_nz * missingness_j$mean_nz_miss) + (original_missing * 1)) / (missingness_j$n_nz + original_missing)
    missingness_j$n_nz <- original
  }
  missingness <- rbind(missingness, missingness_j)
}

# Flip mean missingness to mean overlap
missingness$mean_nz_overlap <- 1 - missingness$mean_nz_miss

# Calculate overlap between score file and LD reference
missingness$eig_overlap <- missingness$n_in_eig / missingness$n_nz
missingness$eig_overlap <- paste0(round(missingness$eig_overlap * 100, 1),'%')

missingness <- missingness[, c('name','method','population','n_nz','mean_nz_overlap','rel_r2','eig_overlap'), with=F]
missingness$mean_nz_overlap <- paste0(round(missingness$mean_nz_overlap * 100, 1),'%')
missingness$rel_r2 <- paste0(round(missingness$rel_r2*100, 1),'%')

missingness <- dcast(
  missingness,
  name + method + n_nz + mean_nz_overlap ~ population,
  value.var = c("rel_r2", "eig_overlap")
)

missingness$rel_r2_TRANS <- NULL
missingness$eig_overlap_TRANS <- NULL

names(missingness)[1:4] <- c('ID', 'Method', "N SNP (original)", 'Overlap with target')
names(missingness)[grepl('rel_r2_', names(missingness))] <- paste0(gsub('rel_r2_', "Relative R2 in target (", names(missingness)[grepl('rel_r2_', names(missingness))]), ")")
names(missingness)[grepl('eig_overlap_', names(missingness))] <- paste0(gsub('eig_overlap_', "Overlap with ", names(missingness)[grepl('eig_overlap_', names(missingness))]), " LD reference")

```

```{r, eval = pgs_incl}

datatable(missingness, 
          rownames = FALSE,
          options = list(
            ordering = TRUE,
            columnDefs = list(
              list(className = "dt-center", targets = "_all")  # Apply the class to all columns
            ),
            scrollX = TRUE
          ),
          selection = 'none')

```

```{r, results='asis', eval = pgs_incl}

cat0("**Note.** Table only considers variants with non-zero effect size in the pseudovalidated PGS for each method-gwas/score pair. N SNP (original) = Number of variants in score file; Missingness in target = Mean missingness of variants in target sample; Relative R2 = Estimated relative R2 of PGS in target sample given missing variants; N SNP (in LD reference)= Number of variants present in LD reference data used to estimate relative R2.\n\n")

cat0("***\n\n")

```

```{r, include = F, eval = all(pgs_incl, targ_incl)}

# Read in prs
pgs <- read_pgs(config = params$config, name = params$name, pseudo_only=T)[[1]]

# Structure PGS for plotting
pgs_melt <- NULL
for(gwas in names(pgs[[1]])){
  for(pgs_method in names(pgs[[1]][[gwas]])){
    for(pop in names(pgs)){
      tmp <- pgs[[pop]][[gwas]][[pgs_method]]
      names(tmp)<-c('FID','IID','score')
      tmp$pop = pop
      tmp$gwas = gwas
      tmp$pgs_method = pgs_method
      pgs_melt <- rbind(pgs_melt, tmp)
    }
  }
}
pgs<-pgs_melt
rm(pgs_melt)

ancestry_log <- read_ancestry(config = params$config,  name = params$name)
for(i in names(ancestry_log$keep_files)){
  pgs$assigned_pop[paste0(pgs$FID, '.', pgs$IID) %in% paste0(ancestry_log$keep_files[[i]]$V1, '.',  ancestry_log$keep_files[[i]]$V2)] <- i
}
pgs$assigned_pop[is.na(pgs$assigned_pop)]<-'Unassigned'

# Plot the distribution of polygenic scores
plot_width <- 250 + length(unique(pgs$pop)) * 255
if(plot_width < 1000) plot_width <- 1000

pgs_dist_plots <- list()
for(pgs_method_i in unique(pgs$pgs_method)){
  pgs_i <- pgs[pgs$pgs_method %in% pgs_method_i,]
  pgs_dist_plots[[pgs_method_i]] <- 
    ggplot(pgs_i, aes(x=score, fill=assigned_pop)) + 
      geom_density(alpha=0.5) +
      labs(x='Polygenic Z-Score', y='Density', fill = 'Population') +
      theme_half_open() +
      background_grid() +
      panel_border() +
      facet_grid(gwas ~ pop) +
      theme(
        legend.position = "bottom",        # Move legend below the plot
        legend.title = element_text(size = 12),  # Adjust legend title size (optional)
        legend.text = element_text(size = 10)    # Adjust legend text size (optional)
      ) +
      guides(fill = guide_legend(nrow = 1)) 

  png(paste0(tmp_folder,'/plot_', pgs_method_i,'.png'), height = 150 + (300*length(unique(pgs_i$gwas))), width = plot_width, res = 170)
    print(pgs_dist_plots[[pgs_method_i]])
  dev.off()
}

```

```{r, results='asis', eval = pgs_incl}

cat0("### PGS Distribution {.tabset .tabset-fade} \n\n")
cat0("This section shows the distribution of PGS in the target sample. PGS are shown scaled according to each ancestry-match reference population. TRANS includes PGS across all populations after continuous adjustment for ancestry.\n\n")

for(pgs_method_i in unique(pgs$pgs_method)){
  # Create a new tab for each method
  cat0("#### ", pgs_method_i, "\n")
  
  # Show the plot
  cat0(paste0("![Density plot of PGS from ", pgs_method_i,"](", tmp_folder,'/plot_',pgs_method_i,".png)"))
  
  cat0("**Note.** Plot shows distribution of pseudovalidated PGS.\n\n")
  cat0("***\n\n")
  }

```

```{r, results='asis', eval = T}

cat0("## Configuration {.tabset .tabset-fade} \n\n")

cat0("### target_list \n\n")

target_list[is.na(target_list)]<-'NA'

datatable(target_list, 
          rownames = FALSE,
          options = list(
            dom = 't', 
            ordering = FALSE,
            paging = FALSE,
            columnDefs = list(
              list(className = "dt-center", targets = "_all")  # Apply the class to all columns
            ),
            scrollX = TRUE
          ),
          selection = 'none')

if(!is.null(gwas_list)){
  cat0("### gwas_list \n\n")
  
  gwas_list[is.na(gwas_list)]<-'NA'
  
  datatable(gwas_list, 
            rownames = FALSE,
            options = list(
              dom = 't', 
              ordering = FALSE,
              paging = FALSE,
              columnDefs = list(
                list(className = "dt-center", targets = "_all")  # Apply the class to all columns
              ),
              scrollX = TRUE
            ),
            selection = 'none')
}

if(!is.null(score_list)){
  cat0("### score_list \n\n")
  
  score_list[is.na(score_list)]<-'NA'
  
  datatable(score_list, 
            rownames = FALSE,
            options = list(
              dom = 't', 
              ordering = FALSE,
              paging = FALSE,
              columnDefs = list(
                list(className = "dt-center", targets = "_all")  # Apply the class to all columns
              ),
              scrollX = TRUE
            ),
            selection = 'none')
}

if(!is.null(gwas_groups)){
  cat0("### gwas_groups \n\n")
  
  gwas_groups[is.na(gwas_groups)]<-'NA'
  
  datatable(gwas_groups, 
            rownames = FALSE,
            options = list(
              dom = 't', 
              ordering = FALSE,
              paging = FALSE,
              columnDefs = list(
                list(className = "dt-center", targets = "_all")  # Apply the class to all columns
              ),
              scrollX = TRUE
            ),
            selection = 'none')
}

cat0("### configfile \n\n")

# Make table showing config parameters
default_config <- readLines('config.yaml')
default_config<-default_config[!grepl('#', default_config)]
default_config<-default_config[default_config != '']
default_config<-data.frame(do.call(rbind, strsplit(default_config, ': ')))
names(default_config)<-c('Parameter', 'Value')

if(!is.na(read_param(config = params$config, param = 'config_file', return_obj = F))){
  user_config <- readLines(params$config)
  user_config<-user_config[!grepl('#', user_config)]
  user_config<-user_config[user_config != '']
  user_config<-data.frame(do.call(rbind, strsplit(user_config, ': ')))
  names(user_config)<-c('Parameter', 'Value')
  config_both <- rbind(user_config, default_config)
  config_both <- config_both[!duplicated(config_both$Parameter),]
} else {
  config_both <- default_config
}

datatable(config_both, 
          rownames = FALSE,
          options = list(
            dom = 't', 
            ordering = FALSE,
            paging = FALSE,
            columnDefs = list(
              list(className = "dt-center", targets = "_all")  # Apply the class to all columns
            ),
            scrollX = TRUE
          ),
          selection = 'none')

cat0("### Version \n\n")

repo_path <- system("git rev-parse --show-toplevel", intern = TRUE)
repo_name <- basename(repo_path)
git_tag <- system("git describe --tags", intern = TRUE)

cat0("
This report was created using ", repo_name, " (", git_tag, ").
")

```
