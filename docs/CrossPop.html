<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Leveraging Global Genetics Resources to Enhance Polygenic Prediction Across Ancestrally Diverse Populations</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />
<link rel="shortcut icon" href="Images/logo/favicon.ico">

<link rel="stylesheet" href="styles/night-mode.css" id="nightModeStylesheet">

<script>
function toggleNightMode() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (stylesheet.disabled) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
}
</script>

<label class="switch">
  <input type="checkbox" id="toggleNightMode" checked>
  <span class="slider round"></span>
</label>

<script>
document.getElementById('toggleNightMode').addEventListener('change', function() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (this.checked) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
});
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YR18ZB3PR3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YR18ZB3PR3');
</script>

<!-- Osano Cookie Consent -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.css" />
<script src="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
  window.cookieconsent.initialise({
    palette: {
      popup: { background: "#000" },
      button: { background: "#f1d600" }
    },
    theme: "classic",
    position: "bottom-right",
    content: {
      message: "We use a cookie for Google Analytics to understand how people use this site. This helps us improve GenoPred and demonstrate its impact. Please click 'Accept' to help us with this.",
      dismiss: "Accept",
      link: "Google's privacy info",
      href: "https://policies.google.com/technologies/partner-sites"
    },
    onStatusChange: function(status) {
      if (status === 'allow') {
        // Now load Google Analytics only if user consents
        var gtagScript = document.createElement('script');
        gtagScript.setAttribute('async', '');
        gtagScript.src = 'https://www.googletagmanager.com/gtag/js?id=G-YR18ZB3PR3';
        document.head.appendChild(gtagScript);

        window.dataLayer = window.dataLayer || [];
        function gtag(){ dataLayer.push(arguments); }
        gtag('js', new Date());
        gtag('config', 'G-YR18ZB3PR3');
      }
    }
  });
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img class="logo-img" src="Images/logo/Horizontal_white.png" style="height: 42px;" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pipeline
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="pipeline_overview.html">Overview</a>
    </li>
    <li>
      <a href="pipeline_readme.html">Instructions</a>
    </li>
    <li>
      <a href="pipeline_technical.html">Technical documentation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="research_index.html">Overview</a>
    </li>
    <li>
      <a href="comparison_of_methods_summary.html">Polygenic Scoring Methods Comparison</a>
    </li>
    <li>
      <a href="Functionally_informed_prediction.html">Quantifying Polygenic Signal Mediated by Altered Gene Expression</a>
    </li>
    <li>
      <a href="Absolute_Conversion.html">Translating Polygenic Scores onto the Absolute Scale</a>
    </li>
    <li>
      <a href="CrossPop_summary.html">Cross-Ancestry Polygenic Prediction</a>
    </li>
  </ul>
</li>
<li>
  <a href="more_index.html">More</a>
</li>
<li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Leveraging Global Genetics Resources to
Enhance Polygenic Prediction Across Ancestrally Diverse Populations</h1>

</div>


<style>
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}

ul li p, ol li p {
  margin: 0 !important;
}
</style>
<hr />
<div id="preprint" class="section level1">
<h1>Preprint</h1>
<p>This document provides code and key figures and tables for the
following preprint:</p>
<div
style="border-left: 4px solid #4A90E2; padding-left: 10px; margin: 10px 0;">
<p><strong>Citation:</strong><br />
Pain, O. (2025). <em>Leveraging Global Genetics Resources to Enhance
Polygenic Prediction Across Ancestrally Diverse Populations</em>.
<strong>medRxiv.</strong> <a
href="https://doi.org/10.1101/2025.03.27.25324773">https://doi.org/10.1101/2025.03.27.25324773</a></p>
</div>
<hr />
<p><strong>Document overview</strong>:</p>
<ul>
<li><p><a href="#data-preparation">Data preparation</a></p>
<ul>
<li><a href="#ukb">UKB</a>
<ul>
<li><a href="#ancestry-inference">Ancestry inference</a><br />
</li>
<li><a href="#phenotype-extraction">Phenotype extraction</a><br />
</li>
</ul></li>
<li><a href="#gwas-sumstats">GWAS sumstats</a>
<ul>
<li><a href="#uk-biobank-gwas">UK Biobank GWAS</a><br />
</li>
<li><a href="#download-bbj-sumstats">Download BBJ sumstats</a><br />
</li>
<li><a href="#download-ugr-sumstats">Download UGR sumstats</a><br />
</li>
</ul></li>
<li><a href="#heritability-and-polygenicity-estimation">Heritability and
polygenicity estimation</a></li>
</ul></li>
<li><p><a href="#main-analysis">Main analysis</a></p>
<ul>
<li><a href="#pgs-calculation">PGS calculation</a><br />
</li>
<li><a href="#pgs-evaluation">PGS evaluation</a><br />
</li>
<li><a href="#leopardquickprs">LEOPARD+QuickPRS</a><br />
</li>
<li><a href="#computational-resources">Computational resources</a></li>
</ul></li>
<li><p><a href="#tl-prs-analysis">TL-PRS analysis</a></p></li>
<li><p><a href="#sensitivity-analyses">Sensitivity analyses</a></p>
<ul>
<li><a href="#using-1kg-reference">Using 1KG reference</a><br />
</li>
<li><a href="#using-three-gwas">Using three GWAS</a><br />
</li>
<li><a href="#using-external-gwas-sumstats">Using external GWAS
sumstats</a><br />
</li>
<li><a href="#using-downsampled-gwas">Using downsampled GWAS</a></li>
</ul></li>
</ul>
<hr />
</div>
<div id="data-preparation" class="section level1">
<h1>Data Preparation</h1>
<hr />
<div id="ukb" class="section level2">
<h2>UKB</h2>
<p>This section will describe the preparation of the UKB data for this
study. We will need to separate UKB participants into ancestral groups
(AFR, EAS, and EUR). Then we will need to prepare phenotype data for
traits that overlap with the BBJ and UGR samples. Then we will need to
split EUR UKB participants into training and testing subsets. We will
then perform GWAS in the training subset, and evaluate PGS in the
testing subset.</p>
<hr />
<div id="ancestry-inference" class="section level3">
<h3>Ancestry inference</h3>
<p>We will perform this using the GenoPred pipeline. We will need to
prepare the configuration files before running the pipeline.</p>
<details>
<summary>
Show code
</summary>
<p><br/></p>
<h4>
Create symlinks
</h4>
<p>We will create symlinks to the imputed genotype data for UKB. We will
use the pgen format data for computationl efficiency and those
restricted to MAF &gt;= 1% and INFO &gt;= 0.4. We are using genetic data
that is not application specific, so the data doesn’t need to be
reprocessed for each application. Therefore we will use row number IDs
for the .psam file so they can be connected to application specific data
downstream.</p>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks

# pgen and pvar files
for chr in $(seq 1 22);do
  for file in $(echo pgen pvar);do
    ln -s /datasets/ukbiobank/June2017/Imputed/ukb_imp_chr${chr}_v3_MAF1_INFO4.${file} /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.${file}
  done
done</code></pre>
<pre class="r"><code># Make .psam 
n = 487409
psam &lt;- data.frame(FID = 1:487409,
                   IID = 1:487409)
names(psam)[1]&lt;-&#39;#FID&#39;
write.table(psam, &#39;/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam&#39;, col.names=T, row.names = F, quote = F)</code></pre>
<pre class="bash"><code>for chr in $(seq 1 22);do
  ln -s /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.psam
done</code></pre>
<hr />
<h4>
Create list of unrelated individuals
</h4>
<pre class="r"><code>library(ukbkings)
library(data.table)

psam&lt;-fread(&#39;/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam&#39;)
psam$rn&lt;-1:nrow(psam)

project_dir &lt;- &quot;/datasets/ukbiobank/ukb82087&quot;
greedy_related &lt;- &quot;/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated&quot;

# Create a list of unrelated individuals irrespective of a phenotype
psam_unrel_all &lt;- psam[!(
  psam$IID %in% bio_gen_related_remove(
    project_dir = project_dir,
    greedy_related = greedy_related,
    thresh = 0.044,
    seed = 1
  )$eid
), ]

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes&#39;)

write.table(psam_unrel_all$IID, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.txt&#39;, row.names=F, col.names=F, quote=F)
write.table(psam_unrel_all$rn, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;, row.names=F, col.names=F, quote=F)</code></pre>
<hr />
<h4>
Create target_list
</h4>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic</code></pre>
<pre class="r"><code>target_list &lt;- data.frame(
  name=&#39;ukb&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4&#39;,
  type=&#39;plink2&#39;,
  indiv_report=F,
  unrel=&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;
)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&#39;, col.names=T, row.names=F, quote=F)</code></pre>
<hr />
<h4>
Create configfile
</h4>
<pre class="r"><code># Create config file
conf &lt;- c(
  &#39;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&#39;,
  &#39;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml&#39;,
  &#39;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&#39;
)

write.table(conf, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
git describe --tags
#v2.2.2-213-g2f05853

snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml \
  outlier_detection -n</code></pre>
</details>
<hr />
</div>
<div id="phenotype-extraction" class="section level3">
<h3>Phenotype extraction</h3>
<p>We will use the same 33 quantitative traits that were used in the
PRS-CSx paper (Supp Table 10 of PRS-CSx paper). We will use ukbkings to
extract the phenotypes, then remove related individuals, split EUR into
training and testing subsets, and adjust EUR training phenotypes for
covariates.</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx</code></pre>
<pre class="r"><code>library(ukbkings)
library(dplyr)
library(stringr)
library(data.table)

# create data.frame showing variables used by prscsx
prscsx_fields&lt;-c(&#39;30620&#39;,&#39;30600&#39;,&#39;30610&#39;,&#39;30650&#39;,&#39;30160&#39;,&#39;21001&#39;,&#39;21002&#39;,&#39;30710&#39;,&#39;30680&#39;,&#39;4079&#39;,&#39;30150&#39;,&#39;30740&#39;,&#39;30750&#39;,&#39;30760&#39;,&#39;50&#39;,&#39;30030&#39;,&#39;30020&#39;,&#39;30780&#39;,&#39;30120&#39;,&#39;30050&#39;,&#39;30060&#39;,&#39;30040&#39;,&#39;30130&#39;,&#39;30140&#39;,&#39;30080&#39;,&#39;30010&#39;,&#39;30700&#39;,&#39;4080&#39;,&#39;30690&#39;,&#39;30860&#39;,&#39;30870&#39;,&#39;30000&#39;,&#39;30730&#39;)
prscsx_trait&lt;-c(&#39;Alanine aminotransferase&#39;,&#39;Albumin&#39;,&#39;Alkaline phosphatase&#39;,&#39;Aspartate transaminase&#39;,&#39;Basophil&#39;,&#39;Body mass index&#39;,&#39;Body weight&#39;,&#39;C-reactive protein&#39;,&#39;Calcium&#39;,&#39;Diastolic blood pressure&#39;,&#39;Eosinophil&#39;,&#39;Glucose&#39;,&#39;HbA1c&#39;,&#39;HDL-cholesterol&#39;,&#39;Height&#39;,&#39;Hematocrit&#39;,&#39;Hemoglobin&#39;,&#39;LDL-cholesterol&#39;,&#39;Lymphocyte&#39;,&#39;Mean corpuscular hemoglobin&#39;,&#39;Mean corpuscular hemoglobin concentration&#39;,&#39;Mean corpuscular volume&#39;,&#39;Monocyte&#39;,&#39;Neutrophil&#39;,&#39;Platelet&#39;,&#39;Red blood cell&#39;,&#39;Serum creatinine&#39;,&#39;Sytolic blood pressure&#39;,&#39;Total cholesterol&#39;,&#39;Total protein&#39;,&#39;Triglycerides&#39;,&#39;White blood cell&#39;,&#39;γ-glutamyl transpeptidase&#39;)
prscsx_labels&lt;-c(&#39;ALT&#39;,&#39;ALB&#39;,&#39;ALP&#39;,&#39;AST&#39;,&#39;BAS&#39;,&#39;BMI&#39;,&#39;BWT&#39;,&#39;CRP&#39;,&#39;Ca&#39;,&#39;DBP&#39;,&#39;EOS&#39;,&#39;GLC&#39;,&#39;HbA1c&#39;,&#39;HDL&#39;,&#39;HT&#39;,&#39;HCT&#39;,&#39;HB&#39;,&#39;LDL&#39;,&#39;LYM&#39;,&#39;MCH&#39;,&#39;MCHC&#39;,&#39;MCV&#39;,&#39;MON&#39;,&#39;NEU&#39;,&#39;PLT&#39;,&#39;RBC&#39;,&#39;CR&#39;,&#39;SBP&#39;,&#39;TC&#39;,&#39;TP&#39;,&#39;TG&#39;,&#39;WBC&#39;,&#39;GGT&#39;)

prscsx_dat&lt;-data.frame(
  trait=prscsx_trait,
  labels=prscsx_labels,
  field=prscsx_fields
)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx&#39;)
write.csv(prscsx_dat, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;, row.names = F)
write.table(prscsx_labels, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt&#39;, col.names=F, row.names = F, quote=F)

# Extract outcomes from UKB (project ukb82087)
project_dir &lt;- &quot;/datasets/ukbiobank/ukb82087&quot;

system(&#39;rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&#39;)
f &lt;- bio_field(project_dir)
f %&gt;%
    select(field, name) %&gt;%
    filter(str_detect(field, paste(paste0(&quot;^&quot;, prscsx_dat$field, &#39;-&#39;), collapse=&#39;|&#39;))) %&gt;%
    bio_field_add(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&quot;)

bio_phen(
    project_dir,
    field = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&quot;,
    out = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset&quot;
)

system(&quot;ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds&quot;)
df &lt;- readRDS(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds&quot;)

# Take the first observation of each outcome
library(tidyr)
df_long &lt;- df %&gt;%
  pivot_longer(cols = names(df)[!grepl(&#39;eid&#39;, names(df))], names_to = &quot;variable&quot;, values_to = &quot;outcome&quot;) %&gt;%
  drop_na(outcome)
df_long$variable&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, df_long$variable)
df_long&lt;-df_long[!duplicated(df_long[,c(&#39;eid&#39;,&#39;variable&#39;)]),]

library(data.table)

for(i in 1:nrow(prscsx_dat)){
  tmp &lt;- df_long[df_long$variable == prscsx_dat$field[i],]
  tmp &lt;- data.frame(
    eid = tmp$eid,
    outcome = tmp$outcome
  )
  
  fwrite(
    tmp,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}

# Read in ancestry inference results to determine sample size per population
# Use ancestry information from GenoPred
keep_files&lt;-list.files(path = &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/&#39;, pattern = &#39;.keep&#39;)

pop_dat&lt;-NULL
for(i in keep_files){
  tmp&lt;-fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/&#39;, i))
  names(tmp)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)
  tmp$POP&lt;-gsub(&#39;.keep&#39;,&#39;&#39;, gsub(&#39;ukb.outlier_detection.&#39;,&#39;&#39;,i))
  pop_dat&lt;-rbind(pop_dat, tmp)
}

# Update row number IDs to project specific IDs
psam&lt;-fread(&#39;/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam&#39;)
psam$rn&lt;-1:nrow(psam)
psam&lt;-psam[,c(&#39;IID&#39;,&#39;rn&#39;), with = F]

pop_dat$FID&lt;-NULL
pop_dat&lt;-merge(pop_dat, psam, by.x=&#39;IID&#39;, by.y=&#39;rn&#39;)
pop_dat&lt;-data.frame(
  eid=pop_dat$IID.y,
  POP=pop_dat$POP
)

# Merge ancestry info with phenotype data
df_short &lt;- dcast(df_long, eid ~ variable, value.var = &quot;outcome&quot;)
df_short&lt;-merge(df_short, pop_dat, by=&#39;eid&#39;)

# Remove related individuals
greedy_related &lt;- &quot;/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated&quot;
rel&lt;-bio_gen_related_remove(
      project_dir = project_dir,
      greedy_related = greedy_related,
      keep = df_short$eid,
      thresh = 0.044,
      seed = 1
    )$eid

df_short_unrel&lt;-df_short[!(df_short$eid %in% rel),]

n_table&lt;-NULL
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(pop_dat$POP[!is.na(pop_dat$POP)])){
    tmp&lt;-data.frame(
      trait=prscsx_dat$trait[i],
      labels=prscsx_dat$label[i],
      field=prscsx_dat$field[i],
      population=j,
      n=sum(!is.na(df_short[[prscsx_dat$field[i]]][df_short$POP == j])),
      n_unrel=sum(!is.na(df_short_unrel[[prscsx_dat$field[i]]][df_short_unrel$POP == j]))
    )
    n_table&lt;-rbind(n_table, tmp)
  }
}

write.csv(n_table, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table&#39;)

# Define training subset for EUR
df_short_unrel_eur&lt;-df_short_unrel[df_short_unrel$POP == &#39;EUR&#39;,]
set.seed(1)
train_size &lt;- floor(0.8 * nrow(df_short_unrel_eur))
train_indices &lt;- sample(seq_len(nrow(df_short_unrel_eur)), size = train_size)

df_short_unrel_eur_train&lt;-df_short_unrel_eur[train_indices,]
df_short_unrel_eur_test&lt;-df_short_unrel_eur[-train_indices,]

n_table_eur&lt;-NULL
for(i in 1:nrow(prscsx_dat)){
  tmp&lt;-data.frame(
    trait=prscsx_dat$trait[i],
    labels=prscsx_dat$label[i],
    field=prscsx_dat$field[i],
    n_train=sum(!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]])),
    n_test=sum(!is.na(df_short_unrel_eur_test[[prscsx_dat$field[i]]]))
  )
  n_table_eur&lt;-rbind(n_table_eur, tmp)
}

write.csv(n_table_eur, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table_eur&#39;)

df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_train$eid]&lt;-&#39;EUR_train&#39;
df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_test$eid]&lt;-&#39;EUR_test&#39;

# Output phenotype data for each population
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(df_short_unrel$POP)){
    tmp&lt;-df_short_unrel[df_short_unrel$POP == j,]
    tmp &lt;- data.frame(
      FID = tmp$eid,
      IID = tmp$eid,
      outcome = tmp[[prscsx_dat$field[i]]]
    )
    
    fwrite(
      tmp,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
        prscsx_dat$label[i],
        &#39;.unrel.&#39;, j, &#39;.txt&#39;
      ),
      row.names = F,
      quote = F,
      na = &#39;NA&#39;,
      sep = &#39;\t&#39;
    )
    
    # Write out with row number based IDs
    pheno&lt;-merge(tmp, psam, by=&#39;IID&#39;)
    pheno&lt;-data.frame(
      FID=pheno$rn,
      IID=pheno$rn,
      outcome=pheno$outcome
    )
  
    fwrite(
      pheno,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
        prscsx_dat$label[i],
        &#39;.unrel.&#39;, j, &#39;.row_number.txt&#39;
      ),
      row.names = F,
      quote = F,
      na = &#39;NA&#39;,
      sep = &#39;\t&#39;
    )
  }
}

# For the EUR training GWAS, normalise and regress covariates
# Use age, sex and PCs as covariates
# Read in PC data released by UKB
qc_dat&lt;-bio_gen_sqc(project_dir)
qc_dat&lt;-qc_dat[,c(&#39;eid&#39;,paste0(&#39;pc&#39;,1:20))]
df_short_unrel&lt;-merge(df_short_unrel, qc_dat, by=&#39;eid&#39;)

# Read in sex and age information
system(&#39;rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&#39;)
f &lt;- bio_field(project_dir)
f %&gt;%
    select(field, name) %&gt;%
    filter(str_detect(field, &quot;^21022-0.0|^31-0.0&quot;)) %&gt;%
    bio_field_add(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&quot;)

bio_phen(
    project_dir,
    field = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&quot;,
    out = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset&quot;
)

system(&quot;ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds&quot;)
df &lt;- readRDS(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds&quot;)
names(df)&lt;-gsub(&#39;-.*&#39;,&#39;&#39;,names(df))
names(df)[names(df) == &#39;31&#39;]&lt;-&#39;sex&#39;
names(df)[names(df) == &#39;21022&#39;]&lt;-&#39;age&#39;
df_short_unrel&lt;-merge(df_short_unrel, df, by=&#39;eid&#39;)

# Within each population, normalise each outcome and regress out covariates
library(RNOmni)
covs&lt;-c(paste0(&#39;pc&#39;,1:20), &#39;sex&#39;, &#39;age&#39;)
df_short_unrel_eur_train&lt;-df_short_unrel[df_short_unrel$POP == &#39;EUR_train&#39;,]
for(i in 1:nrow(prscsx_dat)){
  tmp&lt;-df_short_unrel_eur_train[!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]]),]
  tmp$pheno_norm&lt;-RNOmni::RankNorm(tmp[[prscsx_dat$field[i]]])
  mod&lt;-lm(as.formula(paste0(&#39;pheno_norm ~ &#39;, paste(covs, collapse=&#39; + &#39;))), data=tmp)
  tmp$pheno_norm_resid_scale&lt;-as.numeric(scale(resid(mod)))
  tmp&lt;-data.frame(
    FID=tmp$eid,
    IID=tmp$eid,
    outcome=tmp$pheno_norm_resid_scale
  )
  
  fwrite(
    tmp,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}

# Convert to row number based IDs so it will work with UKB geno data from GenoPred
for(i in 1:nrow(prscsx_dat)){
  pheno&lt;-fread(paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.txt&#39;
    ))
  
  pheno&lt;-merge(pheno, psam, by=&#39;IID&#39;)
  pheno&lt;-data.frame(
    FID=pheno$rn,
    IID=pheno$rn,
    outcome=pheno$outcome
  )
  
  fwrite(
    pheno,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.row_number.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}</code></pre>
</details>
<hr />
</div>
</div>
<div id="gwas-sumstats" class="section level2">
<h2>GWAS sumstats</h2>
<p>We will generate EUR GWAS using the EUR training subset of UKB. BBJ
will be used for EAS GWAS, and UGR will be used for AFR GWAS.</p>
<hr />
<div id="ukb-gwas" class="section level3">
<h3>UKB GWAS</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  mkdir -p /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}
  for chr in $(seq 1 22); do
      sbatch -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/plink2 \
        --pfile /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
        --pheno /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.EUR_train.norm_resid_scale.row_number.txt \
        --linear omit-ref cols=+a1freq,+ax \
        --maf 0.01 \
        --geno 0.05 \
        --out /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}&quot;
  done
done

# Once complete, merge results across chromosomes
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  head -n 1 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr1.outcome.glm.linear &gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    for chr in $(seq 1 22); do
      tail -n +2 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}.outcome.glm.linear &gt;&gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    done
    
    # Remove REF and ALT columns and rename AX column to A2
    cut -f 4,5 --complement /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt | awk &#39;BEGIN{FS=OFS=&quot;\t&quot;} NR==1 {$5=&quot;A2&quot;} 1&#39; &gt; temp.txt &amp;&amp; mv temp.txt /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt

    gzip /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
done

# Delete per chromosome files
rm /users/k1806347/oliverpainfel/Data/ukb/gwas/*/*chr*
</code></pre>
</details>
<hr />
</div>
<div id="download-bbj-sumstats" class="section level3">
<h3>Download BBJ sumstats</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Identify wget command for relevant phenotypes
library(data.table)

# Read in BBJ GWAS info from BBJ website
bbj_gwas&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas.csv&#39;)

# Map BBJ trait names to those used for UKB
bbj_gwas$bbj_labels &lt;-
  gsub(&quot;\\)&quot;, &#39;&#39;, gsub(&quot;.*\\(&quot;, &#39;&#39;, bbj_gwas$Phenotype))
bbj_gwas$trait &lt;- gsub(&quot; \\(.*&quot;, &#39;&#39;, bbj_gwas$Phenotype)

bbj_gwas$Category&lt;-NULL
bbj_gwas$Phenotype&lt;-NULL

# Update trait labels to match what was used in prscsx paper
bbj_gwas$trait&lt;-gsub(&#39; count&#39;,&#39;&#39;, bbj_gwas$trait)
bbj_gwas$trait[bbj_gwas$trait == &#39;G-glutamyl transpeptidase&#39;]&lt;-&#39;γ-glutamyl transpeptidase&#39;

# Merge the bbj trait info with the prscsx trait info
prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
prscsx_dat &lt;- merge(bbj_gwas, prscsx_dat, by=&#39;trait&#39;, all=T)

write.csv(prscsx_dat, &#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;, row.names = F)

# Create column showing what label is used in the wget command
prscsx_dat$wget_label &lt;-
  gsub(&#39;.v1.zip&#39;, &#39;&#39;, gsub(&#39;.*hum0197.v3.BBJ.&#39;, &#39;&#39;, prscsx_dat$wget))

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c(&#39;labels&#39;, &#39;wget&#39;, &#39;wget_label&#39;), with=F], &#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code># wget and unzip sumstats
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  url=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $2}&#39; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
  sbatch -p neurohack_cpu --wrap=&quot;wget -O /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip ${url}
    unzip /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip -d /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx
    rm /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip&quot;
done

# Delete X chromosome sumstats and rename files to be consistent with prscsx sumstat info
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  wget_label=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $3}&#39; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
if [ &quot;$pheno&quot; == &quot;HT&quot; ]; then
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_Height_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.HT.txt.gz
  else
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_${wget_label}_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz
  fi
  rm -r ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1
done

# Format so BOLT P value is used by GenoPred
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
sbatch -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/pigz/pigz -dc ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz | awk &#39;BEGIN {OFS=\&quot;\t\&quot;} {print \$2, \$3, \$4, \$6, \$7, \$8, \$9, \$12, \$13, \$15}&#39; | sed &#39;1s/P_BOLT_LMM_INF/P/&#39; | /users/k1806347/oliverpainfel/Software/pigz/pigz -c &gt; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.reformat.txt.gz&quot;
done
</code></pre>
</details>
<hr />
</div>
<div id="download-ugr-sumstats" class="section level3">
<h3>Download UGR sumstats</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Identify wget command for relevant phenotypes
library(data.table)

# Read in UGR GWAS info from GWAS catalogue
ugr_gwas&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats.csv&#39;)

# Map UGR trait names to those used for UKB
ugr_gwas$trait&lt;-gsub(&#39; levels&#39;,&#39;&#39;, ugr_gwas$reportedTrait)
ugr_gwas$trait&lt;-gsub(&#39; count&#39;,&#39;&#39;, ugr_gwas$trait)

ugr_to_prscsx &lt;- c(
  &quot;Aspartate aminotransferase&quot; = &quot;Aspartate transaminase&quot;,
  &quot;Bilirubin&quot; = NA,  # No direct match
  &quot;Eosinophils&quot; = &quot;Eosinophil&quot;,
  &quot;Gamma glutamyl transferase&quot; = &quot;γ-glutamyl transpeptidase&quot;,
  &quot;HDL cholesterol&quot; = &quot;HDL-cholesterol&quot;,
  &quot;Hemoglobin A1c&quot; = &quot;HbA1c&quot;,
  &quot;Hip circumference&quot; = NA,  # No direct match
  &quot;LDL cholesterol&quot; = &quot;LDL-cholesterol&quot;,
  &quot;Red cell distribution width&quot; = NA,  # No direct match
  &quot;Serum albumin&quot; = &quot;Albumin&quot;,
  &quot;Serum alkaline phosphatase&quot; = &quot;Alkaline phosphatase&quot;,
  &quot;Systolic blood pressure&quot; = &quot;Sytolic blood pressure&quot;,
  &quot;Triglyceride&quot; = &quot;Triglycerides&quot;,
  &quot;Waist circumference&quot; = NA,  # No direct match
  &quot;Waist-hip ratio&quot; = NA,  # No direct match
  &quot;Weight&quot; = &quot;Body weight&quot;
)

ugr_gwas$trait &lt;- ifelse(ugr_gwas$trait %in% names(ugr_to_prscsx),
                                   ugr_to_prscsx[ugr_gwas$trait],
                                   ugr_gwas$trait)

# Merge the ugr trait info with the prscsx trait info
prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
prscsx_dat &lt;- merge(ugr_gwas, prscsx_dat, by=&#39;trait&#39;)

write.csv(prscsx_dat, &#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;, row.names = F)

# Create column indicating wget command
prscsx_dat$wget&lt;-NA
for(i in 1:nrow(prscsx_dat)){
  if(!grepl(&#39;.txt&#39;, prscsx_dat$wget[i])){
    print(i)
    Sys.sleep(2)
    log&lt;-system(paste0(&#39;curl --max-time 10 &#39;, gsub(&#39;http:&#39;,&#39;ftp:&#39;, prscsx_dat$summaryStatistics[i]), &#39;/&#39;), intern = T)
    log&lt;-log[grepl(&#39;annotated.txt.gz|annotated.txt&#39;, log)]
    log&lt;-gsub(&#39;.* &#39;,&#39;&#39;, log)
    prscsx_dat$wget[i]&lt;-paste0(prscsx_dat$summaryStatistics[i], &#39;/&#39;, log)
  }
}
# Note this has to be run a few times due to some requests being blocked.

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c(&#39;labels&#39;, &#39;wget&#39;), with=F], &#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code># wget and unzip sumstats
for pheno in $(cat ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt | cut -d&#39; &#39; -f 1); do
  url=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $2}&#39; ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt)
  sbatch -p cpu --wrap=&quot;wget -O ~/oliverpainfel/Data/GWAS_sumstats/UGR/${pheno}.txt.gz ${url}&quot;
done
</code></pre>
<pre class="r"><code>library(future.batchtools)
library(furrr)
library(data.table)
ugr_data&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)

plan(batchtools_slurm(resources = list(
  time = &quot;12:00:00&quot;,
  ntasks = 2,
  mem = &quot;10g&quot;,
  partition = &quot;neurohack_cpu&quot;
)))

furrr::future_map_dfr(1:nrow(ugr_data), function(i) {
  print(i)
  sumstats &lt;- fread(paste0(&quot;~/oliverpainfel/Data/GWAS_sumstats/UGR/&quot;, ugr_data$label[i], &quot;.txt.gz&quot;))
  sumstats &lt;- sumstats[, names(sumstats) %in% c(&quot;snpid&quot;, &quot;pval_fe&quot;, &quot;se_fe&quot;) | grepl(&#39;^beta_|^af_|^no_&#39;, names(sumstats)), with=F]

  # Extract CHR, BP, A1, A2 from snpid
  snp_split &lt;- tstrsplit(sumstats$snpid, &quot;:&quot;, fixed = TRUE)
  sumstats[, `:=`(CHR = snp_split[[1]], BP = snp_split[[2]], A1 = snp_split[[3]], A2 = snp_split[[4]])]

  # Set no_ and af_ to NA if beta is NA
  cohorts &lt;- gsub(&#39;^no_&#39;,&#39;&#39;, names(sumstats)[grepl(&#39;^no_&#39;, names(sumstats))])
  for (cohort in cohorts) {
    sumstats[[paste0(&#39;no_&#39;, cohort)]][is.na(sumstats[[paste0(&#39;beta_&#39;, cohort)]])] &lt;- NA
    sumstats[[paste0(&#39;af_&#39;, cohort)]][is.na(sumstats[[paste0(&#39;beta_&#39;, cohort)]])] &lt;- NA
  }

  # Calculate sample size weighted average for allele frequency
  for (cohort in cohorts) {
    sumstats[[paste0(&#39;af_&#39;, cohort, &#39;_weighted&#39;)]] &lt;- sumstats[[paste0(&#39;af_&#39;, cohort)]] * sumstats[[paste0(&#39;no_&#39;, cohort)]]
  }
  
  # Calculate total N and frequency
  sumstats[, N := rowSums(.SD, na.rm = TRUE), .SDcols = patterns(&quot;^no_&quot;)]
  sumstats[, FREQ := rowSums(.SD, na.rm = TRUE) / N, .SDcols = patterns(&quot;weighted$&quot;)]

  # Rename columns
  setnames(sumstats, old = c(&#39;beta_fe&#39;, &#39;se_fe&#39;, &#39;pval_fe&#39;), new = c(&#39;BETA&#39;, &#39;SE&#39;, &#39;P&#39;))

  # Select relevant columns and remove rows with missing data
  sumstats &lt;- sumstats[, .(CHR, BP, A1, A2, BETA, SE, P, FREQ, N)]
  sumstats &lt;- sumstats[complete.cases(sumstats)]
  
  fwrite(sumstats, paste0(&quot;~/oliverpainfel/Data/GWAS_sumstats/UGR/&quot;, ugr_data$label[i], &quot;.reformat.txt.gz&quot;), sep=&#39; &#39;, quote=F, na=&#39;NA&#39;)
  
})</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="heritability-and-polygenicity-estimation"
class="section level1">
<h1>Heritability and polygenicity estimation</h1>
<p>We will estimate SNP-h2 using LD-score regression, and the rG using
POPCORN. POPCORN can estimate the SNP-h2, but it will vary according to
the other GWAS included due to SNP overlap. Use the sumstats QC’d by
GenoPred. To estimate polygenicity, lets use AVENGEME based on ptclump
score association results. Lets generate those using GenoPred.</p>
<hr />
<div id="qc-gwas-sumstats" class="section level2">
<h2>QC GWAS sumstats</h2>
<p>Use GenoPred for this.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>######
# gwas_list
######

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop&#39;)

prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)

gwas_list_eur&lt;-data.frame(
  name=paste0(prscsx_dat$labels,&#39;_UKB&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/gwas/&#39;,prscsx_dat$labels,&#39;/ukb.eur_train.&#39;,prscsx_dat$labels,&#39;.GW.txt.gz&#39;),
  population=&#39;EUR&#39;,
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, prscsx_dat$trait, &#39; (UKB)&quot;&#39;)
)

bbj_info&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;)
bbj_info&lt;-bbj_info[bbj_info$labels %in% prscsx_dat$labels,]

gwas_list_eas&lt;-data.frame(
  name=paste0(bbj_info$labels,&#39;_BBJ&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.&#39;,bbj_info$labels,&#39;.reformat.txt.gz&#39;),
  population=&#39;EAS&#39;,
  n=as.numeric(gsub(&#39;,&#39;,&#39;&#39;,bbj_info$`No. samples`)),
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, prscsx_dat$trait, &#39; (BBJ)&quot;&#39;)
)

ugr_data&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)
ugr_data&lt;-ugr_data[ugr_data$labels %in% prscsx_dat$labels,]

gwas_list_afr&lt;-data.frame(
  name=paste0(ugr_data$labels,&#39;_UGR&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/UGR/&#39;,ugr_data$labels,&#39;.reformat.txt.gz&#39;),
  population=&#39;AFR&#39;,
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, ugr_data$trait, &#39; (UGR)&quot;&#39;)
)
gwas_list&lt;-do.call(rbind, list(gwas_list_eur, gwas_list_eas, gwas_list_afr))

# Create file listing phenotypes in common between AFR, EAS and EUR
pheno &lt;- gsub(&#39;_.*&#39;, &#39;&#39;, gwas_list$name)
pheno_intersect &lt;- Reduce(intersect, 
                           list(
                             pheno[gwas_list$population == &#39;EUR&#39;],
                             pheno[gwas_list$population == &#39;EAS&#39;],
                             pheno[gwas_list$population == &#39;AFR&#39;]
                             )
                           )

# Restrict gwas_list to intersecting phenotypes
gwas_list&lt;-gwas_list[pheno %in% pheno_intersect,]

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;, col.names = T, row.names = F, quote = F)

write.table(pheno_intersect, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, col.names = F, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;]&quot;,
  &quot;cores_prep_pgs: 1&quot;,
  &quot;cores_target_pgs: 20&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml \
  target_pgs -n</code></pre>
<hr />
<h4>
Reformat for LDSC and POPCORN
</h4>
<pre class="r"><code>library(data.table)
dir.create(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats&#39;, recursive = T)
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)

for(i in 1:nrow(gwas_list)){
  if(
    file.exists(
      paste0(
        &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/&quot;,
        gwas_list$name[i], 
        &quot;.sumstats.gz&quot;))){
    next    
  }
  print(i)
  gwas_file &lt;-
    paste0(
      &quot;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/&quot;,
      gwas_list$name[i],
      &quot;/&quot;,
      gwas_list$name[i],
      &quot;-cleaned.gz&quot;
    )
  
  gwas_header &lt;- fread(gwas_file, nrows = 1)
  cols_index &lt;- which(names(gwas_header) %in% c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;N&#39;))
  
  system(
    paste0(
      &quot;zcat &quot;,
      gwas_file,
      &quot; | cut -f &quot;, 
      paste0(cols_index, collapse = &#39;,&#39;),
      &quot; | sed -e &#39;1s/BETA/beta/&#39;&quot;,
      &quot; | /users/k1806347/oliverpainfel/Software/pigz/pigz -f&quot;,
      &quot; &gt; /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/&quot;,
      gwas_list$name[i], 
      &quot;.sumstats.gz&quot;
      )
    )
}</code></pre>
</details>
<hr />
</div>
<div id="ldsc" class="section level2">
<h2>LDSC</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>conda activate ldsc

for pop in $(echo EUR EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      samp=&quot;UKB&quot;
  fi
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/munge_sumstats.py \
     --sumstats /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}&quot;

  done
done

for pop in $(echo EUR EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      samp=&quot;UKB&quot;
  fi
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/ldsc.py \
     --h2 /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}.sumstats.gz \
     --ref-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --w-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}/res&quot;
     
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="popcorn" class="section level2">
<h2>POPCORN</h2>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Calculate CSCOREs
</h4>
<pre class="bash"><code>
# Subset the reference data into relevant populations
for pop in $(echo EUR EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
  for chr in $(seq 1 22); do
    /users/k1806347/oliverpainfel/Software/plink2 \
      --pfile /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/ref.chr${chr} \
      --keep /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/keep_files/${pop}.keep \
      --make-bed \
      --out /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr}
    done
done

conda activate /scratch/prj/oliverpainfel/recovered/.conda/envs/popcorn
for pop in $(echo EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES
  for chr in $(seq 1 22); do
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;popcorn \
      compute \
      -v 1 \
      --bfile1 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.EUR.chr${chr} \
      --bfile2 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr} \
      /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr${chr}.txt&quot;
  done
done

for pop in $(echo EAS AFR); do
  cat /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr*.txt &gt; /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt
done

rm -r /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
rm /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_*_CSCORES/*chr*.txt</code></pre>
<hr />
<h4>
Run POPCORN
</h4>
<pre class="bash"><code>conda activate popcorn
for pop in $(echo EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;popcorn \
       fit -v 3 \
       --cfile /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt \
       --sfile1 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_UKB.sumstats.gz \
       --sfile2 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
       --gen_effect \
       /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}/rG_gen_effect&quot;
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="plot-ldsc-and-popcorn-results" class="section level2">
<h2>Plot LDSC and POPCORN results</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Plot the heritability estimates
h2_res &lt;- NULL

for(pop in c(&#39;AFR&#39;,&#39;EAS&#39;, &#39;EUR&#39;)){
  for(pheno in pheno_intersect){
    log &lt;-
      readLines(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/&#39;,
          pheno,
          &#39;/&#39;,
          pop,
          &#39;/res.log&#39;
        )
      )
    
    h2 &lt;- log[grepl(&#39;Total Observed scale h2:&#39;, log)]
    h2_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Total Observed scale h2: &#39;, &#39;&#39;, h2)))
    h2_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, h2)))
    int &lt;- log[grepl(&#39;Intercept:&#39;, log)]
    int_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Intercept: &#39;, &#39;&#39;, int)))
    int_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, int)))
    lambda &lt;- log[grepl(&#39;Lambda GC:&#39;, log)]
    lambda &lt;- as.numeric(gsub(&#39;.* &#39;,&#39;&#39;, lambda))
    
    h2_res &lt;- rbind(
      h2_res,
      data.table(
        Population = pop,
        Phenotype = pheno,
        h2_est = h2_est,
        h2_se = h2_se,
        int_est = int_est,
        int_se = int_se,
        lambda = lambda
      )
    )
  }
}

write.csv(h2_res, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;, row.names = F, quote = F)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/ldsc_h2.png&#39;, res = 100, width = 700, height = 300, units = &#39;px&#39;)
ggplot(h2_res, aes(x = Phenotype, y = h2_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=h2_est-h2_se, ymax=h2_est+h2_se), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;SNP-based Heritability (SE)&quot;, fill = NULL) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()

# Plot rG estimates
rg_res &lt;- NULL
for(pop in c(&#39;AFR&#39;,&#39;EAS&#39;)){
  for(pheno in h2_res$Phenotype){
    pop_res_i&lt;-fread(paste0(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/&#39;, pheno, &#39;/EUR_&#39;, pop, &#39;/rG_gen_effect&#39;))
    names(pop_res_i) &lt;- c(&#39;Test&#39;,&#39;Estimate&#39;,&#39;SE&#39;,&#39;Z&#39;,&#39;P&#39;)
    pop_res_i &lt;- pop_res_i[pop_res_i$Test == &#39;pge&#39;,]
    pop_res_i$Population_1 &lt;- &#39;EUR&#39;
    pop_res_i$Population_2 &lt;- pop
    pop_res_i$Phenotype &lt;- pheno
    rg_res &lt;- rbind(rg_res, pop_res_i)
  }
}

rg_res$Comparison &lt;- paste0(rg_res$Population_1, &#39; vs. &#39;, rg_res$Population_2)

write.csv(rg_res, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results.csv&#39;, row.names = F, quote = F)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/popcorn_rg.png&#39;, res = 100, width = 700, height = 300, units = &#39;px&#39;)
ggplot(rg_res, aes(x = Phenotype, y = Estimate, fill = Comparison)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin=Estimate-SE, ymax=Estimate+SE), width=.2, position=position_dodge(width = 0.7)) +
  labs(y=&quot;SNP-based\nGenetic Correlation (SE)&quot;, fill = NULL) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()</code></pre>
</details>
<details>
<summary>
Show LDSC SNP-heritability
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/ldsc_h2.png"></p>
</div>
</div>
</details>
<details>
<summary>
Show POPCORN genetic correlation estimates
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/popcorn_rg.png"></p>
</div>
</div>
</details>
<hr />
</div>
<div id="avengeme" class="section level2">
<h2>AVENGEME</h2>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Create files for EAS and AFR targets
pop &lt;- c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in pheno_intersect){
  # Make a group containing both GWAS for each single source method
  # Make a group for each multisource method
  scores_i &lt;- scores[grepl(paste0(&#39;^&#39;, trait_i, &#39;_&#39;), scores$name),]
  scores_i$group &lt;- scores_i$method
  
  for(pop_i in pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(pop_i == &#39;EAS&#39;){
      samp_i &lt;- &#39;BBJ&#39;
    }
    if(pop_i == &#39;AFR&#39;){
      samp_i &lt;- &#39;UGR&#39;
    }
    if(pop_i == &#39;EUR&#39;){
      samp_i &lt;- c(&#39;UKB&#39;)
    }

    dir.create(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i
      ),
      recursive = T
    )
    
    scores_i_j &lt;- scores_i[grepl(samp_i, scores_i$name, ignore.case = T),]
    scores_i_j$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i_j$method,
      &#39;/&#39;,
      scores_i_j$name,
      &#39;/ukb-&#39;,
      scores_i_j$name,
      &#39;-TRANS.profiles&#39;
    )
    
    predictors_i &lt;- scores_i_j[, c(&#39;predictor&#39;, &#39;group&#39;), with=F]
    
    write.table(
      predictors_i,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i,
        &#39;/predictor_list.ptclump.txt&#39;
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

for pop in $(echo EUR EAS AFR); do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      pop2=&quot;EUR_test&quot;
  else
      pop2=$pop
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    sbatch --mem 5G -n 5 -p neurohack_cpu --wrap=&quot;Rscript ../Scripts/model_builder/model_builder.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${pop2}.row_number.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/predictor_list.ptclump.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/res.ptclump \
      --n_core 5 \
      --all_model F \
      --assoc T&quot;
  done
done
</code></pre>
<hr />
<h4>
Plot pT+clump association results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Read in results
pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_all &lt;- NULL
for(pheno_i in pheno_intersect){
  res_i&lt;-NULL
  for(pop_i in pop){
    assoc_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          pop_i,
          &#39;.disc_&#39;,
          pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res.ptclump.assoc.txt&#39;
        )
      )
      assoc_i$Population &lt;- pop_i
      res_i&lt;-rbind(res_i, assoc_i)
  }
  
  res_i$Phenotype &lt;- pheno_i
  res_all&lt;-rbind(res_all, res_i)
}

# Extract pT variable from Predictor
res_all$pT &lt;- gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.&#39;, &#39;&#39;, res_all$Predictor))
res_all$pT &lt;- factor(res_all$pT, levels = unique(res_all$pT))

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/ptclump_assoc.png&#39;, res = 100, width = 900, height = 500, units = &#39;px&#39;)
ggplot(res_all, aes(x = Phenotype, y = BETA, fill = pT)) +
  geom_hline(yintercept = 0, colour = &#39;darkgrey&#39;) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.8) +
  geom_errorbar(aes(ymin=BETA-SE, ymax=BETA+SE), width=0, position=position_dodge(width = 0.8, preserve = &quot;single&quot;)) +
  labs(y=&quot;BETA (SE)&quot;) +
  theme_half_open() +
  background_grid() +
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(1, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) +
  scale_fill_manual(values = colorRampPalette(c(&quot;lightblue&quot;, &quot;darkblue&quot;))(length(unique(res_all$pT)))) +
  facet_grid(Population ~.)
dev.off()</code></pre>
<hr />
<h4>
Run AVENGEME
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)
library(avengeme)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)
gwas_list &lt;- read_param(config = config, param = &#39;gwas_list&#39;, return_obj = T)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)

mod_res_all &lt;- NULL
for(pop_i in pop){
  for(pheno_i in pheno_intersect){
    gwas_i&lt;-gwas_list$name[gwas_list$population == pop_i &amp; grepl(paste0(&#39;^&#39;, pheno_i, &#39;_&#39;),  gwas_list$name)]
      
    res_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          pop_i,
          &#39;.disc_&#39;,
          pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res.ptclump.assoc.txt&#39;
        )
      )
    
    res_i$Z &lt;- res_i$BETA / res_i$SE
    
    res_i$pT &lt;- as.numeric(gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.&#39;, &#39;&#39;, res_i$Predictor)))

    nsnp_log &lt;-
      read.table(
        paste0(
          outdir,
          &#39;/reference/pgs_score_files/ptclump/&#39;,
          gwas_i,
          &#39;/ref-&#39;,
          gwas_i,
          &#39;.NSNP_per_pT&#39;
        ),
        header = T
      )
    
    nsnp&lt;-nsnp_log$NSNP[nrow(nsnp_log)]
    
    disc_N &lt;-
      median(
        fread(
          paste0(
            outdir,
            &#39;/reference/gwas_sumstat/&#39;,
            gwas_i,
            &#39;/&#39;,
            gwas_i,
            &#39;-cleaned.gz&#39;
          ), nrows = 10000
        )$N
      )
    
    targ_N &lt;- res_i$N[1]
    
    mod_res &lt;- estimatePolygenicModel(
      p = res_i$Z,
      nsnp = nsnp,
      n = c(disc_N, targ_N),
      pupper = c(0, res_i$pT),
      fixvg2pi02 = T,
      alpha = 0.05
    )
    
    mod_res_all &lt;- rbind(
      mod_res_all,
      data.frame(
        Phenotype = pheno_i,
        Population = pop_i,
        GWAS = gwas_i,
        nsnp = nsnp,
        max_r2 = max(res_i$Obs_R2),
        n_disc = disc_N,
        n_targ = targ_N,
        vg_est = mod_res$vg[1],
        vg_lowCI = mod_res$vg[2],
        vg_highCI = mod_res$vg[3],
        pi0_est = mod_res$pi0[1],
        pi0_lowCI = mod_res$pi0[2],
        pi0_highCI = mod_res$pi0[3]
      )
    )
  }
}

dir.create(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme&#39;)
write.csv(mod_res_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;, row.names = F, quote = F)

mod_res_all&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/avengeme_h2.png&#39;, res = 100, width = 900, height = 500, units = &#39;px&#39;)
ggplot(mod_res_all, aes(x = Phenotype, y = vg_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=vg_lowCI, ymax=vg_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;SNP-based Heritability (95%CI)&quot;, fill = NULL) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(1, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/avengeme_polygenicity.png&#39;, res = 100, width = 900, height = 500, units = &#39;px&#39;)
ggplot(mod_res_all, aes(x = Phenotype, y = 1 - pi0_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=1 - pi0_lowCI, ymax=1 - pi0_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;Proporition non-zero\neffects (95%CI)&quot;, fill = NULL) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(1, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])</code></pre>
</details>
<details>
<summary>
Show AVENGEME results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/avengeme_h2.png"></p>
</div>
</div>
<p><br></p>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/avengeme_polygenicity.png"></p>
</div>
</div>
</details>
<hr />
</div>
<div id="select-traits" class="section level2">
<h2>Select traits</h2>
<p>Here we will identify a list of traits that fulfill our selection
criteria, and that represent a range of heritability and polygenicity
combinations.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>#########
# Select 10 GWAS for downstream analysis
#########
# Criteria are that SNP-h2 &gt; 0.01 in both AVENGEME and LDSC
# Then GWAS are selected to represent a range of polygenicity and heritability, as estimated in EUR since they are most accurate

library(data.table)

# Read in the AVENGEME results
avengeme &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)

# Read in the LDSC results
ldsc &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;)

# Combine results
both &lt;- merge(avengeme, ldsc, by = c(&#39;Population&#39;,&#39;Phenotype&#39;))

# Remove GWAS that have negative SNP-h2 from LDSC in any population
both_h2 &lt;- both[!(both$Phenotype %in% both$Phenotype[both$vg_est &lt; 0.01 | both$h2_est &lt; 0.01]),]

# Select GWAS representing a range of SNP-h2 from LDSC, and a range of polygenicity from AVENGEME.
both_eur&lt;-both_h2[both_h2$Population == &#39;EUR&#39;,]
traits_data &lt;- data.frame(trait = both_eur$Phenotype, heritability = both_eur$vg_est, polygenicity = both_eur$pi0_est)

# Number of bins (e.g., dividing into 5 bins each for heritability and polygenicity)
num_bins &lt;- 5

# Create bins
traits_data$her_bin &lt;- cut(traits_data$heritability, breaks = num_bins)
traits_data$poly_bin &lt;- cut(traits_data$polygenicity, breaks = num_bins)

# Split data by unique bin combinations
split_data &lt;- split(traits_data, list(traits_data$her_bin, traits_data$poly_bin), drop = TRUE)

set.seed(1)
# Randomly select one trait from each bin combination
selected_traits &lt;- do.call(rbind, lapply(split_data, function(df) df[sample(nrow(df), 1), ]))

# Limit to 10 traits if more than 10 unique combinations
if (nrow(selected_traits) &gt; 10) {
  selected_traits &lt;- selected_traits[sample(nrow(selected_traits), 10), ]
}

write.table(selected_traits$trait, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, col.names = F, row.names = F, quote = F)

# Plot max R2 for selected traits
mod_res_all &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)
mod_res_all_selected &lt;- mod_res_all[mod_res_all$Phenotype %in% selected_traits$trait,]

ggplot(mod_res_all_selected, aes(x = Phenotype, y = max_r2, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  labs(y=&quot;Max R2&quot;) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

# 
hist(mod_res_all$max_r2)
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])

round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])), 2)</code></pre>
</details>
<hr />
</div>
<div id="gwas-descriptives" class="section level2">
<h2>GWAS descriptives</h2>
<p>Make a table showing GWAS information for the manuscript.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

#####
# Trait names, labels, and URLs
#####

###
# UKB
###
ukb &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
names(ukb) &lt;- c(&#39;trait&#39;, &#39;labels&#39;,&#39;field&#39;)
trait_labels &lt;- ukb[, c(&#39;trait&#39;,&#39;labels&#39;), with=F]
ukb&lt;-ukb[, c(&#39;trait&#39;,&#39;field&#39;), with=F]
ukb$sample &lt;- &#39;UKB&#39;
ukb$population &lt;- &#39;EUR&#39;
ukb$url&lt;-NA

###
# BBJ
###
bbj &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;)
bbj &lt;- bbj[, c(&#39;trait&#39;, &#39;wget&#39;), with = F]
names(bbj) &lt;- c(&#39;trait&#39;, &#39;url&#39;)
bbj$sample &lt;- &#39;BBJ&#39;
bbj$population &lt;- &#39;EAS&#39;
bbj$field &lt;- NA

###
# UGR
###
ugr &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)
ugr &lt;- ugr[, c(&#39;trait&#39;, &#39;summaryStatistics&#39;), with = F]
names(ugr) &lt;- c(&#39;trait&#39;,&#39;url&#39;)
ugr$sample &lt;- &#39;UGR&#39;
ugr$population &lt;- &#39;AFR&#39;
ugr$field &lt;- NA

info_all &lt;- do.call(rbind, list(ukb, bbj, ugr))
info_all&lt;-merge(info_all, trait_labels, by=&#39;trait&#39;)

#####
# Sample size, SNP-h2 and polygenicity
#####

# Read in the AVENGEME and LDSC results
avengeme &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)
ldsc &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;)
both &lt;- merge(avengeme, ldsc, by = c(&#39;Population&#39;,&#39;Phenotype&#39;))

# Format for descriptives table
both$h2_avengeme&lt;- paste0(
  round(both$vg_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$vg_lowCI, 2), 
  &quot; - &quot; , 
  round(both$vg_highCI, 2), &quot;)&quot;)

both$pi0_avengeme &lt;- paste0(
  round(both$pi0_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$pi0_lowCI, 2), 
  &quot; - &quot; , 
  round(both$pi0_highCI, 2), &quot;)&quot;)

both$h2_ldsc &lt;- paste0(
  round(both$h2_est,2), 
  &quot; (SE = &quot;, 
  round(both$h2_se, 2), 
  &quot;)&quot;)

both$int_ldsc &lt;- paste0(
  round(both$int_est,2), 
  &quot; (SE = &quot;, 
  round(both$int_se, 2), 
  &quot;)&quot;)

both&lt;-both[, c(&#39;Population&#39;,&#39;Phenotype&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;), with = F]
names(both)[1:2]&lt;-c(&#39;population&#39;,&#39;labels&#39;)

info_all &lt;- merge(info_all, both, by = c(&#39;labels&#39;,&#39;population&#39;))
info_all$n_disc&lt;-round(info_all$n_disc, 0)
info_all$n_targ&lt;-round(info_all$n_targ, 0)

info_all&lt;-info_all[, c(&#39;labels&#39;,&#39;trait&#39;,&#39;population&#39;,&#39;sample&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;,&#39;field&#39;,&#39;url&#39;), with=F]
names(info_all) &lt;- c(&#39;Trait Label&#39;, &#39;Trait Description&#39;, &#39;Ancestry&#39;, &#39;GWAS Sample&#39;, &#39;GWAS N&#39;, &#39;Target N&#39;,&quot;SNP-h2 (AVENGEME)&quot;,&quot;pi0 (AVENGEME)&quot;,&quot;SNP-h2 (LDSC)&quot;,&quot;Intercept (LDSC)&quot;,&#39;Lambda&#39;, &#39;UKB Field&#39;, &#39;URL&#39;)

# Add in column indicating whether the trait was used in downstream PGS comparison
selected_traits &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

info_all$`Selected` &lt;- info_all$`Trait Label` %in% selected_traits

write.csv(info_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;, row.names=F)

# Estimate the mean and SD of sample size within each population for selected traits
info_all_selected&lt;-info_all[info_all$Selected == T,]
n_dat &lt;- NULL
for(i in unique(info_all_selected$`GWAS Sample`)){
  n_dat &lt;-rbind(
    n_dat,
    data.table(
      sample = i,
      gwas_n_median = round(median(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_mean = round(mean(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_sd = round(sd(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      target_n_median = round(median(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_mean = round(mean(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_sd = round(sd(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i]))
    )
  )
}</code></pre>
</details>
<details>
<summary>
Show descriptives table
</summary>
<div
style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%; ">
<table class="table table-striped table-hover" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Trait Label
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Trait Description
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Ancestry
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
GWAS Sample
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
GWAS N
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Target N
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
SNP-h2 (AVENGEME)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
pi0 (AVENGEME)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
SNP-h2 (LDSC)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Intercept (LDSC)
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Lambda
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
UKB Field
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
URL
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Selected
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
ALB
</td>
<td style="text-align:left;">
Albumin
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13125
</td>
<td style="text-align:right;">
5868
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.1 - 0.19)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0 - 0.99)
</td>
<td style="text-align:left;">
0.07 (SE = 0.05)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0135
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009048"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009048</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALB
</td>
<td style="text-align:left;">
Albumin
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
120539
</td>
<td style="text-align:right;">
1780
</td>
<td style="text-align:left;">
0.06 (95%CI = 0.04 - 0.07)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.99)
</td>
<td style="text-align:left;">
0.06 (SE = 0.01)
</td>
<td style="text-align:left;">
1.03 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Alb.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Alb.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALB
</td>
<td style="text-align:left;">
Albumin
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
268088
</td>
<td style="text-align:right;">
67382
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.13 - 0.13)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.94 - 0.94)
</td>
<td style="text-align:left;">
0.12 (SE = 0.01)
</td>
<td style="text-align:left;">
1.13 (SE = 0.02)
</td>
<td style="text-align:right;">
1.4281
</td>
<td style="text-align:right;">
30600
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALP
</td>
<td style="text-align:left;">
Alkaline phosphatase
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
9322
</td>
<td style="text-align:right;">
6328
</td>
<td style="text-align:left;">
0.03 (95%CI = 0.02 - 0.06)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.09 (SE = 0.07)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0255
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009049"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009049</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALP
</td>
<td style="text-align:left;">
Alkaline phosphatase
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
118886
</td>
<td style="text-align:right;">
1955
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.1 - 0.14)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.99)
</td>
<td style="text-align:left;">
0.12 (SE = 0.03)
</td>
<td style="text-align:left;">
1.09 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.ALP.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.ALP.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALP
</td>
<td style="text-align:left;">
Alkaline phosphatase
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
292054
</td>
<td style="text-align:right;">
73314
</td>
<td style="text-align:left;">
0.16 (95%CI = 0.16 - 0.16)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.94 - 0.94)
</td>
<td style="text-align:left;">
0.21 (SE = 0.03)
</td>
<td style="text-align:left;">
1.15 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5144
</td>
<td style="text-align:right;">
30610
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALT
</td>
<td style="text-align:left;">
Alanine aminotransferase
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
9401
</td>
<td style="text-align:right;">
6326
</td>
<td style="text-align:left;">
0.07 (95%CI = 0.03 - 0.12)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.11 (SE = 0.07)
</td>
<td style="text-align:left;">
1 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0165
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009047"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009047</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALT
</td>
<td style="text-align:left;">
Alanine aminotransferase
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
150545
</td>
<td style="text-align:right;">
1954
</td>
<td style="text-align:left;">
0.03 (95%CI = 0.02 - 0.04)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.98 - 1)
</td>
<td style="text-align:left;">
0.06 (SE = 0.01)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.ALT.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.ALT.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
ALT
</td>
<td style="text-align:left;">
Alanine aminotransferase
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
291932
</td>
<td style="text-align:right;">
73278
</td>
<td style="text-align:left;">
0.09 (95%CI = 0.08 - 0.09)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.95 - 0.95)
</td>
<td style="text-align:left;">
0.11 (SE = 0.01)
</td>
<td style="text-align:left;">
1.09 (SE = 0.02)
</td>
<td style="text-align:right;">
1.4069
</td>
<td style="text-align:right;">
30620
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
AST
</td>
<td style="text-align:left;">
Aspartate transaminase
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
8995
</td>
<td style="text-align:right;">
6289
</td>
<td style="text-align:left;">
0.03 (95%CI = 0 - 0.09)
</td>
<td style="text-align:left;">
1 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
0.12 (SE = 0.07)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0165
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009046"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009046</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
AST
</td>
<td style="text-align:left;">
Aspartate transaminase
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
150068
</td>
<td style="text-align:right;">
1940
</td>
<td style="text-align:left;">
0.01 (95%CI = 0 - 0.02)
</td>
<td style="text-align:left;">
1 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.AST.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.AST.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
AST
</td>
<td style="text-align:left;">
Aspartate transaminase
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
291016
</td>
<td style="text-align:right;">
73049
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.07 - 0.08)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.95 - 0.95)
</td>
<td style="text-align:left;">
0.12 (SE = 0.01)
</td>
<td style="text-align:left;">
1.11 (SE = 0.02)
</td>
<td style="text-align:right;">
1.3964
</td>
<td style="text-align:right;">
30650
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
BAS
</td>
<td style="text-align:left;">
Basophil
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2681
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0 (95%CI = 0 - 0.02)
</td>
<td style="text-align:left;">
1 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
-0.37 (SE = 0.25)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0046
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009039"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009039</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
BAS
</td>
<td style="text-align:left;">
Basophil
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
91908
</td>
<td style="text-align:right;">
1997
</td>
<td style="text-align:left;">
0 (95%CI = 0 - 0.02)
</td>
<td style="text-align:left;">
1 (95%CI = 0.81 - 1)
</td>
<td style="text-align:left;">
0.07 (SE = 0.02)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0957
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BAS.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BAS.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
BAS
</td>
<td style="text-align:left;">
Basophil
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
296570
</td>
<td style="text-align:right;">
74442
</td>
<td style="text-align:left;">
0.04 (95%CI = 0.04 - 0.04)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.98 - 0.98)
</td>
<td style="text-align:left;">
0.04 (SE = 0)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1811
</td>
<td style="text-align:right;">
30160
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
BMI
</td>
<td style="text-align:left;">
Body mass index
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13976
</td>
<td style="text-align:right;">
6646
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.09 - 0.18)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0 - 0.99)
</td>
<td style="text-align:left;">
0.11 (SE = 0.05)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0315
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009057"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009057</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
BMI
</td>
<td style="text-align:left;">
Body mass index
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
163835
</td>
<td style="text-align:right;">
2046
</td>
<td style="text-align:left;">
0.17 (95%CI = 0.15 - 0.18)
</td>
<td style="text-align:left;">
0.91 (95%CI = 0.88 - 0.93)
</td>
<td style="text-align:left;">
0.18 (SE = 0.01)
</td>
<td style="text-align:left;">
1.14 (SE = 0.02)
</td>
<td style="text-align:right;">
1.4926
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BMI.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BMI.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
BMI
</td>
<td style="text-align:left;">
Body mass index
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
304506
</td>
<td style="text-align:right;">
76393
</td>
<td style="text-align:left;">
0.22 (95%CI = 0.21 - 0.22)
</td>
<td style="text-align:left;">
0.85 (95%CI = 0.85 - 0.86)
</td>
<td style="text-align:left;">
0.23 (SE = 0.01)
</td>
<td style="text-align:left;">
1.14 (SE = 0.02)
</td>
<td style="text-align:right;">
2.0302
</td>
<td style="text-align:right;">
21001
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
BWT
</td>
<td style="text-align:left;">
Body weight
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
14005
</td>
<td style="text-align:right;">
6659
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.08 - 0.15)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.92 - 0.99)
</td>
<td style="text-align:left;">
0.13 (SE = 0.05)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0255
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009056"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009056</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
BWT
</td>
<td style="text-align:left;">
Body weight
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
165419
</td>
<td style="text-align:right;">
2046
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.12 - 0.16)
</td>
<td style="text-align:left;">
0.91 (95%CI = 0.89 - 0.94)
</td>
<td style="text-align:left;">
0.22 (SE = 0.01)
</td>
<td style="text-align:left;">
1.17 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6259
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BW.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.BW.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
BWT
</td>
<td style="text-align:left;">
Body weight
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
304622
</td>
<td style="text-align:right;">
76415
</td>
<td style="text-align:left;">
0.2 (95%CI = 0.2 - 0.2)
</td>
<td style="text-align:left;">
0.87 (95%CI = 0.87 - 0.88)
</td>
<td style="text-align:left;">
0.25 (SE = 0.01)
</td>
<td style="text-align:left;">
1.16 (SE = 0.02)
</td>
<td style="text-align:right;">
2.0556
</td>
<td style="text-align:right;">
21002
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
DBP
</td>
<td style="text-align:left;">
Diastolic blood pressure
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13618
</td>
<td style="text-align:right;">
6658
</td>
<td style="text-align:left;">
0.23 (95%CI = 0.19 - 0.27)
</td>
<td style="text-align:left;">
0.96 (95%CI = 0.74 - 0.98)
</td>
<td style="text-align:left;">
-0.02 (SE = 0.05)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0165
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009052"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009052</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
DBP
</td>
<td style="text-align:left;">
Diastolic blood pressure
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
145515
</td>
<td style="text-align:right;">
1976
</td>
<td style="text-align:left;">
0.09 (95%CI = 0.07 - 0.1)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.89 - 0.96)
</td>
<td style="text-align:left;">
0.05 (SE = 0.01)
</td>
<td style="text-align:left;">
1.07 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.DBP.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.DBP.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
DBP
</td>
<td style="text-align:left;">
Diastolic blood pressure
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
289698
</td>
<td style="text-align:right;">
72640
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.12 - 0.13)
</td>
<td style="text-align:left;">
0.89 (95%CI = 0.89 - 0.9)
</td>
<td style="text-align:left;">
0.12 (SE = 0.01)
</td>
<td style="text-align:left;">
1.08 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5548
</td>
<td style="text-align:right;">
4079
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
EOS
</td>
<td style="text-align:left;">
Eosinophil
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2671
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0 (95%CI = 0 - 0.02)
</td>
<td style="text-align:left;">
1 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
-0.26 (SE = 0.25)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0195
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009041"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009041</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
EOS
</td>
<td style="text-align:left;">
Eosinophil
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
93063
</td>
<td style="text-align:right;">
1997
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.07 - 0.1)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.99)
</td>
<td style="text-align:left;">
0.09 (SE = 0.01)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.EOS.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.EOS.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
EOS
</td>
<td style="text-align:left;">
Eosinophil
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
296570
</td>
<td style="text-align:right;">
74442
</td>
<td style="text-align:left;">
0.15 (95%CI = 0.15 - 0.16)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.19 (SE = 0.02)
</td>
<td style="text-align:left;">
1.17 (SE = 0.02)
</td>
<td style="text-align:right;">
1.4962
</td>
<td style="text-align:right;">
30150
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
GGT
</td>
<td style="text-align:left;">
γ-glutamyl transpeptidase
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
8995
</td>
<td style="text-align:right;">
6322
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.03 - 0.08)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.23 (SE = 0.07)
</td>
<td style="text-align:left;">
0.99 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0075
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009050"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009050</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
GGT
</td>
<td style="text-align:left;">
γ-glutamyl transpeptidase
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
133471
</td>
<td style="text-align:right;">
1952
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.06 - 0.09)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.95 - 0.98)
</td>
<td style="text-align:left;">
0.15 (SE = 0.05)
</td>
<td style="text-align:left;">
1.07 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.GGT.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.GGT.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
GGT
</td>
<td style="text-align:left;">
γ-glutamyl transpeptidase
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
291885
</td>
<td style="text-align:right;">
73270
</td>
<td style="text-align:left;">
0.1 (95%CI = 0.1 - 0.1)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.95 - 0.95)
</td>
<td style="text-align:left;">
0.18 (SE = 0.01)
</td>
<td style="text-align:left;">
1.16 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5696
</td>
<td style="text-align:right;">
30730
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HB
</td>
<td style="text-align:left;">
Hemoglobin
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2741
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.25 (95%CI = 0.16 - 0.36)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
0.22 (SE = 0.25)
</td>
<td style="text-align:left;">
1 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0105
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009034"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009034</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HB
</td>
<td style="text-align:left;">
Hemoglobin
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
152447
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.06 (95%CI = 0.05 - 0.08)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.89 - 0.97)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.09 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Hb.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Hb.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HB
</td>
<td style="text-align:left;">
Hemoglobin
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297083
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.13 - 0.13)
</td>
<td style="text-align:left;">
0.92 (95%CI = 0.92 - 0.92)
</td>
<td style="text-align:left;">
0.15 (SE = 0.01)
</td>
<td style="text-align:left;">
1.16 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5217
</td>
<td style="text-align:right;">
30020
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HCT
</td>
<td style="text-align:left;">
Hematocrit
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2744
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.26 (95%CI = 0.16 - 0.36)
</td>
<td style="text-align:left;">
0.88 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
0.18 (SE = 0.26)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0105
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009033"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009033</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HCT
</td>
<td style="text-align:left;">
Hematocrit
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
153015
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.03 - 0.06)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.94 - 0.98)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.09 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Ht.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Ht.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HCT
</td>
<td style="text-align:left;">
Hematocrit
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297084
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.13 - 0.13)
</td>
<td style="text-align:left;">
0.92 (95%CI = 0.92 - 0.93)
</td>
<td style="text-align:left;">
0.14 (SE = 0.01)
</td>
<td style="text-align:left;">
1.16 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5035
</td>
<td style="text-align:right;">
30030
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HDL
</td>
<td style="text-align:left;">
HDL-cholesterol
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13114
</td>
<td style="text-align:right;">
5863
</td>
<td style="text-align:left;">
0.06 (95%CI = 0.04 - 0.09)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.02 (SE = 0.05)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0225
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009044"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009044</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HDL
</td>
<td style="text-align:left;">
HDL-cholesterol
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
74970
</td>
<td style="text-align:right;">
1783
</td>
<td style="text-align:left;">
0.15 (95%CI = 0.13 - 0.17)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.99)
</td>
<td style="text-align:left;">
0.17 (SE = 0.03)
</td>
<td style="text-align:left;">
1.09 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.HDLC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.HDLC.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HDL
</td>
<td style="text-align:left;">
HDL-cholesterol
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
267973
</td>
<td style="text-align:right;">
67346
</td>
<td style="text-align:left;">
0.2 (95%CI = 0.2 - 0.2)
</td>
<td style="text-align:left;">
0.92 (95%CI = 0.92 - 0.93)
</td>
<td style="text-align:left;">
0.23 (SE = 0.02)
</td>
<td style="text-align:left;">
1.15 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6524
</td>
<td style="text-align:right;">
30760
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HT
</td>
<td style="text-align:left;">
Height
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
14126
</td>
<td style="text-align:right;">
6658
</td>
<td style="text-align:left;">
0.23 (95%CI = 0.19 - 0.26)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.96 - 0.99)
</td>
<td style="text-align:left;">
0.12 (SE = 0.06)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0345
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009055"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009055</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HT
</td>
<td style="text-align:left;">
Height
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
165056
</td>
<td style="text-align:right;">
2048
</td>
<td style="text-align:left;">
0.2 (95%CI = 0.19 - 0.22)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.92 - 0.95)
</td>
<td style="text-align:left;">
0.41 (SE = 0.02)
</td>
<td style="text-align:left;">
1.33 (SE = 0.03)
</td>
<td style="text-align:right;">
1.7648
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Hei.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.Hei.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HT
</td>
<td style="text-align:left;">
Height
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
304826
</td>
<td style="text-align:right;">
76470
</td>
<td style="text-align:left;">
0.24 (95%CI = 0.24 - 0.25)
</td>
<td style="text-align:left;">
0.91 (95%CI = 0.91 - 0.91)
</td>
<td style="text-align:left;">
0.45 (SE = 0.02)
</td>
<td style="text-align:left;">
1.39 (SE = 0.03)
</td>
<td style="text-align:right;">
2.3412
</td>
<td style="text-align:right;">
50
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
6116
</td>
<td style="text-align:right;">
5405
</td>
<td style="text-align:left;">
0 (95%CI = 0 - 0.05)
</td>
<td style="text-align:left;">
1 (95%CI = 0.9 - 1)
</td>
<td style="text-align:left;">
0.42 (SE = 0.15)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0405
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009054"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009054</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
71221
</td>
<td style="text-align:right;">
1949
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.06 - 0.1)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.96 - 0.99)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.05 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0957
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.HbA1c.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.HbA1c.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
HbA1c
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
292134
</td>
<td style="text-align:right;">
73182
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.13 - 0.14)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.2 (SE = 0.02)
</td>
<td style="text-align:left;">
1.17 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5659
</td>
<td style="text-align:right;">
30750
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LDL
</td>
<td style="text-align:left;">
LDL-cholesterol
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13086
</td>
<td style="text-align:right;">
6313
</td>
<td style="text-align:left;">
0.07 (95%CI = 0.07 - 0.08)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.03 (SE = 0.05)
</td>
<td style="text-align:left;">
1.03 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0285
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009043"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009043</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LDL
</td>
<td style="text-align:left;">
LDL-cholesterol
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
72866
</td>
<td style="text-align:right;">
1953
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.03 - 0.06)
</td>
<td style="text-align:left;">
1 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.05 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0957
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.LDLC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.LDLC.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LDL
</td>
<td style="text-align:left;">
LDL-cholesterol
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
291538
</td>
<td style="text-align:right;">
73172
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.11 - 0.12)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.97 - 0.97)
</td>
<td style="text-align:left;">
0.1 (SE = 0.01)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2697
</td>
<td style="text-align:right;">
30780
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LYM
</td>
<td style="text-align:left;">
Lymphocyte
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2681
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0 (95%CI = 0 - 0.06)
</td>
<td style="text-align:left;">
1 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
0.08 (SE = 0.28)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0135
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009037"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009037</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LYM
</td>
<td style="text-align:left;">
Lymphocyte
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
95717
</td>
<td style="text-align:right;">
1997
</td>
<td style="text-align:left;">
0.16 (95%CI = 0.14 - 0.17)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.91 - 0.96)
</td>
<td style="text-align:left;">
0.08 (SE = 0.01)
</td>
<td style="text-align:left;">
1.05 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.LYM.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.LYM.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
LYM
</td>
<td style="text-align:left;">
Lymphocyte
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
296570
</td>
<td style="text-align:right;">
74442
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.08 - 0.08)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.94 - 0.94)
</td>
<td style="text-align:left;">
0.18 (SE = 0.01)
</td>
<td style="text-align:left;">
1.18 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6070
</td>
<td style="text-align:right;">
30120
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCH
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2742
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.21 (95%CI = 0.18 - 0.27)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.26 (SE = 0.22)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0225
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009063"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009063</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCH
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
128028
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.1 - 0.13)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.98)
</td>
<td style="text-align:left;">
0.19 (SE = 0.03)
</td>
<td style="text-align:left;">
1.11 (SE = 0.02)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCH.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCH.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCH
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297080
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.19 (95%CI = 0.18 - 0.19)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.94 - 0.95)
</td>
<td style="text-align:left;">
0.25 (SE = 0.03)
</td>
<td style="text-align:left;">
1.12 (SE = 0.02)
</td>
<td style="text-align:right;">
1.4781
</td>
<td style="text-align:right;">
30050
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCHC
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin concentration
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2744
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.04 - 0.16)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.01 (SE = 0.23)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0225
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009064"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009064</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCHC
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin concentration
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
135482
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.04 (95%CI = 0.03 - 0.05)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.98 - 1)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.06 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCHC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCHC.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCHC
</td>
<td style="text-align:left;">
Mean corpuscular hemoglobin concentration
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297079
</td>
<td style="text-align:right;">
74573
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.05 - 0.05)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.97 - 0.97)
</td>
<td style="text-align:left;">
0.06 (SE = 0.01)
</td>
<td style="text-align:left;">
1.04 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1843
</td>
<td style="text-align:right;">
30060
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCV
</td>
<td style="text-align:left;">
Mean corpuscular volume
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2742
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.23 (95%CI = 0.18 - 0.29)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.41 (SE = 0.23)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0225
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009065"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009065</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCV
</td>
<td style="text-align:left;">
Mean corpuscular volume
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
129832
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.1 - 0.13)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.98)
</td>
<td style="text-align:left;">
0.22 (SE = 0.03)
</td>
<td style="text-align:left;">
1.1 (SE = 0.02)
</td>
<td style="text-align:right;">
1.2531
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCV.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MCV.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MCV
</td>
<td style="text-align:left;">
Mean corpuscular volume
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297083
</td>
<td style="text-align:right;">
74574
</td>
<td style="text-align:left;">
0.22 (95%CI = 0.21 - 0.22)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.25 (SE = 0.03)
</td>
<td style="text-align:left;">
1.13 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5144
</td>
<td style="text-align:right;">
30040
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MON
</td>
<td style="text-align:left;">
Monocyte
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2681
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0.15 (95%CI = 0.06 - 0.24)
</td>
<td style="text-align:left;">
1 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
-0.25 (SE = 0.22)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0135
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009038"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009038</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MON
</td>
<td style="text-align:left;">
Monocyte
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
95119
</td>
<td style="text-align:right;">
1997
</td>
<td style="text-align:left;">
0.1 (95%CI = 0.09 - 0.12)
</td>
<td style="text-align:left;">
0.98 (95%CI = 0.97 - 0.99)
</td>
<td style="text-align:left;">
0.08 (SE = 0.01)
</td>
<td style="text-align:left;">
1.09 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MON.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.MON.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
MON
</td>
<td style="text-align:left;">
Monocyte
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
296570
</td>
<td style="text-align:right;">
74442
</td>
<td style="text-align:left;">
0.13 (95%CI = 0.13 - 0.14)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.95 - 0.95)
</td>
<td style="text-align:left;">
0.19 (SE = 0.02)
</td>
<td style="text-align:left;">
1.2 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5144
</td>
<td style="text-align:right;">
30130
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
NEU
</td>
<td style="text-align:left;">
Neutrophil
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2671
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.1 - 0.15)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.1 (SE = 0.23)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0105
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009040"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009040</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
NEU
</td>
<td style="text-align:left;">
Neutrophil
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
82810
</td>
<td style="text-align:right;">
1997
</td>
<td style="text-align:left;">
0.07 (95%CI = 0.05 - 0.09)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.98 - 0.99)
</td>
<td style="text-align:left;">
0.11 (SE = 0.01)
</td>
<td style="text-align:left;">
1.05 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.NEU.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.NEU.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
NEU
</td>
<td style="text-align:left;">
Neutrophil
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
296570
</td>
<td style="text-align:right;">
74442
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.14 - 0.15)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.15 (SE = 0.01)
</td>
<td style="text-align:left;">
1.15 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5401
</td>
<td style="text-align:right;">
30140
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
PLT
</td>
<td style="text-align:left;">
Platelet
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2723
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.02 - 0.21)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0 - 1)
</td>
<td style="text-align:left;">
0.26 (SE = 0.25)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0225
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009036"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009036</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
PLT
</td>
<td style="text-align:left;">
Platelet
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
148623
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.15 (95%CI = 0.14 - 0.17)
</td>
<td style="text-align:left;">
0.95 (95%CI = 0.94 - 0.96)
</td>
<td style="text-align:left;">
0.18 (SE = 0.02)
</td>
<td style="text-align:left;">
1.13 (SE = 0.01)
</td>
<td style="text-align:right;">
1.3101
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.PLT.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.PLT.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
PLT
</td>
<td style="text-align:left;">
Platelet
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297082
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.24 (95%CI = 0.24 - 0.24)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.27 (SE = 0.02)
</td>
<td style="text-align:left;">
1.2 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6108
</td>
<td style="text-align:right;">
30080
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
RBC
</td>
<td style="text-align:left;">
Red blood cell
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2744
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.32 (95%CI = 0.24 - 0.42)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.97 - 1)
</td>
<td style="text-align:left;">
0.54 (SE = 0.24)
</td>
<td style="text-align:left;">
1 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0165
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009062"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009062</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
RBC
</td>
<td style="text-align:left;">
Red blood cell
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
153512
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.07 - 0.1)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.96 - 0.98)
</td>
<td style="text-align:left;">
0.12 (SE = 0.01)
</td>
<td style="text-align:left;">
1.12 (SE = 0.02)
</td>
<td style="text-align:right;">
1.2531
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.RBC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.RBC.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
RBC
</td>
<td style="text-align:left;">
Red blood cell
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297084
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.17 (95%CI = 0.17 - 0.18)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.93 - 0.93)
</td>
<td style="text-align:left;">
0.2 (SE = 0.02)
</td>
<td style="text-align:left;">
1.19 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6108
</td>
<td style="text-align:right;">
30010
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
SBP
</td>
<td style="text-align:left;">
Sytolic blood pressure
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13613
</td>
<td style="text-align:right;">
6658
</td>
<td style="text-align:left;">
0.17 (95%CI = 0.13 - 0.22)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0 - 0.98)
</td>
<td style="text-align:left;">
0.06 (SE = 0.06)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0285
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009053"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009053</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
SBP
</td>
<td style="text-align:left;">
Sytolic blood pressure
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
145505
</td>
<td style="text-align:right;">
1976
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.09 - 0.12)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.9 - 0.96)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.08 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2005
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.SBP.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.SBP.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
SBP
</td>
<td style="text-align:left;">
Sytolic blood pressure
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
289696
</td>
<td style="text-align:right;">
72639
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.12 - 0.12)
</td>
<td style="text-align:left;">
0.89 (95%CI = 0.88 - 0.9)
</td>
<td style="text-align:left;">
0.13 (SE = 0.01)
</td>
<td style="text-align:left;">
1.1 (SE = 0.01)
</td>
<td style="text-align:right;">
1.5995
</td>
<td style="text-align:right;">
4080
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
TC
</td>
<td style="text-align:left;">
Total cholesterol
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13116
</td>
<td style="text-align:right;">
6324
</td>
<td style="text-align:left;">
0.05 (95%CI = 0.05 - 0.06)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.02 (SE = 0.05)
</td>
<td style="text-align:left;">
1.03 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0285
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009042"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009042</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
TC
</td>
<td style="text-align:left;">
Total cholesterol
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
135808
</td>
<td style="text-align:right;">
1955
</td>
<td style="text-align:left;">
0.08 (95%CI = 0.07 - 0.09)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
0.07 (SE = 0.01)
</td>
<td style="text-align:left;">
1.07 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.TC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.TC.v1.zip</a>
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
TC
</td>
<td style="text-align:left;">
Total cholesterol
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
292046
</td>
<td style="text-align:right;">
73305
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.12 - 0.12)
</td>
<td style="text-align:left;">
0.96 (95%CI = 0.96 - 0.97)
</td>
<td style="text-align:left;">
0.11 (SE = 0.01)
</td>
<td style="text-align:left;">
1.07 (SE = 0.02)
</td>
<td style="text-align:right;">
1.3068
</td>
<td style="text-align:right;">
30690
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
TRUE
</td>
</tr>
<tr>
<td style="text-align:left;">
TG
</td>
<td style="text-align:left;">
Triglycerides
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
13115
</td>
<td style="text-align:right;">
6323
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.08 - 0.15)
</td>
<td style="text-align:left;">
1 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
0.08 (SE = 0.05)
</td>
<td style="text-align:left;">
1.02 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0315
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009045"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009045</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
TG
</td>
<td style="text-align:left;">
Triglycerides
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
111667
</td>
<td style="text-align:right;">
1954
</td>
<td style="text-align:left;">
0.07 (95%CI = 0.06 - 0.09)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 1)
</td>
<td style="text-align:left;">
0.13 (SE = 0.03)
</td>
<td style="text-align:left;">
1.05 (SE = 0.01)
</td>
<td style="text-align:right;">
1.1459
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.TG.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.TG.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
TG
</td>
<td style="text-align:left;">
Triglycerides
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
291813
</td>
<td style="text-align:right;">
73241
</td>
<td style="text-align:left;">
0.16 (95%CI = 0.16 - 0.16)
</td>
<td style="text-align:left;">
0.94 (95%CI = 0.93 - 0.94)
</td>
<td style="text-align:left;">
0.18 (SE = 0.02)
</td>
<td style="text-align:left;">
1.14 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5696
</td>
<td style="text-align:right;">
30870
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
WBC
</td>
<td style="text-align:left;">
White blood cell
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
UGR
</td>
<td style="text-align:right;">
2741
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.03 (95%CI = 0.03 - 0.05)
</td>
<td style="text-align:left;">
1 (95%CI = 1 - 1)
</td>
<td style="text-align:left;">
0.03 (SE = 0.26)
</td>
<td style="text-align:left;">
1.01 (SE = 0.01)
</td>
<td style="text-align:right;">
1.0105
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009061"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST009001-GCST010000/GCST009061</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
WBC
</td>
<td style="text-align:left;">
White blood cell
</td>
<td style="text-align:left;">
EAS
</td>
<td style="text-align:left;">
BBJ
</td>
<td style="text-align:right;">
154355
</td>
<td style="text-align:right;">
1999
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.11 - 0.14)
</td>
<td style="text-align:left;">
0.93 (95%CI = 0.91 - 0.95)
</td>
<td style="text-align:left;">
0.11 (SE = 0.01)
</td>
<td style="text-align:left;">
1.1 (SE = 0.01)
</td>
<td style="text-align:right;">
1.2531
</td>
<td style="text-align:right;">
NA
</td>
<td style="text-align:left;">
<a
href="https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.WBC.v1.zip"
class="uri">https://humandbs.dbcls.jp/files/hum0197/hum0197.v3.BBJ.WBC.v1.zip</a>
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
<tr>
<td style="text-align:left;">
WBC
</td>
<td style="text-align:left;">
White blood cell
</td>
<td style="text-align:left;">
EUR
</td>
<td style="text-align:left;">
UKB
</td>
<td style="text-align:right;">
297079
</td>
<td style="text-align:right;">
74575
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.14 - 0.14)
</td>
<td style="text-align:left;">
0.92 (95%CI = 0.92 - 0.92)
</td>
<td style="text-align:left;">
0.17 (SE = 0.01)
</td>
<td style="text-align:left;">
1.18 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6334
</td>
<td style="text-align:right;">
30000
</td>
<td style="text-align:left;">
NA
</td>
<td style="text-align:left;">
FALSE
</td>
</tr>
</tbody>
</table>
</div>
</details>
<hr />
</div>
</div>
<div id="main-analysis" class="section level1">
<h1>Main analysis</h1>
<hr />
<div id="pgs-calculation" class="section level2">
<h2>PGS calculation</h2>
<p>We will do this using GenoPred.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>######
# gwas_list
######

library(data.table)

# Subset original gwas_list to include selected traits
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)
pheno&lt;-gsub(&#39;_.*&#39;,&#39;&#39;, gwas_list$name)
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
gwas_list&lt;-gwas_list[pheno %in% selected_traits,]
gwas_list$label&lt;-paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

write.table(
  gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;, 
  col.names = T, 
  row.names = F, 
  quote = F)

######
# gwas_groups
######

gwas_groups_eas&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_BBJ&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_BBJ&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+BBJ)&quot;, &#39;&quot;&#39;)
)

gwas_groups_afr&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_UGR&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_UGR&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+UGR)&quot;, &#39;&quot;&#39;)
)

gwas_groups&lt;-rbind(gwas_groups_eas, gwas_groups_afr)

write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;,&#39;prscsx&#39;,&#39;xwing&#39;]&quot;,
  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, # xwing run with 20 cores
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml \
  target_pgs  -n</code></pre>
<div class="note-box">
<p><strong>Note</strong>: The LD reference data for SBayesRC, LDpred2,
QuickPRS, and QuickPRS+LEOPARD can be download using the links
below:</p>
<ul>
<li>LDpred2
<ul>
<li>AFR: <a
href="https://drive.google.com/file/d/1Fc3v_N1m-ocGqw6E4HpzEVq43jS2oWUQ/view?usp=sharing">downoad
link</a></li>
<li>EAS: <a
href="https://drive.google.com/file/d/1NwGHs5zwk1p4Vui-1cRb84xkoYld-kyK/view?usp=sharing">download
link</a></li>
<li>EUR: <a
href="https://drive.google.com/file/d/1Vo4QAw7HiI3Y5Wk1y5-9JLgW34U4KPTZ/view?usp=sharing">download
link</a></li>
</ul></li>
<li>SBayesRC
<ul>
<li>AFR: <a
href="https://drive.google.com/file/d/1osaNy_EyFAoIQd2ZNOoRJbZsr9Vwr9NP/view?usp=sharing">download
link</a></li>
<li>EAS: <a
href="https://drive.google.com/file/d/1eUtC9JEodJf2tnDFbU-xabO_UwL2JutF/view?usp=sharing">download
link</a></li>
<li>EUR: <a
href="https://drive.google.com/file/d/1O05z8nQhPqATuhfQvhJq7LEuxS0bzlXm/view?usp=sharing">download
link</a></li>
</ul></li>
</ul>
</div>
</details>
<hr />
</div>
<div id="pgs-evaluation" class="section level2">
<h2>PGS evaluation</h2>
<p>Lets use the model builder script which implements nested 10 fold
cross validation. Similar set up to previous paper, evaluating a model
containing the best PGS selected by 10-fold cross validation, a model
containing the PGS selected by pseudovalidation (if available), and an
elastic net model containing all PGS from a given method. We will need
to update the model builder script to achieve this</p>
<p>We want to see: - Performance of pseudo and top1 models for
single-source methods - Performance of pseudo and top1 models for
multi-source methods - Performance of multi-source methods: - Using
crossval for tuning step 1 and 2 - Using pseudoval for tuning step 1 and
2 - Using pseudoval for tuning step 1 and crossval for tuning step 2</p>
<p>To achieve this. Will need to define groups of predictors for step 1
modelling, and groups that should then be linearly combined.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]
  scores_i$multi &lt;- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 &lt;-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                     !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_single_top1$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_single_pseudo$predictor)

      ####
      # Make groups for multi-single-source pseudo scores
      ####
      
      scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi_single_pseudo$name[i],
          pgs_method = scores_i_j_multi_single_pseudo$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi_single_pseudo$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_multi_single_pseudo$predictor[i])
          )
        )
      }
      
      scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_multi_single_pseudo$predictor)
      
      scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)

      ####
      # Make groups for the Multi-Source methods
      ####
      
      scores_i_j_multi &lt;- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]

      # Split top1 scores by target population
      # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
      scores_i_j_multi_top1&lt;-NULL
      for(i in 1:which(scores_i_j_multi$method %in% c(&#39;prscsx&#39;))){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_top1 &lt;- rbind(scores_i_j_multi_top1, tmp)
        }
      }

      # Split pop-specific pseudo scores by target population
      scores_i_j_multi_pop_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_pop_pseudo &lt;- rbind(scores_i_j_multi_pop_pseudo, tmp)
        }
      }
      
      # Create pseudo score for multi-source methods
      scores_i_j_multi_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi$name[i],
          pgs_method = scores_i_j_multi$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi$name[i], &#39;_&#39;, param)))

        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
          )
        )
        
        tmp &lt;- scores_i_j_multi[i,]
        tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
        tmp$top1 &lt;- paste0(&#39;EUR_&#39;, disc_pop_j_2)
        tmp$predictor &lt;-
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
        
        scores_i_j_multi_pseudo &lt;- rbind(scores_i_j_multi_pseudo, tmp)
      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo, 
        scores_i_j_multi_single_pseudo,
        scores_i_j_multi_top1,
        scores_i_j_multi_pop_pseudo,
        scores_i_j_multi_pseudo
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
      ####
      # Make a group that will combined all population specific PGS
      ####
      
      predictors_i_all &lt;- predictors_i[predictors_i$top1 %in% c(&#39;EUR&#39;,&#39;AFR&#39;,&#39;EAS&#39;),]
      predictors_i_all$multi &lt;- &#39;all&#39;
      predictors_i&lt;-rbind(predictors_i, predictors_i_all)
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EUR EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 --exclude=erc-hpc-comp058 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5&quot;
      fi
    done
  done
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTune or IndivTune
  tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
  tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Count the number of traits each method is best
tmp &lt;- res_eval_simp[res_eval_simp$label != &#39;All&#39;,]
best_groups &lt;-
  do.call(rbind, by(tmp, list(
    tmp$Target,
    tmp$gwas_group,
    tmp$Trait
  ), function(subset) {
    subset[which.max(subset$R),]  # Select row with max R
  }))

best_counts &lt;- as.data.frame(table(paste0(best_groups$label,&#39;:&#39;, best_groups$Model), best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) &lt;- c(&quot;label&quot;, &quot;gwas_group&quot;, &quot;Target&quot;, &quot;count&quot;)
best_counts$Model&lt;-gsub(&#39;.*:&#39;,&#39;&#39;,best_counts$label)
best_counts$label&lt;-gsub(&#39;:.*&#39;,&#39;&#39;,best_counts$label)
best_counts$label &lt;- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts &lt;- best_counts[best_counts$count &gt; 0, ]

# Create the plot
ggplot(best_counts[best_counts$Target != &#39;EUR&#39;,], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  facet_wrap(~ Target, scales = &#39;free_x&#39;) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() + 
  labs(
    title = &quot;Number of times each method is the best&quot;,
    x = &quot;Method&quot;,
    y = &quot;Count&quot;,
    fill = &quot;GWAS Group&quot;
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#############################
# Identify best methods that improved prediction over next best method by 2% for any trait
# Filter out &#39;All&#39; from the data
tmp &lt;- res_eval_simp[res_eval_simp$label != &#39;All&#39;,]

# Identify the best method for each trait, but only if it improves by &gt;2%
best_groups &lt;- do.call(rbind, by(tmp, list(tmp$Target, tmp$gwas_group, tmp$Trait), function(subset) {
  if (nrow(subset) &gt; 1) {
    # Sort by R in descending order
    subset &lt;- subset[order(-subset$R), ]
    # Check if the best method is more than 2% better than the second best
    if ((subset$R[1] - subset$R[2]) / subset$R[2] &gt; 0.02) {
      return(subset[1, ])  # Return the best method if criteria met
    } 
  } else {
    return(subset[1, ])  # Handle cases with only one method
  }
  return(NULL)  # Return NULL if criteria not met
}))

# Create a count table with label and model combined
best_counts &lt;- as.data.frame(table(paste0(best_groups$label,&#39;:&#39;, best_groups$Model), 
                                   best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) &lt;- c(&quot;label&quot;, &quot;gwas_group&quot;, &quot;Target&quot;, &quot;count&quot;)
best_counts$Model &lt;- gsub(&#39;.*:&#39;, &#39;&#39;, best_counts$label)
best_counts$label &lt;- gsub(&#39;:.*&#39;, &#39;&#39;, best_counts$label)
best_counts$label &lt;- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts &lt;- best_counts[best_counts$count &gt; 0, ]

# Create the plot
library(ggplot2)
ggplot(best_counts[best_counts$Target != &#39;EUR&#39;,], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  facet_wrap(~ Target, scales = &#39;free_x&#39;) +
  theme_minimal() +
  labs(
    title = &quot;Number of times each method is the best (with &gt;2% improvement)&quot;,
    x = &quot;Method&quot;,
    y = &quot;Count&quot;,
    fill = &quot;Model&quot;
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


#############################


# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/plots&#39;)

for(pheno_i in selected_traits){
  tmp &lt;- res_eval_simp[res_eval_simp$Trait == pheno_i,]
  #tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
  tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
  tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)
  tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

  png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/&#39;, pheno_i,&#39;.png&#39;), res=300, width = 3400, height = 2000, units = &#39;px&#39;)
  plot_tmp&lt;-ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
  print(plot_tmp)
  dev.off()
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/r_eval.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot average performance across phenotypes for EUR using AFR or EAS GWAS
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target == &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.png&#39;), res=300, width = 4000, height = 1500, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot performance of -multi models trained using LEOPARD vs using indiv-level data
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = unique(tmp$label[order(!(grepl(&#39;Multi&#39;, tmp$label)), tmp$label)]))
tmp&lt;-tmp[grepl(&#39;multi&#39;, tmp$label),]
tmp &lt;- tmp[tmp$Model != &#39;Multi-IndivTune&#39;,]
tmp$Model&lt;-as.character(tmp$Model)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;]&lt;-&#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;]&lt;-&#39;LEOPARD&#39;
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_leopard.png&#39;), res=300, width = 1500, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Make simplified plot
# Just show performance when using IndivTrain (or SumStat), and Remove &#39;All&#39; model, with both GWAS.
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Method != &#39;all&#39;,]
tmp &lt;- tmp[tmp$Source  == &#39;Multi&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]
tmp&lt;-tmp[tmp$Model == &#39;IndivTune&#39;,]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_simple.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23, fill = &#39;black&#39;) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()

tmp&lt;-tmp[tmp$Method %in% c(&#39;ldpred2&#39;,&#39;prscsx&#39;,&#39;xwing&#39;),]
png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_simple_ldpred2.png&#39;), res=300, width = 500, height = 500, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
  #  geom_point(stat=&quot;identity&quot;, position=position_dodge(1), fill = &#39;#3399FF&#39;) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23, fill = &#39;#3399FF&#39;) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()


####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      comp_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_comp.txt&#39;
          )
        )
      comp_i&lt;-mirror_comp(comp_i)
      comp_i$Target&lt;-targ_pop_i
      comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_comp_i&lt;-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTune&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTune&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;gwas_group&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;)]),]

res_comp_all$r_diff_rel &lt;- res_comp_all$R_diff / res_comp_all$Model_2_R

# Calculate relative improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

# Calculate relative improvement for sbayesrc-multi vs sbayesrc in EUR target as example
tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- res_comp_all
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;pheno&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;, &#39;R_diff_pval&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;, &#39;Trait&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$Trait, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/r_diff.csv&#39;, row.names=F)

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
    res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample&lt;-&#39;A&#39;
    res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
      cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i &lt;-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = &quot;BHHR&quot;,
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$Model_1_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$Model_2_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$R_diff &lt;- meta_res_comp_i$es
        tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$R_diff &lt;- NA
        tmp$R_diff_SE &lt;- NA
        tmp$R_diff_z &lt;- NA
        tmp$R_diff_p &lt;- NA
      }
      meta_res_comp &lt;- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Extract average improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

# Extract average improvement for sbayesrc-multi vs sbayesrc in EUR as example
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

# Extract average improvement for sbayesrc in EUR compared to all model
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p


# Compare QuickPRS-Multi vs QuickPRS to evaluate LEOPARD performance
tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-AFR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;AFR&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-EAS.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EAS&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- meta_res_comp
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp$`Percentage change (R difference / Model 2 R)` &lt;- paste0(round(tmp$R_diff_perc * 100, 1), &#39;%&#39;)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;,&quot;Percentage change (R difference / Model 2 R)&quot;, &#39;R_diff_p&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;Percentage change (R difference / Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/r_diff_average.csv&#39;, row.names=F)

############

# Group differences
meta_res_comp$R_diff_catagory &lt;- cut(
    meta_res_comp$R_diff,
    breaks = c(-Inf, -0.08, -0.025, -0.002, 0.002, 0.025, 0.08, Inf),
    labels = c(&#39;&lt; -0.08&#39;, &#39;-0.08 - -0.025&#39;, &#39;-0.025 - -0.002&#39;, &#39;-0.002 - 0.002&#39;, &#39;0.002 - 0.025&#39;, &#39;0.025 - 0.08&#39;, &#39;&gt; 0.08&#39;),
    right = FALSE
)
meta_res_comp$R_diff_catagory &lt;- factor(meta_res_comp$R_diff_catagory, levels = rev(levels(meta_res_comp$R_diff_catagory)))

# Assign significance stars
meta_res_comp$indep_star&lt;-&#39; &#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 0.05]&lt;-&#39;*&#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-3]&lt;-&#39;**&#39;
# meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-6]&lt;-&#39;***&#39;

meta_res_comp&lt;-meta_res_comp[order(meta_res_comp$Discovery1, meta_res_comp$Discovery2, meta_res_comp$Method1),]

for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){

    tmp &lt;- meta_res_comp[meta_res_comp$Target == targ_pop_i, ]

    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;
    
    tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
    tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)
    
    tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
    tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
    tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
    tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
    
    tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
    tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

    tmp$label1 &lt;- factor(tmp$label1, levels = model_order)
    tmp$label2 &lt;- factor(tmp$label2, levels = model_order)

    tmp&lt;-tmp[order(tmp$label1, tmp$label2),]
    
    tmp$label1 &lt;- paste0(tmp$label1,&quot; (&quot;, ifelse(tmp$Model1 == &#39;SumStatTune&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)
    tmp$label2 &lt;- paste0(tmp$label2,&quot; (&quot;, ifelse(tmp$Model2 == &#39;SumStatTune&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)

    tmp$label1 &lt;- factor(tmp$label1, levels = unique(tmp$label1))
    tmp$label2 &lt;- factor(tmp$label2, levels = unique(tmp$label2))
    
    tmp &lt;- tmp[tmp$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i), ]
    
    plot_tmp &lt;- ggplot(data = tmp, aes(label2, label1, fill = R_diff_catagory)) +
      geom_tile(color = &quot;white&quot;, show.legend = TRUE) +
      labs(y = &#39;Test&#39;, x = &#39;Comparison&#39;, fill = &#39;R difference&#39;, title = paste0(&#39;Target: &#39;, targ_pop_i)) +
      facet_grid(Discovery1 ~ Discovery2, scales = &#39;free&#39;, space = &#39;free&#39;, switch=&quot;both&quot;) +
      geom_text(
        data = tmp,
        aes(label2, label1, label = indep_star),
        color = &quot;black&quot;,
        size = 4,
        angle = 0,
        vjust = 0.8
      ) +
      scale_fill_brewer(
        breaks = levels(tmp$R_diff_catagory),
        palette = &quot;RdBu&quot;,
        drop = F,
        na.value = &#39;grey&#39;
      ) +
      theme_half_open() +
      background_grid() +
      panel_border() +
      theme(axis.text.x = element_text(
        angle = 45,
        vjust = 1,
        hjust = 1
      ))
    
    png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_diff.Discovery_EUR_&#39;, disc_pop_i,&#39;.Target_&#39;, targ_pop_i, &#39;.png&#39;), res=300, width = 4400, height = 3200, units = &#39;px&#39;)
      print(plot_tmp)
    dev.off()
  }
}

####
# Plot relative improvement of methods
####
# Use ptclump IndivTune using EUR GWAS as the reference, as provides an interpretable scale

meta_res_comp_ptclump_top1&lt;-meta_res_comp[meta_res_comp$Method2 == &#39;all&#39; &amp; meta_res_comp$Source2 == &#39;Multi&#39;,]
meta_res_comp_ptclump_top1$reference_point&lt;-F
meta_res_comp_ptclump_top1$reference_point[meta_res_comp_ptclump_top1$Method1 == &#39;all&#39; &amp; meta_res_comp_ptclump_top1$Source1 == &#39;Multi&#39;]&lt;-T
meta_res_comp_ptclump_top1$R_diff[is.na(meta_res_comp_ptclump_top1$R_diff)]&lt;-0
meta_res_comp_ptclump_top1$Discovery1 &lt;- factor(meta_res_comp_ptclump_top1$Discovery1, levels=rev(levels(meta_res_comp_ptclump_top1$Discovery1)))

res_comp_all_ptclump_top1&lt;-res_comp_all[res_comp_all$Method2 == &#39;all&#39; &amp; res_comp_all$Source2 == &#39;Multi&#39;,]
res_comp_all_ptclump_top1$Discovery1 &lt;-  factor(res_comp_all_ptclump_top1$Discovery1, levels=levels(meta_res_comp_ptclump_top1$Discovery1))

# Create data to plot reference points
meta_res_comp_reference &lt;- meta_res_comp_ptclump_top1
meta_res_comp_reference$R_diff[meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
meta_res_comp_reference$R_diff_SE [meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
res_comp_all_ptclump_top1$reference_point&lt;-F

meta_tmp &lt;- meta_res_comp_ptclump_top1
meta_tmp &lt;- merge(meta_tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp$label[is.na(meta_tmp$label)] &lt;- &#39;All&#39;
meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;] &lt;- paste0(meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp$label &lt;- factor(meta_tmp$label, levels = model_order)
meta_tmp$Discovery_clean &lt;- as.character(meta_tmp$Discovery1)
meta_tmp$Discovery_clean[meta_tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp$Discovery_clean &lt;- factor(meta_tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp$Target &lt;- paste0(meta_tmp$Target, &#39; Target&#39;)
meta_tmp$Model1 &lt;- factor(meta_tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

meta_tmp_ref &lt;- meta_res_comp_reference
meta_tmp_ref &lt;- merge(meta_tmp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp_ref$label[is.na(meta_tmp_ref$label)] &lt;- &#39;All&#39;
meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;] &lt;- paste0(meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp_ref$label &lt;- factor(meta_tmp_ref$label, levels = model_order)
meta_tmp_ref$Discovery_clean &lt;- as.character(meta_tmp_ref$Discovery1)
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp_ref$Discovery_clean &lt;- factor(meta_tmp_ref$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp_ref$Target &lt;- paste0(meta_tmp_ref$Target, &#39; Target&#39;)
meta_tmp_ref$Model1 &lt;- factor(meta_tmp_ref$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

tmp &lt;- res_comp_all_ptclump_top1
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery1)
tmp$Discovery_clean[tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model1 &lt;- factor(tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

ggplot(meta_tmp, aes(x=label, y=R_diff , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff - R_diff_SE,
          ymax = R_diff + R_diff_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R_diff (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


# Plot as % change
meta_tmp$R_diff_perc &lt;- meta_tmp$R_diff / meta_tmp$Model_2_R
meta_tmp_ref$R_diff_perc &lt;- meta_tmp_ref$R_diff / meta_tmp_ref$Model_2_R
tmp$R_diff_perc &lt;- tmp$R_diff / tmp$Model_2_R

meta_tmp$R_diff_perc_SE &lt;- meta_tmp$R_diff_SE / meta_tmp$Model_2_R

library(scales)
ggplot(meta_tmp, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R diff. (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# Simplify results showing results only with or without training data
meta_tmp_simple &lt;- meta_tmp
meta_tmp_simple$Model1[meta_tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model1[meta_tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_2 %in% res_eval_simp$Group,]

meta_tmp_ref_simple &lt;- meta_tmp_ref
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_2 %in% res_eval_simp$Group,]

tmp_simple &lt;- tmp
tmp_simple$Model1[tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model1[tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple$Model2[tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model2[tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple&lt;-tmp_simple[tmp_simple$Model_1 %in% res_eval_simp$Group,]
tmp_simple&lt;-tmp_simple[tmp_simple$Model_2 %in% res_eval_simp$Group,]

# Export plot for manuscript
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r.perc_improv.png&#39;, width = 3200, height = 2000, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target != &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
#    geom_boxplot(
#      data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
#        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
#        position = position_dodge(0.7),
#        alpha = 0.3
#      ) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()

# Plot for EUR
meta_tmp_simple$Discovery_clean &lt;- paste0(meta_tmp_simple$Discovery1,&#39; GWAS&#39;)
meta_tmp_ref_simple$Discovery_clean &lt;- paste0(meta_tmp_ref_simple$Discovery1,&#39; GWAS&#39;)
tmp_simple$Discovery_clean &lt;- paste0(tmp_simple$Discovery1,&#39; GWAS&#39;)

meta_tmp_simple&lt;-meta_tmp_simple[!duplicated(meta_tmp_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;), with=F]),]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[!duplicated(meta_tmp_ref_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;), with=F]),]
tmp_simple&lt;-tmp_simple[!duplicated(tmp_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;,&#39;pheno&#39;), with=F]),]

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.perc_improv.png&#39;, width = 4000, height = 1500, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target == &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_simple[tmp_simple$Target == &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target == &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()

########
# Plot relative improvement of LEOPARD over IndivTune of SumStatTune scores
########

# meta res
meta_res_comp_ref &lt;- meta_res_comp[meta_res_comp$Model2 == &#39;Multi-SumStatTune&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[meta_res_comp_ref$Method1 != &#39;all&#39; &amp; meta_res_comp_ref$Method2 != &#39;all&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[meta_res_comp_ref$Model1 == &#39;SumStatTune&#39; &amp; meta_res_comp_ref$Source1 == &#39;Multi&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[gsub(&#39;_multi&#39;,&#39;&#39;, meta_res_comp_ref$Method1) == gsub(&#39;_multi&#39;,&#39;&#39;, meta_res_comp_ref$Method2),]

meta_res_comp_ref$R_diff_perc &lt;- meta_res_comp_ref$R_diff / meta_res_comp_ref$Model_2_R
meta_res_comp_ref$R_diff_perc_SE &lt;- meta_res_comp_ref$R_diff_SE / meta_res_comp_ref$Model_2_R

meta_res_comp_ref$Discovery_clean &lt;- paste0(meta_res_comp_ref$Discovery1,&#39; GWAS&#39;)
meta_res_comp_ref$Discovery_clean[meta_res_comp_ref$Target != &#39;EUR&#39;] &lt;- &#39;EUR + Target-matched GWAS&#39;

meta_res_comp_ref &lt;- merge(meta_res_comp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_res_comp_ref$label[grepl(&#39;Multi&#39;, meta_res_comp_ref$Model1) &amp; !(meta_res_comp_ref$Method1 %in% pgs_group_methods)] &lt;- paste0(meta_res_comp_ref$label[grepl(&#39;Multi&#39;, meta_res_comp_ref$Model1) &amp; !(meta_res_comp_ref$Method1 %in% pgs_group_methods)], &#39;-multi&#39;)
meta_res_comp_ref$label &lt;- factor(meta_res_comp_ref$label, levels = model_order)

meta_res_comp_ref$Target_clean &lt;- paste0(meta_res_comp_ref$Target,&#39; Target&#39;)

# trait-specific res
res_comp_all_ref &lt;- res_comp_all[res_comp_all$Model2 == &#39;Multi-SumStatTune&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[res_comp_all_ref$Method1 != &#39;all&#39; &amp; res_comp_all_ref$Method2 != &#39;all&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[res_comp_all_ref$Model1 == &#39;SumStatTune&#39; &amp; res_comp_all_ref$Source1 == &#39;Multi&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[gsub(&#39;_multi&#39;,&#39;&#39;, res_comp_all_ref$Method1) == gsub(&#39;_multi&#39;,&#39;&#39;, res_comp_all_ref$Method2),]

res_comp_all_ref$R_diff_perc &lt;- res_comp_all_ref$R_diff / res_comp_all_ref$Model_2_R
res_comp_all_ref$R_diff_perc_SE &lt;- res_comp_all_ref$R_diff_SE / res_comp_all_ref$Model_2_R

res_comp_all_ref$Discovery_clean &lt;- paste0(res_comp_all_ref$Discovery1,&#39; GWAS&#39;)
res_comp_all_ref$Discovery_clean[res_comp_all_ref$Target != &#39;EUR&#39;] &lt;- &#39;EUR + Target-matched GWAS&#39;

res_comp_all_ref &lt;- merge(res_comp_all_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
res_comp_all_ref$label[grepl(&#39;Multi&#39;, res_comp_all_ref$Model1) &amp; !(res_comp_all_ref$Method1 %in% pgs_group_methods)] &lt;- paste0(res_comp_all_ref$label[grepl(&#39;Multi&#39;, res_comp_all_ref$Model1) &amp; !(res_comp_all_ref$Method1 %in% pgs_group_methods)], &#39;-multi&#39;)
res_comp_all_ref$label &lt;- factor(res_comp_all_ref$label, levels = model_order)

res_comp_all_ref$Target_clean &lt;- paste0(res_comp_all_ref$Target,&#39; Target&#39;)

tmp_meta&lt;-meta_res_comp_ref
tmp_all&lt;-res_comp_all_ref

tmp_meta&lt;-tmp_meta[!(tmp_meta$Method1 %in% c(&#39;prscsx&#39;,&#39;xwing&#39;)),]
tmp_meta&lt;-tmp_meta[tmp_meta$Target != &#39;EUR&#39;,]

tmp_all&lt;-tmp_all[!(tmp_all$Method1 %in% c(&#39;prscsx&#39;,&#39;xwing&#39;)),]
tmp_all&lt;-tmp_all[tmp_all$Target != &#39;EUR&#39;,]

library(ggrepel)

# plot
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_perc_improv.png&#39;, width = 1800, height = 1100, res= 300, units = &#39;px&#39;)

ggplot(tmp_meta, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp_meta$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Difference (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(. ~ Target_clean) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &#39;none&#39;
    )
dev.off()

# Now compare quickPRS-multi and prs-csx only with trait
tmp_meta&lt;-meta_res_comp_ref
tmp_all&lt;-res_comp_all_ref

tmp_meta&lt;- tmp_meta[tmp_meta$Target != &#39;EUR&#39; &amp; tmp_meta$Method1 %in% c(&#39;quickprs_multi&#39;,&#39;prscsx&#39;),]
tmp_all&lt;- tmp_all[tmp_all$Target != &#39;EUR&#39; &amp; tmp_all$Method1 %in% c(&#39;quickprs_multi&#39;,&#39;prscsx&#39;),]

library(ggrepel)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_perc_improv_restricted.png&#39;, width = 1500, height = 1500, res= 300, units = &#39;px&#39;)
ggplot(tmp_meta, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_all,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(. ~ Target_clean) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &#39;none&#39;
    ) +
    geom_text_repel(
      data = tmp_all[
        tmp_all$R_diff_perc &lt; -0.25,
      ],
      aes(label = pheno),  # label as percent with 1 decimal
      position = position_dodge(width = 0.7),
      size = 3,
      min.segment.length = 0,
      segment.color = NA,
      show.legend = FALSE
    )
dev.off()

# It shows PRS-CSx --meta flag is actually does very well, except when the AFR GWAS is very small (~2700).</code></pre>
</details>
<details>
<summary>
Show average improvement in AFR + EAS
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r.perc_improv.png"></p>
</div>
</div>
</details>
<details>
<summary>
Show average improvement in EUR
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r_eur.perc_improv.png"></p>
</div>
</div>
</details>
<details>
<summary>
Show LEOPARD comparison
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r_leopard.png"></p>
</div>
</div>
</details>
<hr />
</div>
<div id="leopardquickprs" class="section level2">
<h2>LEOPARD+QuickPRS</h2>
<p>Here we will compare the LEOPARD estimated weights for population
specific PGS, to the weights estimated using observed data in the UKB
target sample.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

###
# Read in weights estimated by LEOPARD (QuickPRS)
###

leopard_weights&lt;-NULL
scores_quickprs &lt;- scores$name[scores$method == &#39;quickprs_multi&#39;]
for(i in selected_traits){
  scores_i &lt;- scores_quickprs[grepl(paste0(&#39;^&#39;, i,&#39;_&#39;), scores_quickprs)]
  for(j in scores_i){
      weights_file &lt;- readRDS(paste0(outdir, &#39;/reference/pgs_score_files/leopard/&#39;, j, &#39;/ref-&#39;, j, &#39;.weights.rds&#39;))
      weights_file &lt;- data.frame(weights_file)
      
      weights &lt;-
        data.table(
          Target = do.call(c, lapply(names(weights_file), function(x) rep(x, 2))),
          Discovery = names(weights_file),
          Weight = do.call(c, lapply(weights_file, function(x) x)),
          Trait = i,
          Method = &#39;LEOPARD&#39;
        )
      
      leopard_weights &lt;- rbind(leopard_weights, weights)
  }
}

#####
# Read in the PGS weights estimated using UKB data
#####
# Read in the final model coefficients for multi-source methods

obs_weights&lt;-NULL
for(method_i in unique(scores$method)[!(unique(scores$method) %in% pgs_group_methods)]){
  scores_method&lt;-scores$name[scores$method == method_i]
  method_i &lt;- gsub(&#39;_multi&#39;,&#39;&#39;, method_i)

  for(i in selected_traits){
    for(j in c(&#39;EAS&#39;,&#39;AFR&#39;,&#39;EUR&#39;)){
      if(j == &#39;EUR&#39;){
        pops &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
      } else {
        pops &lt;- j
      }
      
      for(k in pops){
        model &lt;- fread(paste0(&#39;~/oliverpainfel/Analyses/crosspop/targ_&#39;, j, &#39;.disc_EUR_&#39;, k, &#39;/&#39;, i, &#39;/final_models/&#39;, method_i, &#39;.pseudo.multi.final_model.txt&#39;))
        model&lt;-model[-1,]
        
        # Set weight to zero if negative, as this is what LEOPARD does
        if(any(model$V2 &lt; 0)){
          model$V2[model$V2 &lt; 0] &lt;- 0
          model$V2[model$V2 &gt; 0] &lt;- 1
        }
        
        names(model) &lt;- c(&#39;x&#39;, &#39;BETA&#39;)
        model$Discovery[grepl(&#39;UKB&#39;, model$x)]&lt;-&#39;EUR&#39;
        model$Discovery[grepl(&#39;BBJ&#39;, model$x)]&lt;-&#39;EAS&#39;
        model$Discovery[grepl(&#39;UGR&#39;, model$x)]&lt;-&#39;AFR&#39;
        model$Target &lt;- j
        model$Weight &lt;- model$BETA/sum(model$BETA)
        model$Trait &lt;- i
        model$Method &lt;- method_i
        model&lt;-model[,c(&#39;Target&#39;,&#39;Discovery&#39;,&#39;Weight&#39;,&#39;Method&#39;,&#39;Trait&#39;), with=F]
        obs_weights&lt;-rbind(obs_weights, model)
      }
    }
  }
}

####
## Estimate weights if using the inverse variance weighting (realised this doesn&#39;t make sense as PGS are standardised whereas SNP effects in PRS-CSx are not)
####
#
## Read in GWAS descriptives
#gwas_desc&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)
#gwas_desc &lt;- gwas_desc[, c(&#39;Trait Label&#39;,&#39;Ancestry&#39;,&#39;GWAS N&#39;), with=F]
#names(gwas_desc)&lt;-c(&#39;trait&#39;,&#39;ancestry&#39;,&#39;n&#39;)
#gwas_desc&lt;-gwas_desc[gwas_desc$trait %in% selected_traits,]
#
#library(dplyr)
#library(tidyr)
#
## Reshape GWAS table to wide format
#wide_gwas &lt;- gwas_desc %&gt;%
#  pivot_wider(names_from = ancestry, values_from = n, values_fill = 0)
#
## Function to create rows for each pair
#make_weights_long &lt;- wide_gwas %&gt;%
#  rowwise() %&gt;%
#  do({
#    trait &lt;- .$trait
#    eur &lt;- .$EUR
#    afr &lt;- .$AFR
#    eas &lt;- .$EAS
#    
#    tibble(
#      Trait = trait,
#      Method = &quot;inverse_var&quot;,
#      Target = c(&quot;AFR&quot;, &quot;AFR&quot;, &quot;EUR&quot;, &quot;EUR&quot;, &quot;EUR&quot;, &quot;EAS&quot;, &quot;EAS&quot;),
#      Discovery = c(&quot;EUR&quot;, &quot;AFR&quot;, &quot;EUR&quot;, &quot;AFR&quot;, &quot;EAS&quot;, &quot;EUR&quot;, &quot;EAS&quot;),
#      Weight = c(
#        eur / (eur + afr), afr / (eur + afr),  # AFR target
#        eur / (eur + afr), afr / (eur + afr),  # EUR target (vs AFR)
#        eas / (eur + eas),                     # EUR target (vs EAS)
#        eur / (eur + eas), eas / (eur + eas)   # EAS target (vs EUR)
#      )
#    )
#  }) %&gt;%
#  bind_rows()

###
# Combine and compare
###

#both &lt;- do.call(rbind, list(obs_weights, leopard_weights, make_weights_long))
both &lt;- do.call(rbind, list(obs_weights, leopard_weights))

# Remove ptclump as it doesn&#39;t have a sumstattune method
both &lt;- both[both$Method != &#39;ptclump&#39;,]

both&lt;-merge(both, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x=T, sort = F)
both$label[is.na(both$label)] &lt;- both$Method[is.na(both$label)]
both$label &lt;- factor(both$label, levels=unique(both$label))

# Plot non-EUR target first
tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery != &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(10)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights.png&#39;, units = &#39;px&#39;, res = 300, width = 2500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(Target ~ .) +
  theme_half_open() +
  labs(title = &#39;Weight of target ancestry-matched PGS&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

# Plot EUR target
tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery != &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(10)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights_eur.png&#39;, units = &#39;px&#39;, res = 300, width = 2500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(Discovery ~ .) +
  theme_half_open() +
  labs(title = &#39;Weight of non-EUR PGS for EUR Target&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

###
# Check calibration of LEOPARD compared to QuickPRS observed weights
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide_eas &lt;- tmp_wide[tmp_wide$Discovery == &#39;EAS&#39;,]
tmp_wide_afr &lt;- tmp_wide[tmp_wide$Discovery == &#39;AFR&#39;,]

# Calculate metrics
rmse_afr &lt;- sqrt(mean((tmp_wide_afr$QuickPRS - tmp_wide_afr$LEOPARD)^2))
me_afr &lt;- mean(tmp_wide_afr$QuickPRS - tmp_wide_afr$LEOPARD)

rmse_eas &lt;- sqrt(mean((tmp_wide_eas$QuickPRS - tmp_wide_eas$LEOPARD)^2))
me_eas &lt;- mean(tmp_wide_eas$QuickPRS - tmp_wide_eas$LEOPARD)

# Create annotation data.frame
metrics_df &lt;- data.frame(
  Discovery = c(&quot;AFR&quot;, &quot;EAS&quot;),
  x = c(0.5, 0.5),         # Adjust positions as needed
  y = c(-0.05, -0.05),
  label = c(
    paste0(&quot;RMSE = &quot;, round(rmse_afr, 2), &quot;\nME = &quot;, round(me_afr, 2)),
    paste0(&quot;RMSE = &quot;, round(rmse_eas, 2), &quot;\nME = &quot;, round(me_eas, 2))
  )
)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
ggplot(tmp_wide[tmp_wide$Discovery != &#39;EUR&#39;,], aes(x = LEOPARD, y = QuickPRS)) +
  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
  geom_point(alpha = 0.7) +
  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) +
  labs(
    x = &quot;LEOPARD weight&quot;,
    y = &quot;Observed weight&quot;,
  ) +
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  ) +
  facet_grid(. ~ Discovery) +
  coord_fixed()    
dev.off()

####
## Check calibration of inverse_var compared to QuickPRS observed weights (again realised this doesn&#39;t make sense)
####
#
#tmp &lt;- both[both$Target != &#39;EUR&#39;,]
#tmp$Target&lt;-NULL
#tmp_wide &lt;- reshape(tmp, 
#                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
#                     timevar = &quot;label&quot;, 
#                     direction = &quot;wide&quot;)
#
#names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
#tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]
#
#tmp_wide_eas &lt;- tmp_wide[tmp_wide$Discovery == &#39;EAS&#39;,]
#tmp_wide_afr &lt;- tmp_wide[tmp_wide$Discovery == &#39;AFR&#39;,]
#
## Calculate metrics
#rmse_afr &lt;- sqrt(mean((tmp_wide_afr$QuickPRS - tmp_wide_afr$inverse_var)^2))
#me_afr &lt;- mean(tmp_wide_afr$QuickPRS - tmp_wide_afr$inverse_var)
#
#rmse_eas &lt;- sqrt(mean((tmp_wide_eas$QuickPRS - tmp_wide_eas$inverse_var)^2))
#me_eas &lt;- mean(tmp_wide_eas$QuickPRS - tmp_wide_eas$inverse_var)
#
## Create annotation data.frame
#metrics_df &lt;- data.frame(
#  Discovery = c(&quot;AFR&quot;, &quot;EAS&quot;),
#  x = c(0.5, 0.5),         # Adjust positions as needed
#  y = c(-0.05, -0.05),
#  label = c(
#    paste0(&quot;RMSE = &quot;, round(rmse_afr, 2), &quot;\nME = &quot;, round(me_afr, 2)),
#    paste0(&quot;RMSE = &quot;, round(rmse_eas, 2), &quot;\nME = &quot;, round(me_eas, 2))
#  )
#)
#
#png(&#39;~/oliverpainfel/Analyses/crosspop/plots/inverse_var_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
#ggplot(tmp_wide[tmp_wide$Discovery != &#39;EUR&#39;,], aes(x = inverse_var, y = QuickPRS)) +
#  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
#  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
#  geom_point(alpha = 0.7) +
#  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 1.5, size = 3.5) +
#  labs(
#    x = &quot;inverse_var weight&quot;,
#    y = &quot;Observed weight&quot;,
#  ) +
#  theme_half_open() +
#  panel_border() + 
#  theme(
#    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
#  ) +
#  facet_grid(. ~ Discovery) +
#  coord_fixed()    
#dev.off()

###
# Check calibration of observed weights across all methods
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[!(tmp$label %in% c(&#39;LEOPARD&#39;,&#39;inverse_var&#39;)),]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide &lt;- tmp_wide[tmp_wide$Discovery %in% c(&#39;EAS&#39;,&#39;AFR&#39;),]

metrics &lt;- NULL
for(i in c(&#39;EAS&#39;,&#39;AFR&#39;)){
  for(j in unique(tmp$label)){
    for(k in unique(tmp$label)){
      tmp_wide_i &lt;- tmp_wide[tmp_wide$Discovery == i,]
      rmse &lt;- sqrt(mean((tmp_wide_i[[j]] - tmp_wide_i[[k]])^2))
      me &lt;- mean(tmp_wide_i[[j]] - tmp_wide_i[[k]])
      
      metrics &lt;- rbind(
        metrics,
        data.frame(
          Population = i,
          Method1 = j,
          Method2 = k,
          rmse = rmse,
          me = me
        )
      )
    }
  }
}

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/observed_weights_calibration.png&#39;, units = &#39;px&#39;, width = 3000, height = 1650, res = 300)
ggplot(metrics, aes(x = Method1, y = Method2, fill = rmse)) +
  geom_tile(color = &quot;white&quot;) +  # Tile plot with white borders
  geom_text(aes(label = round(rmse, 2)), color = &quot;black&quot;) +  # Add correlation values
  scale_fill_gradient2(mid = &quot;white&quot;, high = &quot;red&quot;, midpoint = 0) +  # Color scale
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  facet_grid(. ~ Population) +
  labs(fill = &quot;RMSE&quot;)
dev.off()

# Calculate average RMSE for each method against all other methods
metrics_unique &lt;- metrics[metrics$Method1 != metrics$Method2, ]
metrics_unique$Comparison &lt;- NA
for (i in 1:nrow(metrics_unique)) {
  metrics_unique$Comparison[i] &lt;-
    paste0(sort(c(
      metrics_unique$Method1[i], metrics_unique$Method2[i]
    )), collapse = &#39; vs. &#39;)
}
metrics_unique &lt;- metrics_unique[!duplicated(paste0(metrics_unique$Population, metrics_unique$Comparison)),]

mean_rmse &lt;- NULL
for(i in unique(tmp$label)){
  for(j in c(&#39;AFR&#39;,&#39;EAS&#39;)){
    metrics_unique_tmp &lt;- metrics_unique[metrics_unique$Method1 == i | metrics_unique$Method2 == i,]
    metrics_unique_tmp &lt;- metrics_unique_tmp[metrics_unique_tmp$Population == j,]
    mean_rmse &lt;- rbind(
      mean_rmse, 
      data.frame(
        Method = i,
        Population = j,
        avg_rmse = mean(metrics_unique_tmp$rmse)
      )
    )
  }
}

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/avg_observed_weight_rmse.png&#39;, units = &#39;px&#39;, width = 1500, height = 1500, res = 300)
ggplot(mean_rmse, aes(x = Method, y = avg_rmse, fill = Method)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, size = 0.1) +
  geom_text(aes(label = round(avg_rmse, 3)),  # &lt;-- Add this
          vjust = 1.5,                    # &lt;-- Move the text slightly above the bar
          size = 3) +                      # &lt;-- Adjust text size
  scale_fill_manual(values = default_colors) +
  facet_grid(Population ~ .) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  labs(y = &#39;Average RMSE&#39;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position=&quot;none&quot;)
dev.off()

####
## Check calibration of estimated (LEOPARD and inverse_var) weights compared to observed QuickPRS weights
####
#
#tmp &lt;- both[both$Target != &#39;EUR&#39;,]
#tmp &lt;- tmp[(tmp$label %in% c(&#39;LEOPARD&#39;,&#39;inverse_var&#39;,&#39;QuickPRS&#39;)),]
#tmp$Target&lt;-NULL
#tmp_wide &lt;- reshape(tmp, 
#                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
#                     timevar = &quot;label&quot;, 
#                     direction = &quot;wide&quot;)
#
#names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
#tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]
#
#tmp_wide &lt;- tmp_wide[tmp_wide$Discovery %in% c(&#39;EAS&#39;,&#39;AFR&#39;),]
#
#metrics &lt;- NULL
#for(i in c(&#39;EAS&#39;,&#39;AFR&#39;)){
#  for(j in unique(tmp$label)){
#    for(k in unique(tmp$label)){
#      tmp_wide_i &lt;- tmp_wide[tmp_wide$Discovery == i,]
#      rmse &lt;- sqrt(mean((tmp_wide_i[[j]] - tmp_wide_i[[k]])^2))
#      me &lt;- mean(tmp_wide_i[[j]] - tmp_wide_i[[k]])
#      
#      metrics &lt;- rbind(
#        metrics,
#        data.frame(
#          Population = i,
#          Method1 = j,
#          Method2 = k,
#          rmse = rmse,
#          me = me
#        )
#      )
#    }
#  }
#}
#
## Plot the rmse for LEOPARD and inverse_var predicting observed QuickPRS weight
#metrics &lt;- metrics[metrics$Method1 == &#39;QuickPRS&#39;,]
#metrics &lt;- metrics[metrics$Method2 != &#39;QuickPRS&#39;,]
#
#png(&#39;~/oliverpainfel/Analyses/crosspop/plots/inverse_var_comp_rmse.png&#39;, units = &#39;px&#39;, width = 800, height = 1500, res = 300)
#ggplot(metrics, aes(x = Method2, y = rmse, fill = Method2)) +
#  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, size = 0.1) +
#  geom_text(aes(label = round(rmse, 3)),  # &lt;-- Add this
#          vjust = 1.5,                    # &lt;-- Move the text slightly above the bar
#          size = 3) +                      # &lt;-- Adjust text size
#  facet_grid(Population ~ .) +
#  theme_half_open() +
#  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
#  panel_border() +
#  labs(y = &#39;RMSE relative to QuickPRS&#39;, x = &#39;Method&#39;) +
#  theme(axis.text.x = element_text(angle = 45, hjust = 1),
#        legend.position=&quot;none&quot;)
#dev.off()</code></pre>
</details>
<details>
<summary>
Show observed and LEOPARD PGS weights
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/leopard_weights.png"></p>
</div>
</div>
</details>
<hr />
</div>
<div id="computational-resoures" class="section level2">
<h2>Computational resoures</h2>
<p>Here we will read in the benchmark data for PGS methods and create a
table for the manuscript.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in configuration specific benchmark files
bm_files_i &lt;- list.files(paste0(outdir, &#39;/reference/benchmarks/&#39;), full.names = T)

# Subset benchmarks for pgs_methods
bm_files_i &lt;- bm_files_i[grepl(&#39;prep_pgs_|leopard_quickprs_&#39;, bm_files_i)]

# Subset to benchmarks for gwas/gwas_groups in config
scores &lt;- list_score_files(config)
bm_files_i &lt;- bm_files_i[grepl(paste0(&#39;-&#39;, unique(scores$name),&#39;.txt&#39;, collapse = &#39;|&#39;), bm_files_i)]

# Read in benchmark files
bm_dat_all &lt;- do.call(rbind, lapply(bm_files_i, function(file) {
  tmp &lt;- fread(file)
  tmp$file &lt;- basename(file)
  return(tmp)
}))

# Create rule column
bm_dat_all$rule &lt;- gsub(&#39;-.*&#39;,&#39;&#39;,bm_dat_all$file)

# Create method column
bm_dat_all$method &lt;-
  gsub(&#39;_i&#39;, &#39;&#39;, gsub(&#39;prep_pgs_&#39;, &#39;&#39;, bm_dat_all$rule))

bm_dat_all &lt;- merge(bm_dat_all, pgs_method_labels, by = &#39;method&#39;, all.x=T)

bm_dat_all$label[bm_dat_all$method == &#39;leopard_quickprs&#39;]&lt;-&quot;LEOPARD (QuickPRS)&quot;

#############
# Time
#############

# Calculate average time taken for each method
method_avg &lt;- NULL
for(i in unique(bm_dat_all$label)){
  method_avg &lt;- rbind(
    method_avg,
    data.frame(
      method = bm_dat_all$method[bm_dat_all$label == i][1],
      Method = i,
      Time = mean(bm_dat_all$s[bm_dat_all$label == i])
    )
  )
}

# Times X-Wing time by two since it used 20 cores, but other methods used 10
method_avg$Time[method_avg$method == &#39;xwing&#39;] &lt;- method_avg$Time[method_avg$method == &#39;xwing&#39;] * 2

# Divide the multi-source methods (PRS-CSx and X-Wing by 2 so it is time per GWAS)
method_avg$Time[method_avg$method %in% c(&#39;prscsx&#39;,&#39;xwing&#39;,&#39;leopard_quickprs&#39;)] &lt;- method_avg$Time[ method_avg$method %in% c(&#39;prscsx&#39;,&#39;xwing&#39;,&#39;leopard_quickprs&#39;)] / 2

# Approximate times for either tuning or grid only
method_avg$Model &lt;- &#39;Full&#39;

tmp &lt;- method_avg[method_avg$method == &#39;prscs&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;auto&#39;
tmp$Time &lt;- tmp$Time * (1/5)
method_avg&lt;-rbind(method_avg, tmp)

tmp &lt;- method_avg[method_avg$method == &#39;prscsx&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;auto&#39;
tmp$Time &lt;- tmp$Time * (1/5)
method_avg&lt;-rbind(method_avg, tmp)

tmp &lt;- method_avg[method_avg$method == &#39;xwing&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;grid&#39;
tmp$Time &lt;- tmp$Time * (2/10)
method_avg&lt;-rbind(method_avg, tmp)

# Format the time taken nicely
method_avg$Time_clean[method_avg$Time &lt; 60] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &lt; 60], 1), &#39; sec&#39;)
method_avg$Time_clean[method_avg$Time &gt; 60] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &gt; 60] / 60, 1), &#39; min&#39;)
method_avg$Time_clean[method_avg$Time &gt; 3600] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &gt; 3600] / 60 / 60, 1), &#39; hr&#39;)

# Convert time in seconds to hours
method_avg$Time_hour &lt;- method_avg$Time / 60/60

# Seperate methods by single or multi source
method_avg$Type[!(method_avg$method %in% pgs_group_methods)]&lt;-&#39;Single-source&#39;
method_avg$Type[method_avg$method %in% pgs_group_methods]&lt;-&#39;Multi-source&#39;
method_avg$Type[method_avg$method == &#39;leopard_quickprs&#39;]&lt;-&#39;Tuning&#39;

method_avg$Type&lt;-factor(method_avg$Type, levels = c(&#39;Single-source&#39;,&#39;Multi-source&#39;,&#39;Tuning&#39;))
method_avg$Method &lt;- factor(method_avg$Method, levels = c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;QuickPRS-Multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;,&quot;LEOPARD (QuickPRS)&quot;))

ggplot(method_avg, aes(x = Method, y = Time_hour, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Time_clean), vjust = 0.5, angle = 90, hjust = -0.2, position = position_dodge(width = 0.9)) +
  labs(x = NULL, y = &quot;Time (hours)&quot;) +
  ylim(0, max(method_avg$Time_hour) + (max(method_avg$Time_hour)/5)) +
  facet_grid(~ Type, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

method_avg &lt;- method_avg[method_avg$Model == &#39;Full&#39;,]
method_avg &lt;- method_avg[, c(&#39;Method&#39;,&#39;Time_hour&#39;)]
method_avg$Time_hour &lt;- round(method_avg$Time_hour, 2)
names(method_avg)&lt;-c(&#39;Method&#39;,&quot;Time (hrs)&quot;)

#############
# Memory
#############

# Calculate average max_rss for each method
method_avg_mem &lt;- NULL
for(i in unique(bm_dat_all$label)){
  method_avg_mem &lt;- rbind(
    method_avg_mem,
    data.frame(
      method = bm_dat_all$method[bm_dat_all$label == i][1],
      Method = i,
      Memory = mean(bm_dat_all$max_rss[bm_dat_all$label == i])
    )
  )
}

# Divide X-Wing memory by two, since it used 20 cores, but other methods used 10
method_avg_mem$Memory[method_avg_mem$method == &#39;xwing&#39;] /2

# Format the Memory nicely
method_avg_mem$Memory_clean &lt;-
  paste0(round(method_avg_mem$Memory/1000, 2), &#39; Gb&#39;)

ggplot(method_avg_mem, aes(x = Method, y = Memory, fill = Method)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Memory_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = &quot;PGS Method&quot;, y = &quot;Memory (Mb)&quot;) +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position=&quot;none&quot;)

method_avg_mem$Memory_gb &lt;- method_avg_mem$Memory/1000
method_avg_mem &lt;- method_avg_mem[, c(&#39;Method&#39;,&#39;Memory_gb&#39;)]
method_avg_mem$Memory_gb &lt;- round(method_avg_mem$Memory_gb, 2)
names(method_avg_mem)&lt;-c(&#39;Method&#39;,&quot;Memory (Gb)&quot;)

method_avg&lt;-merge(method_avg, method_avg_mem, by = &#39;Method&#39;)

write.csv(method_avg, &#39;~/oliverpainfel/Analyses/crosspop/time_memory.csv&#39;, row.names=F)</code></pre>
</details>
<details>
<summary>
Show computational resources table
</summary>
<table class="table table-striped table-hover" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:right;">
Time (hrs)
</th>
<th style="text-align:right;">
Memory (Gb)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
DBSLMM
</td>
<td style="text-align:right;">
0.15
</td>
<td style="text-align:right;">
1.15
</td>
</tr>
<tr>
<td style="text-align:left;">
lassosum
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
7.30
</td>
</tr>
<tr>
<td style="text-align:left;">
LDpred2
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
20.54
</td>
</tr>
<tr>
<td style="text-align:left;">
LEOPARD (QuickPRS)
</td>
<td style="text-align:right;">
0.23
</td>
<td style="text-align:right;">
8.03
</td>
</tr>
<tr>
<td style="text-align:left;">
MegaPRS
</td>
<td style="text-align:right;">
0.72
</td>
<td style="text-align:right;">
11.92
</td>
</tr>
<tr>
<td style="text-align:left;">
PRS-CS
</td>
<td style="text-align:right;">
4.40
</td>
<td style="text-align:right;">
10.57
</td>
</tr>
<tr>
<td style="text-align:left;">
PRS-CSx
</td>
<td style="text-align:right;">
6.84
</td>
<td style="text-align:right;">
15.18
</td>
</tr>
<tr>
<td style="text-align:left;">
pT+clump
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;">
QuickPRS
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
4.41
</td>
</tr>
<tr>
<td style="text-align:left;">
SBayesRC
</td>
<td style="text-align:right;">
0.38
</td>
<td style="text-align:right;">
4.40
</td>
</tr>
<tr>
<td style="text-align:left;">
X-Wing
</td>
<td style="text-align:right;">
34.12
</td>
<td style="text-align:right;">
48.70
</td>
</tr>
</tbody>
</table>
</details>
<hr />
</div>
</div>
<div id="tl-prs" class="section level1">
<h1>TL-PRS</h1>
<p>Run using AFR and EAS subset in UKB to make it quicker to run. This
is the main interest when running TL-PRS anyway.</p>
<hr />
<div id="subset-afr-and-eas-individuals-in-ukb-data"
class="section level2">
<h2>Subset AFR and EAS individuals in UKB data</h2>
<p>To make this quicker, focus on evaluating the PGS methods in the AFR
and EAS target individuals in UKB. This will avoid reprocessing the full
UKB data.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

keep &lt;- NULL
for (i in c(&#39;AFR&#39;, &#39;EAS&#39;)) {
  keep &lt;- rbind(keep, fread(
    paste0(
      &#39;~/oliverpainfel/Data/ukb/GenoPred/output/ukb/ancestry/keep_files/model_based/&#39;,
      i,
      &#39;.keep&#39;
    )
  ))
}

write.table(
  keep,
  &#39;~/oliverpainfel/Data/ukb/afr_eas.keep&#39;,
  row.names = F,
  col.names = F,
  quote = F
)</code></pre>
<pre class="bash"><code>mkdir ~/oliverpainfel/Data/ukb/afr_eas_subset

for chr in $(seq 1 22); do
  ~/oliverpainfel/Software/plink2 \
    --pfile ~/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
    --keep ~/oliverpainfel/Data/ukb/afr_eas.keep \
    --make-pgen \
    --out ~/oliverpainfel/Data/ukb/afr_eas_subset/ukb.chr${chr}
done
</code></pre>
</details>
<hr />
</div>
<div id="pgs-calculation-1" class="section level2">
<h2>PGS calculation</h2>
<p>To save time, run using PGS methods that do not need pre-processed LD
matrix data (ptclump, dbslmm, megaprs, lassosum). If the results vary
from the 1KG+HGDP results, then expand to other methods (LDpred2,
SBayesRC, QuickPRS).</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>library(data.table)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs&#39;)

######
# target_list
######
target_list &lt;- data.frame(
  name=&#39;ukb&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Data/ukb/afr_eas_subset/ukb&#39;,
  type=&#39;plink2&#39;,
  indiv_report=F,
  unrel=&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;
)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&#39;, col.names=T, row.names=F, quote=F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_tlprs&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;tlprs_methods: [&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 50&quot;,
  &quot;prscs_phi: [&#39;auto&#39;]&quot;,
  &quot;ldpred2_model: [&#39;auto&#39;]&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;dbslmm_h2f: [&#39;1&#39;]&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml \
  target_pgs -n</code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-1" class="section level2">
<h2>PGS evaluation</h2>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]

  for(targ_pop_i in targ_pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      #####
      # List single-source PGS
      #####
      # These are actually pseudoval scores (as per the config)
      scores_i_j_single &lt;- scores_i_j[!grepl(&#39;tlprs&#39;, scores_i_j$method),]
      
      scores_i_j_single$top1[grepl(&#39;UKB&#39;, scores_i_j_single$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single$top1[grepl(disc_pop_j, scores_i_j_single$name, ignore.case = F)] &lt;- disc_pop_j_2
      scores_i_j_single$multi &lt;- paste0(scores_i_j_single$method,&#39;.pseudo&#39;)
      
      #####
      # List tlprs scores (split by target population)
      #####
      scores_i_j_tlprs &lt;- scores_i_j[grepl(&#39;tlprs&#39;, scores_i_j$method),]
      scores_i_j_tlprs$multi &lt;- scores_i_j_tlprs$method
      
      scores_i_j_tlprs_pop&lt;-NULL
      for(i in 1:nrow(scores_i_j_tlprs)){
        score_header&lt;-fread(scores_i_j_tlprs$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          score_cols &lt;- which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_&#39;), names(score_header)))

          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_tlprs$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.targ_&#39;, pop, &#39;.profiles&#39;),
                   scores_i_j_tlprs$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_tlprs[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.targ_&#39;, pop, &#39;.profiles&#39;),
                   scores_i_j_tlprs$predictor[i])
          
          scores_i_j_tlprs_pop &lt;- rbind(scores_i_j_tlprs_pop, tmp)
        }
      }

      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single, scores_i_j_tlprs_pop
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;top1&#39;,&#39;multi&#39;), with=F]
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.tlprs.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo AFR EAS)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.tlprs.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.tlprs.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.tlprs \
          --n_core 5&quot;
      fi
    done
  done
done</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.tlprs.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing, TL-*
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;,&quot;TL-DBSLMM&quot;,&quot;TL-LDpred2&quot;,&quot;TL-QuickPRS&quot;,&quot;TL-SBayesRC&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39; &amp; !grepl(&#39;^tlprs_&#39;, tmp$Method)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39; &amp; !grepl(&#39;^tlprs_&#39;, tmp$Method)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

dir.create(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots&#39;)

# Plot unidirectional TL-PRS (as it was intended), comparing the unadjusted EUR PGS to the EUR PGS that has been adjusted according to the target-matched GWAS
tmp_tlprs_uni &lt;- tmp[grepl(&#39;tlprs&#39;, tmp$Method) &amp; !grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;, ]
tmp_tlprs_uni$Type &lt;- &#39;TL-PRS&#39;
tmp_unadj &lt;- tmp[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;, ]
tmp_unadj$Type &lt;- &#39;Original&#39;
tmp_both &lt;- rbind(tmp_unadj, tmp_tlprs_uni)
tmp_both$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp_both$label)
tmp_both$Type&lt;-factor(tmp_both$Type, levels = c(&#39;Original&#39;,&#39;TL-PRS&#39;))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/unidirectional_r.png&#39;), res=300, width = 2000, height = 1600, units = &#39;px&#39;)
ggplot(tmp_both, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

tmp_tlprs_uni &lt;- tmp[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;, ]
tmp_tlprs_uni$Type &lt;- &#39;TL-PRS&#39;
tmp_unadj &lt;- tmp[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;, ]
tmp_unadj$Type &lt;- &#39;Original&#39;
tmp_both &lt;- rbind(tmp_unadj, tmp_tlprs_uni)
tmp_both$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp_both$label)
tmp_both$Type&lt;-factor(tmp_both$Type, levels = c(&#39;Original&#39;,&#39;TL-PRS&#39;))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/unidirectional_r.targ_EUR.png&#39;), res=300, width = 2000, height = 1600, units = &#39;px&#39;)
ggplot(tmp_both, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Have one column per method, but fill according to Original EUR PGS, Original matched-PGS, TL-PRS EUR Target, TL-PRS non-EUR Target, TL-PRS Multi, and Original-Multi
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$Type &lt;- NA
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;pop-EUR.top1&#39;, tmp$Group)]&lt;-&quot;TL-PRS (EUR PGS tuned to target)&quot;
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; !grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;]&lt;-&quot;TL-PRS (Target-matched PGS tuned to EUR)&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;]&lt;-&quot;Original (EUR PGS)&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;]&lt;-&quot;Original (Target-matched PGS)&quot;
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;multi&#39;, tmp$Group)]&lt;-&quot;TL-PRS-multi&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;multi&#39;, tmp$Group)]&lt;-&quot;Original-multi&quot;
tmp &lt;- tmp[!is.na(tmp$Type),]
tmp$Type&lt;-factor(tmp$Type, levels=c(&quot;Original (EUR PGS)&quot;, &quot;Original (Target-matched PGS)&quot;, &quot;TL-PRS (EUR PGS tuned to target)&quot;, &quot;TL-PRS (Target-matched PGS tuned to EUR)&quot;, &quot;Original-multi&quot;, &quot;TL-PRS-multi&quot;))
tmp$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp$label)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/average_r.png&#39;), res=300, width = 4000, height = 2200, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()

#########################
# Check significance of differences between TL-PRS and unadjusted approaches
########################

####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c(&#39;EAS&#39;,&#39;AFR&#39;)
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      comp_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.tlprs.pred_comp.txt&#39;
          )
        )
      comp_i&lt;-mirror_comp(comp_i)
      comp_i$Target&lt;-targ_pop_i
      comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_comp_i&lt;-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTune&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTune&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;)]),]

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
    res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample&lt;-&#39;A&#39;
    res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
      cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i &lt;-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = &quot;BHHR&quot;,
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$Model_1_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$Model_2_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$R_diff &lt;- meta_res_comp_i$es
        tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$R_diff &lt;- NA
        tmp$R_diff_SE &lt;- NA
        tmp$R_diff_z &lt;- NA
        tmp$R_diff_p &lt;- NA
      }
      meta_res_comp &lt;- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Compare IndivTune SBayesRC-multi to TL-SBayesRC-multi
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_1 == &#39;tlprs_sbayesrc.pop.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(min(tmp_sbayesrc$R_diff_perc)*100, 1)
tmp_sbayesrc$R_diff_p

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_1 == &#39;tlprs_sbayesrc.pop.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(min(tmp_sbayesrc$R_diff_perc)*100, 1)
tmp_sbayesrc$R_diff_p</code></pre>
</details>
<details>
<summary>
Show TLPRS results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r_tlprs.png"></p>
</div>
</div>
</details>
<hr />
</div>
<div id="computational-resoures-1" class="section level2">
<h2>Computational resoures</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in configuration specific benchmark files
bm_files_i &lt;- list.files(paste0(outdir, &#39;/reference/benchmarks/&#39;), full.names = T)

# Subset benchmarks for pgs_methods
bm_files_i &lt;- bm_files_i[grepl(&#39;prep_pgs_tlprs&#39;, bm_files_i)]

# Read in benchmark files
bm_dat_all &lt;- do.call(rbind, lapply(bm_files_i, function(file) {
  tmp &lt;- fread(file)
  tmp$file &lt;- basename(file)
  return(tmp)
}))

# Create rule column
bm_dat_all$rule &lt;- gsub(&#39;-.*&#39;,&#39;&#39;,bm_dat_all$file)

# Create method column
bm_dat_all$method &lt;-
  gsub(&#39;_i&#39;, &#39;&#39;, gsub(&#39;prep_pgs_&#39;, &#39;&#39;, bm_dat_all$rule))

#############
# Time
#############

# Calculate average time taken for each method
method_avg &lt;- NULL
for(i in unique(bm_dat_all$method)){
  method_avg &lt;- rbind(
    method_avg,
    data.frame(
      Method = i,
      Time = mean(bm_dat_all$s[bm_dat_all$method == i])
    )
  )
}

# Convert time in seconds to hours
method_avg$Time_hour &lt;- method_avg$Time / 60/60
method_avg$Time_hour &lt;- round(method_avg$Time_hour, 2)

#This is for bidirectional TL-PRS

#############
# Memory
#############

# Calculate average max_rss for each method
method_avg_mem &lt;- NULL
for(i in unique(bm_dat_all$method)){
  method_avg_mem &lt;- rbind(
    method_avg_mem,
    data.frame(
      Method = i,
      Memory = mean(bm_dat_all$max_rss[bm_dat_all$method == i])
    )
  )
}

# Format the Memory nicely
method_avg_mem$Memory_clean &lt;-
  paste0(round(method_avg_mem$Memory/1000, 2), &#39; Gb&#39;)

ggplot(method_avg_mem, aes(x = Method, y = Memory, fill = Method)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Memory_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = &quot;PGS Method&quot;, y = &quot;Memory (Mb)&quot;) +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position=&quot;none&quot;)

method_avg_mem$Memory_gb &lt;- method_avg_mem$Memory/1000
method_avg_mem &lt;- method_avg_mem[, c(&#39;Method&#39;,&#39;Memory_gb&#39;)]
method_avg_mem$Memory_gb &lt;- round(method_avg_mem$Memory_gb, 2)
names(method_avg_mem)&lt;-c(&#39;Method&#39;,&quot;Memory (Gb)&quot;)

method_avg&lt;-merge(method_avg, method_avg_mem, by = &#39;Method&#39;)

write.csv(method_avg, &#39;~/oliverpainfel/Analyses/crosspop/time_memory_tlprs.csv&#39;, row.names=F)</code></pre>
</details>
<details>
<summary>
Show computational resources table
</summary>
<table class="table table-striped table-hover" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Method
</th>
<th style="text-align:right;">
Time
</th>
<th style="text-align:right;">
Time_hour
</th>
<th style="text-align:right;">
Memory (Gb)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
tlprs
</td>
<td style="text-align:right;">
2614.237
</td>
<td style="text-align:right;">
0.73
</td>
<td style="text-align:right;">
31.38
</td>
</tr>
</tbody>
</table>
</details>
<hr />
</div>
</div>
<div id="sensitivity-analyses" class="section level1">
<h1>Sensitivity analyses</h1>
<hr />
<div id="using-1kg-reference" class="section level2">
<h2>Using 1KG reference</h2>
<p>PRS-CS, PRS-CSx and X-Wing all use the 1KG reference sample, whereas
the other methods are using the 1KG+HGDP reference sample. We should
check whether this difference is impacting our conclusions.</p>
<p>To make this quicker, focus on evaluating the PGS methods in the AFR
and EAS target individuals in UKB. This will avoid reprocessing the full
UKB data.</p>
<hr />
<div id="create-1kg-only-genopred-reference-data"
class="section level3">
<h3>Create 1KG only GenoPred reference data</h3>
<p>Subset the 1KG+HGDP reference data to include only 1KG
individuals.</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir -p ~/oliverpainfel/Data/1kg/genopred/
cp -r ~/oliverpainfel/Data/hgdp_1kg/genopred/ref ~/oliverpainfel/Data/1kg/genopred/
rm ~/oliverpainfel/Data/1kg/genopred/ref/ref.chr*.p*</code></pre>
<pre class="r"><code>library(data.table)

ref&lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred/ref/ref.chr1.psam&#39;)
ref&lt;-ref[ref$Project == &#39;gnomAD_1kG&#39;,]

write.table(ref[,1, drop = F], &#39;~/oliverpainfel/Data/1kg/1kg.keep&#39;, col.names=F, row.names=F, quote=F)</code></pre>
<pre class="bash"><code>for chr in $(seq 1 22); do
  ~/oliverpainfel/Software/plink2 \
    --pfile ~/oliverpainfel/Data/hgdp_1kg/genopred/ref/ref.chr${chr} \
    --keep ~/oliverpainfel/Data/1kg/1kg.keep \
    --make-pgen \
    --out ~/oliverpainfel/Data/1kg/genopred/ref/ref.chr${chr}
done</code></pre>
</details>
<hr />
</div>
<div id="pgs-calculation-2" class="section level3">
<h3>PGS calculation</h3>
<p>To save time, run using PGS methods that do not need pre-processed LD
matrix data (ptclump, dbslmm, megaprs, lassosum). If the results vary
from the 1KG+HGDP results, then expand to other methods (LDpred2,
SBayesRC, QuickPRS).</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>library(data.table)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only&#39;)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_1kgref&quot;,
  &quot;refdir: /users/k1806347/oliverpainfel/Data/1kg/genopred/ref&quot;,
  &quot;resdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/resdir_1kgref&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;]&quot;,
#  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 10&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml \
  target_pgs -n</code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-2" class="section level3">
<h3>PGS evaluation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]
  scores_i$multi &lt;- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 &lt;-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                     !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_single_top1$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_single_pseudo$predictor)

#      ####
#      # Make groups for multi-single-source pseudo scores
#      ####
#      
#      scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]
#
#      # Extract the pseudo score for each method and specify as a separate group
#      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
#        param &lt;- find_pseudo(
#          config = config,
#          gwas = scores_i_j_multi_single_pseudo$name[i],
#          pgs_method = scores_i_j_multi_single_pseudo$method[i],
#          target_pop = targ_pop_i
#        )
#        
#        score_header &lt;-
#          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
#        score_cols &lt;-
#          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
#        
#        system(
#          paste0(
#            &quot;cut -d&#39; &#39; -f &quot;, 
#            paste0(score_cols, collapse=&#39;,&#39;),
#            &quot; &quot;, 
#            scores_i_j_multi_single_pseudo$predictor[i], 
#            &quot; &gt; &quot;, 
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
#                 scores_i_j_multi_single_pseudo$predictor[i])
#          )
#        )
#      }
#      
#      scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)
#
#      scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
#                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
#                                    scores_i_j_multi_single_pseudo$predictor)
#      
#      scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)
#
#      ####
#      # Make groups for the Multi-Source methods
#      ####
#      
#      scores_i_j_multi &lt;- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]
#
#      # Split top1 scores by target population
#      # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
#      scores_i_j_multi_top1&lt;-NULL
#      for(i in 1:which(scores_i_j_multi$method %in% c(&#39;prscsx&#39;))){
#        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
#        
#        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
#          
#          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
#          }
#          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
#          }
#          
#          system(
#            paste0(
#              &quot;cut -d&#39; &#39; -f &quot;, 
#              paste0(score_cols, collapse=&#39;,&#39;),
#              &quot; &quot;, 
#              scores_i_j_multi$predictor[i], 
#              &quot; &gt; &quot;, 
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#            )
#          )
#          
#          tmp &lt;- scores_i_j_multi[i,]
#          tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
#          tmp$top1 &lt;- pop
#          tmp$predictor &lt;-
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#          
#          scores_i_j_multi_top1 &lt;- rbind(scores_i_j_multi_top1, tmp)
#        }
#      }
#
#      # Split pop-specific pseudo scores by target population
#      scores_i_j_multi_pop_pseudo&lt;-NULL
#      for(i in 1:nrow(scores_i_j_multi)){
#        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
#        
#        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
#          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
#          }
#          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
#          }
#          
#          system(
#            paste0(
#              &quot;cut -d&#39; &#39; -f &quot;, 
#              paste0(score_cols, collapse=&#39;,&#39;),
#              &quot; &quot;, 
#              scores_i_j_multi$predictor[i], 
#              &quot; &gt; &quot;, 
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#            )
#          )
#          
#          tmp &lt;- scores_i_j_multi[i,]
#          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
#          tmp$top1 &lt;- pop
#          tmp$predictor &lt;-
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#          
#          scores_i_j_multi_pop_pseudo &lt;- rbind(scores_i_j_multi_pop_pseudo, tmp)
#        }
#      }
#      
#      # Create pseudo score for multi-source methods
#      scores_i_j_multi_pseudo&lt;-NULL
#      for(i in 1:nrow(scores_i_j_multi)) {
#        param &lt;- find_pseudo(
#          config = config,
#          gwas = scores_i_j_multi$name[i],
#          pgs_method = scores_i_j_multi$method[i],
#          target_pop = targ_pop_i
#        )
#        
#        score_header &lt;-
#          fread(scores_i_j_multi$predictor[i], nrows = 1)
#        score_cols &lt;-
#          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi$name[i], &#39;_&#39;, param)))
#
#        system(
#          paste0(
#            &quot;cut -d&#39; &#39; -f &quot;, 
#            paste0(score_cols, collapse=&#39;,&#39;),
#            &quot; &quot;, 
#            scores_i_j_multi$predictor[i], 
#            &quot; &gt; &quot;, 
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
#                 scores_i_j_multi$predictor[i])
#          )
#        )
#        
#        tmp &lt;- scores_i_j_multi[i,]
#        tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
#        tmp$top1 &lt;- paste0(&#39;EUR_&#39;, disc_pop_j_2)
#        tmp$predictor &lt;-
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
#                 scores_i_j_multi$predictor[i])
#        
#        scores_i_j_multi_pseudo &lt;- rbind(scores_i_j_multi_pseudo, tmp)
#      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo#, 
#        scores_i_j_multi_single_pseudo,
#        scores_i_j_multi_top1,
#        scores_i_j_multi_pop_pseudo,
#        scores_i_j_multi_pseudo
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5&quot;
      fi
    done
  done
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTune or IndivTune
  tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
  tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_1kgrefplots/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# The results look very similar to when using 1KG+HGDP. 

###################
# Plot a comparison between the runs using different references

# Read in results using 1KG+HGDP reference
main_results&lt;-fread(&#39;~/oliverpainfel/Analyses/crosspop/r_eval.csv&#39;)
sens_results&lt;-meta_res_eval

tmp &lt;- main_results
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
main_results &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

tmp &lt;- sens_results
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
sens_results &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

main_results&lt;-main_results[main_results$Method %in% sens_results$Method,]
main_results&lt;-main_results[main_results$Target %in% sens_results$Target,]

sens_results$Reference &lt;- &#39;1KG&#39;
main_results$Reference &lt;- &#39;1KG+HGDP&#39;

both_results &lt;- rbind(main_results, sens_results)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_1kgrefplots/comparison_to_main_result.png&#39;, units = &#39;px&#39;, res = 300, width=4000, height=2500)
ggplot(both_results, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean + Reference, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()</code></pre>
</details>
<details>
<summary>
Show results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/comparison_to_main_result.png"></p>
</div>
</div>
</details>
<hr />
</div>
</div>
<div id="using-three-gwas" class="section level2">
<h2>Using three GWAS</h2>
<p>Extend analysis to include gwas_groups including AFR EAS and EUR
GWAS. Only some multi-source methods should be applicable here,
including LEOPARD, PRS-CSx, and X-Wing. Given X-Wing with LEOPARD is
slow, limit X-Wing analysis to the IndivTune model alone.</p>
<hr />
<div id="pgs-calculation-3" class="section level3">
<h3>PGS calculation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>library(data.table)

# Subset original gwas_list to include selected traits
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)
pheno&lt;-gsub(&#39;_.*&#39;,&#39;&#39;, gwas_list$name)
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
gwas_list&lt;-gwas_list[pheno %in% selected_traits,]
gwas_list$label&lt;-paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

######
# gwas_groups
######

gwas_groups_three_pop&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_BBJ_UGR&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_BBJ,&#39;,x,&#39;_UGR&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+BBJ+UGR)&quot;, &#39;&quot;&#39;)
)

write.table(gwas_groups_three_pop, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_three_pop.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_three_pop.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_three_pop.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;,&#39;prscsx&#39;]&quot;, # xwing removed for time sake
  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, # xwing run with 20 cores
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_three_pop.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_three_pop.yaml \
  target_pgs  -n</code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-3" class="section level3">
<h3>PGS evaluation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config_2_pop&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
config_3_pop&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_three_pop.yaml&#39;
pgs_methods &lt;- read_param(config = config_3_pop, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config_3_pop, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores_2_pop &lt;- list_score_files(config_2_pop)
scores_3_pop &lt;- list_score_files(config_3_pop)
scores &lt;- rbind(scores_2_pop, scores_3_pop)
scores &lt;- scores[!duplicated(scores),]

# Remove xwing 
scores &lt;- scores[scores$method != &#39;xwing&#39;, ]

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_j &lt;- scores[grepl(trait_i, scores$name),]
  scores_j$multi &lt;- scores_j$method
  
  for(targ_pop_i in targ_pop){
    disc_pop_j &lt;- c(&#39;UGR&#39;,&#39;BBJ&#39;,&#39;UKB&#39;)
    disc_pop_j_2 &lt;- c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;)

    dir.create(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        targ_pop_i,
        &#39;.disc_&#39;, paste(disc_pop_j_2, collapse = &#39;_&#39;),
        &#39;/&#39;,
        trait_i
      ),
      recursive = T
    )
    
    # Insert path to score file
    scores_i &lt;- scores_j[!grepl(paste0(&#39;UKB_&#39;, disc_pop_j[!(disc_pop_j_2 %in% c(&#39;EUR&#39;, targ_pop_i))], &#39;$&#39;), scores_j$name),]
    
    scores_i$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i$method,
      &#39;/&#39;,
      scores_i$name,
      &#39;/ukb-&#39;,
      scores_i$name,
      &#39;-TRANS.profiles&#39;
    )
    
    ####
    # Make groups single source methods
    ####
    
    scores_i_single_top1 &lt;-
      scores_i[!(scores_i$method %in% pgs_group_methods) &amp;
                   !grepl(&#39;_multi$&#39;, scores_i$method), ]

    # Create top1 column indicating which predictors top1 models should be derived
    scores_i_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
    scores_i_single_top1$top1[grepl(&#39;BBJ&#39;, scores_i_single_top1$name, ignore.case = F)] &lt;- &#39;EAS&#39;
    scores_i_single_top1$top1[grepl(&#39;UGR&#39;, scores_i_single_top1$name, ignore.case = F)] &lt;- &#39;AFR&#39;
        
    ####
    # Make groups containing pseudo scores for single source methods
    ####

    # Extract the pseudo score for each method and specify as a separate group
    # This can be skipped as it was done before
    for(i in 1:nrow(scores_i_single_top1)) {
      param &lt;- find_pseudo(
        config = ifelse(scores_i_single_top1$name[i] %in% scores_2_pop$name, config_2_pop, config_3_pop),
        gwas = scores_i_single_top1$name[i],
        pgs_method = scores_i_single_top1$method[i],
        target_pop = targ_pop_i
      )
      
      score_header &lt;-
        fread(scores_i_single_top1$predictor[i], nrows = 1)
      score_cols &lt;-
        which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_single_top1$name[i], &#39;_&#39;, param)))
      
      system(
        paste0(
          &quot;cut -d&#39; &#39; -f &quot;, 
          paste0(score_cols, collapse=&#39;,&#39;),
          &quot; &quot;, 
          scores_i_single_top1$predictor[i], 
          &quot; &gt; &quot;, 
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
               scores_i_single_top1$predictor[i])
        )
      )
    }
    
    scores_i_single_pseudo &lt;- scores_i_single_top1
    scores_i_single_pseudo$multi &lt;- paste0(scores_i_single_pseudo$multi, &#39;.pseudo&#39;)

    scores_i_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                  paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                  scores_i_single_pseudo$predictor)

    ####
    # Make groups for multi-single-source pseudo scores
    ####
    
    scores_i_multi_single_pseudo &lt;- scores_i[grepl(&#39;_multi$&#39;, scores_i$method),]

    # Extract the pseudo score for each method and specify as a separate group
    for(i in 1:nrow(scores_i_multi_single_pseudo)) {
      param &lt;- find_pseudo(
        config = ifelse(scores_i_multi_single_pseudo$name[i] %in% scores_2_pop$name, config_2_pop, config_3_pop),
        gwas = scores_i_multi_single_pseudo$name[i],
        pgs_method = scores_i_multi_single_pseudo$method[i],
        target_pop = targ_pop_i
      )
      
      score_header &lt;-
        fread(scores_i_multi_single_pseudo$predictor[i], nrows = 1)
      score_cols &lt;-
        which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_multi_single_pseudo$name[i], &#39;_&#39;, param)))
      
      system(
        paste0(
          &quot;cut -d&#39; &#39; -f &quot;, 
          paste0(score_cols, collapse=&#39;,&#39;),
          &quot; &quot;, 
          scores_i_multi_single_pseudo$predictor[i], 
          &quot; &gt; &quot;, 
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
               scores_i_multi_single_pseudo$predictor[i])
        )
      )
    }
    
    scores_i_multi_single_pseudo$multi &lt;- paste0(scores_i_multi_single_pseudo$multi, &#39;.pseudo&#39;)

    scores_i_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                  paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                  scores_i_multi_single_pseudo$predictor)
    
    scores_i_multi_single_pseudo$top1&lt;-paste(disc_pop_j_2, collapse = &#39;_&#39;)

    ####
    # Make groups for the Multi-Source methods
    ####
    
    scores_i_multi &lt;- scores_i[(scores_i$method %in% pgs_group_methods),]

    # Split top1 scores by target population
    # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
    scores_i_multi_top1&lt;-NULL
    for(i in which(scores_i_multi$method %in% c(&#39;prscsx&#39;))){
      score_header&lt;-fread(scores_i_multi$predictor[i], nrow = 1)
      
      pops &lt;- gsub(paste0(trait_i, &#39;_&#39;),&#39;&#39;, scores_i_multi$name[i])
      pops &lt;- unlist(strsplit(pops, &#39;_&#39;))
      pops &lt;- disc_pop_j_2[disc_pop_j %in% pops]

      for(pop in pops){
        
        if(scores_i_multi$method[i] == &#39;prscsx&#39;){
          score_cols &lt;-
            which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
        }
        if(scores_i_multi$method[i] == &#39;xwing&#39;){
          score_cols &lt;-
            which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
        }
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_multi$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                 scores_i_multi$predictor[i])
          )
        )
        
        tmp &lt;- scores_i_multi[i,]
        tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
        tmp$top1 &lt;- pop
        tmp$predictor &lt;-
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                 scores_i_multi$predictor[i])
        
        scores_i_multi_top1 &lt;- rbind(scores_i_multi_top1, tmp)
      }
    }

    # Split pop-specific pseudo scores by target population
    scores_i_multi_pop_pseudo&lt;-NULL
    for(i in 1:nrow(scores_i_multi)){
      score_header&lt;-fread(scores_i_multi$predictor[i], nrow = 1)
      
      pops &lt;- gsub(paste0(trait_i, &#39;_&#39;),&#39;&#39;, scores_i_multi$name[i])
      pops &lt;- unlist(strsplit(pops, &#39;_&#39;))
      pops &lt;- disc_pop_j_2[disc_pop_j %in% pops]

      for(pop in pops){
        if(scores_i_multi$method[i] == &#39;prscsx&#39;){
          score_cols &lt;-
            which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
        }
        if(scores_i_multi$method[i] == &#39;xwing&#39;){
          score_cols &lt;-
            which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
        }
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_multi$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                 scores_i_multi$predictor[i])
          )
        )
        
        tmp &lt;- scores_i_multi[i,]
        tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
        tmp$top1 &lt;- pop
        tmp$predictor &lt;-
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                 scores_i_multi$predictor[i])
        
        scores_i_multi_pop_pseudo &lt;- rbind(scores_i_multi_pop_pseudo, tmp)
      }
    }
    
    # Create pseudo score for multi-source methods
    scores_i_multi_pseudo&lt;-NULL
    for(i in 1:nrow(scores_i_multi)) {
      param &lt;- find_pseudo(
        config = ifelse(scores_i_multi$name[i] %in% scores_2_pop$name, config_2_pop, config_3_pop),
        gwas = scores_i_multi$name[i],
        pgs_method = scores_i_multi$method[i],
        target_pop = targ_pop_i
      )
      
      score_header &lt;-
        fread(scores_i_multi$predictor[i], nrows = 1)
      score_cols &lt;-
        which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_multi$name[i], &#39;_&#39;, param)))

      system(
        paste0(
          &quot;cut -d&#39; &#39; -f &quot;, 
          paste0(score_cols, collapse=&#39;,&#39;),
          &quot; &quot;, 
          scores_i_multi$predictor[i], 
          &quot; &gt; &quot;, 
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
               scores_i_multi$predictor[i])
        )
      )
      
      tmp &lt;- scores_i_multi[i,]
      tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
      tmp$top1 &lt;- paste(disc_pop_j_2, collapse = &#39;_&#39;)
      tmp$predictor &lt;-
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
               scores_i_multi$predictor[i])
      
      scores_i_multi_pseudo &lt;- rbind(scores_i_multi_pseudo, tmp)
    }
    
    ####
    # Combine the different predictor groups
    ####
    predictors_i&lt;- do.call(rbind, list(
      scores_i_single_top1, 
      scores_i_single_pseudo, 
      scores_i_multi_single_pseudo,
      scores_i_multi_top1,
      scores_i_multi_pop_pseudo,
      scores_i_multi_pseudo
    ))
    
    ####
    # Make a group that will combined all population specific PGS
    ####
    
    predictors_i_all &lt;- predictors_i[predictors_i$top1 %in% c(&#39;EUR&#39;,&#39;AFR&#39;,&#39;EAS&#39;),]
    predictors_i_all$multi &lt;- &#39;all&#39;
    predictors_i&lt;-rbind(predictors_i, predictors_i_all)
    
    ####
    # Split into pairwise groups (2 pop groups)
    ####
    
    afr_eur &lt;- predictors_i[!grepl(&#39;BBJ&#39;, predictors_i$name),]
    afr_eur$multi &lt;- paste0(afr_eur$multi, &#39;.EUR_AFR&#39;)
    afr_eur$top1[afr_eur$top1 == &#39;AFR_EAS_EUR&#39;] &lt;- &#39;AFR_EUR&#39;
    
    eas_eur &lt;- predictors_i[!grepl(&#39;UGR&#39;, predictors_i$name),]
    eas_eur$multi &lt;- paste0(eas_eur$multi, &#39;.EUR_EAS&#39;)
    eas_eur$top1[eas_eur$top1 == &#39;AFR_EAS_EUR&#39;] &lt;- &#39;EAS_EUR&#39;

    one_or_three &lt;- predictors_i[!grepl(&#39;UKB_BBJ$&#39;, predictors_i$name) &amp;
                                   !grepl(&#39;UKB_UGR$&#39;, predictors_i$name),]
    
    predictors_clean &lt;- do.call(rbind, list(
      afr_eur, eas_eur, one_or_three
    ))
    predictors_clean &lt;- predictors_clean[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]

        
    write.table(
      predictors_clean,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        targ_pop_i,
        &#39;.disc_&#39;, paste(disc_pop_j_2, collapse = &#39;_&#39;),
        &#39;/&#39;,
        trait_i,
        &#39;/predictor_list.txt&#39;
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/targ_*.disc_AFR_EAS_EUR/*/res*

for targ_pop in $(echo EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
    if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_AFR_EAS_EUR/${pheno}/res.pred_comp.txt&quot; ]; then
      sbatch --mem 10G -n 1 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
        --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
        --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_AFR_EAS_EUR/${pheno}/predictor_list.txt \
        --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_AFR_EAS_EUR/${pheno}/res \
        --n_core 1&quot;
    fi
  done
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    eval_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/&#39;,
          &#39;targ_&#39;,
          targ_pop_i,
          &#39;.disc_AFR_EAS_EUR/&#39;,
          pheno_i,
          &#39;/res.pred_eval.txt&#39;
        )
      )
    eval_i$Target&lt;-targ_pop_i
    eval_i$gwas_group &lt;- &#39;EUR+AFR+EAS&#39;
    res_eval_i&lt;-rbind(res_eval_i, eval_i)
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;prscsx.pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;

  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;-EUR|-EAS|-AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Group &lt;- gsub(&#39;\\.multi&#39;, &#39;-multi&#39;, res_eval_i$Group)
  res_eval_i$Group_short &lt;- gsub(&#39;.*\\.&#39;, &#39;&#39;, gsub(&#39;-.*&#39;, &#39;&#39;, res_eval_i$Group)) 
  res_eval_i$n_gwas &lt;- 3
  res_eval_i$n_gwas[grepl(&#39;EUR_&#39;, res_eval_i$Group_short)] &lt;- 2
  res_eval_i$n_gwas[res_eval_i$Source == &#39;Single&#39;] &lt;- 1

  res_eval_i$Discovery[grepl(&#39;-EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;-EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;-AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  res_eval_i$Discovery[res_eval_i$n_gwas == 2] &lt;- gsub(&#39;_&#39;, &#39;+&#39;, res_eval_i$Group_short[res_eval_i$n_gwas == 2])
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;,&#39;EUR+AFR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTune or IndivTune
  tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
  tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/plots_three_pop&#39;)

for(pheno_i in selected_traits){
  tmp &lt;- res_eval_simp[res_eval_simp$Trait == pheno_i,]

  # Remove single GWAS results
  tmp &lt;- tmp[tmp$n_gwas != 1,]
  
  # Restrict to target matched + EUR and All GWAS
  tmp &lt;- tmp[!(tmp$Target == &#39;AFR&#39; &amp; tmp$Discovery == &#39;EUR+EAS&#39;),]
  tmp &lt;- tmp[!(tmp$Target == &#39;EAS&#39; &amp; tmp$Discovery == &#39;EUR+AFR&#39;),]
  tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
  tmp$Discovery_clean[(tmp$Target == &#39;EAS&#39; &amp; tmp$Discovery == &#39;EUR+EAS&#39;)]&lt;-&#39;Target-matched + EUR GWAS&#39;
  tmp$Discovery_clean[(tmp$Target == &#39;AFR&#39; &amp; tmp$Discovery == &#39;EUR+AFR&#39;)]&lt;-&#39;Target-matched + EUR GWAS&#39;
  tmp$Discovery_clean[tmp$Discovery == &#39;EUR+AFR+EAS&#39;]&lt;-&#39;AFR + EAS + EUR GWAS&#39;
  tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, levels = c(
    &#39;Target-matched + EUR GWAS&#39;, &#39;AFR + EAS + EUR GWAS&#39;
  ))
  
  tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

  png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_three_pop/&#39;, pheno_i,&#39;.png&#39;), res=300, width = 3400, height = 2000, units = &#39;px&#39;)
  plot_tmp&lt;-ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
  print(plot_tmp)
  dev.off()
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  # Subset res_eval for each scenario
  res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
    x &lt;- res_eval[[i]]
    x$pheno &lt;- names(res_eval)[i]
    x &lt;- x[x$Target == targ_pop_i]
  }))
  
  # Average res_evalults for each test across phenotypes
  # Use MAd to account for correlation between them
  res_eval_i$Sample&lt;-&#39;A&#39;

  for(group_i in unique(res_eval_i$Group)){
    res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
    missing_pheno &lt;-
      colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
    
    if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
      print(paste0(
        &#39;res_evalults missing for &#39;,
        targ_pop_i,
        &#39; &#39;,
        group_i,
        &#39; &#39;,
        paste0(missing_pheno, collapse = &#39; &#39;)
      ))
    }
    
    cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
    
    meta_res_eval_i &lt;-
      agg(
        id = Sample,
        es = R,
        var = SE ^ 2,
        cor = cors_i,
        method = &quot;BHHR&quot;,
        mod = NULL,
        data = res_eval_group_i
      )
    
    tmp &lt;- data.table(Group = group_i,
                      Method = res_eval_group_i$Method[1],
                      Model = res_eval_group_i$Model[1],
                      Source = res_eval_group_i$Source[1],
                      Discovery = res_eval_group_i$Discovery[1],
                      gwas_group = res_eval_group_i$gwas_group[1],
                      n_gwas = res_eval_group_i$n_gwas[1],
                      Target = targ_pop_i,
                      R = meta_res_eval_i$es,
                      SE = sqrt(meta_res_eval_i$var))
    
    meta_res_eval &lt;- rbind(meta_res_eval, tmp)
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;,&#39;EUR+AFR+EAS&#39;))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/r_eval_three_pop.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]

# Remove single GWAS results
tmp &lt;- tmp[tmp$n_gwas != 1,]

# Restrict to target matched + EUR and All GWAS
tmp &lt;- tmp[!(tmp$Target == &#39;AFR&#39; &amp; tmp$Discovery == &#39;EUR+EAS&#39;),]
tmp &lt;- tmp[!(tmp$Target == &#39;EAS&#39; &amp; tmp$Discovery == &#39;EUR+AFR&#39;),]
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[(tmp$Target == &#39;EAS&#39; &amp; tmp$Discovery == &#39;EUR+EAS&#39;)]&lt;-&#39;Target-matched + EUR GWAS&#39;
tmp$Discovery_clean[(tmp$Target == &#39;AFR&#39; &amp; tmp$Discovery == &#39;EUR+AFR&#39;)]&lt;-&#39;Target-matched + EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery == &#39;EUR+AFR+EAS&#39;]&lt;-&#39;AFR + EAS + EUR GWAS&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, levels = c(
  &#39;Target-matched + EUR GWAS&#39;, &#39;AFR + EAS + EUR GWAS&#39;
))

tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_three_pop/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()</code></pre>
</details>
<details>
<summary>
Show results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r_three_gwas.png"></p>
</div>
</div>
</details>
<hr />
</div>
</div>
<div id="using-external-gwas-sumstats" class="section level2">
<h2>Using external GWAS sumstats</h2>
<p>Here we will use GWAS sumtats that were used in the original GenoPred
paper. These GWAS are from a range of sources, often large
meta-analyses, which can lead to greater mispecification in the
sumstats, which can impact the performance of some PGS methods. This is
to provide more confidence in the performance of SBayesRC and QuickPRS
relative to other methods.</p>
<div class="note-box">
<p><strong>Note</strong>: I am using this opportunity to evaluate
lassosum2, which is not included in other analyses in this project.</p>
</div>
<hr />
<div id="pgs-calculation-4" class="section level3">
<h3>PGS calculation</h3>
<p>We will do this using GenoPred.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<p>We can use the gwas_list from the GenoPred pipeline paper. Just make
the new configuration file.</p>
<pre class="r"><code>######
# gwas_list
######

library(data.table)
gwas_list &lt;- fread(&#39;/scratch/prj/ukbiobank/recovered/Edinburgh_Data/usr/ollie_pain/GenoPredPipe/usr/k1806347/configs/benchmark/gwas_list.txt&#39;)

gwas_list$path &lt;- gsub(&#39;/scratch/prj/ukbiobank/usr/ollie_pain/GenoPredPipe/usr/k1806347/gwas_sumstats/&#39;,
                       &#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/genopred_pipeline_paper/&#39;,
                       gwas_list$path)

gwas_list$label=paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_meta.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_meta.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_meta.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;quickprs&#39;,&#39;sbayesrc&#39;,&#39;ldpred2&#39;,&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;lassosum2&#39;]&quot;,
#  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_meta.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_meta.yaml \
  target_pgs -n</code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-4" class="section level3">
<h3>PGS evaluation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_meta.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in gwas_list
gwas_list&lt;-read_param(config = config, param = &#39;gwas_list&#39;)

# Create column containing the phenotypes corresponding to each GWAS
gwas_list$pheno&lt;-tolower(gwas_list$label)
gwas_list$pheno[gwas_list$pheno == &#39;breast cancer&#39;]&lt;-&#39;bc&#39;
gwas_list$pheno[gwas_list$pheno == &#39;prostate cancer&#39;]&lt;-&#39;pc&#39;
gwas_list$pheno[gwas_list$pheno == &#39;egfr&#39;]&lt;-&#39;egfr,ckd&#39;
gwas_list$pheno[gwas_list$pheno == &#39;urate levels&#39;]&lt;-&#39;urate,gout&#39;
gwas_list$pheno[gwas_list$pheno == &#39;rheumatoid arthritis&#39;]&lt;-&#39;ra&#39;

bin_phenos &lt;- c(&#39;bc&#39;, &#39;ckd&#39;, &#39;gout&#39;, &#39;ibd&#39;, &#39;pc&#39;, &#39;ra&#39;, &#39;stroke&#39;, &#39;t1d&#39;, &#39;t2d&#39;)
con_phenos &lt;- c(&#39;height&#39;,&#39;bmi&#39;,&#39;egfr&#39;,&#39;hba1c&#39;,&#39;urate&#39;,&#39;hdl&#39;)
phenos&lt;-c(bin_phenos, con_phenos)

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EUR target
for(trait_i in phenos){
  scores_i &lt;- scores[scores$name == gwas_list$name[grepl(paste0(&#39;^&#39;, trait_i, &#39;$&#39;,&#39;|&#39;, &#39;,&#39;, trait_i, &#39;$&#39;,&#39;|&#39;, &#39;^&#39;, trait_i, &#39;,&#39;), gwas_list$pheno)],]

  dir.create(
    paste0(
      &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/&#39;, trait_i
    ),
    recursive = T
  )
  
  scores_i$predictor &lt;- paste0(
    outdir,
    &#39;/ukb/pgs/TRANS/&#39;,
    scores_i$method,
    &#39;/&#39;,
    scores_i$name,
    &#39;/ukb-&#39;,
    scores_i$name,
    &#39;-TRANS.profiles&#39;
  )
  
  scores_i$multi&lt;-scores_i$method
  scores_i$top1 &lt;- &#39;EUR&#39;

  # Extract the pseudo score for each method and specify as a separate group
  for(i in 1:nrow(scores_i)) {
    param &lt;- find_pseudo(
      config = config,
      gwas = scores_i$name[i],
      pgs_method = scores_i$method[i],
      target_pop = &#39;EUR&#39;
    )
    
    score_header &lt;-
      fread(scores_i$predictor[i], nrows = 1)
    score_cols &lt;-
      which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i$name[i], &#39;_&#39;, param)))
    
    system(
      paste0(
        &quot;cut -d&#39; &#39; -f &quot;, 
        paste0(score_cols, collapse=&#39;,&#39;),
        &quot; &quot;, 
        scores_i$predictor[i], 
        &quot; &gt; &quot;, 
        gsub(&#39;.profiles&#39;,
             paste0(&#39;.EUR_pseudo.profiles&#39;),
             scores_i$predictor[i])
      )
    )
  }
  
  scores_i_pseudo &lt;- scores_i
  scores_i_pseudo$multi &lt;- paste0(scores_i_pseudo$multi, &#39;.pseudo&#39;)

  scores_i_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                paste0(&#39;.EUR_pseudo.profiles&#39;),
                                scores_i_pseudo$predictor)


  predictors_i&lt;- do.call(rbind, list(
    scores_i, scores_i_pseudo
  ))
  
  predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;top1&#39;,&#39;multi&#39;), with=F]
  
  write.table(
    predictors_i,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/&#39;, trait_i, &#39;/predictor_list.txt&#39;
    ),
    col.names = T,
    row.names = F,
    quote = F
  )
}

########
# Prepare phenotype data
########

# Read in list of EUR in UKB
eur_keep &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/ukb.outlier_detection.EUR.keep&#39;)
names(eur_keep)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)

# Update row number IDs to project specific IDs
psam&lt;-fread(&#39;/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam&#39;)
psam$rn&lt;-1:nrow(psam)
psam&lt;-psam[,c(&#39;IID&#39;,&#39;rn&#39;), with = F]

bin_phenos &lt;- c(&#39;bc&#39;, &#39;ckd&#39;, &#39;gout&#39;, &#39;ibd&#39;, &#39;pc&#39;, &#39;ra&#39;, &#39;stroke&#39;, &#39;t1d&#39;, &#39;t2d&#39;)
con_phenos &lt;- c(&#39;height&#39;,&#39;bmi&#39;,&#39;egfr&#39;,&#39;hba1c&#39;,&#39;urate&#39;,&#39;hdl&#39;)
phenos&lt;-c(bin_phenos, con_phenos)

dir.create(&#39;~/oliverpainfel/Data/ukb/phenotypes/benchmark&#39;)

for(i in phenos){
  # Read in pheno data
  pheno_i &lt;- fread(paste0(
      &#39;/scratch/prj/ukbiobank/recovered/Edinburgh_Data/usr/ollie_pain/phenotypes/&#39;,
      i,
      &#39;.unrel.txt&#39;
    ))
  
  names(pheno_i)&lt;-c(&#39;IID&#39;,&#39;PHENO&#39;)
  
  # Update to row number based IDs
  pheno_i&lt;-merge(psam[,c(&#39;IID&#39;,&#39;rn&#39;), with=F], pheno_i, by=&#39;IID&#39;)
  pheno_i$IID&lt;-pheno_i$rn
  pheno_i$rn&lt;-NULL
  pheno_i$FID&lt;-pheno_i$IID
  pheno_i&lt;-pheno_i[, c(&#39;FID&#39;,&#39;IID&#39;,&#39;PHENO&#39;), with=F]
  
  # Restrict to EUR
  pheno_i &lt;- pheno_i[pheno_i$FID %in% eur_keep$FID,]
  
  # Write file
  write.table(pheno_i, paste0(&#39;~/oliverpainfel/Data/ukb/phenotypes/benchmark/&#39;, i, &#39;.unrel.eur.txt&#39;), row.names = F, quote = F)
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/*/res*

for pheno in $(echo bc ckd gout ibd pc ra stroke t1d t2d height bmi egfr hba1c urate hdl); do
  if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/${pheno}/res.pred_comp.txt&quot; ]; then
    sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/benchmark/${pheno}.unrel.eur.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/${pheno}/predictor_list.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/${pheno}/res \
      --n_core 5&quot;
  fi
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

bin_phenos &lt;- c(&#39;bc&#39;, &#39;ckd&#39;, &#39;gout&#39;, &#39;ibd&#39;, &#39;pc&#39;, &#39;ra&#39;, &#39;stroke&#39;, &#39;t1d&#39;, &#39;t2d&#39;)
con_phenos &lt;- c(&#39;height&#39;,&#39;bmi&#39;,&#39;egfr&#39;,&#39;hba1c&#39;,&#39;urate&#39;,&#39;hdl&#39;)
phenos&lt;-c(bin_phenos, con_phenos)

# Calculate correlation between all phenotypes in each target population
pheno_pop_i &lt;- list()
for(pheno_i in phenos){
  pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/benchmark/&#39;, pheno_i, &#39;.unrel.eur.txt&#39;))
  names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
}

pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

cors &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
cors[is.na(cors)]&lt;-0

# Read in results
res_eval &lt;- list()
for(pheno_i in phenos){
  eval_i &lt;-
    fread(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/meta/targ_EUR.disc_EUR/&#39;, pheno_i,&#39;/res.pred_eval.txt&#39;
      )
    )

  eval_i$Ncase &lt;- NULL
  eval_i$Ncont &lt;- NULL
  eval_i$R2l &lt;- NULL
  eval_i$R2o &lt;- NULL
  
  eval_i &lt;- eval_i[!grepl(&#39;\\.multi&#39;, eval_i$Group),]
  
  eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,eval_i$Group)
  eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, eval_i$Method)
  
  eval_i$Model[grepl(&#39;top1$&#39;, eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, eval_i$Group)]&lt;-&#39;IndivTune&#39;
  eval_i$Model[grepl(&#39;top1$&#39;, eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, eval_i$Group)]&lt;-&#39;SumStatTune&#39;

  eval_i$Method&lt;-factor(eval_i$Method, levels=unique(eval_i$Method))
  eval_i$Model&lt;-factor(eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  eval_i &lt;- eval_i[
    !(eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      eval_i$Model %in% c(&#39;IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  eval_i &lt;- eval_i[
    !(eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;lassosum2&#39;) &amp; 
      eval_i$Model %in% c(&#39;SumStatTune&#39;)),]
  
  res_eval[[pheno_i]]&lt;-eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;,&#39;lassosum2&#39;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in phenos){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label &lt;- factor(tmp$label, levels = model_order)

  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/plots_meta&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_meta/trait_r.png&#39;), res=100, width = 1200, height = 900, units = &#39;px&#39;)
ggplot(res_eval_simp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL) +
    facet_wrap(Trait ~ ., scales = &#39;free_y&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL

# Average res_evalults for each test across phenotypes
# Use MAd to account for correlation between them
res_eval_simp$Sample&lt;-&#39;A&#39;

for(group_i in unique(res_eval_simp$Group)){
  res_eval_group_i &lt;- res_eval_simp[res_eval_simp$Group == group_i,]
  missing_pheno &lt;- colnames(cors)[!(colnames(cors) %in% unique(res_eval_simp$Trait))]
  
  if (!all(colnames(cors) %in% unique(res_eval_simp$Trait))) {
    print(paste0(
      &#39;res_evalults missing for &#39;,
      targ_pop_i,
      &#39; &#39;,
      group_i,
      &#39; &#39;,
      paste0(missing_pheno, collapse = &#39; &#39;)
    ))
  }
  
  cors_i &lt;- cors[unique(res_eval_group_i$Trait), unique(res_eval_group_i$Trait)]
  
  meta_res_eval_simp &lt;-
    agg(
      id = Sample,
      es = R,
      var = SE ^ 2,
      cor = cors_i,
      method = &quot;BHHR&quot;,
      mod = NULL,
      data = res_eval_group_i
    )
  
  tmp &lt;- data.table(Group = group_i,
                    Method = res_eval_group_i$Method[1],
                    Model = res_eval_group_i$Model[1],
                    R = meta_res_eval_simp$es,
                    SE = sqrt(meta_res_eval_simp$var))
  
  meta_res_eval &lt;- rbind(meta_res_eval, tmp)
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/meta/r_eval.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label &lt;- factor(tmp$label, levels = model_order)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_meta/average_r.png&#39;), res=100, width = 500, height = 300, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Results and conclusions remain consistent.</code></pre>
</details>
<details>
<summary>
Show average results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 50%;">
<p><img src="Images/CrossPop_2025/average_r_meta.png"></p>
</div>
</div>
</details>
<details>
<summary>
Show trait-specific results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/trait_r_meta.png"></p>
</div>
</div>
</details>
<hr />
</div>
</div>
<div id="using-downsampled-gwas" class="section level2">
<h2>Using downsampled GWAS</h2>
<p>It seems the performance of methods varies across EAS and AFR
datasets. This could be due to the difference in sample size. To explore
this, lets run the methods on EUR GWAS generated using UKB, using a
range of sample sizes.</p>
<hr />
<div id="downsample-gwas" class="section level3">
<h3>Downsample GWAS</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

# Read in phenotype file
subsample_n&lt;-c(5, 15, 45, 135)
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
set.seed(1)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/subsample&#39;)
for(i in selected_traits){
  pheno_i_dat &lt;- fread(
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      i,
      &#39;.unrel.EUR_train.norm_resid_scale.row_number.txt&#39;
    )
  )
  
  for(n in subsample_n){
    tmp &lt;- pheno_i_dat[sample(1:nrow(pheno_i_dat), size = n*1000),]
    fwrite(tmp, paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/subsample/&#39;, i, &#39;.&#39;,n,&#39;.txt&#39;),
           sep=&#39; &#39;,
           na=&#39;NA&#39;,
           quote=F)
  }
} </code></pre>
<pre class="bash"><code>for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
  for n in $(echo 5 15 45 135); do
    mkdir -p /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled
    for chr in $(seq 1 22); do
      if [ ! -s &quot;/users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.chr${chr}.outcome.glm.linear&quot; ]; then
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt.gz&quot; ]; then
        sbatch -p interruptible_cpu,cpu,neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/plink2 \
          --pfile /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
          --pheno /users/k1806347/oliverpainfel/Data/ukb/phenotypes/subsample/${pheno}.${n}.txt \
          --linear omit-ref cols=+a1freq,+ax \
          --maf 0.01 \
          --geno 0.05 \
          --out /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.chr${chr}&quot;
      fi
      fi
    done
  done
done

# Once complete, merge results across chromosomes
for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
  for n in $(echo 5 15 45 135); do
    if [ ! -f &quot;/users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt.gz&quot; ]; then

    head -n 1 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.chr1.outcome.glm.linear &gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt
      for chr in $(seq 1 22); do
        tail -n +2 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.chr${chr}.outcome.glm.linear &gt;&gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt
      done
      
      # Remove REF and ALT columns and rename AX column to A2
      cut -f 4,5 --complement /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt | awk &#39;BEGIN{FS=OFS=&quot;\t&quot;} NR==1 {$5=&quot;A2&quot;} 1&#39; &gt; temp.txt &amp;&amp; mv temp.txt /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt
  
      gzip /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}_subsampled/ukb.eur_train.${pheno}.${n}.GW.txt
    fi
  done
done

# Delete per chromosome files
rm /users/k1806347/oliverpainfel/Data/ukb/gwas/*_subsampled/*chr*
</code></pre>
</details>
<hr />
</div>
<div id="subset-eur-test-individuals-in-ukb-data"
class="section level3">
<h3>Subset EUR test individuals in UKB data</h3>
<p>To make this quicker, focus on evaluating the PGS methods in the EUR
test subset in UKB. This will avoid reprocessing the full UKB data.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

pheno_long &lt;- NULL
for(i in selected_traits){
  pheno_i &lt;- fread(paste0(
    &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
    i ,
    &#39;.unrel.EUR_test.row_number.txt&#39;
  ))
  
  pheno_long &lt;- rbind(
    pheno_long, 
    pheno_i
  )
}

test_subset &lt;- unique(pheno_long$FID)
keep &lt;- data.frame(FID = test_subset,
                   IID = test_subset)

write.table(
  keep,
  &#39;~/oliverpainfel/Data/ukb/eur_test.keep&#39;,
  row.names = F,
  col.names = F,
  quote = F
)</code></pre>
<pre class="bash"><code>mkdir ~/oliverpainfel/Data/ukb/eur_test_subset

for chr in $(seq 1 22); do
  sbatch -p interruptible_cpu,cpu,neurohack_cpu -n 1 --mem 5G \
  --wrap=&quot;~/oliverpainfel/Software/plink2 \
    --pfile ~/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
    --keep ~/oliverpainfel/Data/ukb/eur_test.keep \
    --make-pgen \
    --out ~/oliverpainfel/Data/ukb/eur_test_subset/ukb.chr${chr}&quot;
done
</code></pre>
</details>
<hr />
</div>
<div id="pgs-calculation-5" class="section level3">
<h3>PGS calculation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>######
# gwas_list
######

gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
pheno&lt;-gsub(&#39;_.*&#39;,&#39;&#39;, gwas_list$name)
gwas_list&lt;-gwas_list[gwas_list$population == &#39;EUR&#39;,]
gwas_list$pheno&lt;-gsub(&#39;_UKB&#39;,&#39;&#39;,gwas_list$name)

gwas_list_subsampled &lt;- NULL
for(n in c(5, 15, 45, 135)){
  gwas_list_tmp&lt;-gwas_list
  
  gwas_list_tmp$name &lt;-
    paste0(
      gwas_list_tmp$name, &#39;_&#39;, n, &#39;K&#39;
    )
  gwas_list_tmp$path &lt;-
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/gwas/&#39;,
      gwas_list_tmp$pheno,
      &#39;_subsampled/ukb.eur_train.&#39;,
      gwas_list_tmp$pheno,
      &#39;.&#39;,
      n,
      &#39;.GW.txt.gz&#39;
    )
  gwas_list_tmp$label &lt;-
    paste0(
      gsub(&quot;\\)&quot;, paste0(&#39; - &#39;, n,&quot;K)&quot;), gwas_list_tmp$label)
    )
  
  gwas_list_subsampled &lt;- rbind(gwas_list_subsampled, gwas_list_tmp)
}

gwas_list_subsampled$pheno&lt;-NULL

gwas_list_subsampled$label&lt;-paste0(&#39;&quot;&#39;, gwas_list_subsampled$label, &#39;&quot;&#39;)

write.table(gwas_list_subsampled, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_subsampled.txt&#39;, col.names = T, row.names = F, quote = F)

######
# target_list
######
target_list &lt;- data.frame(
  name=&#39;ukb&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Data/ukb/eur_test_subset/ukb&#39;,
  type=&#39;plink2&#39;,
  indiv_report=F,
  unrel=&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;
)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eur_test_only&#39;)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eur_test_only/target_list.txt&#39;, col.names=T, row.names=F, quote=F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_eur_test_only&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_subsampled.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eur_test_only/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;quickprs&#39;,&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&#39;, col.names = F, row.names = F, quote = F)

####
# Make a second configuration using EAS GWAS and subsample EUR GWAS with QuickPRS and LEOPARD
####

gwas_groups&lt;-data.frame(
  name=paste0(gwas_list_subsampled$name, &#39;_BBJ&#39;),
  gwas=paste0(gwas_list_subsampled$name),
  label=gsub(&quot;\\)&quot;, &quot; + BBJ)&quot;, gwas_list_subsampled$label)
)

gwas_groups$trait &lt;- gsub(&#39;_.*&#39;,&#39;&#39;,gwas_groups$name)
gwas_groups$gwas&lt;-paste0(gwas_groups$gwas,&#39;,&#39;,gwas_groups$trait,&#39;_BBJ&#39;)

gwas_groups$trait&lt;-NULL

write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_subsampled.txt&#39;, col.names = T, row.names = F, quote = F)

gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
gwas_list_eas&lt;-gwas_list[gwas_list$population == &#39;EAS&#39;,]
gwas_list_eas$label&lt;-paste0(&#39;&quot;&#39;, gwas_list_eas$label, &#39;&quot;&#39;)
gwas_list_subsampled &lt;- rbind(gwas_list_subsampled, gwas_list_eas)

write.table(gwas_list_subsampled, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_subsampled.txt&#39;, col.names = T, row.names = F, quote = F)

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_eur_test_only&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_subsampled.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_subsampled.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eur_test_only/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;quickprs&#39;]&quot;,
  &quot;leopard_methods: [&#39;quickprs&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml \
  target_pgs -n</code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-5" class="section level3">
<h3>PGS evaluation</h3>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Get list of score files using full EUR GWAS
config_full&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
outdir_full &lt;- read_param(config = config_full, param = &#39;outdir&#39;, return_obj = F)
scores_full &lt;- list_score_files(config_full)
scores_full &lt;- scores_full[grepl(&#39;UKB$&#39;, scores_full$name),]
scores_full &lt;- scores_full[scores_full$method %in% pgs_methods,]

# Create files for EAS and AFR targets
for(trait_i in selected_traits){
  
  dir.create(
    paste0(
      &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/&#39;, trait_i
    ),
    recursive = T
  )
  
  scores_i &lt;- scores[grepl(paste0(&#39;^&#39;, trait_i,&#39;_&#39;), scores$name),]

  scores_i$predictor &lt;- paste0(
    outdir,
    &#39;/ukb/pgs/TRANS/&#39;,
    scores_i$method,
    &#39;/&#39;,
    scores_i$name,
    &#39;/ukb-&#39;,
    scores_i$name,
    &#39;-TRANS.profiles&#39;
  )
  
  scores_i$top1 &lt;- paste0(scores_i$method,&#39;.&#39;,gsub(&#39;.*_&#39;, &#39;&#39;, scores_i$name))

  # Now for full GWAS
  scores_full_i &lt;- scores_full[grepl(paste0(&#39;^&#39;, trait_i,&#39;_&#39;), scores_full$name),]

  scores_full_i$predictor &lt;- paste0(
    outdir_full,
    &#39;/ukb/pgs/TRANS/&#39;,
    scores_full_i$method,
    &#39;/&#39;,
    scores_full_i$name,
    &#39;/ukb-&#39;,
    scores_full_i$name,
    &#39;-TRANS.profiles&#39;
  )
  
  scores_full_i$top1 &lt;- paste0(scores_full_i$method,&#39;.full&#39;)

  ####
  # Make groups containing pseudo scores for single source methods
  ####

  # Extract the pseudo score for each method and specify as a separate group
  # This can be skipped as it was done before
  for(i in 1:nrow(scores_i)) {
    param &lt;- find_pseudo(
      config = config,
      gwas = scores_i$name[i],
      pgs_method = scores_i$method[i],
      target_pop = &#39;EUR&#39;
    )
    
    score_header &lt;-
      fread(scores_i$predictor[i], nrows = 1)
    score_cols &lt;-
      which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i$name[i], &#39;_&#39;, param)))
    
    system(
      paste0(
        &quot;cut -d&#39; &#39; -f &quot;, 
        paste0(score_cols, collapse=&#39;,&#39;),
        &quot; &quot;, 
        scores_i$predictor[i], 
        &quot; &gt; &quot;, 
        gsub(&#39;.profiles&#39;,
             paste0(&#39;.EUR_pseudo.profiles&#39;),
             scores_i$predictor[i])
      )
    )
  }
  
  scores_i_pseudo &lt;- scores_i
  scores_i_pseudo$top1&lt;-paste0(scores_i_pseudo$top1,&#39;.pseudo&#39;)

  scores_i_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                paste0(&#39;.EUR_pseudo.profiles&#39;),
                                scores_i_pseudo$predictor)

  # Now for full GWAS - skip subsetting pseudo as done before
  scores_full_i_pseudo &lt;- scores_full_i
  scores_full_i_pseudo$top1&lt;-paste0(scores_full_i_pseudo$top1,&#39;.pseudo&#39;)
  
  scores_full_i_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                paste0(&#39;.EUR_pseudo.profiles&#39;),
                                scores_full_i_pseudo$predictor)

  ####
  # Combine the different predictor groups
  ####
  predictors_i&lt;- do.call(rbind, list(
    scores_i, 
    scores_full_i, 
    scores_i_pseudo, 
    scores_full_i_pseudo
  ))
  predictors_i$multi &lt;- &#39;All&#39;
  predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
  write.table(
    predictors_i,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/&#39;, trait_i, &#39;/predictor_list.txt&#39;
    ),
    col.names = T,
    row.names = F,
    quote = F
  )
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/*/res*

for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
  if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/${pheno}/res.pred_comp.txt&quot; ]; then
    sbatch --mem 10G -n 1 -p neurohack_cpu,interruptible_cpu,cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.EUR_test.row_number.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/${pheno}/predictor_list.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/${pheno}/res \
      --n_core 1&quot;
  fi
done
</code></pre>
<hr />
<h4>
Create predictor list
</h4>
<p>When using EUR and EAS GWAS.</p>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop_i &lt;- &#39;EUR&#39;
disc_pop_j &lt;-&#39;BBJ&#39;
disc_pop_j_2 &lt;-&#39;EAS&#39;

for(trait_i in selected_traits){
  dir.create(paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_&#39;,
        targ_pop_i,
        &#39;.disc_EUR_&#39;,
        disc_pop_j_2,
        &#39;/&#39;,
        trait_i))
        
  for(n in c(5, 15, 45, 135)){
    scores_i &lt;- scores[grepl(paste0(&#39;^&#39;, trait_i,&#39;_&#39;), scores$name),]
    scores_i &lt;- scores_i[grepl(paste0(&#39;_&#39;, n, &#39;K_BBJ|_&#39;, n, &#39;K|&#39;,trait_i,&#39;_BBJ&#39;), scores_i$name),]
  
    scores_i$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i$method,
      &#39;/&#39;,
      scores_i$name,
      &#39;/ukb-&#39;,
      scores_i$name,
      &#39;-TRANS.profiles&#39;
    )
    
    scores_i$multi &lt;- scores_i$method

    scores_i_j &lt;- scores_i

    # Insert path to score file
    scores_i_j$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i_j$method,
      &#39;/&#39;,
      scores_i_j$name,
      &#39;/ukb-&#39;,
      scores_i_j$name,
      &#39;-TRANS.profiles&#39;
    )
    
    ####
    # Make groups single source methods
    ####
    
    scores_i_j_single_top1 &lt;-
      scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                   !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

    # Create top1 column indicating which predictors top1 models should be derived
    scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
    scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
    
    ####
    # Make groups containing pseudo scores for single source methods
    ####

    # Extract the pseudo score for each method and specify as a separate group
    for(i in 1:nrow(scores_i_j_single_top1)) {
      param &lt;- find_pseudo(
        config = config,
        gwas = scores_i_j_single_top1$name[i],
        pgs_method = scores_i_j_single_top1$method[i],
        target_pop = targ_pop_i
      )
      
      score_header &lt;-
        fread(scores_i_j_single_top1$predictor[i], nrows = 1)
      score_cols &lt;-
        which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
      
      system(
        paste0(
          &quot;cut -d&#39; &#39; -f &quot;, 
          paste0(score_cols, collapse=&#39;,&#39;),
          &quot; &quot;, 
          scores_i_j_single_top1$predictor[i], 
          &quot; &gt; &quot;, 
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
               scores_i_j_single_top1$predictor[i])
        )
      )
    }
    
    scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
    scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

    scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                  paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                  scores_i_j_single_pseudo$predictor)

    ####
    # Make groups for multi-single-source pseudo scores
    ####
    
    scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]

    # Extract the pseudo score for each method and specify as a separate group
    for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
      param &lt;- find_pseudo(
        config = config,
        gwas = scores_i_j_multi_single_pseudo$name[i],
        pgs_method = scores_i_j_multi_single_pseudo$method[i],
        target_pop = targ_pop_i
      )
      
      score_header &lt;-
        fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
      score_cols &lt;-
        which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
      
      system(
        paste0(
          &quot;cut -d&#39; &#39; -f &quot;, 
          paste0(score_cols, collapse=&#39;,&#39;),
          &quot; &quot;, 
          scores_i_j_multi_single_pseudo$predictor[i], 
          &quot; &gt; &quot;, 
          gsub(&#39;.profiles&#39;,
               paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
               scores_i_j_multi_single_pseudo$predictor[i])
        )
      )
    }
    
    scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)

    scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                  paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                  scores_i_j_multi_single_pseudo$predictor)
    
    scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)

    ####
    # Combine the different predictor groups
    ####
    predictors_i&lt;- do.call(rbind, list(
      scores_i_j_single_top1, 
      scores_i_j_single_pseudo, 
      scores_i_j_multi_single_pseudo
    ))
    
    predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
    
    write.table(
      predictors_i,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_&#39;,
        targ_pop_i,
        &#39;.disc_EUR_&#39;,
        disc_pop_j_2,
        &#39;/&#39;,
        trait_i,
        &#39;/predictor_list_n&#39;, n, &#39;.txt&#39;
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}</code></pre>
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR_EAS/*/res*

for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
  for n in $(echo 5 15 45 135); do
    if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR_EAS/${pheno}/res_n${n}.pred_comp.txt&quot; ]; then
      sbatch --mem 10G -n 1 -p neurohack_cpu,interruptible_cpu,cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
        --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.EUR_test.row_number.txt \
        --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR_EAS/${pheno}/predictor_list_n${n}.txt \
        --out /users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR_EAS/${pheno}/res_n${n} \
        --n_core 1&quot;
    fi
  done
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Calculate correlation between all phenotypes in each target population
pheno_pop_i &lt;- list()
for(pheno_i in selected_traits){
  pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.EUR_test.row_number.txt&#39;))
  names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
}

pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

cors &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))

# Read in results
res_eval &lt;- list()
for(pheno_i in selected_traits){
  eval_i &lt;-
    fread(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/targ_EUR.disc_EUR/&#39;, pheno_i,&#39;/res.pred_eval.txt&#39;
      )
    )

  eval_i$Ncase &lt;- NULL
  eval_i$Ncont &lt;- NULL
  eval_i$R2l &lt;- NULL
  eval_i$R2o &lt;- NULL
  
  eval_i &lt;- eval_i[!grepl(&#39;\\.multi&#39;, eval_i$Group),]
  
  eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,eval_i$Group)
  eval_i$Method&lt;-gsub(&#39;.*-&#39;,&#39;&#39;, eval_i$Method)
  
  eval_i$GWAS_N &lt;- gsub(&#39;K\\..*&#39;,&#39;&#39;,eval_i$Group)
  eval_i$GWAS_N &lt;- gsub(&#39;.*\\.&#39;,&#39;&#39;,eval_i$GWAS_N)
  eval_i$GWAS_N &lt;- paste0(eval_i$GWAS_N,&#39;K&#39;)
  eval_i$GWAS_N[eval_i$GWAS_N == &#39;top1K&#39;] &lt;- &#39;297K&#39;
  
  eval_i$Model[grepl(&#39;top1$&#39;, eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, eval_i$Group)]&lt;-&#39;IndivTune&#39;
  eval_i$Model[grepl(&#39;top1$&#39;, eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, eval_i$Group)]&lt;-&#39;SumStatTune&#39;

  eval_i$Method&lt;-factor(eval_i$Method, levels=unique(eval_i$Method))
  eval_i$Model&lt;-factor(eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  eval_i &lt;- eval_i[
    !(eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      eval_i$Model %in% c(&#39;IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  eval_i &lt;- eval_i[
    !(eval_i$Method %in%  c(&#39;ptclump&#39;) &amp; 
      eval_i$Model %in% c(&#39;SumStatTune&#39;)),]
  
  res_eval[[pheno_i]]&lt;-eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label &lt;- factor(tmp$label, levels = model_order)

  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/plots_downsample&#39;)

tmp&lt;-res_eval_simp
tmp$GWAS_N &lt;- paste0(&#39;GWAS N = &#39;, tmp$GWAS_N)
tmp$GWAS_N &lt;-factor(tmp$GWAS_N, levels = unique(tmp$GWAS_N))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_downsample/per_trait_r.png&#39;), res=100, width = 1000, height = 6000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL) +
    facet_grid(Trait ~ GWAS_N, scales = &#39;free_y&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
# Subset res_eval for each scenario
res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
  x &lt;- res_eval[[i]]
  x$pheno &lt;- names(res_eval)[i]
  return(x)
}))

# Average res_evalults for each test across phenotypes
# Use MAd to account for correlation between them
res_eval_i$Sample&lt;-&#39;A&#39;

for(group_i in unique(res_eval_i$Group)){
  res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
  missing_pheno &lt;-
    colnames(cors)[!(colnames(cors) %in% unique(res_eval_group_i$pheno))]
  
  cors_i &lt;- cors[unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
  
  meta_res_eval_i &lt;-
    agg(
      id = Sample,
      es = R,
      var = SE ^ 2,
      cor = cors_i,
      method = &quot;BHHR&quot;,
      mod = NULL,
      data = res_eval_group_i
    )
  
  tmp &lt;- data.table(Group = group_i,
                    Method = res_eval_group_i$Method[1],
                    Model = res_eval_group_i$Model[1],
                    Source = res_eval_group_i$Source[1],
                    Discovery = &#39;EUR&#39;,
                    Target = &#39;EUR&#39;,
                    R = meta_res_eval_i$es,
                    SE = sqrt(meta_res_eval_i$var),
                    GWAS_N = res_eval_group_i$GWAS_N[1])
  
  meta_res_eval &lt;- rbind(meta_res_eval, tmp)
}

tmp &lt;- meta_res_eval
# Insert nice PGS method names
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$GWAS_N &lt;- paste0(&#39;GWAS N = &#39;, tmp$GWAS_N)
tmp$GWAS_N &lt;-factor(tmp$GWAS_N, levels = unique(tmp$GWAS_N))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots_downsample/average_r.png&#39;), res=100, width = 1000, height = 600, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL) +
    facet_grid(~ GWAS_N, scales = &#39;free_y&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()</code></pre>
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop_i = &#39;EUR&#39;
disc_pop_i = &#39;EAS&#39;
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i &lt;- NULL
  for (n_i in c(5, 15, 45, 135)) {
    eval_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/&#39;,
          &#39;targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res_n&#39;, n_i, &#39;.pred_eval.txt&#39;
        )
      )
    eval_i$Target&lt;-targ_pop_i
    eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
    eval_i$UKB_GWAS_N &lt;- paste0(n_i,&#39;k&#39;)
    res_eval_i&lt;-rbind(res_eval_i, eval_i)
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;, &quot;UKB_GWAS_N&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots&#39;)

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTune or IndivTune
  tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
  tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for (n_i in c(5, 15, 45, 135)) {
  # Subset res_eval for each scenario
  res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
    x &lt;- res_eval[[i]]
    x$pheno &lt;- names(res_eval)[i]
    x &lt;- x[x$Target == targ_pop_i]
    x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    x &lt;- x[x$UKB_GWAS_N == paste0(n_i,&#39;k&#39;)]
  }))
  
  # Average res_evalults for each test across phenotypes
  # Use MAd to account for correlation between them
  res_eval_i$Sample&lt;-&#39;A&#39;

  for(group_i in unique(res_eval_i$Group)){
    res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
    missing_pheno &lt;-
      colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
    
    if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
      print(paste0(
        &#39;res_evalults missing for &#39;,
        targ_pop_i,
        &#39; &#39;,
        group_i,
        &#39; &#39;,
        paste0(missing_pheno, collapse = &#39; &#39;)
      ))
    }
    
    cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
    
    meta_res_eval_i &lt;-
      agg(
        id = Sample,
        es = R,
        var = SE ^ 2,
        cor = cors_i,
        method = &quot;BHHR&quot;,
        mod = NULL,
        data = res_eval_group_i
      )
    
    tmp &lt;- data.table(Group = group_i,
                      Method = res_eval_group_i$Method[1],
                      Model = res_eval_group_i$Model[1],
                      Source = res_eval_group_i$Source[1],
                      Discovery = res_eval_group_i$Discovery[1],
                      gwas_group = res_eval_group_i$gwas_group[1],
                      UKB_GWAS_N = paste0(n_i,&#39;k&#39;),
                      Target = targ_pop_i,
                      R = meta_res_eval_i$es,
                      SE = sqrt(meta_res_eval_i$var))
    
    meta_res_eval &lt;- rbind(meta_res_eval, tmp)
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))
meta_res_eval$UKB_GWAS_N&lt;-factor(meta_res_eval$UKB_GWAS_N, levels=unique(meta_res_eval$UKB_GWAS_N))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/subsampled/r_eval.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;EAS GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;EUR GWAS&#39;,
                                         &#39;EAS GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;,&#39;UKB_GWAS_N&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/average_r.png&#39;), res=300, width = 3500, height = 1200, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(. ~ UKB_GWAS_N + Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot performance of -multi models trained using LEOPARD vs using indiv-level data
tmp &lt;- meta_res_eval
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = unique(tmp$label[order(!(grepl(&#39;Multi&#39;, tmp$label)), tmp$label)]))
tmp&lt;-tmp[grepl(&#39;multi&#39;, tmp$label),]
tmp &lt;- tmp[tmp$Model != &#39;Multi-IndivTune&#39;,]
tmp$Model&lt;-as.character(tmp$Model)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;]&lt;-&#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;]&lt;-&#39;LEOPARD&#39;
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/average_r_leopard.png&#39;), res=300, width = 1500, height = 1200, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid( ~ UKB_GWAS_N, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for (n_i in c(5, 15, 45, 135)) {
    comp_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/subsampled/&#39;,
          &#39;targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res_n&#39;, n_i, &#39;.pred_comp.txt&#39;
        )
      )
    comp_i&lt;-mirror_comp(comp_i)
    comp_i$Target&lt;-targ_pop_i
    comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
    comp_i$UKB_GWAS_N&lt;-paste0(n_i,&#39;k&#39;)
    res_comp_i&lt;-rbind(res_comp_i, comp_i)
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTune&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTune&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;gwas_group&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;,&#39;UKB_GWAS_N&#39;)]),]

res_comp_all$r_diff_rel &lt;- res_comp_all$R_diff / res_comp_all$Model_2_R

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- res_comp_all
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;pheno&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;, &#39;R_diff_pval&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;, &#39;Trait&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$Trait, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/subsampled/r_diff.csv&#39;, row.names=F)

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for (n_i in c(5, 15, 45, 135)) {
  # Subset res_comp for each scenario
  res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  res_comp_i &lt;- res_comp_i[res_comp_i$UKB_GWAS_N == paste0(n_i,&#39;k&#39;), ]
  
  # Calculate diff SE based on p-value
  res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
  res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
  res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
  res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
      
  # Average results for each test across phenotypes
  # Use MAd to account for correlation between them
  res_comp_i$Sample&lt;-&#39;A&#39;
  res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)

  for(group_i in unique(res_comp_i$Group)){
    res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
    cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
    
    if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
      
      meta_res_comp_i &lt;-
        agg(
          id = Sample,
          es = R_diff,
          var = R_diff_SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_comp_group_i
        )
      
      tmp &lt;- res_comp_group_i[1,]
      tmp$pheno &lt;- NULL
      tmp$Model_1_R &lt;-
        meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                          meta_res_eval$Target == targ_pop_i &amp;
                          meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i) &amp; 
                          meta_res_eval$UKB_GWAS_N == paste0(n_i,&#39;k&#39;)]
      tmp$Model_2_R &lt;-
        meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                          meta_res_eval$Target == targ_pop_i &amp;
                          meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i) &amp; 
                          meta_res_eval$UKB_GWAS_N == paste0(n_i,&#39;k&#39;)]
      tmp$R_diff &lt;- meta_res_comp_i$es
      tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
      tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
      tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
    } else {
      tmp &lt;- res_comp_group_i[1,]
      tmp$pheno &lt;- NULL
      tmp$R_diff &lt;- NA
      tmp$R_diff_SE &lt;- NA
      tmp$R_diff_z &lt;- NA
      tmp$R_diff_p &lt;- NA
    }
    meta_res_comp &lt;- rbind(meta_res_comp, tmp)
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Compare QuickPRS-Multi vs QuickPRS to evaluate LEOPARD performance
tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EUR&#39;,]

tmp_quickprs[,c(&#39;UKB_GWAS_N&#39;, &#39;R_diff_perc&#39;, &#39;R_diff_p&#39;), with = F]

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- meta_res_comp
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp$`Percentage change (R difference / Model 2 R)` &lt;- paste0(round(tmp$R_diff_perc * 100, 1), &#39;%&#39;)

tmp &lt;- tmp[, c(&#39;UKB_GWAS_N&#39;, &#39;Target&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;,&quot;Percentage change (R difference / Model 2 R)&quot;, &#39;R_diff_p&#39;), with=F]
names(tmp) &lt;- c(&#39;UKB GWAS N&#39;, &#39;Target&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;Percentage change (R difference / Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/subsampled/r_diff_average.csv&#39;, row.names=F)

####
# Plot relative improvement of methods
####
# Use the QuickPRS-Multi (IndivTune) as the reference for each UKB_GWAS_N

meta_res_comp_ptclump_top1&lt;-meta_res_comp[meta_res_comp$Method2 == &#39;quickprs&#39; &amp; meta_res_comp$Source2 == &#39;Multi&#39; &amp; meta_res_comp$Model2 == &#39;Multi-SumStatTune&#39;,]
meta_res_comp_ptclump_top1$reference_point&lt;-F
meta_res_comp_ptclump_top1$reference_point[meta_res_comp_ptclump_top1$Method1 == &#39;quickprs&#39; &amp; meta_res_comp_ptclump_top1$Source1 == &#39;Multi&#39; &amp; meta_res_comp_ptclump_top1$Model1 == &#39;Multi-SumStatTune&#39;]&lt;-T
meta_res_comp_ptclump_top1$R_diff[is.na(meta_res_comp_ptclump_top1$R_diff)]&lt;-0
meta_res_comp_ptclump_top1$Discovery1 &lt;- factor(meta_res_comp_ptclump_top1$Discovery1, levels=rev(levels(meta_res_comp_ptclump_top1$Discovery1)))

res_comp_all_ptclump_top1&lt;-res_comp_all[res_comp_all$Method2 == &#39;quickprs&#39; &amp; res_comp_all$Source2 == &#39;Multi&#39; &amp; res_comp_all$Model2 == &#39;Multi-SumStatTune&#39;,]
res_comp_all_ptclump_top1$Discovery1 &lt;-  factor(res_comp_all_ptclump_top1$Discovery1, levels=levels(meta_res_comp_ptclump_top1$Discovery1))

# Create data to plot reference points
meta_res_comp_reference &lt;- meta_res_comp_ptclump_top1
meta_res_comp_reference$R_diff[meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
meta_res_comp_reference$R_diff_SE [meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
res_comp_all_ptclump_top1$reference_point&lt;-F

meta_tmp &lt;- meta_res_comp_ptclump_top1
meta_tmp &lt;- merge(meta_tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp$label[is.na(meta_tmp$label)] &lt;- &#39;All&#39;
meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;] &lt;- paste0(meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp$label &lt;- factor(meta_tmp$label, levels = model_order)
meta_tmp$Discovery_clean &lt;- as.character(meta_tmp$Discovery1)
meta_tmp$Discovery_clean[meta_tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Single&#39;] &lt;- &#39;EAS GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp$Discovery_clean &lt;- factor(meta_tmp$Discovery_clean, 
                              levels = c(&#39;EUR GWAS&#39;,
                                         &#39;EAS GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp$Target &lt;- paste0(meta_tmp$Target, &#39; Target&#39;)
meta_tmp$Model1 &lt;- factor(meta_tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_tmp$UKB_GWAS_N &lt;- factor(meta_tmp$UKB_GWAS_N, levels = unique(meta_tmp$UKB_GWAS_N))

meta_tmp_ref &lt;- meta_res_comp_reference
meta_tmp_ref &lt;- merge(meta_tmp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp_ref$label[is.na(meta_tmp_ref$label)] &lt;- &#39;All&#39;
meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;] &lt;- paste0(meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp_ref$label &lt;- factor(meta_tmp_ref$label, levels = model_order)
meta_tmp_ref$Discovery_clean &lt;- as.character(meta_tmp_ref$Discovery1)
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Single&#39;] &lt;- &#39;EAS GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp_ref$Discovery_clean &lt;- factor(meta_tmp_ref$Discovery_clean, 
                              levels = c(&#39;EUR GWAS&#39;,
                                         &#39;EAS GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp_ref$Target &lt;- paste0(meta_tmp_ref$Target, &#39; Target&#39;)
meta_tmp_ref$Model1 &lt;- factor(meta_tmp_ref$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_tmp_ref$UKB_GWAS_N &lt;- factor(meta_tmp_ref$UKB_GWAS_N, levels = unique(meta_tmp_ref$UKB_GWAS_N))

tmp &lt;- res_comp_all_ptclump_top1
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery1)
tmp$Discovery_clean[tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Single&#39;] &lt;- &#39;EAS GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;EUR GWAS&#39;,
                                         &#39;EAS GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model1 &lt;- factor(tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
tmp$UKB_GWAS_N &lt;- factor(tmp$UKB_GWAS_N, levels = unique(tmp$UKB_GWAS_N))

ggplot(meta_tmp, aes(x=label, y=R_diff , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff - R_diff_SE,
          ymax = R_diff + R_diff_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R_diff (SE)&quot;) +
    facet_grid(UKB_GWAS_N ~ Discovery_clean, scales = &#39;free_x&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


# Plot as % change
meta_tmp$R_diff_perc &lt;- meta_tmp$R_diff / meta_tmp$Model_2_R
meta_tmp_ref$R_diff_perc &lt;- meta_tmp_ref$R_diff / meta_tmp_ref$Model_2_R
tmp$R_diff_perc &lt;- tmp$R_diff / tmp$Model_2_R

meta_tmp$R_diff_perc_SE &lt;- meta_tmp$R_diff_SE / meta_tmp$Model_2_R

library(scales)
ggplot(meta_tmp, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R diff. (SE)&quot;) +
    facet_grid(UKB_GWAS_N ~ Discovery_clean, scales = &#39;free_x&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# Simplify results showing results only with or without training data
meta_tmp_simple &lt;- meta_tmp
meta_tmp_simple$Model1[meta_tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model1[meta_tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_2 %in% res_eval_simp$Group,]

meta_tmp_ref_simple &lt;- meta_tmp_ref
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_2 %in% res_eval_simp$Group,]

tmp_simple &lt;- tmp
tmp_simple$Model1[tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model1[tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple$Model2[tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model2[tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple&lt;-tmp_simple[tmp_simple$Model_1 %in% res_eval_simp$Group,]
tmp_simple&lt;-tmp_simple[tmp_simple$Model_2 %in% res_eval_simp$Group,]

# Export plot for manuscript
png(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/average_r.perc_improv.png&#39;, width = 3200, height = 2000, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target == &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
#    geom_boxplot(
#      data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
#        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
#        position = position_dodge(0.7),
#        alpha = 0.3
#      ) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(UKB_GWAS_N ~ Discovery_clean, scales = &#39;free_x&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()

# Export plot comparing sumstat vs indivtune for QuickPRS
# Export plot for manuscript
png(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/average_r.perc_improv.png&#39;, width = 1500, height = 1200, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target == &#39;EUR Target&#39; &amp; meta_tmp_simple$Discovery_clean == &#39;Both&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
#    geom_boxplot(
#      data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
#        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
#        position = position_dodge(0.7),
#        alpha = 0.3
#      ) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(. ~ UKB_GWAS_N, scales = &#39;free_x&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()</code></pre>
</details>
<details>
<summary>
Show results
</summary>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<p><img src="Images/CrossPop_2025/average_r_downsample.png"></p>
</div>
</div>
</details>
<hr />
</div>
</div>
<div id="leopardquickprs-1" class="section level2">
<h2>LEOPARD+QuickPRS</h2>
<p>Here we will compare the LEOPARD estimated weights for population
specific PGS, to the weights estimated using observed data in the UKB
target sample.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_subsampled.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

###
# Read in weights estimated by LEOPARD (QuickPRS)
###

leopard_weights&lt;-NULL
scores_quickprs &lt;- scores$name[scores$method == &#39;quickprs_multi&#39;]
for(i in selected_traits){
  for(n in c(&#39;5&#39;,&#39;15&#39;,&#39;45&#39;,&#39;135&#39;)){
    scores_i &lt;- scores_quickprs[grepl(paste0(&#39;^&#39;, i,&#39;_&#39;), scores_quickprs) &amp; grepl(paste0(&#39;_&#39;, n,&#39;K_&#39;), scores_quickprs)]
    for(j in scores_i){
        weights_file &lt;- readRDS(paste0(outdir, &#39;/reference/pgs_score_files/leopard/&#39;, j, &#39;/ref-&#39;, j, &#39;.weights.rds&#39;))
        weights_file &lt;- data.frame(weights_file)
        
        weights &lt;-
          data.table(
            Target = do.call(c, lapply(names(weights_file), function(x) rep(x, 2))),
            Discovery = names(weights_file),
            Weight = do.call(c, lapply(weights_file, function(x) x)),
            UKB_GWAS_N = paste0(n, &#39;k&#39;),
            Trait = i,
            Method = &#39;LEOPARD&#39;
          )
        
        leopard_weights &lt;- rbind(leopard_weights, weights)
    }
  }
}

leopard_weights&lt;-leopard_weights[leopard_weights$Target == &#39;EUR&#39; &amp; leopard_weights$Discovery == &#39;EUR&#39;,]

#####
# Read in the PGS weights estimated using UKB data
#####
# Read in the final model coefficients for multi-source methods

obs_weights&lt;-NULL
for(method_i in unique(scores$method)[!(unique(scores$method) %in% pgs_group_methods)]){
  scores_method&lt;-scores$name[scores$method == method_i]
  method_i &lt;- gsub(&#39;_multi&#39;,&#39;&#39;, method_i)

  for(i in selected_traits){
    for(j in c(&#39;EUR&#39;)){
      if(j == &#39;EUR&#39;){
        pops &lt;- c(&#39;EAS&#39;)
      } else {
        pops &lt;- j
      }
      
      for(k in pops){
          for(n in c(&#39;5&#39;,&#39;15&#39;,&#39;45&#39;,&#39;135&#39;)){
          model &lt;- fread(paste0(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/targ_&#39;, j, &#39;.disc_EUR_&#39;, k, &#39;/&#39;, i, &#39;/res&#39;, n, &#39;_final_models/&#39;, method_i, &#39;.pseudo.multi.final_model.txt&#39;))
          model&lt;-model[-1,]
          
          # Set weight to zero if negative, as this is what LEOPARD does
          if(any(model$V2 &lt; 0)){
            model$V2[model$V2 &lt; 0] &lt;- 0
            model$V2[model$V2 &gt; 0] &lt;- 1
          }
          
          names(model) &lt;- c(&#39;x&#39;, &#39;BETA&#39;)
          model$Discovery[grepl(&#39;UKB&#39;, model$x)]&lt;-&#39;EUR&#39;
          model$Discovery[grepl(&#39;BBJ&#39;, model$x)]&lt;-&#39;EAS&#39;
          model$Discovery[grepl(&#39;UGR&#39;, model$x)]&lt;-&#39;AFR&#39;
          model$UKB_GWAS_N&lt;-paste0(n,&#39;k&#39;)
          model$Target &lt;- j
          model$Weight &lt;- model$BETA/sum(model$BETA)
          model$Trait &lt;- i
          model$Method &lt;- method_i
          model&lt;-model[,c(&#39;Target&#39;,&#39;Discovery&#39;,&#39;Weight&#39;,&#39;Method&#39;,&#39;UKB_GWAS_N&#39;,&#39;Trait&#39;), with=F]
          obs_weights&lt;-rbind(obs_weights, model)
        }
      }
    }
  }
}

obs_weights&lt;-obs_weights[obs_weights$Target == &#39;EUR&#39; &amp; obs_weights$Discovery == &#39;EUR&#39;,]

###
# Estimate weights if using the inverse variance weighting
###

# Read in GWAS descriptives
gwas_desc&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)
gwas_desc &lt;- gwas_desc[, c(&#39;Trait Label&#39;,&#39;Ancestry&#39;,&#39;GWAS N&#39;), with=F]
names(gwas_desc)&lt;-c(&#39;trait&#39;,&#39;ancestry&#39;,&#39;n&#39;)
gwas_desc&lt;-gwas_desc[gwas_desc$trait %in% selected_traits,]

gwas_desc_eas &lt;- gwas_desc[gwas_desc$ancestry == &#39;EAS&#39;,]
gwas_desc_eas$name&lt;-&#39;BBJ&#39;

gwas_desc_eur &lt;- data.frame(
  trait = gwas_desc_eas$trait,
  ancestry = &#39;EUR&#39;,
  n = c(rep(5000, 10), rep(15000, 10), rep(45000, 10), rep(135000, 10))
)

gwas_desc&lt;-merge(gwas_desc_eas, gwas_desc_eur, by=&#39;trait&#39;)
gwas_desc$inverse_var &lt;- gwas_desc$n.y / (gwas_desc$n.y + gwas_desc$n.x)

gwas_desc$Target &lt;- &#39;EUR&#39;
gwas_desc$Discovery &lt;- &#39;EUR&#39;
gwas_desc$Weight &lt;- gwas_desc$inverse_var
gwas_desc$Method &lt;- &#39;inverse_var&#39;
gwas_desc$UKB_GWAS_N &lt;- paste0(gwas_desc$n.y/1000,&#39;k&#39;)
gwas_desc$Trait &lt;- gwas_desc$trait

gwas_desc &lt;- gwas_desc[, names(obs_weights), with=F]

###
# Combine and compare
###

both &lt;- do.call(rbind, list(obs_weights, leopard_weights, gwas_desc))

both&lt;-merge(both, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x=T, sort = F)
both$label[is.na(both$label)] &lt;- both$Method[is.na(both$label)]
both$label &lt;- factor(both$label, levels=unique(both$label))

# Plot EUR target
tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery == &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(10)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

tmp$UKB_GWAS_N &lt;- factor(tmp$UKB_GWAS_N, levels = unique(tmp$UKB_GWAS_N))

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/leopard_weights_eur.png&#39;, units = &#39;px&#39;, res = 300, width = 3500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(. ~ UKB_GWAS_N) +
  theme_half_open() +
  labs(title = &#39;Weight of EUR PGS for EUR Target&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

###
# Check calibration of LEOPARD compared to QuickPRS observed weights
###

tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp &lt;- tmp[both$Discovery == &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;,&quot;UKB_GWAS_N&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

# Calculate metrics
metrics &lt;- NULL
for(n in c(&#39;5&#39;,&#39;15&#39;,&#39;45&#39;,&#39;135&#39;)){
  tmp_wide_n &lt;- tmp_wide[tmp_wide$UKB_GWAS_N == paste0(n,&#39;k&#39;),]
  metrics&lt;-rbind(metrics, 
                 data.frame(
                   n = paste0(n, &#39;k&#39;),
                   rmse = sqrt(mean((tmp_wide_n$QuickPRS - tmp_wide_n$LEOPARD)^2)),
                   me = mean(tmp_wide_n$QuickPRS - tmp_wide_n$LEOPARD)
                 ))
}

# Create annotation data.frame
metrics_df &lt;- data.frame(
  UKB_GWAS_N = metrics$n,
  x = 0.1,
  y = 0.15,
  label = paste0(&quot;RMSE = &quot;, round(metrics$rmse, 2), &quot;\nME = &quot;, round(metrics$me, 2))
)

tmp_wide$UKB_GWAS_N &lt;- factor(tmp_wide$UKB_GWAS_N, levels = unique(tmp_wide$UKB_GWAS_N))
metrics_df$UKB_GWAS_N &lt;- factor(metrics_df$UKB_GWAS_N, levels = unique(tmp_wide$UKB_GWAS_N))

png(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/leopard_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
ggplot(tmp_wide, aes(x = LEOPARD, y = QuickPRS)) +
  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
  geom_point(alpha = 0.7) +
  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) +
  labs(
    x = &quot;LEOPARD weight&quot;,
    y = &quot;Observed weight&quot;,
  ) +
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  ) +
  facet_grid(. ~ UKB_GWAS_N) +
  coord_fixed()    
dev.off()

###
# Check calibration of inverse_var compared to QuickPRS observed weights
###

tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp &lt;- tmp[both$Discovery == &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;,&quot;UKB_GWAS_N&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

# Calculate metrics
metrics &lt;- NULL
for(n in c(&#39;5&#39;,&#39;15&#39;,&#39;45&#39;,&#39;135&#39;)){
  tmp_wide_n &lt;- tmp_wide[tmp_wide$UKB_GWAS_N == paste0(n,&#39;k&#39;),]
  metrics&lt;-rbind(metrics, 
                 data.frame(
                   n = paste0(n, &#39;k&#39;),
                   rmse = sqrt(mean((tmp_wide_n$QuickPRS - tmp_wide_n$inverse_var)^2)),
                   me = mean(tmp_wide_n$QuickPRS - tmp_wide_n$inverse_var)
                 ))
}

# Create annotation data.frame
metrics_df &lt;- data.frame(
  UKB_GWAS_N = metrics$n,
  x = 0.3,
  y = 0.25,
  label = paste0(&quot;RMSE = &quot;, round(metrics$rmse, 2), &quot;\nME = &quot;, round(metrics$me, 2))
)

tmp_wide$UKB_GWAS_N &lt;- factor(tmp_wide$UKB_GWAS_N, levels = unique(tmp_wide$UKB_GWAS_N))
metrics_df$UKB_GWAS_N &lt;- factor(metrics_df$UKB_GWAS_N, levels = unique(tmp_wide$UKB_GWAS_N))

png(&#39;~/oliverpainfel/Analyses/crosspop/subsampled/plots/leopard_weights_calibration_inverse_var.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
ggplot(tmp_wide, aes(x = inverse_var, y = QuickPRS)) +
  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
  geom_point(alpha = 0.7) +
  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) +
  labs(
    x = &quot;inverse_var weight&quot;,
    y = &quot;Observed weight&quot;,
  ) +
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  ) +
  facet_grid(. ~ UKB_GWAS_N) +
  coord_fixed()    
dev.off()</code></pre>
</details>
<hr />
</div>
<div id="using-mvp-sumstats" class="section level2">
<h2>Using MVP sumstats</h2>
<div id="download-mvp-sumstats" class="section level3">
<h3>Download MVP sumstats</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

mvp &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/MVP/MVP_sumstats.txt&#39;)
mvp_afr &lt;- mvp[grepl(&#39;Afr&#39;, mvp$discoverySampleAncestry),]
mvp_afr &lt;- mvp_afr[!grepl(&#39;Eur|Asi|His&#39;, mvp_afr$discoverySampleAncestry),]

# Identify traits in common with UKB, UGR, EAS
prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
selected_traits &lt;-
  fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;,
        header = F)$V1

prscsx_dat &lt;- prscsx_dat[prscsx_dat$labels %in% selected_traits, ]

# Subset MVP to selected traits
mvp_afr_subset &lt;- mvp_afr[
  mvp_afr$accessionId %in% 
    c(
      &#39;GCST90475361&#39;, &#39;GCST90475375&#39;, &#39;GCST90476298&#39;, &#39;GCST90475155&#39;, &#39;GCST90476462&#39;, &#39;GCST90475457&#39;, &#39;GCST90476423&#39;, &#39;GCST90475528&#39;, &#39;GCST90475351&#39;, &#39;GCST90476402&#39;
    )
, ]

# Insert labels
mvp_afr_subset$labels &lt;- NA
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;body mass index&#39;] &lt;- &#39;BMI&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;body weight&#39;] &lt;- &#39;BWT&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;high density lipoprotein cholesterol measurement&#39;] &lt;- &#39;HDL&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;body height&#39;] &lt;- &#39;HT&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;hemoglobin measurement&#39;] &lt;- &#39;HB&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;mean corpuscular hemoglobin concentration&#39;] &lt;- &#39;MCHC&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;neutrophil count&#39;] &lt;- &#39;NEU&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;platelet count&#39;] &lt;- &#39;PLT&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;systolic blood pressure&#39;] &lt;- &#39;SBP&#39;
mvp_afr_subset$labels[mvp_afr_subset$efoTraits == &#39;total cholesterol measurement&#39;] &lt;- &#39;TC&#39;

mvp_afr_subset$url &lt;-paste0(mvp_afr_subset$summaryStatistics, &#39;/&#39;, mvp_afr_subset$accessionId, &#39;.tsv.gz&#39;)

dir.create(&#39;~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR&#39;)

write.table(
  mvp_afr_subset[, c(&#39;url&#39;, &#39;labels&#39;), with = F],
  &#39;~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/urls.txt&#39;,
  row.names = F,
  quote = F,
  col.names = F
)

write.table(
  mvp_afr_subset,
  &#39;~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/info.txt&#39;,
  row.names = F,
  quote = T,
  col.names = T
)

write.table(mvp_afr_subset$labels, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code>for pheno in $(cat ~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/urls.txt | cut -d&#39; &#39; -f 2); do
  url=$(awk -v var=&quot;$pheno&quot; &#39;$2 == var {print $1}&#39; ~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/urls.txt)
  sbatch -p interruptible_cpu,neurohack_cpu -t 1:00:00 --wrap=&quot;wget -O ~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/${pheno}.txt.gz ${url}&quot;
done</code></pre>
</details>
<hr />
</div>
<div id="pgs-calculation-6" class="section level3">
<h3>PGS calculation</h3>
<p>Run leading single-source PGS methods using MVP GWAS sumstats.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Prepare configuration
</h4>
<pre class="r"><code>library(data.table)

# Subset original gwas_list to include AFR traits
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
gwas_list &lt;- gwas_list[gwas_list$population == &#39;AFR&#39;,]
selected_traits &lt;- gsub(&#39;_UGR&#39;, &#39;&#39;, gwas_list$name)
gwas_list$name &lt;- gsub(&#39;UGR&#39;, &#39;MVP_AFR&#39;, gwas_list$name)
gwas_list$label &lt;- gsub(&#39;UGR&#39;, &#39;MVP_AFR&#39;, gwas_list$label)
gwas_list$path &lt;-
  paste0(&#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/&#39;,
         selected_traits,&#39;.txt.gz&#39;)

gwas_list_eur&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
gwas_list_eur&lt;-gwas_list_eur[gwas_list_eur$population == &#39;EUR&#39;, ]

gwas_list &lt;- rbind(gwas_list, gwas_list_eur)

gwas_list$label &lt;- paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp.txt&#39;, col.names = T, row.names = F, quote = F)

######
# gwas_groups
######

gwas_groups&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_MVP_AFR&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_MVP_AFR&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+MVP_AFR)&quot;, &#39;&quot;&#39;)
)

write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_mvp.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_mvp.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;,&#39;prscsx&#39;,&#39;xwing&#39;]&quot;,
  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, # xwing run with 20 cores
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;, col.names = F, row.names = F, quote = F)

# Make a version of the gwas_list without NEU
gwas_list &lt;- gwas_list[!grepl(&#39;NEU&#39;, gwas_list$name),]
write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp_noneu.txt&#39;, col.names = T, row.names = F, quote = F)

gwas_groups &lt;- gwas_groups[!grepl(&#39;NEU&#39;, gwas_groups$name),]
write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_mvp_noneu.txt&#39;, col.names = T, row.names = F, quote = F)

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp_noneu.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_mvp_noneu.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;,&#39;prscsx&#39;,&#39;xwing&#39;]&quot;,
  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, # xwing run with 20 cores
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml \
  target_pgs -n
  
# Note. xwing fails for PLT. Remove PLT from gwas_list to get scores for other traits.
# Save PLT results for other methods to check the pattern is similar.
snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml \
  target_pgs -n
  </code></pre>
</details>
<hr />
</div>
<div id="pgs-evaluation-6" class="section level3">
<h3>PGS evaluation</h3>
<p>Compare the single-source PGS within AFR ancestry target
individuals.</p>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, header=F)$V1
selected_traits&lt;-selected_traits[selected_traits != &#39;NEU&#39;]

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for AFR targets
targ_pop &lt;- c(&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]
  scores_i$multi &lt;- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;MVP_AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;MVP_AFR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 &lt;-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                     !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_single_top1$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_single_pseudo$predictor)

      ####
      # Make groups for multi-single-source pseudo scores
      ####
      
      scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi_single_pseudo$name[i],
          pgs_method = scores_i_j_multi_single_pseudo$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi_single_pseudo$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_multi_single_pseudo$predictor[i])
          )
        )
      }
      
      scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_multi_single_pseudo$predictor)
      
      scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)

      ####
      # Make groups for the Multi-Source methods
      ####
      
      scores_i_j_multi &lt;- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]

      # Split top1 scores by target population
      # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
      scores_i_j_multi_top1&lt;-NULL
      for(i in 1:which(scores_i_j_multi$method %in% c(&#39;prscsx&#39;))){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_top1 &lt;- rbind(scores_i_j_multi_top1, tmp)
        }
      }

      # Split pop-specific pseudo scores by target population
      scores_i_j_multi_pop_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_pop_pseudo &lt;- rbind(scores_i_j_multi_pop_pseudo, tmp)
        }
      }
      
      # Create pseudo score for multi-source methods
      scores_i_j_multi_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi$name[i],
          pgs_method = scores_i_j_multi$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi$name[i], &#39;_&#39;, param)))

        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
          )
        )
        
        tmp &lt;- scores_i_j_multi[i,]
        tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
        tmp$top1 &lt;- paste0(&#39;EUR_&#39;, disc_pop_j_2)
        tmp$predictor &lt;-
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
        
        scores_i_j_multi_pseudo &lt;- rbind(scores_i_j_multi_pseudo, tmp)
      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo,
        scores_i_j_multi_single_pseudo,
        scores_i_j_multi_top1,
        scores_i_j_multi_pop_pseudo,
        scores_i_j_multi_pseudo
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
      ####
      # Make a group that will combined all population specific PGS
      ####
      
      predictors_i_all &lt;- predictors_i[predictors_i$top1 %in% c(&#39;EUR&#39;,&#39;AFR&#39;,&#39;EAS&#39;),]
      predictors_i_all$multi &lt;- &#39;all&#39;
      predictors_i&lt;-rbind(predictors_i, predictors_i_all)
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 --exclude=erc-hpc-comp058 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5&quot;
      fi
    done
  done
done
</code></pre>
<hr />
<h4>
Plot results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, header=F)$V1
selected_traits &lt;- selected_traits[selected_traits != &#39;NEU&#39;]
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTune&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTune&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTune&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTune&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTune or IndivTune
  tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
  tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots&#39;)

per_trait_plot &lt;- list()
for(pheno_i in selected_traits){
  tmp &lt;- res_eval_simp[res_eval_simp$Trait == pheno_i,]
  #tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
  tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
  tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)
  tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

  png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/&#39;, pheno_i,&#39;.png&#39;), res=300, width = 3400, height = 2000, units = &#39;px&#39;)
  plot_tmp&lt;-ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
  print(plot_tmp)
  dev.off()
  per_trait_plot[[pheno_i]]&lt;-plot_tmp
}

tmp &lt;- res_eval_simp
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/per_trait_part1.png&#39;), res=300, width = 3000, height = 3800, units = &#39;px&#39;)
ggplot(tmp[tmp$Trait %in% selected_traits[order(selected_traits)][1:5],], aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL) +
    facet_grid(Trait ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/per_trait_part2.png&#39;), res=300, width = 3000, height = 3800, units = &#39;px&#39;)
ggplot(tmp[tmp$Trait %in% selected_traits[order(selected_traits)][6:10],], aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL) +
    facet_grid(Trait ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()


####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/r_eval.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot performance of -multi models trained using LEOPARD vs using indiv-level data
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = unique(tmp$label[order(!(grepl(&#39;Multi&#39;, tmp$label)), tmp$label)]))
tmp&lt;-tmp[grepl(&#39;multi&#39;, tmp$label),]
tmp &lt;- tmp[tmp$Model != &#39;Multi-IndivTune&#39;,]
tmp$Model&lt;-as.character(tmp$Model)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;]&lt;-&#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;]&lt;-&#39;LEOPARD&#39;
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r_leopard.png&#39;), res=300, width = 1500, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Make simplified plot
# Just show performance when using IndivTrain (or SumStat), and Remove &#39;All&#39; model, with both GWAS.
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Method != &#39;all&#39;,]
tmp &lt;- tmp[tmp$Source  == &#39;Multi&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model[tmp$Model == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]
tmp&lt;-tmp[tmp$Model == &#39;IndivTune&#39;,]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r_simple.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23, fill = &#39;black&#39;) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()

tmp&lt;-tmp[tmp$Method %in% c(&#39;ldpred2&#39;,&#39;prscsx&#39;,&#39;xwing&#39;),]
png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r_simple_ldpred2.png&#39;), res=300, width = 500, height = 500, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
  #  geom_point(stat=&quot;identity&quot;, position=position_dodge(1), fill = &#39;#3399FF&#39;) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23, fill = &#39;#3399FF&#39;) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()


####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c(&#39;AFR&#39;)
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      comp_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_comp.txt&#39;
          )
        )
      comp_i&lt;-mirror_comp(comp_i)
      comp_i$Target&lt;-targ_pop_i
      comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_comp_i&lt;-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTune&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTune&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTune&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTune&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTune and Multi-IndivTune model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTune&#39;,&#39;Multi-IndivTune&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTune&#39;,&#39;Multi-SumStatTune&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;gwas_group&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;)]),]

res_comp_all$r_diff_rel &lt;- res_comp_all$R_diff / res_comp_all$Model_2_R

# Calculate relative improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

# Calculate relative improvement for sbayesrc-multi vs sbayesrc in EUR target as example
tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- res_comp_all
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;pheno&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;, &#39;R_diff_pval&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;, &#39;Trait&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$Trait, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/r_diff.csv&#39;, row.names=F)

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
    res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample&lt;-&#39;A&#39;
    res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
      cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i &lt;-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = &quot;BHHR&quot;,
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$Model_1_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$Model_2_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$R_diff &lt;- meta_res_comp_i$es
        tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$R_diff &lt;- NA
        tmp$R_diff_SE &lt;- NA
        tmp$R_diff_z &lt;- NA
        tmp$R_diff_p &lt;- NA
      }
      meta_res_comp &lt;- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Extract average improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

# Extract average improvement for sbayesrc-multi vs sbayesrc in EUR as example
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

# Extract average improvement for sbayesrc in EUR compared to all model
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p


# Compare QuickPRS-Multi vs QuickPRS to evaluate LEOPARD performance
tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-AFR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;AFR&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-EAS.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EAS&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTune or SumStatTune result
tmp &lt;- meta_res_comp
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp$`Percentage change (R difference / Model 2 R)` &lt;- paste0(round(tmp$R_diff_perc * 100, 1), &#39;%&#39;)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;,&quot;Percentage change (R difference / Model 2 R)&quot;, &#39;R_diff_p&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;Percentage change (R difference / Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/r_diff_average.csv&#39;, row.names=F)

############

# Group differences
meta_res_comp$R_diff_catagory &lt;- cut(
    meta_res_comp$R_diff,
    breaks = c(-Inf, -0.08, -0.025, -0.002, 0.002, 0.025, 0.08, Inf),
    labels = c(&#39;&lt; -0.08&#39;, &#39;-0.08 - -0.025&#39;, &#39;-0.025 - -0.002&#39;, &#39;-0.002 - 0.002&#39;, &#39;0.002 - 0.025&#39;, &#39;0.025 - 0.08&#39;, &#39;&gt; 0.08&#39;),
    right = FALSE
)
meta_res_comp$R_diff_catagory &lt;- factor(meta_res_comp$R_diff_catagory, levels = rev(levels(meta_res_comp$R_diff_catagory)))

# Assign significance stars
meta_res_comp$indep_star&lt;-&#39; &#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 0.05]&lt;-&#39;*&#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-3]&lt;-&#39;**&#39;
# meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-6]&lt;-&#39;***&#39;

meta_res_comp&lt;-meta_res_comp[order(meta_res_comp$Discovery1, meta_res_comp$Discovery2, meta_res_comp$Method1),]

for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){

    tmp &lt;- meta_res_comp[meta_res_comp$Target == targ_pop_i, ]

    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;
    
    tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
    tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)
    
    tmp$Model1[tmp$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
    tmp$Model1[tmp$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
    tmp$Model2[tmp$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
    tmp$Model2[tmp$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
    
    tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
    tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

    tmp$label1 &lt;- factor(tmp$label1, levels = model_order)
    tmp$label2 &lt;- factor(tmp$label2, levels = model_order)

    tmp&lt;-tmp[order(tmp$label1, tmp$label2),]
    
    tmp$label1 &lt;- paste0(tmp$label1,&quot; (&quot;, ifelse(tmp$Model1 == &#39;SumStatTune&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)
    tmp$label2 &lt;- paste0(tmp$label2,&quot; (&quot;, ifelse(tmp$Model2 == &#39;SumStatTune&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)

    tmp$label1 &lt;- factor(tmp$label1, levels = unique(tmp$label1))
    tmp$label2 &lt;- factor(tmp$label2, levels = unique(tmp$label2))
    
    tmp &lt;- tmp[tmp$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i), ]
    
    plot_tmp &lt;- ggplot(data = tmp, aes(label2, label1, fill = R_diff_catagory)) +
      geom_tile(color = &quot;white&quot;, show.legend = TRUE) +
      labs(y = &#39;Test&#39;, x = &#39;Comparison&#39;, fill = &#39;R difference&#39;, title = paste0(&#39;Target: &#39;, targ_pop_i)) +
      facet_grid(Discovery1 ~ Discovery2, scales = &#39;free&#39;, space = &#39;free&#39;, switch=&quot;both&quot;) +
      geom_text(
        data = tmp,
        aes(label2, label1, label = indep_star),
        color = &quot;black&quot;,
        size = 4,
        angle = 0,
        vjust = 0.8
      ) +
      scale_fill_brewer(
        breaks = levels(tmp$R_diff_catagory),
        palette = &quot;RdBu&quot;,
        drop = F,
        na.value = &#39;grey&#39;
      ) +
      theme_half_open() +
      background_grid() +
      panel_border() +
      theme(axis.text.x = element_text(
        angle = 45,
        vjust = 1,
        hjust = 1
      ))
    
    png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r_diff.Discovery_EUR_&#39;, disc_pop_i,&#39;.Target_&#39;, targ_pop_i, &#39;.png&#39;), res=300, width = 4400, height = 3200, units = &#39;px&#39;)
      print(plot_tmp)
    dev.off()
  }
}

####
# Plot relative improvement of methods
####
# Use ptclump IndivTune using EUR GWAS as the reference, as provides an interpretable scale

meta_res_comp_ptclump_top1&lt;-meta_res_comp[meta_res_comp$Method2 == &#39;all&#39; &amp; meta_res_comp$Source2 == &#39;Multi&#39;,]
meta_res_comp_ptclump_top1$reference_point&lt;-F
meta_res_comp_ptclump_top1$reference_point[meta_res_comp_ptclump_top1$Method1 == &#39;all&#39; &amp; meta_res_comp_ptclump_top1$Source1 == &#39;Multi&#39;]&lt;-T
meta_res_comp_ptclump_top1$R_diff[is.na(meta_res_comp_ptclump_top1$R_diff)]&lt;-0
meta_res_comp_ptclump_top1$Discovery1 &lt;- factor(meta_res_comp_ptclump_top1$Discovery1, levels=rev(levels(meta_res_comp_ptclump_top1$Discovery1)))

res_comp_all_ptclump_top1&lt;-res_comp_all[res_comp_all$Method2 == &#39;all&#39; &amp; res_comp_all$Source2 == &#39;Multi&#39;,]
res_comp_all_ptclump_top1$Discovery1 &lt;-  factor(res_comp_all_ptclump_top1$Discovery1, levels=levels(meta_res_comp_ptclump_top1$Discovery1))

# Create data to plot reference points
meta_res_comp_reference &lt;- meta_res_comp_ptclump_top1
meta_res_comp_reference$R_diff[meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
meta_res_comp_reference$R_diff_SE [meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
res_comp_all_ptclump_top1$reference_point&lt;-F

meta_tmp &lt;- meta_res_comp_ptclump_top1
meta_tmp &lt;- merge(meta_tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp$label[is.na(meta_tmp$label)] &lt;- &#39;All&#39;
meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;] &lt;- paste0(meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp$label &lt;- factor(meta_tmp$label, levels = model_order)
meta_tmp$Discovery_clean &lt;- as.character(meta_tmp$Discovery1)
meta_tmp$Discovery_clean[meta_tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Single&#39;] &lt;- &#39;AFR GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;EUR + AFR GWAS&#39;
meta_tmp$Discovery_clean &lt;- factor(meta_tmp$Discovery_clean, 
                              levels = c(&#39;AFR GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;EUR + AFR GWAS&#39;))
meta_tmp$Target &lt;- paste0(meta_tmp$Target, &#39; Target&#39;)
meta_tmp$Model1 &lt;- factor(meta_tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

meta_tmp_ref &lt;- meta_res_comp_reference
meta_tmp_ref &lt;- merge(meta_tmp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp_ref$label[is.na(meta_tmp_ref$label)] &lt;- &#39;All&#39;
meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;] &lt;- paste0(meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp_ref$label &lt;- factor(meta_tmp_ref$label, levels = model_order)
meta_tmp_ref$Discovery_clean &lt;- as.character(meta_tmp_ref$Discovery1)
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Single&#39;] &lt;- &#39;AFR GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Multi&#39;] &lt;- &#39;EUR + AFR GWAS&#39;
meta_tmp_ref$Discovery_clean &lt;- factor(meta_tmp_ref$Discovery_clean, 
                              levels = c(&#39;AFR GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;EUR + AFR GWAS&#39;))
meta_tmp_ref$Target &lt;- paste0(meta_tmp_ref$Target, &#39; Target&#39;)
meta_tmp_ref$Model1 &lt;- factor(meta_tmp_ref$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

tmp &lt;- res_comp_all_ptclump_top1
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery1)
tmp$Discovery_clean[tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Single&#39;] &lt;- &#39;AFR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;EUR + AFR GWAS&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;AFR GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;EUR + AFR GWAS&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model1 &lt;- factor(tmp$Model1, levels = c(&#39;IndivTune&#39;,&#39;SumStatTune&#39;,&#39;Multi-IndivTune&#39;,&#39;Multi-SumStatTune&#39;))

ggplot(meta_tmp, aes(x=label, y=R_diff , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff - R_diff_SE,
          ymax = R_diff + R_diff_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R_diff (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


# Plot as % change
meta_tmp$R_diff_perc &lt;- meta_tmp$R_diff / meta_tmp$Model_2_R
meta_tmp_ref$R_diff_perc &lt;- meta_tmp_ref$R_diff / meta_tmp_ref$Model_2_R
tmp$R_diff_perc &lt;- tmp$R_diff / tmp$Model_2_R

meta_tmp$R_diff_perc_SE &lt;- meta_tmp$R_diff_SE / meta_tmp$Model_2_R

library(scales)
ggplot(meta_tmp, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R diff. (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# Simplify results showing results only with or without training data
meta_tmp_simple &lt;- meta_tmp
meta_tmp_simple$Model1[meta_tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model1[meta_tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_2 %in% res_eval_simp$Group,]

meta_tmp_ref_simple &lt;- meta_tmp_ref
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_2 %in% res_eval_simp$Group,]

tmp_simple &lt;- tmp
tmp_simple$Model1[tmp_simple$Model1 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model1[tmp_simple$Model1 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple$Model2[tmp_simple$Model2 != &#39;SumStatTune&#39;] &lt;- &#39;IndivTune&#39;
tmp_simple$Model2[tmp_simple$Model2 == &#39;SumStatTune&#39;] &lt;- &#39;SumStatTune&#39;
tmp_simple&lt;-tmp_simple[tmp_simple$Model_1 %in% res_eval_simp$Group,]
tmp_simple&lt;-tmp_simple[tmp_simple$Model_2 %in% res_eval_simp$Group,]

# Export plot for manuscript
png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/average_r.perc_improv.png&#39;, width = 3200, height = 1500, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target != &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
#    geom_boxplot(
#      data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
#        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
#        position = position_dodge(0.7),
#        alpha = 0.3
#      ) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()

########
# Plot relative improvement of LEOPARD over IndivTune of SumStatTune scores
########

# meta res
meta_res_comp_ref &lt;- meta_res_comp[meta_res_comp$Model2 == &#39;Multi-SumStatTune&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[meta_res_comp_ref$Method1 != &#39;all&#39; &amp; meta_res_comp_ref$Method2 != &#39;all&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[meta_res_comp_ref$Model1 == &#39;SumStatTune&#39; &amp; meta_res_comp_ref$Source1 == &#39;Multi&#39;,]
meta_res_comp_ref &lt;- meta_res_comp_ref[gsub(&#39;_multi&#39;,&#39;&#39;, meta_res_comp_ref$Method1) == gsub(&#39;_multi&#39;,&#39;&#39;, meta_res_comp_ref$Method2),]

meta_res_comp_ref$R_diff_perc &lt;- meta_res_comp_ref$R_diff / meta_res_comp_ref$Model_2_R
meta_res_comp_ref$R_diff_perc_SE &lt;- meta_res_comp_ref$R_diff_SE / meta_res_comp_ref$Model_2_R

meta_res_comp_ref$Discovery_clean &lt;- paste0(meta_res_comp_ref$Discovery1,&#39; GWAS&#39;)
meta_res_comp_ref$Discovery_clean[meta_res_comp_ref$Target != &#39;EUR&#39;] &lt;- &#39;EUR + Target-matched GWAS&#39;

meta_res_comp_ref &lt;- merge(meta_res_comp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_res_comp_ref$label[grepl(&#39;Multi&#39;, meta_res_comp_ref$Model1) &amp; !(meta_res_comp_ref$Method1 %in% pgs_group_methods)] &lt;- paste0(meta_res_comp_ref$label[grepl(&#39;Multi&#39;, meta_res_comp_ref$Model1) &amp; !(meta_res_comp_ref$Method1 %in% pgs_group_methods)], &#39;-multi&#39;)
meta_res_comp_ref$label &lt;- factor(meta_res_comp_ref$label, levels = model_order)

meta_res_comp_ref$Target_clean &lt;- paste0(meta_res_comp_ref$Target,&#39; Target&#39;)

# trait-specific res
res_comp_all_ref &lt;- res_comp_all[res_comp_all$Model2 == &#39;Multi-SumStatTune&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[res_comp_all_ref$Method1 != &#39;all&#39; &amp; res_comp_all_ref$Method2 != &#39;all&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[res_comp_all_ref$Model1 == &#39;SumStatTune&#39; &amp; res_comp_all_ref$Source1 == &#39;Multi&#39;,]
res_comp_all_ref &lt;- res_comp_all_ref[gsub(&#39;_multi&#39;,&#39;&#39;, res_comp_all_ref$Method1) == gsub(&#39;_multi&#39;,&#39;&#39;, res_comp_all_ref$Method2),]

res_comp_all_ref$R_diff_perc &lt;- res_comp_all_ref$R_diff / res_comp_all_ref$Model_2_R
res_comp_all_ref$R_diff_perc_SE &lt;- res_comp_all_ref$R_diff_SE / res_comp_all_ref$Model_2_R

res_comp_all_ref$Discovery_clean &lt;- paste0(res_comp_all_ref$Discovery1,&#39; GWAS&#39;)
res_comp_all_ref$Discovery_clean[res_comp_all_ref$Target != &#39;EUR&#39;] &lt;- &#39;EUR + Target-matched GWAS&#39;

res_comp_all_ref &lt;- merge(res_comp_all_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
res_comp_all_ref$label[grepl(&#39;Multi&#39;, res_comp_all_ref$Model1) &amp; !(res_comp_all_ref$Method1 %in% pgs_group_methods)] &lt;- paste0(res_comp_all_ref$label[grepl(&#39;Multi&#39;, res_comp_all_ref$Model1) &amp; !(res_comp_all_ref$Method1 %in% pgs_group_methods)], &#39;-multi&#39;)
res_comp_all_ref$label &lt;- factor(res_comp_all_ref$label, levels = model_order)

res_comp_all_ref$Target_clean &lt;- paste0(res_comp_all_ref$Target,&#39; Target&#39;)

tmp_meta&lt;-meta_res_comp_ref
tmp_all&lt;-res_comp_all_ref

tmp_meta&lt;-tmp_meta[!(tmp_meta$Method1 %in% c(&#39;prscsx&#39;,&#39;xwing&#39;)),]
tmp_meta&lt;-tmp_meta[tmp_meta$Target != &#39;EUR&#39;,]

tmp_all&lt;-tmp_all[!(tmp_all$Method1 %in% c(&#39;prscsx&#39;,&#39;xwing&#39;)),]
tmp_all&lt;-tmp_all[tmp_all$Target != &#39;EUR&#39;,]

library(ggrepel)

# plot
png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/leopard_perc_improv.png&#39;, width = 1800, height = 1100, res= 300, units = &#39;px&#39;)

ggplot(tmp_meta, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp_meta$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Difference (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(. ~ Target_clean) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &#39;none&#39;
    )
dev.off()

# Now compare quickPRS-multi and prs-csx only with trait
tmp_meta&lt;-meta_res_comp_ref
tmp_all&lt;-res_comp_all_ref

tmp_meta&lt;- tmp_meta[tmp_meta$Target != &#39;EUR&#39; &amp; tmp_meta$Method1 %in% c(&#39;quickprs_multi&#39;,&#39;prscsx&#39;),]
tmp_all&lt;- tmp_all[tmp_all$Target != &#39;EUR&#39; &amp; tmp_all$Method1 %in% c(&#39;quickprs_multi&#39;,&#39;prscsx&#39;),]

library(ggrepel)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/leopard_perc_improv_restricted.png&#39;, width = 1500, height = 1500, res= 300, units = &#39;px&#39;)
ggplot(tmp_meta, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_all,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Difference (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(. ~ Target_clean) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &#39;none&#39;
    ) +
    geom_text_repel(
      data = tmp_all[
        tmp_all$R_diff_perc &lt; -0.05,
      ],
      aes(label = pheno),  # label as percent with 1 decimal
      position = position_dodge(width = 0.7),
      size = 3,
      min.segment.length = 0,
      segment.color = NA,
      show.legend = FALSE
    )
dev.off()</code></pre>
</details>
<hr />
</div>
<div id="descriptive-statistics" class="section level3">
<h3>Descriptive statistics</h3>
<p>Create a table showing descriptive statistics for the MVP sumstats.
This should include LDSC SNP-heritability and AVENGEME results.</p>
<hr />
<div id="ldsc-1" class="section level4">
<h4>LDSC</h4>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>conda activate ldsc

for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt); do
  mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/sumstats

  sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/munge_sumstats.py \
   --sumstats /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/${pheno}_MVP_AFR/${pheno}_MVP_AFR-cleaned.gz \
   --out /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/${pheno}_MVP_AFR/${pheno}_MVP_AFR&quot;
done

for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt); do
  mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/results/${pheno}/MVP_AFR

  sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/ldsc.py \
   --h2 /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/${pheno}_MVP_AFR/${pheno}_MVP_AFR.sumstats.gz \
   --ref-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.AFR.rsid \
   --w-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.AFR.rsid \
   --out /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/results/${pheno}/MVP_AFR/res&quot;
done
</code></pre>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, header=F)$V1

# Plot the heritability estimates
h2_res &lt;- NULL

for(pheno in pheno_intersect){
  log &lt;-
    readLines(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/results/&#39;,
        pheno,
        &#39;/&#39;,
        &#39;MVP_AFR&#39;,
        &#39;/res.log&#39;
      )
    )
  
  h2 &lt;- log[grepl(&#39;Total Observed scale h2:&#39;, log)]
  h2_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Total Observed scale h2: &#39;, &#39;&#39;, h2)))
  h2_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, h2)))
  int &lt;- log[grepl(&#39;Intercept:&#39;, log)]
  int_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Intercept: &#39;, &#39;&#39;, int)))
  int_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, int)))
  lambda &lt;- log[grepl(&#39;Lambda GC:&#39;, log)]
  lambda &lt;- as.numeric(gsub(&#39;.* &#39;,&#39;&#39;, lambda))
  
  h2_res &lt;- rbind(
    h2_res,
    data.table(
      Population = &#39;AFR&#39;,
      Phenotype = pheno,
      h2_est = h2_est,
      h2_se = h2_se,
      int_est = int_est,
      int_se = int_se,
      lambda = lambda
    )
  )
}


write.csv(h2_res, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/results.csv&#39;, row.names = F, quote = F)</code></pre>
</details>
<hr />
</div>
<div id="avengeme-1" class="section level4">
<h4>AVENGEME</h4>
<details>
<summary>
Show code
</summary>
<div class="shallow-break">

</div>
<h4>
Create predictor list
</h4>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

# Read in phenotypes
pheno_intersect &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, header=F)$V1

# Create files for EAS and AFR targets
pop &lt;- c(&#39;AFR&#39;)
for(trait_i in pheno_intersect){
  # Make a group containing both GWAS for each single source method
  # Make a group for each multisource method
  scores_i &lt;- scores[grepl(paste0(&#39;^&#39;, trait_i, &#39;_&#39;), scores$name),]
  scores_i$group &lt;- scores_i$method
  
  for(pop_i in pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    samp_i &lt;- &#39;MVP_AFR&#39;

    dir.create(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i
      ),
      recursive = T
    )
    
    scores_i_j &lt;- scores_i[grepl(samp_i, scores_i$name, ignore.case = T),]
    scores_i_j &lt;- scores_i_j[!grepl(&#39;UKB&#39;, scores_i_j$name),]
    scores_i_j &lt;- scores_i_j[scores_i_j$method == &#39;ptclump&#39;,]
    scores_i_j$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i_j$method,
      &#39;/&#39;,
      scores_i_j$name,
      &#39;/ukb-&#39;,
      scores_i_j$name,
      &#39;-TRANS.profiles&#39;
    )
    
    predictors_i &lt;- scores_i_j[, c(&#39;predictor&#39;, &#39;group&#39;), with=F]
    
    write.table(
      predictors_i,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i,
        &#39;/predictor_list.ptclump.txt&#39;
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}</code></pre>
<hr />
<h4>
Run model_builder
</h4>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

for pop in $(echo AFR); do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      pop2=&quot;EUR_test&quot;
  else
      pop2=$pop
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt); do
    sbatch --mem 5G -n 5 -p neurohack_cpu --wrap=&quot;Rscript ../Scripts/model_builder/model_builder.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${pop2}.row_number.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_${pop}.disc_${pop}/${pheno}/predictor_list.ptclump.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_${pop}.disc_${pop}/${pheno}/res.ptclump \
      --n_core 5 \
      --all_model F \
      --assoc T&quot;
  done
done
</code></pre>
<hr />
<h4>
Plot pT+clump association results
</h4>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)
library(avengeme)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)
gwas_list &lt;- read_param(config = config, param = &#39;gwas_list&#39;, return_obj = T)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/trait_subset.txt&#39;, header=F)$V1

pop = c(&#39;AFR&#39;)

mod_res_all &lt;- NULL
for(pop_i in pop){
  for(pheno_i in pheno_intersect){
    gwas_i&lt;-gwas_list$name[gwas_list$population == pop_i &amp; grepl(paste0(&#39;^&#39;, pheno_i, &#39;_&#39;),  gwas_list$name)]
      
    res_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;,
          pop_i,
          &#39;.disc_&#39;,
          pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res.ptclump.assoc.txt&#39;
        )
      )
    
    res_i$Z &lt;- res_i$BETA / res_i$SE
    
    res_i$pT &lt;- as.numeric(gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.|.*MVP.AFR\\.0\\.&#39;, &#39;&#39;, res_i$Predictor)))

    nsnp_log &lt;-
      read.table(
        paste0(
          outdir,
          &#39;/reference/pgs_score_files/ptclump/&#39;,
          gwas_i,
          &#39;/ref-&#39;,
          gwas_i,
          &#39;.NSNP_per_pT&#39;
        ),
        header = T
      )
    
    nsnp&lt;-nsnp_log$NSNP[nrow(nsnp_log)]
    
    disc_N &lt;-
      median(
        fread(
          paste0(
            outdir,
            &#39;/reference/gwas_sumstat/&#39;,
            gwas_i,
            &#39;/&#39;,
            gwas_i,
            &#39;-cleaned.gz&#39;
          ), nrows = 10000
        )$N
      )
    
    targ_N &lt;- res_i$N[1]
    
    mod_res &lt;- estimatePolygenicModel(
      p = res_i$Z,
      nsnp = nsnp,
      n = c(disc_N, targ_N),
      pupper = c(0, res_i$pT),
      fixvg2pi02 = T,
      alpha = 0.05
    )
    
    mod_res_all &lt;- rbind(
      mod_res_all,
      data.frame(
        Phenotype = pheno_i,
        Population = pop_i,
        GWAS = gwas_i,
        nsnp = nsnp,
        max_r2 = max(res_i$Obs_R2),
        n_disc = disc_N,
        n_targ = targ_N,
        vg_est = mod_res$vg[1],
        vg_lowCI = mod_res$vg[2],
        vg_highCI = mod_res$vg[3],
        pi0_est = mod_res$pi0[1],
        pi0_lowCI = mod_res$pi0[2],
        pi0_highCI = mod_res$pi0[3]
      )
    )
  }
}

dir.create(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/avengeme&#39;)
write.csv(mod_res_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/avengeme/results.csv&#39;, row.names = F, quote = F)

mod_res_all&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/avengeme/results.csv&#39;)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/avengeme_h2.png&#39;, res = 100, width = 900, height = 500, units = &#39;px&#39;)
ggplot(mod_res_all, aes(x = Phenotype, y = vg_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=vg_lowCI, ymax=vg_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;SNP-based Heritability (95%CI)&quot;, fill = NULL) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(1, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/avengeme_polygenicity.png&#39;, res = 100, width = 900, height = 500, units = &#39;px&#39;)
ggplot(mod_res_all, aes(x = Phenotype, y = 1 - pi0_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=1 - pi0_lowCI, ymax=1 - pi0_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;Proporition non-zero\neffects (95%CI)&quot;, fill = NULL) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(1, &quot;cm&quot;),
        legend.justification = &quot;center&quot;) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)
dev.off()

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])</code></pre>
</details>
<hr />
</div>
<div id="make-table" class="section level4">
<h4>Make table</h4>
<p>Make a table showing GWAS information for the manuscript.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

#####
# Trait names, labels, and URLs
#####

mvp &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/MVP/AFR/info.txt&#39;)
mvp &lt;- mvp[, c(&#39;efoTraits&#39;,&#39;labels&#39;,&#39;url&#39;), with=F]
names(mvp) &lt;- c(&#39;trait&#39;, &#39;labels&#39;,&#39;url&#39;)
mvp$sample &lt;- &#39;MVP&#39;
mvp$population &lt;- &#39;AFR&#39;

#####
# Sample size, SNP-h2 and polygenicity
#####

# Read in the AVENGEME and LDSC results
avengeme &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/avengeme/results.csv&#39;)
ldsc &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/ldsc/results.csv&#39;)
both &lt;- merge(avengeme, ldsc, by = c(&#39;Population&#39;,&#39;Phenotype&#39;))

# Format for descriptives table
both$h2_avengeme&lt;- paste0(
  round(both$vg_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$vg_lowCI, 2), 
  &quot; - &quot; , 
  round(both$vg_highCI, 2), &quot;)&quot;)

both$pi0_avengeme &lt;- paste0(
  round(both$pi0_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$pi0_lowCI, 2), 
  &quot; - &quot; , 
  round(both$pi0_highCI, 2), &quot;)&quot;)

both$h2_ldsc &lt;- paste0(
  round(both$h2_est,2), 
  &quot; (SE = &quot;, 
  round(both$h2_se, 2), 
  &quot;)&quot;)

both$int_ldsc &lt;- paste0(
  round(both$int_est,2), 
  &quot; (SE = &quot;, 
  round(both$int_se, 2), 
  &quot;)&quot;)

both&lt;-both[, c(&#39;Population&#39;,&#39;Phenotype&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;), with = F]
names(both)[1:2]&lt;-c(&#39;population&#39;,&#39;labels&#39;)

info_all &lt;- merge(mvp, both, by = c(&#39;labels&#39;,&#39;population&#39;))
info_all$n_disc&lt;-round(info_all$n_disc, 0)
info_all$n_targ&lt;-round(info_all$n_targ, 0)

info_all&lt;-info_all[, c(&#39;labels&#39;,&#39;trait&#39;,&#39;population&#39;,&#39;sample&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;,&#39;url&#39;), with=F]
names(info_all) &lt;- c(&#39;Trait Label&#39;, &#39;Trait Description&#39;, &#39;Ancestry&#39;, &#39;GWAS Sample&#39;, &#39;GWAS N&#39;, &#39;Target N&#39;,&quot;SNP-h2 (AVENGEME)&quot;,&quot;pi0 (AVENGEME)&quot;,&quot;SNP-h2 (LDSC)&quot;,&quot;Intercept (LDSC)&quot;,&#39;Lambda&#39;, &#39;URL&#39;)

write.csv(info_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/gwas_descriptives.csv&#39;, row.names=F)

# Estimate the mean and SD of sample size within each population for selected traits
info_all_selected&lt;-info_all
n_dat &lt;- NULL
for(i in unique(info_all_selected$`GWAS Sample`)){
  n_dat &lt;-rbind(
    n_dat,
    data.table(
      sample = i,
      gwas_n_median = round(median(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_mean = round(mean(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_sd = round(sd(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      target_n_median = round(median(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_mean = round(mean(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_sd = round(sd(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i]))
    )
  )
}</code></pre>
</details>
<details>
<summary>
Show descriptives table
</summary>
<div
style="border: 1px solid #ddd; padding: 0px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%; ">
<table class="table table-striped table-hover" style="color: black; width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Trait Label
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Trait Description
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Ancestry
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
GWAS Sample
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
GWAS N
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Target N
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
SNP-h2 (AVENGEME)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
pi0 (AVENGEME)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
SNP-h2 (LDSC)
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
Intercept (LDSC)
</th>
<th style="text-align:right;position: sticky; top:0; background-color: #FFFFFF;">
Lambda
</th>
<th style="text-align:left;position: sticky; top:0; background-color: #FFFFFF;">
URL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
BMI
</td>
<td style="text-align:left;">
body mass index
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
118993
</td>
<td style="text-align:right;">
6646
</td>
<td style="text-align:left;">
0.12 (95%CI = 0.11 - 0.14)
</td>
<td style="text-align:left;">
0.96 (95%CI = 0.95 - 0.97)
</td>
<td style="text-align:left;">
0.37 (SE = 0.03)
</td>
<td style="text-align:left;">
1.32 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6715
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475155/GCST90475155.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475155/GCST90475155.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
BWT
</td>
<td style="text-align:left;">
body weight
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
119279
</td>
<td style="text-align:right;">
6659
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.13 - 0.16)
</td>
<td style="text-align:left;">
0.96 (95%CI = 0.95 - 0.97)
</td>
<td style="text-align:left;">
0.4 (SE = 0.03)
</td>
<td style="text-align:left;">
1.36 (SE = 0.03)
</td>
<td style="text-align:right;">
1.7334
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476462/GCST90476462.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476462/GCST90476462.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
HB
</td>
<td style="text-align:left;">
hemoglobin measurement
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
114985
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.06 (95%CI = 0.05 - 0.07)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 0.99)
</td>
<td style="text-align:left;">
0.19 (SE = 0.02)
</td>
<td style="text-align:left;">
1.2 (SE = 0.02)
</td>
<td style="text-align:right;">
1.3685
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475375/GCST90475375.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475375/GCST90475375.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
HDL
</td>
<td style="text-align:left;">
high density lipoprotein cholesterol measurement
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
113085
</td>
<td style="text-align:right;">
5863
</td>
<td style="text-align:left;">
0.11 (95%CI = 0.1 - 0.12)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 0.99)
</td>
<td style="text-align:left;">
0.32 (SE = 0.04)
</td>
<td style="text-align:left;">
1.3 (SE = 0.02)
</td>
<td style="text-align:right;">
1.5071
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475351/GCST90475351.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475351/GCST90475351.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
HT
</td>
<td style="text-align:left;">
body height
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
119012
</td>
<td style="text-align:right;">
6658
</td>
<td style="text-align:left;">
0.14 (95%CI = 0.12 - 0.15)
</td>
<td style="text-align:left;">
0.96 (95%CI = 0.95 - 0.97)
</td>
<td style="text-align:left;">
0.93 (SE = 0.08)
</td>
<td style="text-align:left;">
1.69 (SE = 0.06)
</td>
<td style="text-align:right;">
2.2871
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475361/GCST90475361.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475361/GCST90475361.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
MCHC
</td>
<td style="text-align:left;">
mean corpuscular hemoglobin concentration
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
114851
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.09 (95%CI = 0.08 - 0.1)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 0.99)
</td>
<td style="text-align:left;">
0.27 (SE = 0.1)
</td>
<td style="text-align:left;">
1.32 (SE = 0.03)
</td>
<td style="text-align:right;">
1.4034
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475457/GCST90475457.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475457/GCST90475457.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
NEU
</td>
<td style="text-align:left;">
neutrophil count
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
73258
</td>
<td style="text-align:right;">
6353
</td>
<td style="text-align:left;">
0.36 (95%CI = 0.34 - 0.38)
</td>
<td style="text-align:left;">
0.97 (95%CI = 0.96 - 0.97)
</td>
<td style="text-align:left;">
2.32 (SE = 1.19)
</td>
<td style="text-align:left;">
1.43 (SE = 0.07)
</td>
<td style="text-align:right;">
1.4459
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475528/GCST90475528.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90475001-GCST90476000/GCST90475528/GCST90475528.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
PLT
</td>
<td style="text-align:left;">
platelet count
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
114731
</td>
<td style="text-align:right;">
6375
</td>
<td style="text-align:left;">
0.1 (95%CI = 0.09 - 0.11)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 0.99)
</td>
<td style="text-align:left;">
0.38 (SE = 0.03)
</td>
<td style="text-align:left;">
1.38 (SE = 0.02)
</td>
<td style="text-align:right;">
1.6639
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476298/GCST90476298.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476298/GCST90476298.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
SBP
</td>
<td style="text-align:left;">
systolic blood pressure
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
119331
</td>
<td style="text-align:right;">
6658
</td>
<td style="text-align:left;">
0.06 (95%CI = 0.05 - 0.07)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.98 - 0.99)
</td>
<td style="text-align:left;">
0.19 (SE = 0.02)
</td>
<td style="text-align:left;">
1.2 (SE = 0.01)
</td>
<td style="text-align:right;">
1.3964
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476402/GCST90476402.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476402/GCST90476402.tsv.gz</a>
</td>
</tr>
<tr>
<td style="text-align:left;">
TC
</td>
<td style="text-align:left;">
total cholesterol measurement
</td>
<td style="text-align:left;">
AFR
</td>
<td style="text-align:left;">
MVP
</td>
<td style="text-align:right;">
112265
</td>
<td style="text-align:right;">
6324
</td>
<td style="text-align:left;">
0.1 (95%CI = 0.09 - 0.12)
</td>
<td style="text-align:left;">
0.99 (95%CI = 0.99 - 0.99)
</td>
<td style="text-align:left;">
0.2 (SE = 0.04)
</td>
<td style="text-align:left;">
1.25 (SE = 0.02)
</td>
<td style="text-align:right;">
1.3615
</td>
<td style="text-align:left;">
<a
href="http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476423/GCST90476423.tsv.gz"
class="uri">http://ftp.ebi.ac.uk/pub/databases/gwas/summary_statistics/GCST90476001-GCST90477000/GCST90476423/GCST90476423.tsv.gz</a>
</td>
</tr>
</tbody>
</table>
</div>
</details>
<hr />
</div>
</div>
<div id="leopardquickprs-2" class="section level3">
<h3>LEOPARD+QuickPRS</h3>
<p>Here we will compare the LEOPARD estimated weights for population
specific PGS, to the weights estimated using observed data in the UKB
target sample.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_mvp.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

###
# Read in weights estimated by LEOPARD (QuickPRS)
###

leopard_weights&lt;-NULL
scores_quickprs &lt;- scores$name[scores$method == &#39;quickprs_multi&#39;]
for(i in selected_traits){
  scores_i &lt;- scores_quickprs[grepl(paste0(&#39;^&#39;, i,&#39;_&#39;), scores_quickprs)]
  for(j in scores_i){
      weights_file &lt;- readRDS(paste0(outdir, &#39;/reference/pgs_score_files/leopard/&#39;, j, &#39;/ref-&#39;, j, &#39;.weights.rds&#39;))
      weights_file &lt;- data.frame(weights_file)
      
      weights &lt;-
        data.table(
          Target = do.call(c, lapply(names(weights_file), function(x) rep(x, 2))),
          Discovery = names(weights_file),
          Weight = do.call(c, lapply(weights_file, function(x) x)),
          Trait = i,
          Method = &#39;LEOPARD&#39;
        )
      
      leopard_weights &lt;- rbind(leopard_weights, weights)
  }
}

#####
# Read in the PGS weights estimated using UKB data
#####
# Read in the final model coefficients for multi-source methods

obs_weights&lt;-NULL
for(method_i in unique(scores$method)[!(unique(scores$method) %in% pgs_group_methods)]){
  scores_method&lt;-scores$name[scores$method == method_i]
  method_i &lt;- gsub(&#39;_multi&#39;,&#39;&#39;, method_i)

  for(i in selected_traits){
    for(j in c(&#39;AFR&#39;)){
      if(j == &#39;EUR&#39;){
        pops &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
      } else {
        pops &lt;- j
      }
      
      for(k in pops){
        model &lt;- fread(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/targ_&#39;, j, &#39;.disc_EUR_&#39;, k, &#39;/&#39;, i, &#39;/final_models/&#39;, method_i, &#39;.pseudo.multi.final_model.txt&#39;))
        model&lt;-model[-1,]
        
        # Set weight to zero if negative, as this is what LEOPARD does
        if(any(model$V2 &lt; 0)){
          model$V2[model$V2 &lt; 0] &lt;- 0
          model$V2[model$V2 &gt; 0] &lt;- 1
        }
        
        names(model) &lt;- c(&#39;x&#39;, &#39;BETA&#39;)
        model$Discovery[grepl(&#39;UKB&#39;, model$x)]&lt;-&#39;EUR&#39;
        model$Discovery[grepl(&#39;MVP&#39;, model$x)]&lt;-&#39;AFR&#39;
        model$Target &lt;- j
        model$Weight &lt;- model$BETA/sum(model$BETA)
        model$Trait &lt;- i
        model$Method &lt;- method_i
        model&lt;-model[,c(&#39;Target&#39;,&#39;Discovery&#39;,&#39;Weight&#39;,&#39;Method&#39;,&#39;Trait&#39;), with=F]
        obs_weights&lt;-rbind(obs_weights, model)
      }
    }
  }
}

###
# Estimate weights if using the inverse variance weighting
###

# Read in GWAS descriptives
gwas_desc&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)
gwas_desc &lt;- gwas_desc[, c(&#39;Trait Label&#39;,&#39;Ancestry&#39;,&#39;GWAS N&#39;), with=F]
names(gwas_desc)&lt;-c(&#39;trait&#39;,&#39;ancestry&#39;,&#39;n&#39;)
gwas_desc&lt;-gwas_desc[gwas_desc$trait %in% selected_traits,]

gwas_desc &lt;- gwas_desc[gwas_desc$ancestry == &#39;EUR&#39;,]

gwas_desc_mvp &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_mvp/gwas_descriptives.csv&#39;)
gwas_desc_mvp &lt;- gwas_desc_mvp[, c(&#39;Trait Label&#39;,&#39;Ancestry&#39;,&#39;GWAS N&#39;), with=F]
names(gwas_desc_mvp)&lt;-c(&#39;trait&#39;,&#39;ancestry&#39;,&#39;n&#39;)
gwas_desc_mvp&lt;-gwas_desc_mvp[gwas_desc_mvp$trait %in% selected_traits,]

gwas_desc&lt;-rbind(gwas_desc, gwas_desc_mvp)

library(dplyr)
library(tidyr)

# Reshape GWAS table to wide format
wide_gwas &lt;- gwas_desc %&gt;%
  pivot_wider(names_from = ancestry, values_from = n, values_fill = 0)

# Function to create rows for each pair
make_weights_long &lt;- wide_gwas %&gt;%
  rowwise() %&gt;%
  do({
    trait &lt;- .$trait
    eur &lt;- .$EUR
    afr &lt;- .$AFR
    eas &lt;- .$EAS
    
    tibble(
      Trait = trait,
      Method = &quot;inverse_var&quot;,
      Target = c(&quot;AFR&quot;, &quot;AFR&quot;, &quot;EUR&quot;, &quot;EUR&quot;),
      Discovery = c(&quot;EUR&quot;, &quot;AFR&quot;, &quot;EUR&quot;, &quot;AFR&quot;),
      Weight = c(
        eur / (eur + afr), afr / (eur + afr),  # AFR target
        eur / (eur + afr), afr / (eur + afr)  # EUR target (vs AFR)
      )
    )
  }) %&gt;%
  bind_rows()

###
# Combine and compare
###

both &lt;- do.call(rbind, list(obs_weights, leopard_weights, make_weights_long))

# Remove ptclump as it doesn&#39;t have a sumstattune method
both &lt;- both[both$Method != &#39;ptclump&#39;,]

both&lt;-merge(both, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x=T, sort = F)
both$label[is.na(both$label)] &lt;- both$Method[is.na(both$label)]
both$label &lt;- factor(both$label, levels=unique(both$label))

# Plot non-EUR target first
tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery != &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(10)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/leopard_weights.png&#39;, units = &#39;px&#39;, res = 300, width = 2500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(Target ~ .) +
  theme_half_open() +
  labs(title = &#39;Weight of target ancestry-matched PGS&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

###
# Check calibration of LEOPARD compared to QuickPRS observed weights
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide_afr &lt;- tmp_wide[tmp_wide$Discovery == &#39;AFR&#39;,]

# Calculate metrics
rmse_afr &lt;- sqrt(mean((tmp_wide_afr$QuickPRS - tmp_wide_afr$LEOPARD)^2))
me_afr &lt;- mean(tmp_wide_afr$QuickPRS - tmp_wide_afr$LEOPARD)

# Create annotation data.frame
metrics_df &lt;- data.frame(
  Discovery = c(&quot;AFR&quot;),
  x = c(0.5),         # Adjust positions as needed
  y = c(-0.05),
  label = c(
    paste0(&quot;RMSE = &quot;, round(rmse_afr, 2), &quot;\nME = &quot;, round(me_afr, 2))
  )
)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/leopard_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
ggplot(tmp_wide[tmp_wide$Discovery != &#39;EUR&#39;,], aes(x = LEOPARD, y = QuickPRS)) +
  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
  geom_point(alpha = 0.7) +
  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 0, size = 3.5) +
  labs(
    x = &quot;LEOPARD weight&quot;,
    y = &quot;Observed weight&quot;,
  ) +
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  ) +
  coord_fixed()    
dev.off()

###
# Check calibration of inverse_var compared to QuickPRS observed weights
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide_afr &lt;- tmp_wide[tmp_wide$Discovery == &#39;AFR&#39;,]

# Calculate metrics
rmse_afr &lt;- sqrt(mean((tmp_wide_afr$QuickPRS - tmp_wide_afr$inverse_var)^2))
me_afr &lt;- mean(tmp_wide_afr$QuickPRS - tmp_wide_afr$inverse_var)


# Create annotation data.frame
metrics_df &lt;- data.frame(
  Discovery = c(&quot;AFR&quot;),
  x = c(0.5),         # Adjust positions as needed
  y = c(-0.05),
  label = c(
    paste0(&quot;RMSE = &quot;, round(rmse_afr, 2), &quot;\nME = &quot;, round(me_afr, 2))
  )
)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/inverse_var_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 2000, res = 300)
ggplot(tmp_wide[tmp_wide$Discovery != &#39;EUR&#39;,], aes(x = inverse_var, y = QuickPRS)) +
  geom_abline(slope = 1, intercept = 0, linetype = &quot;dashed&quot;, colour = &quot;grey40&quot;) +  # Perfect calibration
  geom_smooth(method = &quot;lm&quot;, se = TRUE, colour = &quot;blue&quot;) +  # Regression line
  geom_point(alpha = 0.7) +
  geom_text(data = metrics_df, aes(x = x, y = y, label = label), inherit.aes = FALSE, hjust = 1.5, size = 3.5) +
  labs(
    x = &quot;inverse_var weight&quot;,
    y = &quot;Observed weight&quot;,
  ) +
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
  ) +
  coord_fixed()    
dev.off()

###
# Check calibration of observed weights across all methods
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[!(tmp$label %in% c(&#39;LEOPARD&#39;,&#39;inverse_var&#39;)),]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide &lt;- tmp_wide[tmp_wide$Discovery %in% c(&#39;AFR&#39;),]

metrics &lt;- NULL
for(i in c(&#39;AFR&#39;)){
  for(j in unique(tmp$label)){
    for(k in unique(tmp$label)){
      tmp_wide_i &lt;- tmp_wide[tmp_wide$Discovery == i,]
      rmse &lt;- sqrt(mean((tmp_wide_i[[j]] - tmp_wide_i[[k]])^2))
      me &lt;- mean(tmp_wide_i[[j]] - tmp_wide_i[[k]])
      
      metrics &lt;- rbind(
        metrics,
        data.frame(
          Population = i,
          Method1 = j,
          Method2 = k,
          rmse = rmse,
          me = me
        )
      )
    }
  }
}

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/observed_weights_calibration.png&#39;, units = &#39;px&#39;, width = 2000, height = 1650, res = 300)
ggplot(metrics, aes(x = Method1, y = Method2, fill = rmse)) +
  geom_tile(color = &quot;white&quot;) +  # Tile plot with white borders
  geom_text(aes(label = round(rmse, 2)), color = &quot;black&quot;) +  # Add correlation values
  scale_fill_gradient2(mid = &quot;white&quot;, high = &quot;red&quot;, midpoint = 0) +  # Color scale
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  labs(fill = &quot;RMSE&quot;)
dev.off()

# Calculate average RMSE for each method against all other methods
metrics_unique &lt;- metrics[metrics$Method1 != metrics$Method2, ]
metrics_unique$Comparison &lt;- NA
for (i in 1:nrow(metrics_unique)) {
  metrics_unique$Comparison[i] &lt;-
    paste0(sort(c(
      metrics_unique$Method1[i], metrics_unique$Method2[i]
    )), collapse = &#39; vs. &#39;)
}
metrics_unique &lt;- metrics_unique[!duplicated(paste0(metrics_unique$Population, metrics_unique$Comparison)),]

mean_rmse &lt;- NULL
for(i in unique(tmp$label)){
  for(j in c(&#39;AFR&#39;)){
    metrics_unique_tmp &lt;- metrics_unique[metrics_unique$Method1 == i | metrics_unique$Method2 == i,]
    metrics_unique_tmp &lt;- metrics_unique_tmp[metrics_unique_tmp$Population == j,]
    mean_rmse &lt;- rbind(
      mean_rmse, 
      data.frame(
        Method = i,
        Population = j,
        avg_rmse = mean(metrics_unique_tmp$rmse)
      )
    )
  }
}

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/avg_observed_weight_rmse.png&#39;, units = &#39;px&#39;, width = 1500, height = 800, res = 300)
ggplot(mean_rmse, aes(x = Method, y = avg_rmse, fill = Method)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, size = 0.1) +
  geom_text(aes(label = round(avg_rmse, 3)),  # &lt;-- Add this
          vjust = 1.5,                    # &lt;-- Move the text slightly above the bar
          size = 3) +                      # &lt;-- Adjust text size
  scale_fill_manual(values = default_colors) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  labs(y = &#39;Average RMSE&#39;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position=&quot;none&quot;)
dev.off()

###
# Check calibration of estimated (LEOPARD and inverse_var) weights compared to observed QuickPRS weights
###

tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[(tmp$label %in% c(&#39;LEOPARD&#39;,&#39;inverse_var&#39;,&#39;QuickPRS&#39;)),]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))
tmp_wide&lt;-tmp_wide[, !(grepl(&#39;Method&#39;, names(tmp_wide))), with = F]

tmp_wide &lt;- tmp_wide[tmp_wide$Discovery %in% c(&#39;EAS&#39;,&#39;AFR&#39;),]

metrics &lt;- NULL
for(i in c(&#39;AFR&#39;)){
  for(j in unique(tmp$label)){
    for(k in unique(tmp$label)){
      tmp_wide_i &lt;- tmp_wide[tmp_wide$Discovery == i,]
      rmse &lt;- sqrt(mean((tmp_wide_i[[j]] - tmp_wide_i[[k]])^2))
      me &lt;- mean(tmp_wide_i[[j]] - tmp_wide_i[[k]])
      
      metrics &lt;- rbind(
        metrics,
        data.frame(
          Population = i,
          Method1 = j,
          Method2 = k,
          rmse = rmse,
          me = me
        )
      )
    }
  }
}

# Plot the rmse for LEOPARD and inverse_var predicting observed QuickPRS weight
metrics &lt;- metrics[metrics$Method1 == &#39;QuickPRS&#39;,]
metrics &lt;- metrics[metrics$Method2 != &#39;QuickPRS&#39;,]

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_mvp/plots/inverse_var_comp_rmse.png&#39;, units = &#39;px&#39;, width = 800, height = 1500, res = 300)
ggplot(metrics, aes(x = Method2, y = rmse, fill = Method2)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, size = 0.1) +
  geom_text(aes(label = round(rmse, 3)),  # &lt;-- Add this
          vjust = 1.5,                    # &lt;-- Move the text slightly above the bar
          size = 3) +                      # &lt;-- Adjust text size
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  labs(y = &#39;RMSE relative to QuickPRS&#39;, x = &#39;Method&#39;) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position=&quot;none&quot;)
dev.off()</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="check-genetic-distances" class="section level1">
<h1>Check genetic distances</h1>
<p>We will use two approaches to compare the ancestry within the GWAS
and LD reference samples: 1. Project reference genetic principal
components into the GWAS samples 2. Estimate ancestral proportions
within GWAS and LD reference samples using bigsnpr</p>
<hr />
<div id="compare-genetic-principal-components" class="section level2">
<h2>Compare genetic principal components</h2>
<p>This involves using the allele frequencies within the GWAS summary
statistics to estimate the mean of reference genetic principal
components in the GWAS samples.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Read in reference PC SNP-weights
pc_score_file &lt;- fread(&#39;~/oliverpainfel/Data/ukb/GenoPred/output/reference/pc_score_files/TRANS/ref-TRANS-pcs.eigenvec.var.gz&#39;)

# Read in allele frequencies for each reference population
ref_pop_freq &lt;- list()
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  freq_i &lt;- NULL
  for(j in 1:22){
    freq_i &lt;- rbind(freq_i, fread(paste0(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/freq_files/&#39;, i,&#39;/ref.&#39;, i, &#39;.chr&#39;, j, &#39;.afreq&#39;)))
  }
  ref_pop_freq[[i]] &lt;- freq_i
}

# Calculate PCs for reference populations
ref_pc_all &lt;- NULL
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  # Merge on SNP ID
  merged &lt;- merge(
    pc_score_file, 
    ref_pop_freq[[i]], 
    by.x = &quot;SNP&quot;, 
    by.y = &quot;ID&quot;
  )
  
  # Flip frequencies where needed (if ALT != A1, assume ALT_FREQ = 1 - A1_FREQ)
  merged[, A1_FREQ := ifelse(ALT == A1, ALT_FREQS, 1 - ALT_FREQS)]
  
  # Calculate PCs using dot product: sum(allele_freq * SNP_weight) for each PC
  ref_PC &lt;- merged[, lapply(.SD, function(w) sum(w * A1_FREQ, na.rm = TRUE)), 
                   .SDcols = patterns(&quot;^PC&quot;)]
  
  ref_pc_all &lt;- rbind(ref_pc_all, data.frame(group = i,
                                             ref_PC))
}

# Read in GWAS allele frequencies for BMI
gwas_list_main &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
gwas_list_main &lt;- gwas_list_main[grepl(&#39;BMI&#39;, gwas_list_main$name),]

gwas_list_mvp &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp.txt&#39;)
gwas_list_mvp &lt;- gwas_list_mvp[grepl(&#39;BMI&#39;, gwas_list_mvp$name),]

gwas_list&lt;-rbind(gwas_list_main, gwas_list_mvp)

outdir &lt;- &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&#39;
gwas_freq &lt;- list()
for(i in 1:nrow(gwas_list)){
  ss_i &lt;- fread(paste0(
            outdir,
            &#39;/reference/gwas_sumstat/&#39;,
            gwas_list$name[i],
            &#39;/&#39;,
            gwas_list$name[i],
            &#39;-cleaned.gz&#39;
          ))
  
  gwas_freq[[gwas_list$name[i]]] &lt;- ss_i[, c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;FREQ&#39;), with = F]
}

gwas_pc_all &lt;- NULL
for(i in names(gwas_freq)){
  # Merge on SNP ID
  merged &lt;- merge(
    pc_score_file, 
    gwas_freq[[i]], 
    by = &quot;SNP&quot;
  )
  
  # Flip frequencies where needed (if ALT != A1, assume ALT_FREQ = 1 - A1_FREQ)
  merged[, FREQ := ifelse(A1.x == A1.y, FREQ, 1 - FREQ)]
  
  # Calculate PCs using dot product: sum(allele_freq * SNP_weight) for each PC
  ref_PC &lt;- merged[, lapply(.SD, function(w) sum(w * FREQ, na.rm = TRUE)), 
                   .SDcols = patterns(&quot;^PC&quot;)]
  
  gwas_pc_all &lt;- rbind(gwas_pc_all, data.frame(group = i,
                                             ref_PC))
}

ref_pc_all$type &lt;- &#39;Reference&#39;
gwas_pc_all$type &lt;- &#39;GWAS&#39;

pc_all &lt;- rbind(ref_pc_all, gwas_pc_all)

ggplot(pc_all, aes(x=PC1, y = PC2, colour = group, shape = type)) +
  geom_point(size = 5)

# There is a big shift in the PCs for GWAS and reference data, probably due to missing variants. Restrict to variant present in all GWAS.

extract &lt;- Reduce(intersect, list(
  pc_score_file$SNP,
  gwas_freq$BMI_UKB$SNP,
  gwas_freq$BMI_BBJ$SNP,
  gwas_freq$BMI_UGR$SNP,
  gwas_freq$BMI_MVP_AFR$SNP
))

pc_score_file_overlapping &lt;- pc_score_file[pc_score_file$SNP %in% extract,]

# Calculate PCs for reference populations
ref_pc_all &lt;- NULL
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  # Merge on SNP ID
  merged &lt;- merge(
    pc_score_file_overlapping, 
    ref_pop_freq[[i]], 
    by.x = &quot;SNP&quot;, 
    by.y = &quot;ID&quot;
  )
  
  # Flip frequencies where needed (if ALT != A1, assume ALT_FREQ = 1 - A1_FREQ)
  merged[, A1_FREQ := ifelse(ALT == A1, ALT_FREQS, 1 - ALT_FREQS)]
  
  # Calculate PCs using dot product: sum(allele_freq * SNP_weight) for each PC
  ref_PC &lt;- merged[, lapply(.SD, function(w) sum(w * A1_FREQ, na.rm = TRUE)), 
                   .SDcols = patterns(&quot;^PC&quot;)]
  
  ref_pc_all &lt;- rbind(ref_pc_all, data.frame(group = i,
                                             ref_PC))
}

gwas_pc_all &lt;- NULL
for(i in names(gwas_freq)){
  # Merge on SNP ID
  merged &lt;- merge(
    pc_score_file_overlapping, 
    gwas_freq[[i]], 
    by = &quot;SNP&quot;
  )
  
  # Flip frequencies where needed (if ALT != A1, assume ALT_FREQ = 1 - A1_FREQ)
  merged[, FREQ := ifelse(A1.x == A1.y, FREQ, 1 - FREQ)]
  
  # Calculate PCs using dot product: sum(allele_freq * SNP_weight) for each PC
  ref_PC &lt;- merged[, lapply(.SD, function(w) sum(w * FREQ, na.rm = TRUE)), 
                   .SDcols = patterns(&quot;^PC&quot;)]
  
  gwas_pc_all &lt;- rbind(gwas_pc_all, data.frame(group = i,
                                             ref_PC))
}

ref_pc_all$Population &lt;- ref_pc_all$group
ref_pc_all$GWAS &lt;- NA

gwas_pc_all$GWAS &lt;- gwas_pc_all$group
gwas_pc_all$GWAS[gwas_pc_all$GWAS == &#39;BMI_UKB&#39;] &lt;- &quot;UKB (EUR)&quot;
gwas_pc_all$GWAS[gwas_pc_all$GWAS == &#39;BMI_BBJ&#39;] &lt;- &quot;BBJ (EAS)&quot;
gwas_pc_all$GWAS[gwas_pc_all$GWAS == &#39;BMI_UGR&#39;] &lt;- &quot;UGR (AFR)&quot;
gwas_pc_all$GWAS[gwas_pc_all$GWAS == &#39;BMI_MVP_AFR&#39;] &lt;- &quot;MVP (AFR)&quot;
gwas_pc_all$Population &lt;- NA

ref_pc_all$type &lt;- &#39;Reference&#39;
gwas_pc_all$type &lt;- &#39;GWAS&#39;

pc_all &lt;- rbind(ref_pc_all, gwas_pc_all)

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/genetic_distance.png&#39;, units = &#39;px&#39;, width = 2000, height = 1500, res = 300)

ggplot(pc_all, aes(x=PC1, y = PC2)) +
  geom_point(data=pc_all[pc_all$type == &#39;Reference&#39;,], aes(x=PC1, y = PC2, fill = Population), size = 5, shape = 21) +
  geom_point(data=pc_all[pc_all$type == &#39;GWAS&#39;,], aes(x=PC1, y = PC2, colour = GWAS), size = 4, shape = 3, stroke = 1.5) +
  theme_half_open() +
  background_grid()

dev.off()

# Perfect. Shows UKB match EUR, BBJ match EAS, UGR matches AFR, but MVP is close to AFR.</code></pre>
</details>
<hr />
</div>
<div id="estimate-ancestry-proportions" class="section level2">
<h2>Estimate ancestry proportions</h2>
<p>This involves using Florian Prive’s bigsnpr packages and UKB
reference data to calculate principal components and then estimate
ancestral proportions.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(bigsnpr)
library(dplyr)

DIR &lt;- &quot;~/oliverpainfel/Data/bigsnpr&quot;  # you can replace by e.g. &quot;data&quot; or &quot;tmp-data&quot;

# /!\ This downloads 850 Mb (each)
all_freq &lt;- bigreadr::fread2(
  runonce::download_file(&quot;https://figshare.com/ndownloader/files/31620968&quot;,
                         dir = DIR, fname = &quot;ref_freqs.csv.gz&quot;))
projection &lt;- bigreadr::fread2(
  runonce::download_file(&quot;https://figshare.com/ndownloader/files/31620953&quot;,
                         dir = DIR, fname = &quot;projection.csv.gz&quot;))

# Read in allele frequencies for each reference population
ref_rds &lt;- NULL
for(i in 1:22){
  ref_rds &lt;- rbind(ref_rds, 
                   readRDS(paste0(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/ref.chr&#39;, i, &#39;.rds&#39;)))
}

ref_pop_freq &lt;- list()
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  ref_pop_freq[[i]] &lt;- ref_rds[, c(&#39;CHR&#39;,&#39;SNP&#39;,&#39;BP_GRCh37&#39;,&#39;A1&#39;,&#39;A2&#39;,paste0(&#39;REF.FRQ.&#39;,i)), with=F]
  names(ref_pop_freq[[i]]) &lt;-c(&#39;chr&#39;,&#39;rsid&#39;,&#39;pos&#39;,&#39;a1&#39;,&#39;a0&#39;,&#39;freq&#39;)
}

# Read in GWAS allele frequencies for BMI
gwas_list_main &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;)
gwas_list_main &lt;- gwas_list_main[grepl(&#39;BMI&#39;, gwas_list_main$name),]

gwas_list_mvp &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_mvp.txt&#39;)
gwas_list_mvp &lt;- gwas_list_mvp[grepl(&#39;BMI&#39;, gwas_list_mvp$name),]
gwas_list_mvp &lt;- gwas_list_mvp[gwas_list_mvp$population == &#39;AFR&#39;,]

gwas_list&lt;-rbind(gwas_list_main, gwas_list_mvp)

outdir &lt;- &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&#39;
gwas_freq &lt;- list()
for(i in 1:nrow(gwas_list)){
  ss_i &lt;- fread(paste0(
            outdir,
            &#39;/reference/gwas_sumstat/&#39;,
            gwas_list$name[i],
            &#39;/&#39;,
            gwas_list$name[i],
            &#39;-cleaned.gz&#39;
          ))
  
  gwas_freq[[gwas_list$name[i]]] &lt;- ss_i[, c(&#39;CHR&#39;,&#39;BP&#39;,&#39;SNP&#39;,&#39;A2&#39;,&#39;A1&#39;,&#39;FREQ&#39;), with = F]
  names(gwas_freq[[gwas_list$name[i]]]) &lt;- c(&quot;chr&quot;, &quot;pos&quot;, &#39;rsid&#39;, &quot;a0&quot;, &quot;a1&quot;, &quot;freq&quot;)
}

# Harmonise the data
gwas_freq_matched &lt;- list()
for(i in 1:nrow(gwas_list)){
  gwas_freq_matched[[gwas_list$name[i]]] &lt;- snp_match(
    mutate(gwas_freq[[gwas_list$name[i]]], chr = as.integer(chr), beta = 1),
    all_freq[1:5]
  ) %&gt;%
    mutate(freq = ifelse(beta &lt; 0, 1 - freq, freq))
}

ref_pop_freq_matched &lt;- list()
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  ref_pop_freq_matched[[i]] &lt;- snp_match(
    mutate(ref_pop_freq[[i]], chr = as.integer(chr), beta = 1),
    all_freq[1:5]
  ) %&gt;%
    mutate(freq = ifelse(beta &lt; 0, 1 - freq, freq))
}

# Infer ancestry with shrinkage (https://privefl.github.io/bigsnpr/articles/ancestry.html)
correction &lt;- c(1, 1, 1, 1.008, 1.021, 1.034, 1.052, 1.074, 1.099,
                1.123, 1.15, 1.195, 1.256, 1.321, 1.382, 1.443)

gwas_ancestry &lt;- list()
for(i in 1:nrow(gwas_list)){
  res &lt;- snp_ancestry_summary(
    freq = gwas_freq_matched[[gwas_list$name[i]]]$freq,
    info_freq_ref = all_freq[gwas_freq_matched[[gwas_list$name[i]]]$`_NUM_ID_`, -(1:5)],
    projection = projection[gwas_freq_matched[[gwas_list$name[i]]]$`_NUM_ID_`, -(1:5)],
    correction = correction
  )
  
  # Group similar popualtions
  group &lt;- colnames(all_freq)[-(1:5)]
  group[group %in% c(&quot;Scandinavia&quot;, &quot;United Kingdom&quot;, &quot;Ireland&quot;)]   &lt;- &quot;Europe (North West)&quot;
  group[group %in% c(&quot;Europe (South East)&quot;, &quot;Europe (North East)&quot;)] &lt;- &quot;Europe (East)&quot;
  grp_fct &lt;- factor(group, unique(group))
  
  gwas_ancestry[[gwas_list$name[i]]] &lt;- tapply(res, grp_fct, sum)
}

ref_ancestry &lt;- list()
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;AMR&#39;,&#39;MID&#39;,&#39;CSA&#39;)){
  res &lt;- snp_ancestry_summary(
    freq = ref_pop_freq_matched[[i]]$freq,
    info_freq_ref = all_freq[ref_pop_freq_matched[[i]]$`_NUM_ID_`, -(1:5)],
    projection = projection[ref_pop_freq_matched[[i]]$`_NUM_ID_`, -(1:5)],
    correction = correction
  )
  
  # Group similar popualtions
  group &lt;- colnames(all_freq)[-(1:5)]
  group[group %in% c(&quot;Scandinavia&quot;, &quot;United Kingdom&quot;, &quot;Ireland&quot;)]   &lt;- &quot;Europe (North West)&quot;
  group[group %in% c(&quot;Europe (South East)&quot;, &quot;Europe (North East)&quot;)] &lt;- &quot;Europe (East)&quot;
  grp_fct &lt;- factor(group, unique(group))
  
  ref_ancestry[[i]] &lt;- tapply(res, grp_fct, sum)
}

# Plot the results
gwas_ancestry_table &lt;- do.call(cbind, gwas_ancestry)
colnames(gwas_ancestry_table) &lt;- c(&quot;UKB (EUR)&quot;, &quot;BBJ (EAS)&quot;, &quot;UGR (AFR)&quot;, &quot;MVP (AFR)&quot;)
gwas_ancestry_table_melt &lt;- melt(gwas_ancestry_table)

gwas_ancestry_table_melt&lt;-gwas_ancestry_table_melt[gwas_ancestry_table_melt$value &gt;= 0.02,]

library(scales)  # for percent_format()

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/gwas_ancestry.png&#39;, units = &#39;px&#39;, width = 2000, height = 1500, res = 300)
ggplot(gwas_ancestry_table_melt, aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(stat = &quot;identity&quot;, colour = &quot;black&quot;, size = 0.2) +
  geom_text(data = subset(gwas_ancestry_table_melt, value &gt;= 0.02),
            aes(label = scales::percent(value, accuracy = 1)),
            position = position_stack(vjust = 0.5),
            size = 3) +
  labs(x = &quot;GWAS&quot;, y = &quot;Proportion&quot;, fill = &quot;Population&quot;,
       title = &quot;Ancestry proportions in BMI GWAS&quot;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = -45, hjust = 1))
dev.off()

write.csv(gwas_ancestry_table, &#39;~/oliverpainfel/Analyses/crosspop/plots/gwas_ancestry.csv&#39;)

ref_ancestry_table &lt;- do.call(cbind, ref_ancestry)
ref_ancestry_table_melt &lt;- melt(ref_ancestry_table)

ref_ancestry_table_melt&lt;-ref_ancestry_table_melt[ref_ancestry_table_melt$value &gt;= 0.02,]

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/ref_ancestry.png&#39;, units = &#39;px&#39;, width = 2000, height = 1500, res = 300)
ggplot(ref_ancestry_table_melt, aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(stat = &quot;identity&quot;, colour = &#39;black&#39;, size = 0.2) +
  geom_text(data = subset(ref_ancestry_table_melt, value &gt;= 0.02),
            aes(label = scales::percent(value, accuracy = 1)),
            position = position_stack(vjust = 0.5),
            size = 3) +
  labs(x = &quot;Reference Label&quot;, y = &quot;Proportion&quot;, fill = &#39;Population&#39;, title = &#39;Ancestry proportions in 1KG+HGDP reference&#39;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
dev.off()

write.csv(ref_ancestry_table, &#39;~/oliverpainfel/Analyses/crosspop/plots/ref_ancestry.csv&#39;)

gwas_ancestry_table_melt$Type &lt;- &#39;GWAS&#39;
ref_ancestry_table_melt$Type &lt;- &#39;Reference&#39;

both&lt;-rbind(gwas_ancestry_table_melt, ref_ancestry_table_melt)
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/ancestry_composition.png&#39;, units = &#39;px&#39;, width = 3000, height = 1500, res = 300)

ggplot(both, aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(stat = &quot;identity&quot;, colour = &#39;black&#39;, size = 0.2) +
  geom_text(data = subset(both, value &gt;= 0.02),
            aes(label = scales::percent(value, accuracy = 1)),
            position = position_stack(vjust = 0.5),
            size = 3) +
  labs(x = NULL, y = &quot;Proportion&quot;, fill = &#39;Population&#39;) +
  facet_grid(. ~ Type, scales = &#39;free_x&#39;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  panel_border()
dev.off()</code></pre>
</details>
<hr />
</div>
</div>
<div id="bridgeprs" class="section level1">
<h1>BridgePRS</h1>
<p>The below code is incomplete due to current compatability issues
between BridgePRS and GenoPred. Work to incorporate BridgePRS into
GenoPred is on going.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>######
# gwas_list
######

library(data.table)

# Subset original gwas_list to include selected traits
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)
pheno&lt;-gsub(&#39;_.*&#39;,&#39;&#39;, gwas_list$name)
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
gwas_list&lt;-gwas_list[pheno %in% selected_traits,]
gwas_list$label&lt;-paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

gwas_list&lt;-gwas_list[grepl(&#39;BMI&#39;, gwas_list$name),]

write.table(
  gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_bridge.txt&#39;, 
  col.names = T, 
  row.names = F, 
  quote = F)

######
# gwas_groups
######

gwas_groups_eas&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_BBJ&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_BBJ&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+BBJ)&quot;, &#39;&quot;&#39;)
)

gwas_groups_afr&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_UGR&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_UGR&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+UGR)&quot;, &#39;&quot;&#39;)
)

gwas_groups&lt;-rbind(gwas_groups_eas, gwas_groups_afr)

gwas_groups&lt;-gwas_groups[grepl(&#39;BMI&#39;, gwas_groups$name),]

write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_bridge.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_bridgeprs.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_bridge.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups_bridge.txt&quot;,
  &quot;pgs_methods: [&#39;bridgeprs&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, 
  &quot;cores_target_pgs: 50&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_bridgeprs.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<hr />
<h4>
Run pipeline
</h4>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_bridgeprs.yaml \
  target_pgs  -n</code></pre>
</details>
</div>

<!-- footer.html -->
<hr/>

<div class="centered-container">
<div class="rounded-image-container" style="width: 500px;">
<img src="Images/logo/sponsors.png">
</div>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
