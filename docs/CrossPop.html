<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Cross-population evaluation of polygenic scores</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />
<link rel="shortcut icon" href="Images/logo/favicon.ico">

<link rel="stylesheet" href="styles/night-mode.css" id="nightModeStylesheet">

<script>
function toggleNightMode() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (stylesheet.disabled) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
}
</script>

<label class="switch">
  <input type="checkbox" id="toggleNightMode" checked>
  <span class="slider round"></span>
</label>

<script>
document.getElementById('toggleNightMode').addEventListener('change', function() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (this.checked) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
});
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YR18ZB3PR3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YR18ZB3PR3');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img class="logo-img" src="Images/logo/Horizontal_white.png" style="height: 42px;" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pipeline
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="pipeline_overview.html">Overview</a>
    </li>
    <li>
      <a href="pipeline_readme.html">Instructions</a>
    </li>
    <li>
      <a href="pipeline_technical.html">Technical documentation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="research_index.html">Overview</a>
    </li>
    <li>
      <a href="comparison_of_methods_summary.html">Polygenic Scoring Methods Comparison</a>
    </li>
    <li>
      <a href="Functionally_informed_prediction.html">Quantifying Polygenic Signal Mediated by Altered Gene Expression</a>
    </li>
    <li>
      <a href="Absolute_Conversion.html">Translating Polygenic Scores onto the Absolute Scale</a>
    </li>
  </ul>
</li>
<li>
  <a href="more_index.html">More</a>
</li>
<li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Cross-population evaluation of polygenic
scores</h1>

</div>


<hr />
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>European (EUR) GWAS are typically the largest in sample size, or even
the only GWAS for certain outcomes. Here we will evaluate approaches for
calculating polygenic scores (PGS) across populations. We will include
single- and multi-source PGS methods, using EUR GWAS alone, or using EUR
GWAS in combination with GWAS from other populations.</p>
<hr />
</div>
<div id="derive-gwas-in-ukb" class="section level1">
<h1>Derive GWAS in UKB</h1>
<p>To avoid sample overlap between the EUR GWAS and the EUR target
sample for evaluation, we will split EUR individuals in UKB into
training and testing subsets. The GWAS will be performed in the training
subset, and the PGS evaluation will occur in the testing subset.</p>
<hr />
<div id="perform-ancestry-inference-in-ukb" class="section level2">
<h2>Perform ancestry inference in UKB</h2>
<div id="create-target_list" class="section level3">
<h3>Create target_list</h3>
<div class="shallow-break">

</div>
<details>
<summary>
Show code
</summary>
<p><br/></p>
<h3>
Create symlinks
</h3>
<p>We will create symlinks to the imputed genotype data for UKB. We will
use the pgen format data for computationl efficiency and those
restricted to MAF &gt;= 1% and INFO &gt;= 0.4. We are using genetic data
that is not application specific, so the data doesn’t need to be
reprocessed for each application. Therefore we will use row number IDs
for the .psam file so they can be connected to application specific data
downstream.</p>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks

# pgen and pvar files
for chr in $(seq 1 22);do
  for file in $(echo pgen pvar);do
    ln -s /datasets/ukbiobank/June2017/Imputed/ukb_imp_chr${chr}_v3_MAF1_INFO4.${file} /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.${file}
  done
done</code></pre>
<pre class="r"><code># Make .psam 
n = 487409
psam &lt;- data.frame(FID = 1:487409,
                   IID = 1:487409)
names(psam)[1]&lt;-&#39;#FID&#39;
write.table(psam, &#39;/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam&#39;, col.names=T, row.names = F, quote = F)</code></pre>
<pre class="bash"><code>for chr in $(seq 1 22);do
  ln -s /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.psam
done</code></pre>
<hr />
<h3>
Create list of unrelated individuals
</h3>
<pre class="r"><code>library(ukbkings)
library(data.table)

psam&lt;-fread(&#39;/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam&#39;)
psam$rn&lt;-1:nrow(psam)

project_dir &lt;- &quot;/datasets/ukbiobank/ukb82087&quot;
greedy_related &lt;- &quot;/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated&quot;

# Create a list of unrelated individuals irrespective of a phenotype
psam_unrel_all &lt;- psam[!(
  psam$IID %in% bio_gen_related_remove(
    project_dir = project_dir,
    greedy_related = greedy_related,
    thresh = 0.044,
    seed = 1
  )$eid
), ]

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes&#39;)

write.table(psam_unrel_all$IID, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.txt&#39;, row.names=F, col.names=F, quote=F)
write.table(psam_unrel_all$rn, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;, row.names=F, col.names=F, quote=F)</code></pre>
<hr />
<h3>
Create target_list
</h3>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic</code></pre>
<pre class="r"><code>target_list &lt;- data.frame(
  name=&#39;ukb&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4&#39;,
  type=&#39;plink2&#39;,
  indiv_report=F,
  unrel=&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;
)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&#39;, col.names=T, row.names=F, quote=F)</code></pre>
</details>
<hr />
</div>
<div id="create-configfile" class="section level3">
<h3>Create configfile</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Create config file
conf &lt;- c(
  &#39;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&#39;,
  &#39;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml&#39;,
  &#39;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&#39;
)

write.table(conf, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
</details>
<hr />
</div>
<div id="run-pipeline" class="section level3">
<h3>Run pipeline</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
git describe --tags
#v2.2.2-213-g2f05853

snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml \
  outlier_detection -n</code></pre>
</details>
<hr />
</div>
</div>
<div id="collect-phenotype-data" class="section level2">
<h2>Collect phenotype data</h2>
<p>We will use the same 33 quantitative traits that were used in the
PRS-CSx paper (Supp Table 10).</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx</code></pre>
<pre class="r"><code>library(ukbkings)
library(dplyr)
library(stringr)
library(data.table)

# create data.frame showing variables used by prscsx
prscsx_fields&lt;-c(&#39;30620&#39;,&#39;30600&#39;,&#39;30610&#39;,&#39;30650&#39;,&#39;30160&#39;,&#39;21001&#39;,&#39;21002&#39;,&#39;30710&#39;,&#39;30680&#39;,&#39;4079&#39;,&#39;30150&#39;,&#39;30740&#39;,&#39;30750&#39;,&#39;30760&#39;,&#39;50&#39;,&#39;30030&#39;,&#39;30020&#39;,&#39;30780&#39;,&#39;30120&#39;,&#39;30050&#39;,&#39;30060&#39;,&#39;30040&#39;,&#39;30130&#39;,&#39;30140&#39;,&#39;30080&#39;,&#39;30010&#39;,&#39;30700&#39;,&#39;4080&#39;,&#39;30690&#39;,&#39;30860&#39;,&#39;30870&#39;,&#39;30000&#39;,&#39;30730&#39;)
prscsx_trait&lt;-c(&#39;Alanine aminotransferase&#39;,&#39;Albumin&#39;,&#39;Alkaline phosphatase&#39;,&#39;Aspartate transaminase&#39;,&#39;Basophil&#39;,&#39;Body mass index&#39;,&#39;Body weight&#39;,&#39;C-reactive protein&#39;,&#39;Calcium&#39;,&#39;Diastolic blood pressure&#39;,&#39;Eosinophil&#39;,&#39;Glucose&#39;,&#39;HbA1c&#39;,&#39;HDL-cholesterol&#39;,&#39;Height&#39;,&#39;Hematocrit&#39;,&#39;Hemoglobin&#39;,&#39;LDL-cholesterol&#39;,&#39;Lymphocyte&#39;,&#39;Mean corpuscular hemoglobin&#39;,&#39;Mean corpuscular hemoglobin concentration&#39;,&#39;Mean corpuscular volume&#39;,&#39;Monocyte&#39;,&#39;Neutrophil&#39;,&#39;Platelet&#39;,&#39;Red blood cell&#39;,&#39;Serum creatinine&#39;,&#39;Sytolic blood pressure&#39;,&#39;Total cholesterol&#39;,&#39;Total protein&#39;,&#39;Triglycerides&#39;,&#39;White blood cell&#39;,&#39;γ-glutamyl transpeptidase&#39;)
prscsx_labels&lt;-c(&#39;ALT&#39;,&#39;ALB&#39;,&#39;ALP&#39;,&#39;AST&#39;,&#39;BAS&#39;,&#39;BMI&#39;,&#39;BWT&#39;,&#39;CRP&#39;,&#39;Ca&#39;,&#39;DBP&#39;,&#39;EOS&#39;,&#39;GLC&#39;,&#39;HbA1c&#39;,&#39;HDL&#39;,&#39;HT&#39;,&#39;HCT&#39;,&#39;HB&#39;,&#39;LDL&#39;,&#39;LYM&#39;,&#39;MCH&#39;,&#39;MCHC&#39;,&#39;MCV&#39;,&#39;MON&#39;,&#39;NEU&#39;,&#39;PLT&#39;,&#39;RBC&#39;,&#39;CR&#39;,&#39;SBP&#39;,&#39;TC&#39;,&#39;TP&#39;,&#39;TG&#39;,&#39;WBC&#39;,&#39;GGT&#39;)

prscsx_dat&lt;-data.frame(
  trait=prscsx_trait,
  labels=prscsx_labels,
  field=prscsx_fields
)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx&#39;)
write.csv(prscsx_dat, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;, row.names = F)
write.table(prscsx_labels, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt&#39;, col.names=F, row.names = F, quote=F)

# Extract outcomes from UKB (project ukb82087)
project_dir &lt;- &quot;/datasets/ukbiobank/ukb82087&quot;

system(&#39;rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&#39;)
f &lt;- bio_field(project_dir)
f %&gt;%
    select(field, name) %&gt;%
    filter(str_detect(field, paste(paste0(&quot;^&quot;, prscsx_dat$field, &#39;-&#39;), collapse=&#39;|&#39;))) %&gt;%
    bio_field_add(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&quot;)

bio_phen(
    project_dir,
    field = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt&quot;,
    out = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset&quot;
)

system(&quot;ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds&quot;)
df &lt;- readRDS(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds&quot;)

# Take the first observation of each outcome
library(tidyr)
df_long &lt;- df %&gt;%
  pivot_longer(cols = names(df)[!grepl(&#39;eid&#39;, names(df))], names_to = &quot;variable&quot;, values_to = &quot;outcome&quot;) %&gt;%
  drop_na(outcome)
df_long$variable&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, df_long$variable)
df_long&lt;-df_long[!duplicated(df_long[,c(&#39;eid&#39;,&#39;variable&#39;)]),]

library(data.table)

for(i in 1:nrow(prscsx_dat)){
  tmp &lt;- df_long[df_long$variable == prscsx_dat$field[i],]
  tmp &lt;- data.frame(
    eid = tmp$eid,
    outcome = tmp$outcome
  )
  
  fwrite(
    tmp,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}

# Read in ancestry inference results to determine sample size per population
# Use ancestry information from GenoPred
keep_files&lt;-list.files(path = &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/&#39;, pattern = &#39;.keep&#39;)

pop_dat&lt;-NULL
for(i in keep_files){
  tmp&lt;-fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/&#39;, i))
  names(tmp)&lt;-c(&#39;FID&#39;,&#39;IID&#39;)
  tmp$POP&lt;-gsub(&#39;.keep&#39;,&#39;&#39;, gsub(&#39;ukb.outlier_detection.&#39;,&#39;&#39;,i))
  pop_dat&lt;-rbind(pop_dat, tmp)
}

# Update row number IDs to project specific IDs
psam&lt;-fread(&#39;/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam&#39;)
psam$rn&lt;-1:nrow(psam)
psam&lt;-psam[,c(&#39;IID&#39;,&#39;rn&#39;), with = F]

pop_dat$FID&lt;-NULL
pop_dat&lt;-merge(pop_dat, psam, by.x=&#39;IID&#39;, by.y=&#39;rn&#39;)
pop_dat&lt;-data.frame(
  eid=pop_dat$IID.y,
  POP=pop_dat$POP
)

# Merge ancestry info with phenotype data
df_short &lt;- dcast(df_long, eid ~ variable, value.var = &quot;outcome&quot;)
df_short&lt;-merge(df_short, pop_dat, by=&#39;eid&#39;)

# Remove related individuals
greedy_related &lt;- &quot;/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated&quot;
rel&lt;-bio_gen_related_remove(
      project_dir = project_dir,
      greedy_related = greedy_related,
      keep = df_short$eid,
      thresh = 0.044,
      seed = 1
    )$eid

df_short_unrel&lt;-df_short[!(df_short$eid %in% rel),]

n_table&lt;-NULL
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(pop_dat$POP[!is.na(pop_dat$POP)])){
    tmp&lt;-data.frame(
      trait=prscsx_dat$trait[i],
      labels=prscsx_dat$label[i],
      field=prscsx_dat$field[i],
      population=j,
      n=sum(!is.na(df_short[[prscsx_dat$field[i]]][df_short$POP == j])),
      n_unrel=sum(!is.na(df_short_unrel[[prscsx_dat$field[i]]][df_short_unrel$POP == j]))
    )
    n_table&lt;-rbind(n_table, tmp)
  }
}

write.csv(n_table, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table&#39;)

# Define training subset for EUR
df_short_unrel_eur&lt;-df_short_unrel[df_short_unrel$POP == &#39;EUR&#39;,]
set.seed(1)
train_size &lt;- floor(0.8 * nrow(df_short_unrel_eur))
train_indices &lt;- sample(seq_len(nrow(df_short_unrel_eur)), size = train_size)

df_short_unrel_eur_train&lt;-df_short_unrel_eur[train_indices,]
df_short_unrel_eur_test&lt;-df_short_unrel_eur[-train_indices,]

n_table_eur&lt;-NULL
for(i in 1:nrow(prscsx_dat)){
  tmp&lt;-data.frame(
    trait=prscsx_dat$trait[i],
    labels=prscsx_dat$label[i],
    field=prscsx_dat$field[i],
    n_train=sum(!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]])),
    n_test=sum(!is.na(df_short_unrel_eur_test[[prscsx_dat$field[i]]]))
  )
  n_table_eur&lt;-rbind(n_table_eur, tmp)
}

write.csv(n_table_eur, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table_eur&#39;)

df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_train$eid]&lt;-&#39;EUR_train&#39;
df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_test$eid]&lt;-&#39;EUR_test&#39;

# Output phenotype data for each population
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(df_short_unrel$POP)){
    tmp&lt;-df_short_unrel[df_short_unrel$POP == j,]
    tmp &lt;- data.frame(
      FID = tmp$eid,
      IID = tmp$eid,
      outcome = tmp[[prscsx_dat$field[i]]]
    )
    
    fwrite(
      tmp,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
        prscsx_dat$label[i],
        &#39;.unrel.&#39;, j, &#39;.txt&#39;
      ),
      row.names = F,
      quote = F,
      na = &#39;NA&#39;,
      sep = &#39;\t&#39;
    )
    
    # Write out with row number based IDs
    pheno&lt;-merge(tmp, psam, by=&#39;IID&#39;)
    pheno&lt;-data.frame(
      FID=pheno$rn,
      IID=pheno$rn,
      outcome=pheno$outcome
    )
  
    fwrite(
      pheno,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
        prscsx_dat$label[i],
        &#39;.unrel.&#39;, j, &#39;.row_number.txt&#39;
      ),
      row.names = F,
      quote = F,
      na = &#39;NA&#39;,
      sep = &#39;\t&#39;
    )
  }
}

# For the EUR training GWAS, normalise and regress covariates
# Use age, sex and PCs as covariates
# Read in PC data released by UKB
qc_dat&lt;-bio_gen_sqc(project_dir)
qc_dat&lt;-qc_dat[,c(&#39;eid&#39;,paste0(&#39;pc&#39;,1:20))]
df_short_unrel&lt;-merge(df_short_unrel, qc_dat, by=&#39;eid&#39;)

# Read in sex and age information
system(&#39;rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&#39;)
f &lt;- bio_field(project_dir)
f %&gt;%
    select(field, name) %&gt;%
    filter(str_detect(field, &quot;^21022-0.0|^31-0.0&quot;)) %&gt;%
    bio_field_add(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&quot;)

bio_phen(
    project_dir,
    field = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt&quot;,
    out = &quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset&quot;
)

system(&quot;ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds&quot;)
df &lt;- readRDS(&quot;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds&quot;)
names(df)&lt;-gsub(&#39;-.*&#39;,&#39;&#39;,names(df))
names(df)[names(df) == &#39;31&#39;]&lt;-&#39;sex&#39;
names(df)[names(df) == &#39;21022&#39;]&lt;-&#39;age&#39;
df_short_unrel&lt;-merge(df_short_unrel, df, by=&#39;eid&#39;)

# Within each population, normalise each outcome and regress out covariates
library(RNOmni)
covs&lt;-c(paste0(&#39;pc&#39;,1:20), &#39;sex&#39;, &#39;age&#39;)
df_short_unrel_eur_train&lt;-df_short_unrel[df_short_unrel$POP == &#39;EUR_train&#39;,]
for(i in 1:nrow(prscsx_dat)){
  tmp&lt;-df_short_unrel_eur_train[!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]]),]
  tmp$pheno_norm&lt;-RNOmni::RankNorm(tmp[[prscsx_dat$field[i]]])
  mod&lt;-lm(as.formula(paste0(&#39;pheno_norm ~ &#39;, paste(covs, collapse=&#39; + &#39;))), data=tmp)
  tmp$pheno_norm_resid_scale&lt;-as.numeric(scale(resid(mod)))
  tmp&lt;-data.frame(
    FID=tmp$eid,
    IID=tmp$eid,
    outcome=tmp$pheno_norm_resid_scale
  )
  
  fwrite(
    tmp,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}

# Convert to row number based IDs so it will work with UKB geno data from GenoPred
for(i in 1:nrow(prscsx_dat)){
  pheno&lt;-fread(paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.txt&#39;
    ))
  
  pheno&lt;-merge(pheno, psam, by=&#39;IID&#39;)
  pheno&lt;-data.frame(
    FID=pheno$rn,
    IID=pheno$rn,
    outcome=pheno$outcome
  )
  
  fwrite(
    pheno,
    paste0(
      &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;,
      prscsx_dat$label[i],
      &#39;.unrel.EUR_train.norm_resid_scale.row_number.txt&#39;
    ),
    row.names = F,
    quote = F,
    na = &#39;NA&#39;,
    sep = &#39;\t&#39;
  )
}</code></pre>
</details>
<hr />
</div>
<div id="run-gwas" class="section level2">
<h2>Run GWAS</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  mkdir -p /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}
  for chr in $(seq 1 22); do
      sbatch -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/plink2 \
        --pfile /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
        --pheno /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.EUR_train.norm_resid_scale.row_number.txt \
        --linear omit-ref cols=+a1freq,+ax \
        --maf 0.01 \
        --geno 0.05 \
        --out /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}&quot;
  done
done

# Once complete, merge results across chromosomes
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  head -n 1 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr1.outcome.glm.linear &gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    for chr in $(seq 1 22); do
      tail -n +2 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}.outcome.glm.linear &gt;&gt; /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    done
    
    # Remove REF and ALT columns and rename AX column to A2
    cut -f 4,5 --complement /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt | awk &#39;BEGIN{FS=OFS=&quot;\t&quot;} NR==1 {$5=&quot;A2&quot;} 1&#39; &gt; temp.txt &amp;&amp; mv temp.txt /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt

    gzip /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
done

# Delete per chromosome files
rm /users/k1806347/oliverpainfel/Data/ukb/gwas/*/*chr*
</code></pre>
</details>
<hr />
</div>
</div>
<div id="download-relevant-bbj-sumstats" class="section level1">
<h1>Download relevant BBJ sumstats</h1>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Identify wget command for relevant phenotypes
library(data.table)

# Read in BBJ GWAS info from BBJ website
bbj_gwas&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas.csv&#39;)

# Map BBJ trait names to those used for UKB
bbj_gwas$bbj_labels &lt;-
  gsub(&quot;\\)&quot;, &#39;&#39;, gsub(&quot;.*\\(&quot;, &#39;&#39;, bbj_gwas$Phenotype))
bbj_gwas$trait &lt;- gsub(&quot; \\(.*&quot;, &#39;&#39;, bbj_gwas$Phenotype)

bbj_gwas$Category&lt;-NULL
bbj_gwas$Phenotype&lt;-NULL

# Update trait labels to match what was used in prscsx paper
bbj_gwas$trait&lt;-gsub(&#39; count&#39;,&#39;&#39;, bbj_gwas$trait)
bbj_gwas$trait[bbj_gwas$trait == &#39;G-glutamyl transpeptidase&#39;]&lt;-&#39;γ-glutamyl transpeptidase&#39;

# Merge the bbj trait info with the prscsx trait info
prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
prscsx_dat &lt;- merge(bbj_gwas, prscsx_dat, by=&#39;trait&#39;, all=T)

write.csv(prscsx_dat, &#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;, row.names = F)

# Create column showing what label is used in the wget command
prscsx_dat$wget_label &lt;-
  gsub(&#39;.v1.zip&#39;, &#39;&#39;, gsub(&#39;.*hum0197.v3.BBJ.&#39;, &#39;&#39;, prscsx_dat$wget))

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c(&#39;labels&#39;, &#39;wget&#39;, &#39;wget_label&#39;), with=F], &#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code># wget and unzip sumstats
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  url=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $2}&#39; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
  sbatch -p neurohack_cpu --wrap=&quot;wget -O /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip ${url}
    unzip /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip -d /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx
    rm /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip&quot;
done

# Delete X chromosome sumstats and rename files to be consistent with prscsx sumstat info
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  wget_label=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $3}&#39; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
if [ &quot;$pheno&quot; == &quot;HT&quot; ]; then
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_Height_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.HT.txt.gz
  else
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_${wget_label}_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz
  fi
  rm -r ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1
done

# Format so BOLT P value is used by GenoPred
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
sbatch -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/pigz/pigz -dc ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz | awk &#39;BEGIN {OFS=\&quot;\t\&quot;} {print \$2, \$3, \$4, \$6, \$7, \$8, \$9, \$12, \$13, \$15}&#39; | sed &#39;1s/P_BOLT_LMM_INF/P/&#39; | /users/k1806347/oliverpainfel/Software/pigz/pigz -c &gt; ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.reformat.txt.gz&quot;
done
</code></pre>
</details>
<hr />
</div>
<div id="download-relevant-ugr-sumstats" class="section level1">
<h1>Download relevant UGR sumstats</h1>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Identify wget command for relevant phenotypes
library(data.table)

# Read in UGR GWAS info from GWAS catalogue
ugr_gwas&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats.csv&#39;)

# Map UGR trait names to those used for UKB
ugr_gwas$trait&lt;-gsub(&#39; levels&#39;,&#39;&#39;, ugr_gwas$reportedTrait)
ugr_gwas$trait&lt;-gsub(&#39; count&#39;,&#39;&#39;, ugr_gwas$trait)

ugr_to_prscsx &lt;- c(
  &quot;Aspartate aminotransferase&quot; = &quot;Aspartate transaminase&quot;,
  &quot;Bilirubin&quot; = NA,  # No direct match
  &quot;Eosinophils&quot; = &quot;Eosinophil&quot;,
  &quot;Gamma glutamyl transferase&quot; = &quot;γ-glutamyl transpeptidase&quot;,
  &quot;HDL cholesterol&quot; = &quot;HDL-cholesterol&quot;,
  &quot;Hemoglobin A1c&quot; = &quot;HbA1c&quot;,
  &quot;Hip circumference&quot; = NA,  # No direct match
  &quot;LDL cholesterol&quot; = &quot;LDL-cholesterol&quot;,
  &quot;Red cell distribution width&quot; = NA,  # No direct match
  &quot;Serum albumin&quot; = &quot;Albumin&quot;,
  &quot;Serum alkaline phosphatase&quot; = &quot;Alkaline phosphatase&quot;,
  &quot;Systolic blood pressure&quot; = &quot;Sytolic blood pressure&quot;,
  &quot;Triglyceride&quot; = &quot;Triglycerides&quot;,
  &quot;Waist circumference&quot; = NA,  # No direct match
  &quot;Waist-hip ratio&quot; = NA,  # No direct match
  &quot;Weight&quot; = &quot;Body weight&quot;
)

ugr_gwas$trait &lt;- ifelse(ugr_gwas$trait %in% names(ugr_to_prscsx),
                                   ugr_to_prscsx[ugr_gwas$trait],
                                   ugr_gwas$trait)

# Merge the ugr trait info with the prscsx trait info
prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
prscsx_dat &lt;- merge(ugr_gwas, prscsx_dat, by=&#39;trait&#39;)

write.csv(prscsx_dat, &#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;, row.names = F)

# Create column indicating wget command
prscsx_dat$wget&lt;-NA
for(i in 1:nrow(prscsx_dat)){
  if(!grepl(&#39;.txt&#39;, prscsx_dat$wget[i])){
    print(i)
    Sys.sleep(2)
    log&lt;-system(paste0(&#39;curl --max-time 10 &#39;, gsub(&#39;http:&#39;,&#39;ftp:&#39;, prscsx_dat$summaryStatistics[i]), &#39;/&#39;), intern = T)
    log&lt;-log[grepl(&#39;annotated.txt.gz|annotated.txt&#39;, log)]
    log&lt;-gsub(&#39;.* &#39;,&#39;&#39;, log)
    prscsx_dat$wget[i]&lt;-paste0(prscsx_dat$summaryStatistics[i], &#39;/&#39;, log)
  }
}
# Note this has to be run a few times due to some requests being blocked.

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c(&#39;labels&#39;, &#39;wget&#39;), with=F], &#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code># wget and unzip sumstats
for pheno in $(cat ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt | cut -d&#39; &#39; -f 1); do
  url=$(awk -v var=&quot;$pheno&quot; &#39;$1 == var {print $2}&#39; ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt)
  sbatch -p cpu --wrap=&quot;wget -O ~/oliverpainfel/Data/GWAS_sumstats/UGR/${pheno}.txt.gz ${url}&quot;
done
</code></pre>
<pre class="r"><code>library(future.batchtools)
library(furrr)
library(data.table)
ugr_data&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)

plan(batchtools_slurm(resources = list(
  time = &quot;12:00:00&quot;,
  ntasks = 2,
  mem = &quot;10g&quot;,
  partition = &quot;neurohack_cpu&quot;
)))

furrr::future_map_dfr(1:nrow(ugr_data), function(i) {
  print(i)
  sumstats &lt;- fread(paste0(&quot;~/oliverpainfel/Data/GWAS_sumstats/UGR/&quot;, ugr_data$label[i], &quot;.txt.gz&quot;))
  sumstats &lt;- sumstats[, names(sumstats) %in% c(&quot;snpid&quot;, &quot;pval_fe&quot;, &quot;se_fe&quot;) | grepl(&#39;^beta_|^af_|^no_&#39;, names(sumstats)), with=F]

  # Extract CHR, BP, A1, A2 from snpid
  snp_split &lt;- tstrsplit(sumstats$snpid, &quot;:&quot;, fixed = TRUE)
  sumstats[, `:=`(CHR = snp_split[[1]], BP = snp_split[[2]], A1 = snp_split[[3]], A2 = snp_split[[4]])]

  # Set no_ and af_ to NA if beta is NA
  cohorts &lt;- gsub(&#39;^no_&#39;,&#39;&#39;, names(sumstats)[grepl(&#39;^no_&#39;, names(sumstats))])
  for (cohort in cohorts) {
    sumstats[[paste0(&#39;no_&#39;, cohort)]][is.na(sumstats[[paste0(&#39;beta_&#39;, cohort)]])] &lt;- NA
    sumstats[[paste0(&#39;af_&#39;, cohort)]][is.na(sumstats[[paste0(&#39;beta_&#39;, cohort)]])] &lt;- NA
  }

  # Calculate sample size weighted average for allele frequency
  for (cohort in cohorts) {
    sumstats[[paste0(&#39;af_&#39;, cohort, &#39;_weighted&#39;)]] &lt;- sumstats[[paste0(&#39;af_&#39;, cohort)]] * sumstats[[paste0(&#39;no_&#39;, cohort)]]
  }
  
  # Calculate total N and frequency
  sumstats[, N := rowSums(.SD, na.rm = TRUE), .SDcols = patterns(&quot;^no_&quot;)]
  sumstats[, FREQ := rowSums(.SD, na.rm = TRUE) / N, .SDcols = patterns(&quot;weighted$&quot;)]

  # Rename columns
  setnames(sumstats, old = c(&#39;beta_fe&#39;, &#39;se_fe&#39;, &#39;pval_fe&#39;), new = c(&#39;BETA&#39;, &#39;SE&#39;, &#39;P&#39;))

  # Select relevant columns and remove rows with missing data
  sumstats &lt;- sumstats[, .(CHR, BP, A1, A2, BETA, SE, P, FREQ, N)]
  sumstats &lt;- sumstats[complete.cases(sumstats)]
  
  fwrite(sumstats, paste0(&quot;~/oliverpainfel/Data/GWAS_sumstats/UGR/&quot;, ugr_data$label[i], &quot;.reformat.txt.gz&quot;), sep=&#39; &#39;, quote=F, na=&#39;NA&#39;)
  
})</code></pre>
</details>
<hr />
</div>
<div id="estimate-snp-h2-polygenicity-and-rg-across-populations"
class="section level1">
<h1>Estimate SNP-h2, polygenicity and rG across populations</h1>
<p>We will estimate SNP-h2 using LD-score regression, and the rG using
POPCORN. POPCORN can estimate the SNP-h2, but it will vary according to
the other GWAS included due to SNP overlap. Use the sumstats QC’d by
GenoPred. To estimate polygenicity, lets use AVENGEME based on ptclump
score association results. Lets generate those using GenoPred.</p>
<hr />
<div id="prepare-configuration-for-genopred" class="section level2">
<h2>Prepare configuration for GenoPred</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>######
# gwas_list
######

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop&#39;)

prscsx_dat&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)

gwas_list_eur&lt;-data.frame(
  name=paste0(prscsx_dat$labels,&#39;_UKB&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/gwas/&#39;,prscsx_dat$labels,&#39;/ukb.eur_train.&#39;,prscsx_dat$labels,&#39;.GW.txt.gz&#39;),
  population=&#39;EUR&#39;,
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, prscsx_dat$trait, &#39; (UKB)&quot;&#39;)
)

bbj_info&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;)
bbj_info&lt;-bbj_info[bbj_info$labels %in% prscsx_dat$labels,]

gwas_list_eas&lt;-data.frame(
  name=paste0(bbj_info$labels,&#39;_BBJ&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.&#39;,bbj_info$labels,&#39;.reformat.txt.gz&#39;),
  population=&#39;EAS&#39;,
  n=as.numeric(gsub(&#39;,&#39;,&#39;&#39;,bbj_info$`No. samples`)),
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, prscsx_dat$trait, &#39; (BBJ)&quot;&#39;)
)

ugr_data&lt;-fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)
ugr_data&lt;-ugr_data[ugr_data$labels %in% prscsx_dat$labels,]

gwas_list_afr&lt;-data.frame(
  name=paste0(ugr_data$labels,&#39;_UGR&#39;),
  path=paste0(&#39;/users/k1806347/oliverpainfel/Data/GWAS_sumstats/UGR/&#39;,ugr_data$labels,&#39;.reformat.txt.gz&#39;),
  population=&#39;AFR&#39;,
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0(&#39;&quot;&#39;, ugr_data$trait, &#39; (UGR)&quot;&#39;)
)
gwas_list&lt;-do.call(rbind, list(gwas_list_eur, gwas_list_eas, gwas_list_afr))

# Create file listing phenotypes in common between AFR, EAS and EUR
pheno &lt;- gsub(&#39;_.*&#39;, &#39;&#39;, gwas_list$name)
pheno_intersect &lt;- Reduce(intersect, 
                           list(
                             pheno[gwas_list$population == &#39;EUR&#39;],
                             pheno[gwas_list$population == &#39;EAS&#39;],
                             pheno[gwas_list$population == &#39;AFR&#39;]
                             )
                           )

# Restrict gwas_list to intersecting phenotypes
gwas_list&lt;-gwas_list[pheno %in% pheno_intersect,]

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;, col.names = T, row.names = F, quote = F)

write.table(pheno_intersect, &#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, col.names = F, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;]&quot;,
  &quot;cores_prep_pgs: 1&quot;,
  &quot;cores_target_pgs: 20&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
</details>
<hr />
</div>
<div id="run-pipeline-1" class="section level2">
<h2>Run pipeline</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml \
  target_pgs -n</code></pre>
</details>
<hr />
</div>
<div id="reformat-for-ldsc-and-popcorn" class="section level2">
<h2>Reformat for LDSC and POPCORN</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
dir.create(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats&#39;, recursive = T)
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)

for(i in 1:nrow(gwas_list)){
  if(
    file.exists(
      paste0(
        &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/&quot;,
        gwas_list$name[i], 
        &quot;.sumstats.gz&quot;))){
    next    
  }
  print(i)
  gwas_file &lt;-
    paste0(
      &quot;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/&quot;,
      gwas_list$name[i],
      &quot;/&quot;,
      gwas_list$name[i],
      &quot;-cleaned.gz&quot;
    )
  
  gwas_header &lt;- fread(gwas_file, nrows = 1)
  cols_index &lt;- which(names(gwas_header) %in% c(&#39;SNP&#39;,&#39;A1&#39;,&#39;A2&#39;,&#39;BETA&#39;,&#39;SE&#39;,&#39;P&#39;,&#39;N&#39;))
  
  system(
    paste0(
      &quot;zcat &quot;,
      gwas_file,
      &quot; | cut -f &quot;, 
      paste0(cols_index, collapse = &#39;,&#39;),
      &quot; | sed -e &#39;1s/BETA/beta/&#39;&quot;,
      &quot; | /users/k1806347/oliverpainfel/Software/pigz/pigz -f&quot;,
      &quot; &gt; /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/&quot;,
      gwas_list$name[i], 
      &quot;.sumstats.gz&quot;
      )
    )
}</code></pre>
</details>
<hr />
</div>
<div id="run-ldsc" class="section level2">
<h2>Run LDSC</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>conda activate ldsc

for pop in $(echo EUR EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      samp=&quot;UKB&quot;
  fi
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/munge_sumstats.py \
     --sumstats /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}&quot;

  done
done

for pop in $(echo EUR EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      samp=&quot;UKB&quot;
  fi
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;/users/k1806347/oliverpainfel/Software/ldsc/ldsc.py \
     --h2 /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}.sumstats.gz \
     --ref-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --w-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}/res&quot;
     
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="calculate-cscores" class="section level2">
<h2>Calculate CSCOREs</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>
# Subset the reference data into relevant populations
for pop in $(echo EUR EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
  for chr in $(seq 1 22); do
    /users/k1806347/oliverpainfel/Software/plink2 \
      --pfile /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/ref.chr${chr} \
      --keep /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/keep_files/${pop}.keep \
      --make-bed \
      --out /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr}
    done
done

conda activate /scratch/prj/oliverpainfel/recovered/.conda/envs/popcorn
for pop in $(echo EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES
  for chr in $(seq 1 22); do
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;popcorn \
      compute \
      -v 1 \
      --bfile1 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.EUR.chr${chr} \
      --bfile2 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr} \
      /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr${chr}.txt&quot;
  done
done

for pop in $(echo EAS AFR); do
  cat /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr*.txt &gt; /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt
done

rm -r /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
rm /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_*_CSCORES/*chr*.txt</code></pre>
</details>
<hr />
</div>
<div id="run-popcorn" class="section level2">
<h2>Run POPCORN</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>conda activate popcorn
for pop in $(echo EAS AFR);do
  if [ &quot;$pop&quot; == &quot;EAS&quot; ]; then
      samp=&quot;BBJ&quot;
  fi
  if [ &quot;$pop&quot; == &quot;AFR&quot; ]; then
      samp=&quot;UGR&quot;
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap=&quot;popcorn \
       fit -v 3 \
       --cfile /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt \
       --sfile1 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_UKB.sumstats.gz \
       --sfile2 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
       --gen_effect \
       /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}/rG_gen_effect&quot;
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="plot-the-ldsc-and-popcorn-results" class="section level2">
<h2>Plot the LDSC and POPCORN results</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Plot the heritability estimates
h2_res &lt;- NULL

for(pop in c(&#39;AFR&#39;,&#39;EAS&#39;, &#39;EUR&#39;)){
  for(pheno in pheno_intersect){
    log &lt;-
      readLines(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/&#39;,
          pheno,
          &#39;/&#39;,
          pop,
          &#39;/res.log&#39;
        )
      )
    
    h2 &lt;- log[grepl(&#39;Total Observed scale h2:&#39;, log)]
    h2_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Total Observed scale h2: &#39;, &#39;&#39;, h2)))
    h2_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, h2)))
    int &lt;- log[grepl(&#39;Intercept:&#39;, log)]
    int_est &lt;- as.numeric(gsub(&#39; .*&#39;,&#39;&#39;, gsub(&#39;Intercept: &#39;, &#39;&#39;, int)))
    int_se &lt;- as.numeric(gsub(&quot;\\)&quot;,&#39;&#39;, gsub(&quot;.* \\(&quot;, &#39;&#39;, int)))
    lambda &lt;- log[grepl(&#39;Lambda GC:&#39;, log)]
    lambda &lt;- as.numeric(gsub(&#39;.* &#39;,&#39;&#39;, lambda))
    
    h2_res &lt;- rbind(
      h2_res,
      data.table(
        Population = pop,
        Phenotype = pheno,
        h2_est = h2_est,
        h2_se = h2_se,
        int_est = int_est,
        int_se = int_se,
        lambda = lambda
      )
    )
  }
}

write.csv(h2_res, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;, row.names = F, quote = F)

ggplot(h2_res, aes(x = Phenotype, y = h2_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=h2_est-h2_se, ymax=h2_est+h2_se), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;SNP-based Heritability (SE)&quot;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

# Plot rG estimates
rg_res &lt;- NULL
for(pop in c(&#39;AFR&#39;,&#39;EAS&#39;)){
  for(pheno in h2_res$Phenotype){
    pop_res_i&lt;-fread(paste0(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/&#39;, pheno, &#39;/EUR_&#39;, pop, &#39;/rG_gen_effect&#39;))
    names(pop_res_i) &lt;- c(&#39;Test&#39;,&#39;Estimate&#39;,&#39;SE&#39;,&#39;Z&#39;,&#39;P&#39;)
    pop_res_i &lt;- pop_res_i[pop_res_i$Test == &#39;pge&#39;,]
    pop_res_i$Population_1 &lt;- &#39;EUR&#39;
    pop_res_i$Population_2 &lt;- pop
    pop_res_i$Phenotype &lt;- pheno
    rg_res &lt;- rbind(rg_res, pop_res_i)
  }
}

rg_res$Comparison &lt;- paste0(rg_res$Population_1, &#39; vs. &#39;, rg_res$Population_2)

write.csv(rg_res, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results.csv&#39;, row.names = F, quote = F)

ggplot(rg_res, aes(x = Phenotype, y = Estimate, fill = Comparison)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin=Estimate-SE, ymax=Estimate+SE), width=.2, position=position_dodge(width = 0.7)) +
  labs(y=&quot;SNP-based\nGenetic Correlation (SE)&quot;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)</code></pre>
</details>
</div>
<div id="avengeme" class="section level2">
<h2>AVENGEME</h2>
<div id="create-predictor-lists" class="section level3">
<h3>Create predictor lists</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Create files for EAS and AFR targets
pop &lt;- c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in pheno_intersect){
  # Make a group containing both GWAS for each single source method
  # Make a group for each multisource method
  scores_i &lt;- scores[grepl(paste0(&#39;^&#39;, trait_i, &#39;_&#39;), scores$name),]
  scores_i$group &lt;- scores_i$method
  
  for(pop_i in pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(pop_i == &#39;EAS&#39;){
      samp_i &lt;- &#39;BBJ&#39;
    }
    if(pop_i == &#39;AFR&#39;){
      samp_i &lt;- &#39;UGR&#39;
    }
    if(pop_i == &#39;EUR&#39;){
      samp_i &lt;- c(&#39;UKB&#39;)
    }

    dir.create(
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i
      ),
      recursive = T
    )
    
    scores_i_j &lt;- scores_i[grepl(samp_i, scores_i$name, ignore.case = T),]
    scores_i_j$predictor &lt;- paste0(
      outdir,
      &#39;/ukb/pgs/TRANS/&#39;,
      scores_i_j$method,
      &#39;/&#39;,
      scores_i_j$name,
      &#39;/ukb-&#39;,
      scores_i_j$name,
      &#39;-TRANS.profiles&#39;
    )
    
    predictors_i &lt;- scores_i_j[, c(&#39;predictor&#39;, &#39;group&#39;), with=F]
    
    write.table(
      predictors_i,
      paste0(
        &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
        pop_i,
        &#39;.disc_&#39;,
        pop_i,
        &#39;/&#39;,
        trait_i,
        &#39;/predictor_list.ptclump.txt&#39;
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}</code></pre>
</details>
<hr />
</div>
<div id="run-model_builder" class="section level3">
<h3>Run model_builder</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

for pop in $(echo EUR EAS AFR); do
  if [ &quot;$pop&quot; == &quot;EUR&quot; ]; then
      pop2=&quot;EUR_test&quot;
  else
      pop2=$pop
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    sbatch --mem 5G -n 5 -p neurohack_cpu --wrap=&quot;Rscript ../Scripts/model_builder/model_builder.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${pop2}.row_number.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/predictor_list.ptclump.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/res.ptclump \
      --n_core 5 \
      --all_model F \
      --assoc T&quot;
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="plot-assoc-results" class="section level3">
<h3>Plot assoc results</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

# Read in results
pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_all &lt;- NULL
for(pheno_i in pheno_intersect){
  res_i&lt;-NULL
  for(pop_i in pop){
    assoc_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          pop_i,
          &#39;.disc_&#39;,
          pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res.ptclump.assoc.txt&#39;
        )
      )
      assoc_i$Population &lt;- pop_i
      res_i&lt;-rbind(res_i, assoc_i)
  }
  
  res_i$Phenotype &lt;- pheno_i
  res_all&lt;-rbind(res_all, res_i)
}

# Extract pT variable from Predictor
res_all$pT &lt;- gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.&#39;, &#39;&#39;, res_all$Predictor))
res_all$pT &lt;- factor(res_all$pT, levels = unique(res_all$pT))

ggplot(res_all, aes(x = Phenotype, y = BETA, fill = pT)) +
  geom_hline(yintercept = 0, colour = &#39;darkgrey&#39;) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.8) +
  geom_errorbar(aes(ymin=BETA-SE, ymax=BETA+SE), width=0, position=position_dodge(width = 0.8, preserve = &quot;single&quot;)) +
  labs(y=&quot;BETA (SE)&quot;) +
  theme_half_open() +
  background_grid() +
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) +
  scale_fill_manual(values = colorRampPalette(c(&quot;lightblue&quot;, &quot;darkblue&quot;))(length(unique(res_all$pT)))) +
  facet_grid(Population ~.)</code></pre>
</details>
</div>
<div id="run-avengeme" class="section level3">
<h3>Run AVENGEME</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)
library(avengeme)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)
gwas_list &lt;- read_param(config = config, param = &#39;gwas_list&#39;, return_obj = T)

# Read in phenotypes
pheno_intersect &lt;- read.table(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt&#39;, header=F)$V1

pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)

mod_res_all &lt;- NULL
for(pop_i in pop){
  for(pheno_i in pheno_intersect){
    gwas_i&lt;-gwas_list$name[gwas_list$population == pop_i &amp; grepl(paste0(&#39;^&#39;, pheno_i, &#39;_&#39;),  gwas_list$name)]
      
    res_i &lt;-
      fread(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          pop_i,
          &#39;.disc_&#39;,
          pop_i,
          &#39;/&#39;,
          pheno_i,
          &#39;/res.ptclump.assoc.txt&#39;
        )
      )
    
    res_i$Z &lt;- res_i$BETA / res_i$SE
    
    res_i$pT &lt;- as.numeric(gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.&#39;, &#39;&#39;, res_i$Predictor)))

    nsnp_log &lt;-
      read.table(
        paste0(
          outdir,
          &#39;/reference/pgs_score_files/ptclump/&#39;,
          gwas_i,
          &#39;/ref-&#39;,
          gwas_i,
          &#39;.NSNP_per_pT&#39;
        ),
        header = T
      )
    
    nsnp&lt;-nsnp_log$NSNP[nrow(nsnp_log)]
    
    disc_N &lt;-
      median(
        fread(
          paste0(
            outdir,
            &#39;/reference/gwas_sumstat/&#39;,
            gwas_i,
            &#39;/&#39;,
            gwas_i,
            &#39;-cleaned.gz&#39;
          ), nrows = 10000
        )$N
      )
    
    targ_N &lt;- res_i$N[1]
    
    mod_res &lt;- estimatePolygenicModel(
      p = res_i$Z,
      nsnp = nsnp,
      n = c(disc_N, targ_N),
      pupper = c(0, res_i$pT),
      fixvg2pi02 = T,
      alpha = 0.05
    )
    
    mod_res_all &lt;- rbind(
      mod_res_all,
      data.frame(
        Phenotype = pheno_i,
        Population = pop_i,
        GWAS = gwas_i,
        nsnp = nsnp,
        max_r2 = max(res_i$Obs_R2),
        n_disc = disc_N,
        n_targ = targ_N,
        vg_est = mod_res$vg[1],
        vg_lowCI = mod_res$vg[2],
        vg_highCI = mod_res$vg[3],
        pi0_est = mod_res$pi0[1],
        pi0_lowCI = mod_res$pi0[2],
        pi0_highCI = mod_res$pi0[3]
      )
    )
  }
}

dir.create(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme&#39;)
write.csv(mod_res_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;, row.names = F, quote = F)

ggplot(mod_res_all, aes(x = Phenotype, y = vg_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=vg_lowCI, ymax=vg_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;SNP-based Heritability (95%CI)&quot;) +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

ggplot(mod_res_all, aes(x = Phenotype, y = 1 - pi0_est, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  geom_errorbar(aes(ymin=1 - pi0_lowCI, ymax=1 - pi0_highCI), width=.2, position=position_dodge(width = 0.7, preserve = &quot;single&quot;)) +
  labs(y=&quot;Proporition non-zero\neffects (95%CI)&quot;) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

ggplot(mod_res_all, aes(x = Phenotype, y = max_r2, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  labs(y=&quot;Max R2&quot;) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

# 
hist(mod_res_all$max_r2)
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])</code></pre>
</details>
<hr />
</div>
<div id="select-gwas-for-downstream-analyses" class="section level3">
<h3>Select GWAS for downstream analyses</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>#########
# Select 10 GWAS for downstream analysis
#########
# Criteria are that SNP-h2 &gt; 0.01 in both AVENGEME and LDSC
# Then GWAS are selected to represent a range of polygenicity and heritability, as estimated in EUR since they are most accurate

library(data.table)

# Read in the AVENGEME results
avengeme &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)

# Read in the LDSC results
ldsc &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;)

# Combine results
both &lt;- merge(avengeme, ldsc, by = c(&#39;Population&#39;,&#39;Phenotype&#39;))

# Remove GWAS that have negative SNP-h2 from LDSC in any population
both_h2 &lt;- both[!(both$Phenotype %in% both$Phenotype[both$vg_est &lt; 0.01 | both$h2_est &lt; 0.01]),]

# Select GWAS representing a range of SNP-h2 from LDSC, and a range of polygenicity from AVENGEME.
both_eur&lt;-both_h2[both_h2$Population == &#39;EUR&#39;,]
traits_data &lt;- data.frame(trait = both_eur$Phenotype, heritability = both_eur$vg_est, polygenicity = both_eur$pi0_est)

# Number of bins (e.g., dividing into 5 bins each for heritability and polygenicity)
num_bins &lt;- 5

# Create bins
traits_data$her_bin &lt;- cut(traits_data$heritability, breaks = num_bins)
traits_data$poly_bin &lt;- cut(traits_data$polygenicity, breaks = num_bins)

# Split data by unique bin combinations
split_data &lt;- split(traits_data, list(traits_data$her_bin, traits_data$poly_bin), drop = TRUE)

set.seed(1)
# Randomly select one trait from each bin combination
selected_traits &lt;- do.call(rbind, lapply(split_data, function(df) df[sample(nrow(df), 1), ]))

# Limit to 10 traits if more than 10 unique combinations
if (nrow(selected_traits) &gt; 10) {
  selected_traits &lt;- selected_traits[sample(nrow(selected_traits), 10), ]
}

write.table(selected_traits$trait, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, col.names = F, row.names = F, quote = F)

# Plot max R2 for selected traits
mod_res_all &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)
mod_res_all_selected &lt;- mod_res_all[mod_res_all$Phenotype %in% selected_traits$trait,]

ggplot(mod_res_all_selected, aes(x = Phenotype, y = max_r2, fill = Population)) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.7) +
  labs(y=&quot;Max R2&quot;) +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;)

# 
hist(mod_res_all$max_r2)
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
hist(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])
summary(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])

round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;EUR&#39;])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;EAS&#39;])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == &#39;AFR&#39;])), 2)</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="make-a-descriptives-table-of-gwas" class="section level1">
<h1>Make a descriptives table of GWAS</h1>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

#####
# Trait names, labels, and URLs
#####

###
# UKB
###
ukb &lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv&#39;)
names(ukb) &lt;- c(&#39;trait&#39;, &#39;labels&#39;,&#39;field&#39;)
trait_labels &lt;- ukb[, c(&#39;trait&#39;,&#39;labels&#39;), with=F]
ukb&lt;-ukb[, c(&#39;trait&#39;,&#39;field&#39;), with=F]
ukb$sample &lt;- &#39;UKB&#39;
ukb$population &lt;- &#39;EUR&#39;
ukb$url&lt;-NA

###
# BBJ
###
bbj &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv&#39;)
bbj &lt;- bbj[, c(&#39;trait&#39;, &#39;wget&#39;), with = F]
names(bbj) &lt;- c(&#39;trait&#39;, &#39;url&#39;)
bbj$sample &lt;- &#39;BBJ&#39;
bbj$population &lt;- &#39;EAS&#39;
bbj$field &lt;- NA

###
# UGR
###
ugr &lt;- fread(&#39;~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv&#39;)
ugr &lt;- ugr[, c(&#39;trait&#39;, &#39;summaryStatistics&#39;), with = F]
names(ugr) &lt;- c(&#39;trait&#39;,&#39;url&#39;)
ugr$sample &lt;- &#39;UGR&#39;
ugr$population &lt;- &#39;AFR&#39;
ugr$field &lt;- NA

info_all &lt;- do.call(rbind, list(ukb, bbj, ugr))
info_all&lt;-merge(info_all, trait_labels, by=&#39;trait&#39;)

#####
# Sample size, SNP-h2 and polygenicity
#####

# Read in the AVENGEME and LDSC results
avengeme &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv&#39;)
ldsc &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv&#39;)
both &lt;- merge(avengeme, ldsc, by = c(&#39;Population&#39;,&#39;Phenotype&#39;))

# Format for descriptives table
both$h2_avengeme&lt;- paste0(
  round(both$vg_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$vg_lowCI, 2), 
  &quot; - &quot; , 
  round(both$vg_highCI, 2), &quot;)&quot;)

both$pi0_avengeme &lt;- paste0(
  round(both$pi0_est,2), 
  &quot; (95%CI = &quot;, 
  round(both$pi0_lowCI, 2), 
  &quot; - &quot; , 
  round(both$pi0_highCI, 2), &quot;)&quot;)

both$h2_ldsc &lt;- paste0(
  round(both$h2_est,2), 
  &quot; (SE = &quot;, 
  round(both$h2_se, 2), 
  &quot;)&quot;)

both$int_ldsc &lt;- paste0(
  round(both$int_est,2), 
  &quot; (SE = &quot;, 
  round(both$int_se, 2), 
  &quot;)&quot;)

both&lt;-both[, c(&#39;Population&#39;,&#39;Phenotype&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;), with = F]
names(both)[1:2]&lt;-c(&#39;population&#39;,&#39;labels&#39;)

info_all &lt;- merge(info_all, both, by = c(&#39;labels&#39;,&#39;population&#39;))
info_all$n_disc&lt;-round(info_all$n_disc, 0)
info_all$n_targ&lt;-round(info_all$n_targ, 0)

info_all&lt;-info_all[, c(&#39;labels&#39;,&#39;trait&#39;,&#39;population&#39;,&#39;sample&#39;,&#39;n_disc&#39;,&#39;n_targ&#39;,&#39;h2_avengeme&#39;,&#39;pi0_avengeme&#39;,&#39;h2_ldsc&#39;,&#39;int_ldsc&#39;,&#39;lambda&#39;,&#39;field&#39;,&#39;url&#39;), with=F]
names(info_all) &lt;- c(&#39;Trait Label&#39;, &#39;Trait Description&#39;, &#39;Ancestry&#39;, &#39;GWAS Sample&#39;, &#39;GWAS N&#39;, &#39;Target N&#39;,&quot;SNP-h2 (AVENGEME)&quot;,&quot;pi0 (AVENGEME)&quot;,&quot;SNP-h2 (LDSC)&quot;,&quot;Intercept (LDSC)&quot;,&#39;Lambda&#39;, &#39;UKB Field&#39;, &#39;URL&#39;)

# Add in column indicating whether the trait was used in downstream PGS comparison
selected_traits &lt;- fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

info_all$`Selected` &lt;- info_all$`Trait Label` %in% selected_traits

write.csv(info_all, &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;, row.names=F)

# Estimate the mean and SD of sample size within each population for selected traits
info_all_selected&lt;-info_all[info_all$Selected == T,]
n_dat &lt;- NULL
for(i in unique(info_all_selected$`GWAS Sample`)){
  n_dat &lt;-rbind(
    n_dat,
    data.table(
      sample = i,
      gwas_n_median = round(median(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_mean = round(mean(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_sd = round(sd(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      target_n_median = round(median(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_mean = round(mean(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_sd = round(sd(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i]))
    )
  )
}</code></pre>
</details>
<hr />
</div>
<div id="run-genopred" class="section level1">
<h1>Run GenoPred</h1>
<div id="prepare-configuration-for-genopred-1" class="section level2">
<h2>Prepare configuration for GenoPred</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>######
# gwas_list
######
library(data.table)
# Subset original gwas_list to include selected traits
gwas_list&lt;-fread(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt&#39;)
pheno&lt;-gsub(&#39;_.*&#39;,&#39;&#39;, gwas_list$name)
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
gwas_list&lt;-gwas_list[pheno %in% selected_traits,]
gwas_list$label&lt;-paste0(&#39;&quot;&#39;, gwas_list$label, &#39;&quot;&#39;)

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&#39;, col.names = T, row.names = F, quote = F)

######
# gwas_groups
######

gwas_groups_eas&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_BBJ&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_BBJ&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+BBJ)&quot;, &#39;&quot;&#39;)
)

gwas_groups_afr&lt;-data.frame(
  name=paste0(selected_traits, &#39;_UKB_UGR&#39;),
  gwas=sapply(selected_traits, function(x) paste0(x,&#39;_UKB,&#39;,x,&#39;_UGR&#39;)),
  label=paste0(&#39;&quot;&#39;, selected_traits, &quot; (UKB+UGR)&quot;, &#39;&quot;&#39;)
)

gwas_groups&lt;-rbind(gwas_groups_eas, gwas_groups_afr)

write.table(gwas_groups, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&#39;, col.names = T, row.names = F, quote = F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;,&#39;prscsx&#39;,&#39;xwing&#39;]&quot;,
  &quot;tlprs_methods: [&#39;dbslmm&#39;]&quot;,
  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;,&#39;prscs&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;, # xwing run with 20 cores
  &quot;cores_target_pgs: 50&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
</details>
<hr />
</div>
<div id="run-pipeline-2" class="section level2">
<h2>Run pipeline</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml \
  target_pgs  -n</code></pre>
</details>
<hr />
</div>
</div>
<div id="evaluate-pgs" class="section level1">
<h1>Evaluate PGS</h1>
<p>Lets use the model builder script which implements nested 10 fold
cross validation. Similar set up to previous paper, evaluating a model
containing the best PGS selected by 10-fold cross validation, a model
containing the PGS selected by pseudovalidation (if available), and an
elastic net model containing all PGS from a given method. We will need
to update the model builder script to achieve this</p>
<hr />
<div id="compare-all-methods" class="section level2">
<h2>Compare all methods</h2>
<p>We want to see: - Performance of pseudo and top1 models for
single-source methods - Performance of pseudo and top1 models for
multi-source methods - Performance of multi-source methods: - Using
crossval for tuning step 1 and 2 - Using pseudoval for tuning step 1 and
2 - Using pseudoval for tuning step 1 and crossval for tuning step 2</p>
<p>To achieve this. Will need to define groups of predictors for step 1
modelling, and groups that should then be linearly combined.</p>
<hr />
<div id="create-predictor-lists-1" class="section level3">
<h3>Create predictor lists</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]
  scores_i$multi &lt;- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 &lt;-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                     !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_single_top1$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_single_pseudo$predictor)

      ####
      # Make groups for multi-single-source pseudo scores
      ####
      
      scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi_single_pseudo$name[i],
          pgs_method = scores_i_j_multi_single_pseudo$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi_single_pseudo$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_multi_single_pseudo$predictor[i])
          )
        )
      }
      
      scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_multi_single_pseudo$predictor)
      
      scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)

      ####
      # Make groups for the Multi-Source methods
      ####
      
      scores_i_j_multi &lt;- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]

      # Split top1 scores by target population
      # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
      scores_i_j_multi_top1&lt;-NULL
      for(i in 1:which(scores_i_j_multi$method %in% c(&#39;prscsx&#39;))){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_top1 &lt;- rbind(scores_i_j_multi_top1, tmp)
        }
      }

      # Split pop-specific pseudo scores by target population
      scores_i_j_multi_pop_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)){
        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
            score_cols &lt;-
              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
          }
          
          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_multi$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_multi[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_pop_pseudo &lt;- rbind(scores_i_j_multi_pop_pseudo, tmp)
        }
      }
      
      # Create pseudo score for multi-source methods
      scores_i_j_multi_pseudo&lt;-NULL
      for(i in 1:nrow(scores_i_j_multi)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_multi$name[i],
          pgs_method = scores_i_j_multi$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_multi$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi$name[i], &#39;_&#39;, param)))

        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_multi$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
          )
        )
        
        tmp &lt;- scores_i_j_multi[i,]
        tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
        tmp$top1 &lt;- paste0(&#39;EUR_&#39;, disc_pop_j_2)
        tmp$predictor &lt;-
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
                 scores_i_j_multi$predictor[i])
        
        scores_i_j_multi_pseudo &lt;- rbind(scores_i_j_multi_pseudo, tmp)
      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo, 
        scores_i_j_multi_single_pseudo,
        scores_i_j_multi_top1,
        scores_i_j_multi_pop_pseudo,
        scores_i_j_multi_pseudo
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
      ####
      # Make a group that will combined all population specific PGS
      ####
      
      predictors_i_all &lt;- predictors_i[predictors_i$top1 %in% c(&#39;EUR&#39;,&#39;AFR&#39;,&#39;EAS&#39;),]
      predictors_i_all$multi &lt;- &#39;all&#39;
      predictors_i&lt;-rbind(predictors_i, predictors_i_all)
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
</details>
<hr />
</div>
<div id="run-model_builder-1" class="section level3">
<h3>Run model_builder</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EUR EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5&quot;
      fi
    done
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="plot-results" class="section level3">
<h3>Plot results</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTrain&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTrain or IndivTrain
  tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
  tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

# Count the number of traits each method is best
tmp &lt;- res_eval_simp[res_eval_simp$label != &#39;All&#39;,]
best_groups &lt;-
  do.call(rbind, by(tmp, list(
    tmp$Target,
    tmp$gwas_group,
    tmp$Trait
  ), function(subset) {
    subset[which.max(subset$R),]  # Select row with max R
  }))

best_counts &lt;- as.data.frame(table(paste0(best_groups$label,&#39;:&#39;, best_groups$Model), best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) &lt;- c(&quot;label&quot;, &quot;gwas_group&quot;, &quot;Target&quot;, &quot;count&quot;)
best_counts$Model&lt;-gsub(&#39;.*:&#39;,&#39;&#39;,best_counts$label)
best_counts$label&lt;-gsub(&#39;:.*&#39;,&#39;&#39;,best_counts$label)
best_counts$label &lt;- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts &lt;- best_counts[best_counts$count &gt; 0, ]

# Create the plot
ggplot(best_counts[best_counts$Target != &#39;EUR&#39;,], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  facet_wrap(~ Target, scales = &#39;free_x&#39;) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() + 
  labs(
    title = &quot;Number of times each method is the best&quot;,
    x = &quot;Method&quot;,
    y = &quot;Count&quot;,
    fill = &quot;GWAS Group&quot;
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#############################
# Identify best methods that improved prediction over next best method by 2% for any trait
# Filter out &#39;All&#39; from the data
tmp &lt;- res_eval_simp[res_eval_simp$label != &#39;All&#39;,]

# Identify the best method for each trait, but only if it improves by &gt;2%
best_groups &lt;- do.call(rbind, by(tmp, list(tmp$Target, tmp$gwas_group, tmp$Trait), function(subset) {
  if (nrow(subset) &gt; 1) {
    # Sort by R in descending order
    subset &lt;- subset[order(-subset$R), ]
    # Check if the best method is more than 2% better than the second best
    if ((subset$R[1] - subset$R[2]) / subset$R[2] &gt; 0.02) {
      return(subset[1, ])  # Return the best method if criteria met
    } 
  } else {
    return(subset[1, ])  # Handle cases with only one method
  }
  return(NULL)  # Return NULL if criteria not met
}))

# Create a count table with label and model combined
best_counts &lt;- as.data.frame(table(paste0(best_groups$label,&#39;:&#39;, best_groups$Model), 
                                   best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) &lt;- c(&quot;label&quot;, &quot;gwas_group&quot;, &quot;Target&quot;, &quot;count&quot;)
best_counts$Model &lt;- gsub(&#39;.*:&#39;, &#39;&#39;, best_counts$label)
best_counts$label &lt;- gsub(&#39;:.*&#39;, &#39;&#39;, best_counts$label)
best_counts$label &lt;- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts &lt;- best_counts[best_counts$count &gt; 0, ]

# Create the plot
library(ggplot2)
ggplot(best_counts[best_counts$Target != &#39;EUR&#39;,], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position = &quot;dodge&quot;) +
  facet_wrap(~ Target, scales = &#39;free_x&#39;) +
  theme_minimal() +
  labs(
    title = &quot;Number of times each method is the best (with &gt;2% improvement)&quot;,
    x = &quot;Method&quot;,
    y = &quot;Count&quot;,
    fill = &quot;Model&quot;
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


#############################


# Plot results for each phenotype separately
dir.create(&#39;~/oliverpainfel/Analyses/crosspop/plots&#39;)

for(pheno_i in selected_traits){
  tmp &lt;- res_eval_simp[res_eval_simp$Trait == pheno_i,]
  #tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
  tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
  tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)
  tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

  png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/&#39;, pheno_i,&#39;.png&#39;), res=300, width = 3400, height = 2000, units = &#39;px&#39;)
  plot_tmp&lt;-ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
  print(plot_tmp)
  dev.off()
}

# Compare performance of each method in each target population across values of GWAS sample size
# Because we cannot hold all other things constant, this plot is confusing. I think relative performance might be easier to read.
for(targ_pop_i in targ_pop){
    tmp &lt;- res_eval_simp[res_eval_simp$Target == targ_pop_i,]
    for(disc_pop_i in unique(tmp$Discovery)){
      tmp2 &lt;- tmp[tmp$Discovery == disc_pop_i,]
      
      ggplot(tmp2, aes(x=label, y=R , fill = Model)) +
        geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                      width = 0,
                      position = position_dodge(width = 1)) +
        geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
        geom_vline(xintercept = seq(1.5, length(unique(tmp2$Trait))), linetype=&quot;dotted&quot;) +
        labs(y = &quot;R (SE)&quot;, x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
        facet_grid(. ~ Trait, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
        theme_half_open() +
        background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
        panel_border() + 
        theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
      
    }
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

write.csv(meta_res_eval, &#39;~/oliverpainfel/Analyses/crosspop/r_eval.csv&#39;, row.names = F)

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot average performance across phenotypes for EUR using AFR or EAS GWAS
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target == &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean &lt;- paste0(tmp$Discovery_clean, &#39; GWAS&#39;)
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.png&#39;), res=300, width = 4000, height = 1500, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Plot performance of -multi models trained using LEOPARD vs using indiv-level data
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;)
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = unique(tmp$label[order(!(grepl(&#39;Multi&#39;, tmp$label)), tmp$label)]))
tmp&lt;-tmp[grepl(&#39;multi&#39;, tmp$label),]
tmp &lt;- tmp[tmp$Model != &#39;Multi-IndivTrain&#39;,]
tmp$Model&lt;-as.character(tmp$Model)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;]&lt;-&#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;]&lt;-&#39;LEOPARD&#39;
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_leopard.png&#39;), res=300, width = 1500, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      comp_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_comp.txt&#39;
          )
        )
      comp_i&lt;-mirror_comp(comp_i)
      comp_i$Target&lt;-targ_pop_i
      comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_comp_i&lt;-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTrain&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTrain&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTrain&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTrain&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTrain&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTrain&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTrain&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;)]),]

res_comp_all$r_diff_rel &lt;- res_comp_all$R_diff / res_comp_all$Model_2_R

# Calculate relative improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

tmp_ldpred2 &lt;- res_comp_all[res_comp_all$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 &lt;- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

# Calculate relative improvement for sbayesrc-multi vs sbayesrc in EUR target as example
tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

tmp_sbayesrc &lt;- res_comp_all[res_comp_all$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo-&#39;, res_comp_all$Model_2) &amp;
                    res_comp_all$Target == &#39;EUR&#39; &amp;
                    res_comp_all$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    res_comp_all$Discovery2 == &#39;EUR&#39;,]
tmp_sbayesrc &lt;- tmp_sbayesrc[order(-tmp_sbayesrc$Model_2_R),]
round(min(tmp_sbayesrc$r_diff_rel)*100, 1)
round(max(tmp_sbayesrc$r_diff_rel)*100, 1)

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTrain or SumStatTrain result
tmp &lt;- res_comp_all
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;pheno&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;, &#39;R_diff_pval&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;, &#39;Trait&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$Trait, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/r_diff.csv&#39;, row.names=F)

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
    res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample&lt;-&#39;A&#39;
    res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
      cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i &lt;-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = &quot;BHHR&quot;,
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$Model_1_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$Model_2_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$R_diff &lt;- meta_res_comp_i$es
        tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$R_diff &lt;- NA
        tmp$R_diff_SE &lt;- NA
        tmp$R_diff_z &lt;- NA
        tmp$R_diff_p &lt;- NA
      }
      meta_res_comp &lt;- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Extract average improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

tmp_ldpred2 &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;ldpred2.multi&#39; &amp; 
                    grepl(&#39;ldpred2-&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
tmp_ldpred2 &lt;- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

# Extract average improvement for sbayesrc-multi vs sbayesrc in EUR as example
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                    grepl(&#39;sbayesrc.pseudo&#39;, meta_res_comp$Model_2) &amp;
                    meta_res_comp$Target == &#39;EUR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EUR+EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EUR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)

# Extract average improvement for sbayesrc in EUR compared to all model
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo-EUR.top1&#39; &amp;
                    meta_res_comp$Model_1 == &#39;all-EUR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(tmp_sbayesrc$R_diff_perc*100, 1)
tmp_sbayesrc$R_diff_p


# Compare QuickPRS-Multi vs QuickPRS to evaluate LEOPARD performance
tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

tmp_quickprs &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;quickprs_multi.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_2 == &#39;quickprs.pseudo.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Source2 == &#39;Multi&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

# Compare all.multi method to next best method
tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-AFR.top1&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;AFR&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;AFR&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

tmp_all &lt;- meta_res_comp[meta_res_comp$Model_1 == &#39;all-EAS.top1&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery1 == &#39;EAS&#39; &amp;
                    meta_res_comp$Discovery2 == &#39;EAS&#39;,]
tmp_all &lt;- tmp_all[order(tmp_all$R_diff),]
tmp_all &lt;- tmp_all[1,]
round(tmp_all$R_diff_perc*100, 1)
tmp_all$R_diff_p

#####
# Export a csv containing difference results for all traits
#####
# Simplify to contain only IndivTrain or SumStatTrain result
tmp &lt;- meta_res_comp
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;

tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)

tmp$Model1[tmp$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model1[tmp$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp$Model2[tmp$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model2[tmp$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;

tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

tmp$`Model 1` &lt;- paste0(tmp$label1, &#39; - &#39;, tmp$Model1, &#39; - &#39;, tmp$Discovery1)
tmp$`Model 2` &lt;- paste0(tmp$label2, &#39; - &#39;, tmp$Model2, &#39; - &#39;, tmp$Discovery2)

tmp$`Percentage change (R difference / Model 2 R)` &lt;- paste0(round(tmp$R_diff_perc * 100, 1), &#39;%&#39;)

tmp &lt;- tmp[, c(&#39;Target&#39;, &#39;Model 1&#39;, &#39;Model 2&#39;, &#39;Model_1_R&#39;, &#39;Model_2_R&#39;, &#39;R_diff&#39;,&quot;Percentage change (R difference / Model 2 R)&quot;, &#39;R_diff_p&#39;), with=F]
names(tmp) &lt;- c(&#39;Target&#39;,&#39;Model 1&#39;, &#39;Model 2&#39;, &quot;R (Model 1)&quot;, &quot;R (Model 2)&quot;, &quot;R difference (Model 1 R - Model 2 R)&quot;, &quot;Percentage change (R difference / Model 2 R)&quot;, &quot;R difference p-value&quot;)

tmp&lt;-tmp[order(tmp$Target, tmp$`Model 1`, tmp$`Model 2`),]
tmp$`R difference (Model 1 R - Model 2 R)` &lt;- round(tmp$`R difference (Model 1 R - Model 2 R)`, 3)
tmp$`R (Model 1)` &lt;- round(tmp$`R (Model 1)`, 3)
tmp$`R (Model 2)` &lt;- round(tmp$`R (Model 2)`, 3)

write.csv(tmp, &#39;~/oliverpainfel/Analyses/crosspop/r_diff_average.csv&#39;, row.names=F)

############

# Group differences
meta_res_comp$R_diff_catagory &lt;- cut(
    meta_res_comp$R_diff,
    breaks = c(-Inf, -0.08, -0.025, -0.002, 0.002, 0.025, 0.08, Inf),
    labels = c(&#39;&lt; -0.08&#39;, &#39;-0.08 - -0.025&#39;, &#39;-0.025 - -0.002&#39;, &#39;-0.002 - 0.002&#39;, &#39;0.002 - 0.025&#39;, &#39;0.025 - 0.08&#39;, &#39;&gt; 0.08&#39;),
    right = FALSE
)
meta_res_comp$R_diff_catagory &lt;- factor(meta_res_comp$R_diff_catagory, levels = rev(levels(meta_res_comp$R_diff_catagory)))

# Assign significance stars
meta_res_comp$indep_star&lt;-&#39; &#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 0.05]&lt;-&#39;*&#39;
meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-3]&lt;-&#39;**&#39;
# meta_res_comp$indep_star[meta_res_comp$R_diff_p &lt; 1e-6]&lt;-&#39;***&#39;

meta_res_comp&lt;-meta_res_comp[order(meta_res_comp$Discovery1, meta_res_comp$Discovery2, meta_res_comp$Method1),]

for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){

    tmp &lt;- meta_res_comp[meta_res_comp$Target == targ_pop_i, ]

    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label1&#39;
    tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method2&#39;, by.y = &#39;method&#39;, all.x = T)
    tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
    names(tmp)[names(tmp) == &#39;label&#39;] &lt;- &#39;label2&#39;
    
    tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;] &lt;- paste0(tmp$label1[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label1 != &#39;All&#39;], &#39;-multi&#39;)
    tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;] &lt;- paste0(tmp$label2[grepl(&#39;Multi&#39;, tmp$Model2) &amp; !(tmp$Method2 %in% pgs_group_methods) &amp; tmp$label2 != &#39;All&#39;], &#39;-multi&#39;)
    
    tmp$Model1[tmp$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
    tmp$Model1[tmp$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
    tmp$Model2[tmp$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
    tmp$Model2[tmp$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
    
    tmp&lt;-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
    tmp&lt;-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

    tmp$label1 &lt;- factor(tmp$label1, levels = model_order)
    tmp$label2 &lt;- factor(tmp$label2, levels = model_order)

    tmp&lt;-tmp[order(tmp$label1, tmp$label2),]
    
    tmp$label1 &lt;- paste0(tmp$label1,&quot; (&quot;, ifelse(tmp$Model1 == &#39;SumStatTrain&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)
    tmp$label2 &lt;- paste0(tmp$label2,&quot; (&quot;, ifelse(tmp$Model2 == &#39;SumStatTrain&#39;, &#39;ST&#39;, &#39;IT&#39;), &quot;)&quot;)

    tmp$label1 &lt;- factor(tmp$label1, levels = unique(tmp$label1))
    tmp$label2 &lt;- factor(tmp$label2, levels = unique(tmp$label2))
    
    tmp &lt;- tmp[tmp$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i), ]
    
    plot_tmp &lt;- ggplot(data = tmp, aes(label2, label1, fill = R_diff_catagory)) +
      geom_tile(color = &quot;white&quot;, show.legend = TRUE) +
      labs(y = &#39;Test&#39;, x = &#39;Comparison&#39;, fill = &#39;R difference&#39;, title = paste0(&#39;Target: &#39;, targ_pop_i)) +
      facet_grid(Discovery1 ~ Discovery2, scales = &#39;free&#39;, space = &#39;free&#39;, switch=&quot;both&quot;) +
      geom_text(
        data = tmp,
        aes(label2, label1, label = indep_star),
        color = &quot;black&quot;,
        size = 4,
        angle = 0,
        vjust = 0.8
      ) +
      scale_fill_brewer(
        breaks = levels(tmp$R_diff_catagory),
        palette = &quot;RdBu&quot;,
        drop = F,
        na.value = &#39;grey&#39;
      ) +
      theme_half_open() +
      background_grid() +
      panel_border() +
      theme(axis.text.x = element_text(
        angle = 45,
        vjust = 1,
        hjust = 1
      ))
    
    png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_diff.Discovery_EUR_&#39;, disc_pop_i,&#39;.Target_&#39;, targ_pop_i, &#39;.png&#39;), res=300, width = 4400, height = 3200, units = &#39;px&#39;)
      print(plot_tmp)
    dev.off()
  }
}

####
# Plot relative improvement of methods
####
# Use ptclump IndivTrain using EUR GWAS as the reference, as provides an interpretable scale

meta_res_comp_ptclump_top1&lt;-meta_res_comp[meta_res_comp$Method2 == &#39;all&#39; &amp; meta_res_comp$Source2 == &#39;Multi&#39;,]
meta_res_comp_ptclump_top1$reference_point&lt;-F
meta_res_comp_ptclump_top1$reference_point[meta_res_comp_ptclump_top1$Method1 == &#39;all&#39; &amp; meta_res_comp_ptclump_top1$Source1 == &#39;Multi&#39;]&lt;-T
meta_res_comp_ptclump_top1$R_diff[is.na(meta_res_comp_ptclump_top1$R_diff)]&lt;-0
meta_res_comp_ptclump_top1$Discovery1 &lt;- factor(meta_res_comp_ptclump_top1$Discovery1, levels=rev(levels(meta_res_comp_ptclump_top1$Discovery1)))

res_comp_all_ptclump_top1&lt;-res_comp_all[res_comp_all$Method2 == &#39;all&#39; &amp; res_comp_all$Source2 == &#39;Multi&#39;,]
res_comp_all_ptclump_top1$Discovery1 &lt;-  factor(res_comp_all_ptclump_top1$Discovery1, levels=levels(meta_res_comp_ptclump_top1$Discovery1))

# Create data to plot reference points
meta_res_comp_reference &lt;- meta_res_comp_ptclump_top1
meta_res_comp_reference$R_diff[meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
meta_res_comp_reference$R_diff_SE [meta_res_comp_ptclump_top1$reference_point == F] &lt;- NA
res_comp_all_ptclump_top1$reference_point&lt;-F

meta_tmp &lt;- meta_res_comp_ptclump_top1
meta_tmp &lt;- merge(meta_tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp$label[is.na(meta_tmp$label)] &lt;- &#39;All&#39;
meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;] &lt;- paste0(meta_tmp$label[grepl(&#39;Multi&#39;, meta_tmp$Model1) &amp; !(meta_tmp$Method1 %in% pgs_group_methods) &amp; meta_tmp$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp$label &lt;- factor(meta_tmp$label, levels = model_order)
meta_tmp$Discovery_clean &lt;- as.character(meta_tmp$Discovery1)
meta_tmp$Discovery_clean[meta_tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != &#39;EUR&#39; &amp; meta_tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp$Discovery_clean &lt;- factor(meta_tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp$Target &lt;- paste0(meta_tmp$Target, &#39; Target&#39;)
meta_tmp$Model1 &lt;- factor(meta_tmp$Model1, levels = names(model_palette))

meta_tmp_ref &lt;- meta_res_comp_reference
meta_tmp_ref &lt;- merge(meta_tmp_ref, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
meta_tmp_ref$label[is.na(meta_tmp_ref$label)] &lt;- &#39;All&#39;
meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;] &lt;- paste0(meta_tmp_ref$label[grepl(&#39;Multi&#39;, meta_tmp_ref$Model1) &amp; !(meta_tmp_ref$Method1 %in% pgs_group_methods) &amp; meta_tmp_ref$label != &#39;All&#39;], &#39;-multi&#39;)
meta_tmp_ref$label &lt;- factor(meta_tmp_ref$label, levels = model_order)
meta_tmp_ref$Discovery_clean &lt;- as.character(meta_tmp_ref$Discovery1)
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != &#39;EUR&#39; &amp; meta_tmp_ref$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
meta_tmp_ref$Discovery_clean &lt;- factor(meta_tmp_ref$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
meta_tmp_ref$Target &lt;- paste0(meta_tmp_ref$Target, &#39; Target&#39;)
meta_tmp_ref$Model1 &lt;- factor(meta_tmp_ref$Model1, levels = names(model_palette))

tmp &lt;- res_comp_all_ptclump_top1
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method1&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model1) &amp; !(tmp$Method1 %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery1)
tmp$Discovery_clean[tmp$Discovery1 == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery1 != &#39;EUR&#39; &amp; tmp$Source1 == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model1 &lt;- factor(tmp$Model1, levels = names(model_palette))

ggplot(meta_tmp, aes(x=label, y=R_diff , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff - R_diff_SE,
          ymax = R_diff + R_diff_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R_diff (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


# Plot as % change
meta_tmp$R_diff_perc &lt;- meta_tmp$R_diff / meta_tmp$Model_2_R
meta_tmp_ref$R_diff_perc &lt;- meta_tmp_ref$R_diff / meta_tmp_ref$Model_2_R
tmp$R_diff_perc &lt;- tmp$R_diff / tmp$Model_2_R

meta_tmp$R_diff_perc_SE &lt;- meta_tmp$R_diff_SE / meta_tmp$Model_2_R

library(scales)
ggplot(meta_tmp, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R diff. (SE)&quot;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# Simplify results showing results only with or without training data
meta_tmp_simple &lt;- meta_tmp
meta_tmp_simple$Model1[meta_tmp_simple$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
meta_tmp_simple$Model1[meta_tmp_simple$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
meta_tmp_simple$Model2[meta_tmp_simple$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_simple&lt;-meta_tmp_simple[meta_tmp_simple$Model_2 %in% res_eval_simp$Group,]

meta_tmp_ref_simple &lt;- meta_tmp_ref
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_2 %in% res_eval_simp$Group,]

tmp_simple &lt;- tmp
tmp_simple$Model1[tmp_simple$Model1 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp_simple$Model1[tmp_simple$Model1 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp_simple$Model2[tmp_simple$Model2 != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp_simple$Model2[tmp_simple$Model2 == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp_simple&lt;-tmp_simple[tmp_simple$Model_1 %in% res_eval_simp$Group,]
tmp_simple&lt;-tmp_simple[tmp_simple$Model_2 %in% res_eval_simp$Group,]

# Export plot for manuscript
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r.perc_improv.png&#39;, width = 3200, height = 2000, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target != &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()

# Plot for EUR
meta_tmp_simple$Discovery_clean &lt;- paste0(meta_tmp_simple$Discovery1,&#39; GWAS&#39;)
meta_tmp_ref_simple$Discovery_clean &lt;- paste0(meta_tmp_ref_simple$Discovery1,&#39; GWAS&#39;)
tmp_simple$Discovery_clean &lt;- paste0(tmp_simple$Discovery1,&#39; GWAS&#39;)

meta_tmp_simple&lt;-meta_tmp_simple[!duplicated(meta_tmp_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;), with=F]),]
meta_tmp_ref_simple&lt;-meta_tmp_ref_simple[!duplicated(meta_tmp_ref_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;), with=F]),]
tmp_simple&lt;-tmp_simple[!duplicated(tmp_simple[, c(&#39;label&#39;, &#39;Discovery_clean&#39;, &#39;Model1&#39;,&#39;pheno&#39;), with=F]),]

png(&#39;~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.perc_improv.png&#39;, width = 4000, height = 1500, res= 300, units = &#39;px&#39;)
ggplot(meta_tmp_simple[meta_tmp_simple$Target == &#39;EUR Target&#39;,], aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_simple[tmp_simple$Target == &#39;EUR Target&#39;,],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = &quot;identity&quot;,
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target == &#39;EUR Target&#39;,],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = &quot;identity&quot;,
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype=&quot;dotted&quot;) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = &quot;Relative Improvement (SE)&quot;, fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = &quot;top&quot;,
        legend.key.spacing.x = unit(2, &quot;cm&quot;),
        legend.justification = &quot;center&quot;
    )
dev.off()</code></pre>
</details>
<hr />
</div>
<div id="check-leopard-weights" class="section level3">
<h3>Check LEOPARD weights</h3>
<p>Here we will compare the LEOPARD estimated weights for population
specific PGS, to the weights estimated using observed data in the UKB
target sample.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

###
# Read in weights estimated by LEOPARD (QuickPRS)
###

leopard_weights&lt;-NULL
scores_quickprs &lt;- scores$name[scores$method == &#39;quickprs_multi&#39;]
for(i in selected_traits){
  scores_i &lt;- scores_quickprs[grepl(paste0(&#39;^&#39;, i,&#39;_&#39;), scores_quickprs)]
  for(j in scores_i){
      weights_file &lt;- readRDS(paste0(outdir, &#39;/reference/pgs_score_files/leopard/&#39;, j, &#39;/ref-&#39;, j, &#39;.weights.rds&#39;))
      weights_file &lt;- data.frame(weights_file)
      
      weights &lt;-
        data.table(
          Target = do.call(c, lapply(names(weights_file), function(x) rep(x, 2))),
          Discovery = names(weights_file),
          Weight = do.call(c, lapply(weights_file, function(x) x)),
          Trait = i,
          Method = &#39;LEOPARD&#39;
        )
      
      leopard_weights &lt;- rbind(leopard_weights, weights)
  }
}

#####
# Read in the PGS weights estimated using UKB data
#####
# Read in the final model coefficients for multi-source methods

obs_weights&lt;-NULL
for(method_i in unique(scores$method)[!(unique(scores$method) %in% pgs_group_methods)]){
  scores_method&lt;-scores$name[scores$method == method_i]
  method_i &lt;- gsub(&#39;_multi&#39;,&#39;&#39;, method_i)

  for(i in selected_traits){
    for(j in c(&#39;EAS&#39;,&#39;AFR&#39;,&#39;EUR&#39;)){
      if(j == &#39;EUR&#39;){
        pops &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
      } else {
        pops &lt;- j
      }
      
      for(k in pops){
        model &lt;- fread(paste0(&#39;~/oliverpainfel/Analyses/crosspop/targ_&#39;, j, &#39;.disc_EUR_&#39;, k, &#39;/&#39;, i, &#39;/final_models/&#39;, method_i, &#39;.pseudo.multi.final_model.txt&#39;))
        model&lt;-model[-1,]
        
        # Set weight to zero if negative, as this is what LEOPARD does
        if(any(model$V2 &lt; 0)){
          model$V2[model$V2 &lt; 0] &lt;- 0
          model$V2[model$V2 &gt; 0] &lt;- 1
        }
        
        names(model) &lt;- c(&#39;x&#39;, &#39;BETA&#39;)
        model$Discovery[grepl(&#39;UKB&#39;, model$x)]&lt;-&#39;EUR&#39;
        model$Discovery[grepl(&#39;BBJ&#39;, model$x)]&lt;-&#39;EAS&#39;
        model$Discovery[grepl(&#39;UGR&#39;, model$x)]&lt;-&#39;AFR&#39;
        model$Target &lt;- j
        model$Weight &lt;- model$BETA/sum(model$BETA)
        model$Trait &lt;- i
        model$Method &lt;- method_i
        model&lt;-model[,c(&#39;Target&#39;,&#39;Discovery&#39;,&#39;Weight&#39;,&#39;Method&#39;,&#39;Trait&#39;), with=F]
        obs_weights&lt;-rbind(obs_weights, model)
      }
    }
  }
}

###
# Combine and compare
###

both &lt;- do.call(rbind, list(obs_weights, leopard_weights))
both&lt;-merge(both, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x=T, sort = F)
both$label[is.na(both$label)] &lt;- both$Method[is.na(both$label)]
both$label &lt;- factor(both$label, levels=unique(both$label))

# Plot non-EUR target first
tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery != &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(9)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights.png&#39;, units = &#39;px&#39;, res = 300, width = 2500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(Target ~ .) +
  theme_half_open() +
  labs(title = &#39;Weight of target ancestry-matched PGS&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

# Plot EUR target
tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp &lt;- tmp[tmp$Discovery != &#39;EUR&#39;,]

# Set LEOPARD to black fill
default_colors &lt;- hue_pal()(9)
names(default_colors) &lt;- levels(tmp$label)
default_colors[&quot;LEOPARD&quot;] &lt;- &quot;black&quot;

# Plot the estimated and observed weights
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights_eur.png&#39;, units = &#39;px&#39;, res = 300, width = 2500, height = 1500)
ggplot(tmp, aes(x = Trait, y = Weight, fill = label)) +
  geom_bar(width= 0.7, position=position_dodge(0.7), stat=&quot;identity&quot;, colour = &#39;black&#39;, size = 0.1) +
  scale_fill_manual(values = default_colors) +
  facet_grid(Discovery ~ .) +
  theme_half_open() +
  labs(title = &#39;Weight of non-EUR PGS for EUR Target&#39;, fill = NULL) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
dev.off()

# Calculate correlation between weights from each method
# Start with non-EUR target
tmp &lt;- both[both$Target != &#39;EUR&#39;,]
tmp$Discovery&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Target&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))

cor_matrix_EAS &lt;- cor(tmp_wide[tmp_wide$Target == &#39;EAS&#39;, -1:-2])
cor_matrix_AFR &lt;- cor(tmp_wide[tmp_wide$Target == &#39;AFR&#39;, -1:-2])

# Convert correlation matrix to long format for ggplot
cor_df_EAS &lt;- melt(cor_matrix_EAS)
cor_df_AFR &lt;- melt(cor_matrix_AFR)
cor_df_EAS$Target &lt;- &#39;Target = EAS&#39;
cor_df_AFR$Target &lt;- &#39;Target = AFR&#39;
cor_df &lt;- rbind(cor_df_AFR, cor_df_EAS)

# Create ggplot correlation heatmap with text inside
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights_corr.png&#39;, units = &#39;px&#39;, width = 3300, height = 1700, res = 300)
ggplot(cor_df, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = &quot;white&quot;) +  # Tile plot with white borders
  geom_text(aes(label = round(value, 2)), color = &quot;black&quot;) +  # Add correlation values
  scale_fill_gradient2(low = &quot;blue&quot;, mid = &quot;white&quot;, high = &quot;red&quot;, midpoint = 0) +  # Color scale
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  facet_grid(. ~ Target) +
  labs(fill = &quot;Correlation&quot;)
dev.off()

# Start with non-EUR target
tmp &lt;- both[both$Target == &#39;EUR&#39;,]
tmp$Target&lt;-NULL
tmp_wide &lt;- reshape(tmp, 
                     idvar = c(&quot;Trait&quot;, &quot;Discovery&quot;), 
                     timevar = &quot;label&quot;, 
                     direction = &quot;wide&quot;)

names(tmp_wide) &lt;- gsub(&#39;Weight.&#39;, &#39;&#39;, names(tmp_wide))

cor_matrix_EAS &lt;- cor(tmp_wide[tmp_wide$Discovery == &#39;EAS&#39;, -1:-2])
cor_matrix_AFR &lt;- cor(tmp_wide[tmp_wide$Discovery == &#39;AFR&#39;, -1:-2])

# Convert correlation matrix to long format for ggplot
cor_df_EAS &lt;- melt(cor_matrix_EAS)
cor_df_AFR &lt;- melt(cor_matrix_AFR)
cor_df_EAS$Target &lt;- &#39;Discovery = EAS + EUR&#39;
cor_df_AFR$Target &lt;- &#39;Discovery = AFR + EUR&#39;
cor_df &lt;- rbind(cor_df_AFR, cor_df_EAS)

# Create ggplot correlation heatmap with text inside
png(&#39;~/oliverpainfel/Analyses/crosspop/plots/leopard_weights_corr_eur.png&#39;, units = &#39;px&#39;, width = 3300, height = 1700, res = 300)
ggplot(cor_df, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = &quot;white&quot;) +  # Tile plot with white borders
  geom_text(aes(label = round(value, 2)), color = &quot;black&quot;) +  # Add correlation values
  scale_fill_gradient2(low = &quot;blue&quot;, mid = &quot;white&quot;, high = &quot;red&quot;, midpoint = 0) +  # Color scale
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  facet_grid(. ~ Target) +
  labs(fill = &quot;Correlation&quot;)
dev.off()</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="computational-resoures" class="section level1">
<h1>Computational resoures</h1>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in configuration specific benchmark files
bm_files_i &lt;- list.files(paste0(outdir, &#39;/reference/benchmarks/&#39;), full.names = T)

# Subset benchmarks for pgs_methods
bm_files_i &lt;- bm_files_i[grepl(&#39;prep_pgs_|leopard_quickprs_&#39;, bm_files_i)]

# Subset to benchmarks for gwas/gwas_groups in config
scores &lt;- list_score_files(config)
bm_files_i &lt;- bm_files_i[grepl(paste0(&#39;-&#39;, unique(scores$name),&#39;.txt&#39;, collapse = &#39;|&#39;), bm_files_i)]

# Read in benchmark files
bm_dat_all &lt;- do.call(rbind, lapply(bm_files_i, function(file) {
  tmp &lt;- fread(file)
  tmp$file &lt;- basename(file)
  return(tmp)
}))

# Create rule column
bm_dat_all$rule &lt;- gsub(&#39;-.*&#39;,&#39;&#39;,bm_dat_all$file)

# Create method column
bm_dat_all$method &lt;-
  gsub(&#39;_i&#39;, &#39;&#39;, gsub(&#39;prep_pgs_&#39;, &#39;&#39;, bm_dat_all$rule))

bm_dat_all &lt;- merge(bm_dat_all, pgs_method_labels, by = &#39;method&#39;, all.x=T)

bm_dat_all$label[bm_dat_all$method == &#39;leopard_quickprs&#39;]&lt;-&quot;LEOPARD (QuickPRS)&quot;

#############
# Time
#############

# Calculate average time taken for each method
method_avg &lt;- NULL
for(i in unique(bm_dat_all$label)){
  method_avg &lt;- rbind(
    method_avg,
    data.frame(
      method = bm_dat_all$method[bm_dat_all$label == i][1],
      Method = i,
      Time = mean(bm_dat_all$s[bm_dat_all$label == i])
    )
  )
}

# Times X-Wing time by two since it used 20 cores, but other methods used 10
method_avg$Time[method_avg$method == &#39;xwing&#39;] &lt;- method_avg$Time[method_avg$method == &#39;xwing&#39;] * 2

# Divide the multi-source methods (PRS-CSx and X-Wing by 2 so it is time per GWAS)
method_avg$Time[method_avg$method %in% c(&#39;prscsx&#39;,&#39;xwing&#39;,&#39;leopard_quickprs&#39;)] &lt;- method_avg$Time[ method_avg$method %in% c(&#39;prscsx&#39;,&#39;xwing&#39;,&#39;leopard_quickprs&#39;)] / 2

# Approximate times for either tuning or grid only
method_avg$Model &lt;- &#39;Full&#39;

tmp &lt;- method_avg[method_avg$method == &#39;prscs&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;auto&#39;
tmp$Time &lt;- tmp$Time * (1/5)
method_avg&lt;-rbind(method_avg, tmp)

tmp &lt;- method_avg[method_avg$method == &#39;prscsx&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;auto&#39;
tmp$Time &lt;- tmp$Time * (1/5)
method_avg&lt;-rbind(method_avg, tmp)

tmp &lt;- method_avg[method_avg$method == &#39;xwing&#39; &amp; method_avg$Model == &#39;Full&#39;,] 
tmp$Model &lt;- &#39;grid&#39;
tmp$Time &lt;- tmp$Time * (2/10)
method_avg&lt;-rbind(method_avg, tmp)

# Format the time taken nicely
method_avg$Time_clean[method_avg$Time &lt; 60] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &lt; 60], 1), &#39; sec&#39;)
method_avg$Time_clean[method_avg$Time &gt; 60] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &gt; 60] / 60, 1), &#39; min&#39;)
method_avg$Time_clean[method_avg$Time &gt; 3600] &lt;-
  paste0(round(method_avg$Time[method_avg$Time &gt; 3600] / 60 / 60, 1), &#39; hr&#39;)

# Convert time in seconds to hours
method_avg$Time_hour &lt;- method_avg$Time / 60/60

# Seperate methods by single or multi source
method_avg$Type[!(method_avg$method %in% pgs_group_methods)]&lt;-&#39;Single-source&#39;
method_avg$Type[method_avg$method %in% pgs_group_methods]&lt;-&#39;Multi-source&#39;
method_avg$Type[method_avg$method == &#39;leopard_quickprs&#39;]&lt;-&#39;Tuning&#39;

method_avg$Type&lt;-factor(method_avg$Type, levels = c(&#39;Single-source&#39;,&#39;Multi-source&#39;,&#39;Tuning&#39;))
method_avg$Method &lt;- factor(method_avg$Method, levels = c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;QuickPRS-Multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;,&quot;LEOPARD (QuickPRS)&quot;))

ggplot(method_avg, aes(x = Method, y = Time_hour, fill = Model)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Time_clean), vjust = 0.5, angle = 90, hjust = -0.2, position = position_dodge(width = 0.9)) +
  labs(x = NULL, y = &quot;Time (hours)&quot;) +
  ylim(0, max(method_avg$Time_hour) + (max(method_avg$Time_hour)/5)) +
  facet_grid(~ Type, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
  theme_half_open() +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
  panel_border() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

method_avg &lt;- method_avg[method_avg$Model == &#39;Full&#39;,]
method_avg &lt;- method_avg[, c(&#39;Method&#39;,&#39;Time_hour&#39;)]
method_avg$Time_hour &lt;- round(method_avg$Time_hour, 2)
names(method_avg)&lt;-c(&#39;Method&#39;,&quot;Time (hrs)&quot;)

#############
# Memory
#############

# Calculate average max_rss for each method
method_avg_mem &lt;- NULL
for(i in unique(bm_dat_all$label)){
  method_avg_mem &lt;- rbind(
    method_avg_mem,
    data.frame(
      method = bm_dat_all$method[bm_dat_all$label == i][1],
      Method = i,
      Memory = mean(bm_dat_all$max_rss[bm_dat_all$label == i])
    )
  )
}

# Divide X-Wing memory by two, since it used 20 cores, but other methods used 10
method_avg_mem$Memory[method_avg_mem$method == &#39;xwing&#39;] /2

# Format the Memory nicely
method_avg_mem$Memory_clean &lt;-
  paste0(round(method_avg_mem$Memory/1000, 2), &#39; Gb&#39;)

ggplot(method_avg_mem, aes(x = Method, y = Memory, fill = Method)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Memory_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = &quot;PGS Method&quot;, y = &quot;Memory (Mb)&quot;) +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position=&quot;none&quot;)

method_avg_mem$Memory_gb &lt;- method_avg_mem$Memory/1000
method_avg_mem &lt;- method_avg_mem[, c(&#39;Method&#39;,&#39;Memory_gb&#39;)]
method_avg_mem$Memory_gb &lt;- round(method_avg_mem$Memory_gb, 2)
names(method_avg_mem)&lt;-c(&#39;Method&#39;,&quot;Memory (Gb)&quot;)

method_avg&lt;-merge(method_avg, method_avg_mem, by = &#39;Method&#39;)

write.csv(method_avg, &#39;~/oliverpainfel/Analyses/crosspop/time_memory.csv&#39;, row.names=F)</code></pre>
</details>
<hr />
</div>
<div id="sensitivity-analysis-using-1kg-reference"
class="section level1">
<h1>Sensitivity analysis using 1KG reference</h1>
<p>PRS-CS, PRS-CSx and X-Wing all use the 1KG reference sample, whereas
the other methods are using the 1KG+HGDP reference sample. We should
check whether this difference is impacting our conclusions.</p>
<hr />
<div id="subset-afr-and-eas-individuals-in-ukb-data"
class="section level2">
<h2>Subset AFR and EAS individuals in UKB data</h2>
<p>To make this quicker, focus on evaluating the PGS methods in the AFR
and EAS target individuals in UKB. This will avoid reprocessing the full
UKB data.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

keep &lt;- NULL
for (i in c(&#39;AFR&#39;, &#39;EAS&#39;)) {
  keep &lt;- rbind(keep, fread(
    paste0(
      &#39;~/oliverpainfel/Data/ukb/GenoPred/output/ukb/ancestry/keep_files/model_based/&#39;,
      i,
      &#39;.keep&#39;
    )
  ))
}

write.table(
  keep,
  &#39;~/oliverpainfel/Data/ukb/afr_eas.keep&#39;,
  row.names = F,
  col.names = F,
  quote = F
)</code></pre>
<pre class="bash"><code>mkdir ~/oliverpainfel/Data/ukb/afr_eas_subset

for chr in $(seq 1 22); do
  ~/oliverpainfel/Software/plink2 \
    --pfile ~/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
    --keep ~/oliverpainfel/Data/ukb/afr_eas.keep \
    --make-pgen \
    --out ~/oliverpainfel/Data/ukb/afr_eas_subset/ukb.chr${chr}
done
</code></pre>
</details>
<hr />
</div>
<div id="create-1kg-only-genopred-reference-data"
class="section level2">
<h2>Create 1KG only GenoPred reference data</h2>
<p>Subset the 1KG+HGDP reference data to include only 1KG
individuals.</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir -p ~/oliverpainfel/Data/1kg/genopred/
cp -r ~/oliverpainfel/Data/hgdp_1kg/genopred/ref ~/oliverpainfel/Data/1kg/genopred/
rm ~/oliverpainfel/Data/1kg/genopred/ref/ref.chr*.p*</code></pre>
<pre class="r"><code>library(data.table)

ref&lt;- fread(&#39;/users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred/ref/ref.chr1.psam&#39;)
ref&lt;-ref[ref$Project == &#39;gnomAD_1kG&#39;,]

write.table(ref[,1, drop = F], &#39;~/oliverpainfel/Data/1kg/1kg.keep&#39;, col.names=F, row.names=F, quote=F)</code></pre>
<pre class="bash"><code>for chr in $(seq 1 22); do
  ~/oliverpainfel/Software/plink2 \
    --pfile ~/oliverpainfel/Data/hgdp_1kg/genopred/ref/ref.chr${chr} \
    --keep ~/oliverpainfel/Data/1kg/1kg.keep \
    --make-pgen \
    --out ~/oliverpainfel/Data/1kg/genopred/ref/ref.chr${chr}
done</code></pre>
</details>
<hr />
</div>
<div id="run-pipeline-3" class="section level2">
<h2>Run pipeline</h2>
<p>To save time, run using PGS methods that do not need pre-processed LD
matrix data (ptclump, dbslmm, megaprs, lassosum). If the results vary
from the 1KG+HGDP results, then expand to other methods (LDpred2,
SBayesRC, QuickPRS).</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only&#39;)

######
# target_list
######
target_list &lt;- data.frame(
  name=&#39;ukb&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Data/ukb/afr_eas_subset/ukb&#39;,
  type=&#39;plink2&#39;,
  indiv_report=F,
  unrel=&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt&#39;
)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&#39;, col.names=T, row.names=F, quote=F)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_1kgref&quot;,
  &quot;refdir: /users/k1806347/oliverpainfel/Data/1kg/genopred/ref&quot;,
  &quot;resdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/resdir_1kgref&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;]&quot;,
#  &quot;leopard_methods: [&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;lassosum&#39;,&#39;megaprs&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 10&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml \
  output_all -n</code></pre>
</details>
<hr />
</div>
<div id="evaluate-pgs-1" class="section level2">
<h2>Evaluate PGS</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]
  scores_i$multi &lt;- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 &lt;-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &amp;
                     !grepl(&#39;_multi$&#39;, scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl(&#39;UKB&#39;, scores_i_j_single_top1$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] &lt;- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param &lt;- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header &lt;-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols &lt;-
          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_single_top1$name[i], &#39;_&#39;, param)))
        
        system(
          paste0(
            &quot;cut -d&#39; &#39; -f &quot;, 
            paste0(score_cols, collapse=&#39;,&#39;),
            &quot; &quot;, 
            scores_i_j_single_top1$predictor[i], 
            &quot; &gt; &quot;, 
            gsub(&#39;.profiles&#39;,
                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo &lt;- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi &lt;- paste0(scores_i_j_single_pseudo$multi, &#39;.pseudo&#39;)

      scores_i_j_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
                                    scores_i_j_single_pseudo$predictor)

#      ####
#      # Make groups for multi-single-source pseudo scores
#      ####
#      
#      scores_i_j_multi_single_pseudo &lt;- scores_i_j[grepl(&#39;_multi$&#39;, scores_i_j$method),]
#
#      # Extract the pseudo score for each method and specify as a separate group
#      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
#        param &lt;- find_pseudo(
#          config = config,
#          gwas = scores_i_j_multi_single_pseudo$name[i],
#          pgs_method = scores_i_j_multi_single_pseudo$method[i],
#          target_pop = targ_pop_i
#        )
#        
#        score_header &lt;-
#          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
#        score_cols &lt;-
#          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi_single_pseudo$name[i], &#39;_&#39;, param)))
#        
#        system(
#          paste0(
#            &quot;cut -d&#39; &#39; -f &quot;, 
#            paste0(score_cols, collapse=&#39;,&#39;),
#            &quot; &quot;, 
#            scores_i_j_multi_single_pseudo$predictor[i], 
#            &quot; &gt; &quot;, 
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
#                 scores_i_j_multi_single_pseudo$predictor[i])
#          )
#        )
#      }
#      
#      scores_i_j_multi_single_pseudo$multi &lt;- paste0(scores_i_j_multi_single_pseudo$multi, &#39;.pseudo&#39;)
#
#      scores_i_j_multi_single_pseudo$predictor &lt;- gsub(&#39;.profiles&#39;, 
#                                    paste0(&#39;.&#39;, targ_pop_i, &#39;_pseudo.profiles&#39;),
#                                    scores_i_j_multi_single_pseudo$predictor)
#      
#      scores_i_j_multi_single_pseudo$top1&lt;-paste0(&#39;EUR_&#39;, disc_pop_j_2)
#
#      ####
#      # Make groups for the Multi-Source methods
#      ####
#      
#      scores_i_j_multi &lt;- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]
#
#      # Split top1 scores by target population
#      # This doesn&#39;t apply to xwing because it only has pop-specific pseudo scores
#      scores_i_j_multi_top1&lt;-NULL
#      for(i in 1:which(scores_i_j_multi$method %in% c(&#39;prscsx&#39;))){
#        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
#        
#        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
#          
#          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi&#39;), names(score_header)))
#          }
#          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst&#39;), names(score_header)))
#          }
#          
#          system(
#            paste0(
#              &quot;cut -d&#39; &#39; -f &quot;, 
#              paste0(score_cols, collapse=&#39;,&#39;),
#              &quot; &quot;, 
#              scores_i_j_multi$predictor[i], 
#              &quot; &gt; &quot;, 
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#            )
#          )
#          
#          tmp &lt;- scores_i_j_multi[i,]
#          tmp$multi &lt;- paste0(tmp$multi, &#39;.grid&#39;)
#          tmp$top1 &lt;- pop
#          tmp$predictor &lt;-
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_grid.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#          
#          scores_i_j_multi_top1 &lt;- rbind(scores_i_j_multi_top1, tmp)
#        }
#      }
#
#      # Split pop-specific pseudo scores by target population
#      scores_i_j_multi_pop_pseudo&lt;-NULL
#      for(i in 1:nrow(scores_i_j_multi)){
#        score_header&lt;-fread(scores_i_j_multi$predictor[i], nrow = 1)
#        
#        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
#          if(scores_i_j_multi$method[i] == &#39;prscsx&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_&#39;, pop, &#39;_phi_auto&#39;), names(score_header)))
#          }
#          if(scores_i_j_multi$method[i] == &#39;xwing&#39;){
#            score_cols &lt;-
#              which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_pst_&#39;, pop), names(score_header)))
#          }
#          
#          system(
#            paste0(
#              &quot;cut -d&#39; &#39; -f &quot;, 
#              paste0(score_cols, collapse=&#39;,&#39;),
#              &quot; &quot;, 
#              scores_i_j_multi$predictor[i], 
#              &quot; &gt; &quot;, 
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#            )
#          )
#          
#          tmp &lt;- scores_i_j_multi[i,]
#          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop_pseudo&#39;)
#          tmp$top1 &lt;- pop
#          tmp$predictor &lt;-
#              gsub(&#39;.profiles&#39;,
#                   paste0(&#39;.&#39;, pop, &#39;_pseudo.profiles&#39;),
#                   scores_i_j_multi$predictor[i])
#          
#          scores_i_j_multi_pop_pseudo &lt;- rbind(scores_i_j_multi_pop_pseudo, tmp)
#        }
#      }
#      
#      # Create pseudo score for multi-source methods
#      scores_i_j_multi_pseudo&lt;-NULL
#      for(i in 1:nrow(scores_i_j_multi)) {
#        param &lt;- find_pseudo(
#          config = config,
#          gwas = scores_i_j_multi$name[i],
#          pgs_method = scores_i_j_multi$method[i],
#          target_pop = targ_pop_i
#        )
#        
#        score_header &lt;-
#          fread(scores_i_j_multi$predictor[i], nrows = 1)
#        score_cols &lt;-
#          which(names(score_header) %in% c(&#39;FID&#39;, &#39;IID&#39;, paste0(scores_i_j_multi$name[i], &#39;_&#39;, param)))
#
#        system(
#          paste0(
#            &quot;cut -d&#39; &#39; -f &quot;, 
#            paste0(score_cols, collapse=&#39;,&#39;),
#            &quot; &quot;, 
#            scores_i_j_multi$predictor[i], 
#            &quot; &gt; &quot;, 
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
#                 scores_i_j_multi$predictor[i])
#          )
#        )
#        
#        tmp &lt;- scores_i_j_multi[i,]
#        tmp$multi &lt;- paste0(tmp$multi, &#39;.pseudo&#39;)
#        tmp$top1 &lt;- paste0(&#39;EUR_&#39;, disc_pop_j_2)
#        tmp$predictor &lt;-
#            gsub(&#39;.profiles&#39;,
#                 paste0(&#39;.pseudo.targ_&#39;, targ_pop_i,&#39;.profiles&#39;),
#                 scores_i_j_multi$predictor[i])
#        
#        scores_i_j_multi_pseudo &lt;- rbind(scores_i_j_multi_pseudo, tmp)
#      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo#, 
#        scores_i_j_multi_single_pseudo,
#        scores_i_j_multi_top1,
#        scores_i_j_multi_pop_pseudo,
#        scores_i_j_multi_pseudo
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;multi&#39;,&#39;top1&#39;), with=F]
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
</details>
<hr />
<div id="run-model_builder-2" class="section level3">
<h3>Run model_builder</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5&quot;
      fi
    done
  done
done
</code></pre>
</details>
<hr />
</div>
<div id="plot-results-1" class="section level3">
<h3>Plot results</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/sensitivity_1kgref/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTrain&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

res_eval_simp &lt;- NULL
for(pheno_i in selected_traits){
  tmp &lt;- res_eval[[pheno_i]]
  tmp$Trait &lt;- pheno_i
  
  # Insert nice PGS method names
  tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
  tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
  tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
  tmp$label &lt;- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTrain or IndivTrain
  tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
  tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
  tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery&#39;,&#39;Model&#39;), with=F]),]
  
  res_eval_simp &lt;- rbind(res_eval_simp, tmp)
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_1kgrefplots/average_r.png&#39;), res=300, width = 3200, height = 2000, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# The results look very similar to when using 1KG+HGDP. 

###################
# Plot a comparison between the runs using different references

# Read in results using 1KG+HGDP reference
main_results&lt;-fread(&#39;~/oliverpainfel/Analyses/crosspop/r_eval.csv&#39;)
sens_results&lt;-meta_res_eval

tmp &lt;- main_results
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
main_results &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

tmp &lt;- sens_results
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39;], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
sens_results &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

main_results&lt;-main_results[main_results$Method %in% sens_results$Method,]
main_results&lt;-main_results[main_results$Target %in% sens_results$Target,]

sens_results$Reference &lt;- &#39;1KG&#39;
main_results$Reference &lt;- &#39;1KG+HGDP&#39;

both_results &lt;- rbind(main_results, sens_results)

png(&#39;~/oliverpainfel/Analyses/crosspop/sensitivity_1kgrefplots/comparison_to_main_result.png&#39;, units = &#39;px&#39;, res = 300, width=4000, height=2500)
ggplot(both_results, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ Discovery_clean + Reference, scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="tl-prs" class="section level1">
<h1>TL-PRS</h1>
<p>Run using AFR and EAS subset in UKB to make it quicker to run. This
is the main interest when running TL-PRS anyway.</p>
<hr />
<div id="run-pipeline-4" class="section level2">
<h2>Run pipeline</h2>
<p>To save time, run using PGS methods that do not need pre-processed LD
matrix data (ptclump, dbslmm, megaprs, lassosum). If the results vary
from the 1KG+HGDP results, then expand to other methods (LDpred2,
SBayesRC, QuickPRS).</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

dir.create(&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs&#39;)

######
# config
######

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output_tlprs&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/eas_afr_only/target_list.txt&quot;,
  &quot;gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt&quot;,
  &quot;pgs_methods: [&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;tlprs_methods: [&#39;quickprs&#39;,&#39;dbslmm&#39;,&#39;ldpred2&#39;,&#39;sbayesrc&#39;]&quot;,
  &quot;cores_prep_pgs: 10&quot;,
  &quot;cores_target_pgs: 50&quot;,
  &quot;prscs_phi: [&#39;auto&#39;]&quot;,
  &quot;ldpred2_model: [&#39;auto&#39;]&quot;,
  &quot;ldpred2_inference: F&quot;,
  &quot;dbslmm_h2f: [&#39;1&#39;]&quot;,
  &quot;ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3&quot;,
  &quot;quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3&quot;,
  &quot;sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
<pre class="bash"><code>snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml \
  output_all -n</code></pre>
</details>
<hr />
</div>
<div id="create-predictor-lists-2" class="section level2">
<h2>Create predictor lists</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1

# Get a list of score files
scores &lt;- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
for(trait_i in selected_traits){
  scores_i &lt;- scores[grepl(trait_i, scores$name),]

  for(targ_pop_i in targ_pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;BBJ&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;UGR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;BBJ&#39;,&#39;UGR&#39;)
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == &#39;BBJ&#39;){
        disc_pop_j_2 &lt;- &#39;EAS&#39;
      }
      if(disc_pop_j == &#39;UGR&#39;){
        disc_pop_j_2 &lt;- &#39;AFR&#39;
      }

      dir.create(
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j &lt;- scores_i[
        (grepl(&#39;UKB$&#39;, scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, &#39;$&#39;), scores_i$name, ignore.case = T)),]

      scores_i_j$predictor &lt;- paste0(
        outdir,
        &#39;/ukb/pgs/TRANS/&#39;,
        scores_i_j$method,
        &#39;/&#39;,
        scores_i_j$name,
        &#39;/ukb-&#39;,
        scores_i_j$name,
        &#39;-TRANS.profiles&#39;
      )
      
      #####
      # List single-source PGS
      #####
      # These are actually pseudoval scores (as per the config)
      scores_i_j_single &lt;- scores_i_j[!grepl(&#39;tlprs&#39;, scores_i_j$method),]
      
      scores_i_j_single$top1[grepl(&#39;UKB&#39;, scores_i_j_single$name, ignore.case = F)] &lt;- &#39;EUR&#39;
      scores_i_j_single$top1[grepl(disc_pop_j, scores_i_j_single$name, ignore.case = F)] &lt;- disc_pop_j_2
      scores_i_j_single$multi &lt;- paste0(scores_i_j_single$method,&#39;.pseudo&#39;)
      
      #####
      # List tlprs scores (split by target population)
      #####
      scores_i_j_tlprs &lt;- scores_i_j[grepl(&#39;tlprs&#39;, scores_i_j$method),]
      scores_i_j_tlprs$multi &lt;- scores_i_j_tlprs$method
      
      scores_i_j_tlprs_pop&lt;-NULL
      for(i in 1:nrow(scores_i_j_tlprs)){
        score_header&lt;-fread(scores_i_j_tlprs$predictor[i], nrow = 1)
        
        for(pop in c(&#39;EUR&#39;, disc_pop_j_2)){
          score_cols &lt;- which(grepl(paste0(&#39;^FID$|^IID$|_targ_&#39;, pop, &#39;_&#39;), names(score_header)))

          system(
            paste0(
              &quot;cut -d&#39; &#39; -f &quot;, 
              paste0(score_cols, collapse=&#39;,&#39;),
              &quot; &quot;, 
              scores_i_j_tlprs$predictor[i], 
              &quot; &gt; &quot;, 
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.targ_&#39;, pop, &#39;.profiles&#39;),
                   scores_i_j_tlprs$predictor[i])
            )
          )
          
          tmp &lt;- scores_i_j_tlprs[i,]
          tmp$multi &lt;- paste0(tmp$multi, &#39;.pop&#39;)
          tmp$top1 &lt;- pop
          tmp$predictor &lt;-
              gsub(&#39;.profiles&#39;,
                   paste0(&#39;.targ_&#39;, pop, &#39;.profiles&#39;),
                   scores_i_j_tlprs$predictor[i])
          
          scores_i_j_tlprs_pop &lt;- rbind(scores_i_j_tlprs_pop, tmp)
        }
      }

      predictors_i&lt;- do.call(rbind, list(
        scores_i_j_single, scores_i_j_tlprs_pop
      ))
      
      predictors_i &lt;- predictors_i[, c(&#39;predictor&#39;, &#39;top1&#39;,&#39;multi&#39;), with=F]
      
      write.table(
        predictors_i,
        paste0(
          &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_&#39;,
          targ_pop_i,
          &#39;.disc_EUR_&#39;,
          disc_pop_j_2,
          &#39;/&#39;,
          trait_i,
          &#39;/predictor_list.tlprs.txt&#39;
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}</code></pre>
</details>
<hr />
</div>
<div id="run-model_builder-3" class="section level2">
<h2>Run model_builder</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EAS AFR); do
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
      targ_pop2=&quot;EUR_test&quot;
  else
      targ_pop2=$targ_pop
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EUR&quot; ]; then
    disc_pop=$(echo AFR EAS)
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;EAS&quot; ]; then
    disc_pop=&quot;EAS&quot;
  fi
  
  if [ &quot;$targ_pop&quot; == &quot;AFR&quot; ]; then
    disc_pop=&quot;AFR&quot;
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f &quot;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.tlprs.pred_comp.txt&quot; ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap=&quot;Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.tlprs.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.tlprs \
          --n_core 5&quot;
      fi
    done
  done
done</code></pre>
</details>
<hr />
</div>
<div id="plot-results-2" class="section level2">
<h2>Plot results</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)

library(data.table)
library(ggplot2)
library(cowplot)

source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Read in list of outcomes 
selected_traits&lt;-fread(&#39;/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt&#39;, header=F)$V1
info_all &lt;- fread(&#39;~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv&#39;)

# Calculate correlation between all phenotypes in each target population
cors &lt;- list()
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;,&#39;CSA&#39;,&#39;AMR&#39;)){
  if(pop_i == &#39;EUR&#39;){
    pop_i_2 &lt;- &#39;EUR_test&#39;
  } else {
    pop_i_2 &lt;- pop_i
  }
  pheno_pop_i &lt;- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/&#39;, pheno_i, &#39;.unrel.&#39;, pop_i_2, &#39;.row_number.txt&#39;))
    names(pheno_pop_i[[pheno_i]])[3] &lt;- pheno_i
  }
  
  pheno_pop_i_merged &lt;- merged_df &lt;- Reduce(function(x, y) merge(x, y, all = TRUE, by = c(&#39;FID&#39;,&#39;IID&#39;)), pheno_pop_i)

  cors_i &lt;- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use=&#39;p&#39;))
  cors[[pop_i]] &lt;- cors_i
}

# Read in results
targ_pop = c(&#39;EAS&#39;,&#39;AFR&#39;)
res_eval &lt;- list()
for(pheno_i in selected_traits){
  res_eval_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      eval_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.tlprs.pred_eval.txt&#39;
          )
        )
      eval_i$Target&lt;-targ_pop_i
      eval_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_eval_i&lt;-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_eval_i$Group)
  res_eval_i$Method&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_eval_i$Method)
  
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;top1$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   !grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-IndivTrain&#39;
  res_eval_i$Model[grepl(&#39;multi$&#39;, res_eval_i$Group) &amp;
                   grepl(&#39;pseudo&#39;, res_eval_i$Group)]&lt;-&#39;Multi-SumStatTrain&#39;
  
  res_eval_i$Model[grepl(&#39;_multi&#39;, res_eval_i$Group)]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;prscsx.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  res_eval_i$Model[res_eval_i$Group == &#39;xwing.pseudo.multi&#39;]&lt;-&#39;SumStatTrain&#39;
  
  res_eval_i$Source&lt;-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_eval_i$Method) | 
    !grepl(&#39;EUR|EAS|AFR&#39;, res_eval_i$Group), &#39;Multi&#39;, &#39;Single&#39;)
  
  res_eval_i$Discovery[grepl(&#39;EUR&#39;, res_eval_i$Group)] &lt;- &#39;EUR&#39;
  res_eval_i$Discovery[grepl(&#39;EAS&#39;, res_eval_i$Group)] &lt;- &#39;EAS&#39;
  res_eval_i$Discovery[grepl(&#39;AFR&#39;, res_eval_i$Group)] &lt;- &#39;AFR&#39;
  res_eval_i$Discovery[res_eval_i$Source == &#39;Multi&#39;] &lt;- res_eval_i$gwas_group[res_eval_i$Source == &#39;Multi&#39;]
  
  res_eval_i$Method&lt;-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model&lt;-factor(res_eval_i$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
  res_eval_i$Discovery&lt;-factor(res_eval_i$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

  # Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]
  
  # Remove pseudo model for methods that don&#39;t really have one 
  res_eval_i &lt;- res_eval_i[
    !(res_eval_i$Method %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
      res_eval_i$Model %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing, TL-*
  res_eval_i &lt;- res_eval_i[
    !((res_eval_i$Method %in%  c(&#39;prscsx&#39;, &#39;xwing&#39;) | grepl(&#39;_multi$&#39;, res_eval_i$Method)) &amp; 
      grepl(&#39;top1&#39;, res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i &lt;- res_eval_i[!duplicated(res_eval_i[, c(
    &quot;Target&quot;, &quot;Method&quot;, &quot;Model&quot;, &quot;Source&quot;, &quot;Discovery&quot;,&quot;gwas_group&quot;
  )]),]
  
  res_eval[[pheno_i]]&lt;-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order &lt;- c(&quot;DBSLMM&quot;, &quot;lassosum&quot;, &quot;LDpred2&quot;, &quot;MegaPRS&quot;, &quot;PRS-CS&quot;, &quot;pT+clump&quot;, &quot;QuickPRS&quot;, &quot;SBayesRC&quot;, &quot;DBSLMM-multi&quot;, &quot;lassosum-multi&quot;, &quot;LDpred2-multi&quot;, &quot;MegaPRS-multi&quot;, &quot;PRS-CS-multi&quot;, &quot;pT+clump-multi&quot;, &quot;QuickPRS-multi&quot;, &quot;SBayesRC-multi&quot;,&quot;TL-DBSLMM&quot;,&quot;TL-LDpred2&quot;,&quot;TL-QuickPRS&quot;,&quot;TL-SBayesRC&quot;, &quot;PRS-CSx&quot;, &quot;X-Wing&quot;, &quot;All&quot;) 

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i &lt;- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x &lt;- res_eval[[i]]
      x$pheno &lt;- names(res_eval)[i]
      x &lt;- x[x$Target == targ_pop_i]
      x &lt;- x[x$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample&lt;-&#39;A&#39;
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i &lt;- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno &lt;-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          &#39;res_evalults missing for &#39;,
          targ_pop_i,
          &#39; &#39;,
          group_i,
          &#39; &#39;,
          paste0(missing_pheno, collapse = &#39; &#39;)
        ))
      }
      
      cors_i &lt;- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i &lt;-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = &quot;BHHR&quot;,
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp &lt;- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval &lt;- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model&lt;-factor(meta_res_eval$Model, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
meta_res_eval$Discovery&lt;-factor(meta_res_eval$Discovery, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Plot average performance across phenotypes for AFR and EAS targets
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$label[is.na(tmp$label)] &lt;- &#39;All&#39;
tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39; &amp; !grepl(&#39;^tlprs_&#39;, tmp$Method)] &lt;- paste0(tmp$label[grepl(&#39;Multi&#39;, tmp$Model) &amp; !(tmp$Method %in% pgs_group_methods) &amp; tmp$label != &#39;All&#39; &amp; !grepl(&#39;^tlprs_&#39;, tmp$Method)], &#39;-multi&#39;)
tmp$label &lt;- factor(tmp$label, levels = model_order)
tmp$Discovery_clean &lt;- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == &#39;EUR&#39;] &lt;- &#39;EUR GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;] &lt;- &#39;Target-matched GWAS&#39;
tmp$Discovery_clean[tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Multi&#39;] &lt;- &#39;Both&#39;
tmp$Discovery_clean &lt;- factor(tmp$Discovery_clean, 
                              levels = c(&#39;Target-matched GWAS&#39;,
                                         &#39;EUR GWAS&#39;,
                                         &#39;Both&#39;))
tmp$Target &lt;- paste0(tmp$Target, &#39; Target&#39;)
tmp$Model[tmp$Model != &#39;SumStatTrain&#39;] &lt;- &#39;IndivTrain&#39;
tmp$Model[tmp$Model == &#39;SumStatTrain&#39;] &lt;- &#39;SumStatTrain&#39;
tmp &lt;- tmp[!duplicated(tmp[, c(&#39;label&#39;,&#39;Target&#39;,&#39;Discovery_clean&#39;,&#39;Model&#39;), with=F]),]

dir.create(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots&#39;)

# Plot unidirectional TL-PRS (as it was intended), comparing the unadjusted EUR PGS to the EUR PGS that has been adjusted according to the target-matched GWAS
tmp_tlprs_uni &lt;- tmp[grepl(&#39;tlprs&#39;, tmp$Method) &amp; !grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;, ]
tmp_tlprs_uni$Type &lt;- &#39;TL-PRS&#39;
tmp_unadj &lt;- tmp[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;, ]
tmp_unadj$Type &lt;- &#39;Original&#39;
tmp_both &lt;- rbind(tmp_unadj, tmp_tlprs_uni)
tmp_both$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp_both$label)
tmp_both$Type&lt;-factor(tmp_both$Type, levels = c(&#39;Original&#39;,&#39;TL-PRS&#39;))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/unidirectional_r.png&#39;), res=300, width = 2000, height = 1600, units = &#39;px&#39;)
ggplot(tmp_both, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

tmp_tlprs_uni &lt;- tmp[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;, ]
tmp_tlprs_uni$Type &lt;- &#39;TL-PRS&#39;
tmp_unadj &lt;- tmp[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;, ]
tmp_unadj$Type &lt;- &#39;Original&#39;
tmp_both &lt;- rbind(tmp_unadj, tmp_tlprs_uni)
tmp_both$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp_both$label)
tmp_both$Type&lt;-factor(tmp_both$Type, levels = c(&#39;Original&#39;,&#39;TL-PRS&#39;))

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/unidirectional_r.targ_EUR.png&#39;), res=300, width = 2000, height = 1600, units = &#39;px&#39;)
ggplot(tmp_both, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = &quot;top&quot;,
          legend.key.spacing.x = unit(1, &quot;cm&quot;),
          legend.justification = &quot;center&quot;)
dev.off()

# Have one column per method, but fill according to Original EUR PGS, Original matched-PGS, TL-PRS EUR Target, TL-PRS non-EUR Target, TL-PRS Multi, and Original-Multi
tmp &lt;- meta_res_eval
tmp &lt;- tmp[tmp$Target != &#39;EUR&#39;,]
tmp &lt;- merge(tmp, pgs_method_labels, by.x = &#39;Method&#39;, by.y = &#39;method&#39;, all.x = T)
tmp$Type &lt;- NA
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;pop-EUR.top1&#39;, tmp$Group)]&lt;-&quot;TL-PRS (EUR PGS tuned to target)&quot;
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; !grepl(&#39;pop-EUR.top1&#39;, tmp$Group) &amp; tmp$Source == &#39;Single&#39;]&lt;-&quot;TL-PRS (Target-matched PGS tuned to EUR)&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery == &#39;EUR&#39;]&lt;-&quot;Original (EUR PGS)&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; tmp$Discovery != &#39;EUR&#39; &amp; tmp$Source == &#39;Single&#39;]&lt;-&quot;Original (Target-matched PGS)&quot;
tmp$Type[grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;multi&#39;, tmp$Group)]&lt;-&quot;TL-PRS-multi&quot;
tmp$Type[!grepl(&#39;tlprs&#39;, tmp$Method) &amp; grepl(&#39;multi&#39;, tmp$Group)]&lt;-&quot;Original-multi&quot;
tmp &lt;- tmp[!is.na(tmp$Type),]
tmp$Type&lt;-factor(tmp$Type, levels=c(&quot;Original (EUR PGS)&quot;, &quot;Original (Target-matched PGS)&quot;, &quot;TL-PRS (EUR PGS tuned to target)&quot;, &quot;TL-PRS (Target-matched PGS tuned to EUR)&quot;, &quot;Original-multi&quot;, &quot;TL-PRS-multi&quot;))
tmp$label&lt;-gsub(&#39;TL-&#39;,&#39;&#39;,tmp$label)

png(paste0(&#39;~/oliverpainfel/Analyses/crosspop/tlprs/plots/average_r.png&#39;), res=300, width = 4000, height = 2200, units = &#39;px&#39;)
ggplot(tmp, aes(x=label, y=R , fill = Type)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat=&quot;identity&quot;, position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype=&quot;dotted&quot;) +
    labs(y = &quot;R (SE)&quot;, x=&#39;Method&#39;) +
    facet_grid(Target ~ ., scales=&#39;free&#39;, space = &#39;free_x&#39;) +
    theme_half_open() +
    background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
dev.off()

#########################
# Check significance of differences between TL-PRS and unadjusted approaches
########################

####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp&lt;-function(x){
  x_sym &lt;- x
  x_sym$Model_1 &lt;- x$Model_2
  x_sym$Model_2 &lt;- x$Model_1
  x_sym$Model_1_R &lt;- x$Model_2_R
  x_sym$Model_2_R &lt;- x$Model_1_R
  x_sym$R_diff &lt;- -x_sym$R_diff
  x_mirrored &lt;- rbind(x, x_sym)
  x_diag&lt;-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp&lt;-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c(&#39;EAS&#39;,&#39;AFR&#39;)
res_comp &lt;- list()
for(pheno_i in selected_traits){
  res_comp_i&lt;-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == &#39;EAS&#39;){
      disc_pop &lt;- &#39;EAS&#39;
    }
    if(targ_pop_i == &#39;AFR&#39;){
      disc_pop &lt;- &#39;AFR&#39;
    }
    if(targ_pop_i == &#39;EUR&#39;){
      disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
    }
    for(disc_pop_i in disc_pop){
      comp_i &lt;-
        fread(
          paste0(
            &#39;/users/k1806347/oliverpainfel/Analyses/crosspop/tlprs/&#39;,
            &#39;targ_&#39;,
            targ_pop_i,
            &#39;.disc_EUR_&#39;,
            disc_pop_i,
            &#39;/&#39;,
            pheno_i,
            &#39;/res.tlprs.pred_comp.txt&#39;
          )
        )
      comp_i&lt;-mirror_comp(comp_i)
      comp_i$Target&lt;-targ_pop_i
      comp_i$gwas_group&lt;-paste0(&#39;EUR+&#39;, disc_pop_i)
      res_comp_i&lt;-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]&lt;-res_comp_i
}

res_comp_all &lt;- do.call(rbind, lapply(names(res_comp), function(name) {
  x &lt;- res_comp[[name]]
  x$pheno &lt;- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_1)
res_comp_all$Method1&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method1)
res_comp_all$Method2&lt;-sub(&#39;\\..*&#39;,&#39;&#39;,res_comp_all$Model_2)
res_comp_all$Method2&lt;-gsub(&#39;-.*&#39;,&#39;&#39;, res_comp_all$Method2)

find_model&lt;-function(x){
  mod &lt;- x
  mod[grepl(&#39;top1$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;IndivTrain&#39;
  mod[grepl(&#39;top1$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;SumStatTrain&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; !grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-IndivTrain&#39;
  mod[grepl(&#39;multi$&#39;, x) &amp; grepl(&#39;pseudo&#39;, x)] &lt;- &#39;Multi-SumStatTrain&#39;
  mod[grepl(&#39;_multi&#39;, x)] &lt;- &#39;SumStatTrain&#39;
  mod[x == &#39;prscsx.pseudo.multi&#39;] &lt;- &#39;SumStatTrain&#39;
  mod[x == &#39;xwing.pseudo.multi&#39;] &lt;- &#39;SumStatTrain&#39;
  
  return(mod)
}

res_comp_all$Model1&lt;-find_model(res_comp_all$Model_1)
res_comp_all$Model2&lt;-find_model(res_comp_all$Model_2)

res_comp_all$Source1&lt;-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method1) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_1), &#39;Multi&#39;, &#39;Single&#39;)
res_comp_all$Source2&lt;-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl(&#39;_multi$&#39;, res_comp_all$Method2) | !grepl(&#39;AFR|EAS|EUR&#39;, res_comp_all$Model_2), &#39;Multi&#39;, &#39;Single&#39;)
  
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] &lt;- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] &lt;- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source1 == &#39;Multi&#39;]
res_comp_all$Discovery2[res_comp_all$Source2 == &#39;Multi&#39;] &lt;- res_comp_all$gwas_group[res_comp_all$Source2 == &#39;Multi&#39;]

res_comp_all$Method1&lt;-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2&lt;-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1&lt;-factor(res_comp_all$Model1, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
res_comp_all$Model2&lt;-factor(res_comp_all$Model2, levels=c(&#39;IndivTrain&#39;,&#39;SumStatTrain&#39;,&#39;Multi-IndivTrain&#39;,&#39;Multi-SumStatTrain&#39;))
res_comp_all$Discovery1&lt;-factor(res_comp_all$Discovery1, levels=rev(c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;)))
res_comp_all$Discovery2&lt;-factor(res_comp_all$Discovery2, levels=c(&#39;AFR&#39;,&#39;EAS&#39;,&#39;EUR&#39;,&#39;EUR+AFR&#39;,&#39;EUR+EAS&#39;))

# Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;quickprs&#39;,&#39;sbayesrc&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;IndivTrain&#39;,&#39;Multi-IndivTrain&#39;)),]

# Remove pseudo model for methods that don&#39;t really have one 
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method1 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model1 %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]
res_comp_all &lt;- res_comp_all[
!(res_comp_all$Method2 %in%  c(&#39;ptclump&#39;,&#39;ptclump_multi&#39;) &amp; 
  res_comp_all$Model2 %in% c(&#39;SumStatTrain&#39;,&#39;Multi-SumStatTrain&#39;)),]

# Remove top1 models for PRS-CSx
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method1) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_1)),]
res_comp_all &lt;- res_comp_all[
!(grepl(&#39;prscsx|xwing|_multi&#39;, res_comp_all$Method2) &amp; 
  grepl(&#39;top1&#39;, res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all &lt;- res_comp_all[!duplicated(res_comp_all[, c(&quot;Target&quot;, &quot;Method1&quot;, &quot;Model1&quot;, &quot;Source1&quot;, &quot;Discovery1&quot;, &quot;Method2&quot;, &quot;Model2&quot;, &quot;Source2&quot;, &quot;Discovery2&quot;,&#39;pheno&#39;)]),]

###########

library(MAd)

# Average R across phenotypes
meta_res_comp &lt;- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == &#39;EAS&#39;){
    disc_pop &lt;- &#39;EAS&#39;
  }
  if(targ_pop_i == &#39;AFR&#39;){
    disc_pop &lt;- &#39;AFR&#39;
  }
  if(targ_pop_i == &#39;EUR&#39;){
    disc_pop &lt;- c(&#39;EAS&#39;,&#39;AFR&#39;)
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i &lt;- res_comp_all[res_comp_all$Target == targ_pop_i &amp; res_comp_all$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] &lt;- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]&lt;-1-0.001
    res_comp_i$R_diff_z&lt;-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE&lt;-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample&lt;-&#39;A&#39;
    res_comp_i$Group &lt;- paste0(res_comp_i$Model_1, &#39;_vs_&#39;, res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i &lt;- res_comp_i[res_comp_i$Group == group_i,]
      cors_i &lt;- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i &lt;-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = &quot;BHHR&quot;,
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$Model_1_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$Model_2_R &lt;-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &amp;
                            meta_res_eval$Target == targ_pop_i &amp;
                            meta_res_eval$gwas_group == paste0(&#39;EUR+&#39;, disc_pop_i)]
        tmp$R_diff &lt;- meta_res_comp_i$es
        tmp$R_diff_SE &lt;- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z &lt;- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p &lt;- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp &lt;- res_comp_group_i[1,]
        tmp$pheno &lt;- NULL
        tmp$R_diff &lt;- NA
        tmp$R_diff_SE &lt;- NA
        tmp$R_diff_z &lt;- NA
        tmp$R_diff_p &lt;- NA
      }
      meta_res_comp &lt;- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc &lt;- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Compare IndivTrain SBayesRC-multi to TL-SBayesRC-multi
tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_1 == &#39;tlprs_sbayesrc.pop.multi&#39; &amp;
                    meta_res_comp$Target == &#39;AFR&#39;,]
round(min(tmp_sbayesrc$R_diff_perc)*100, 1)
tmp_sbayesrc$R_diff_p

tmp_sbayesrc &lt;- meta_res_comp[meta_res_comp$Model_2 == &#39;sbayesrc.pseudo.multi&#39; &amp; 
                                meta_res_comp$Model_1 == &#39;tlprs_sbayesrc.pop.multi&#39; &amp;
                    meta_res_comp$Target == &#39;EAS&#39;,]
round(min(tmp_sbayesrc$R_diff_perc)*100, 1)
tmp_sbayesrc$R_diff_p</code></pre>
</details>
<hr />
</div>
<div id="computational-resoures-1" class="section level2">
<h2>Computational resoures</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)
library(ggplot2)
library(cowplot)

setwd(&#39;~/oliverpainfel/Software/MyGit/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/tlprs/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Read in configuration specific benchmark files
bm_files_i &lt;- list.files(paste0(outdir, &#39;/reference/benchmarks/&#39;), full.names = T)

# Subset benchmarks for pgs_methods
bm_files_i &lt;- bm_files_i[grepl(&#39;prep_pgs_tlprs&#39;, bm_files_i)]

# Read in benchmark files
bm_dat_all &lt;- do.call(rbind, lapply(bm_files_i, function(file) {
  tmp &lt;- fread(file)
  tmp$file &lt;- basename(file)
  return(tmp)
}))

# Create rule column
bm_dat_all$rule &lt;- gsub(&#39;-.*&#39;,&#39;&#39;,bm_dat_all$file)

# Create method column
bm_dat_all$method &lt;-
  gsub(&#39;_i&#39;, &#39;&#39;, gsub(&#39;prep_pgs_&#39;, &#39;&#39;, bm_dat_all$rule))

#############
# Time
#############

# Calculate average time taken for each method
method_avg &lt;- NULL
for(i in unique(bm_dat_all$method)){
  method_avg &lt;- rbind(
    method_avg,
    data.frame(
      Method = i,
      Time = mean(bm_dat_all$s[bm_dat_all$method == i])
    )
  )
}

# Convert time in seconds to hours
method_avg$Time_hour &lt;- method_avg$Time / 60/60
method_avg$Time_hour &lt;- round(method_avg$Time_hour, 2)

#This is for bidirectional TL-PRS

#############
# Memory
#############

# Calculate average max_rss for each method
method_avg_mem &lt;- NULL
for(i in unique(bm_dat_all$method)){
  method_avg_mem &lt;- rbind(
    method_avg_mem,
    data.frame(
      Method = i,
      Memory = mean(bm_dat_all$max_rss[bm_dat_all$method == i])
    )
  )
}

# Format the Memory nicely
method_avg_mem$Memory_clean &lt;-
  paste0(round(method_avg_mem$Memory/1000, 2), &#39; Gb&#39;)

ggplot(method_avg_mem, aes(x = Method, y = Memory, fill = Method)) +
  geom_bar(stat = &quot;identity&quot;, position=&quot;dodge&quot;) +
  geom_text(aes(label = Memory_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = &quot;PGS Method&quot;, y = &quot;Memory (Mb)&quot;) +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position=&quot;none&quot;)

method_avg_mem$Memory_gb &lt;- method_avg_mem$Memory/1000
method_avg_mem &lt;- method_avg_mem[, c(&#39;Method&#39;,&#39;Memory_gb&#39;)]
method_avg_mem$Memory_gb &lt;- round(method_avg_mem$Memory_gb, 2)
names(method_avg_mem)&lt;-c(&#39;Method&#39;,&quot;Memory (Gb)&quot;)

method_avg&lt;-merge(method_avg, method_avg_mem, by = &#39;Method&#39;)

write.csv(method_avg, &#39;~/oliverpainfel/Analyses/crosspop/time_memory.csv&#39;, row.names=F)</code></pre>
</details>
</div>
</div>

<!-- footer.html -->
<hr/>

<div class="centered-container">
<div class="rounded-image-container" style="width: 500px;">
<img src="Images/logo/sponsors.png">
</div>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
