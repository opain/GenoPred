---
title: Cross-population evaluation of polygenic scores
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
    toc_depth: 2
    css: styles/styles.css
    includes:
      in_header: header.html
      after_body: footer.html

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{css, echo=F}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

***

# Introduction

European (EUR) GWAS are typically the largest in sample size, or even the only GWAS for certain outcomes. Here we will evaluate approaches for calculating polygenic scores (PGS) across populations. We will include single- and multi-source PGS methods, using EUR GWAS alone, or using EUR GWAS in combination with GWAS from other populations.

In first instance, we will use EUR individuals in UK Biobank (UKB), to derive GWAS summary statistics, and Biobank Japan GWAS. We will evaluate PGS across populations in UKB, using outcomes available in the majority of participants to ensure sufficient sample size in non-EUR populations.

***

# Derive GWAS in UKB

To avoid sample overlap between the EUR GWAS and the EUR target sample for evaluation, we will split EUR individuals in UKB into training and testing subsets. The GWAS will be performed in the training subset, and the PGS evaluation will occur in the testing subset.

***

## Perform ancestry inference in UKB

### Create target_list

<div class="shallow-break"></div>

<details><summary>Show code</summary>
<br/>

<h3>Create symlinks</h3>

We will create symlinks to the imputed genotype data for UKB. We will use the pgen format data for computationl efficiency and those restricted to MAF >= 1% and INFO >= 0.4. We are using genetic data that is not application specific, so the data doesn't need to be reprocessed for each application. Therefore we will use row number IDs for the .psam file so they can be connected to application specific data downstream.

```{bash}
mkdir -p /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks

# pgen and pvar files
for chr in $(seq 1 22);do
  for file in $(echo pgen pvar);do
    ln -s /datasets/ukbiobank/June2017/Imputed/ukb_imp_chr${chr}_v3_MAF1_INFO4.${file} /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.${file}
  done
done
```

```{r}
# Make .psam 
n = 487409
psam <- data.frame(FID = 1:487409,
                   IID = 1:487409)
names(psam)[1]<-'#FID'
write.table(psam, '/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam', col.names=T, row.names = F, quote = F)
```

```{bash}
for chr in $(seq 1 22);do
  ln -s /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/rownumber.psam /users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4.chr${chr}.psam
done
```

***

<h3>Create list of unrelated individuals</h3>

```{r}
library(ukbkings)
library(data.table)

psam<-fread('/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam')
psam$rn<-1:nrow(psam)

project_dir <- "/datasets/ukbiobank/ukb82087"
greedy_related <- "/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated"

# Create a list of unrelated individuals irrespective of a phenotype
psam_unrel_all <- psam[!(
  psam$IID %in% bio_gen_related_remove(
    project_dir = project_dir,
    greedy_related = greedy_related,
    thresh = 0.044,
    seed = 1
  )$eid
), ]

dir.create('/users/k1806347/oliverpainfel/Data/ukb/phenotypes')

write.table(psam_unrel_all$IID, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.txt', row.names=F, col.names=F, quote=F)
write.table(psam_unrel_all$rn, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt', row.names=F, col.names=F, quote=F)
```

***

<h3>Create target_list</h3>

```{bash}
mkdir -p /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic
```

```{r}
target_list <- data.frame(
  name='ukb',
  path='/users/k1806347/oliverpainfel/Data/ukb/ukb_symlinks/ukb_imp_maf1_info4',
  type='plink2',
  indiv_report=F,
  unrel='/users/k1806347/oliverpainfel/Data/ukb/phenotypes/unrelated.row_number.txt'
)

write.table(target_list, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt', col.names=T, row.names=F, quote=F)
```

</details>

***

### Create configfile

<details><summary>Show code</summary>

```{r}
# Create config file
conf <- c(
  'outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output',
  'config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml',
  'target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt'
)

write.table(conf, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml', col.names = F, row.names = F, quote = F)
```

</details>

***

### Run pipeline

<details><summary>Show code</summary>
```{bash}
cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
git describe --tags
#v2.2.2-213-g2f05853

snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/config.yaml \
  outlier_detection -n
```
</details>

***

## Collect phenotype data

We will use the same 33 quantitative traits that were used in the PRS-CSx paper (Supp Table 10). 

<details><summary>Show code</summary>
```{bash}
mkdir /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx
```

```{r}
library(ukbkings)
library(dplyr)
library(stringr)
library(data.table)

# create data.frame showing variables used by prscsx
prscsx_fields<-c('30620','30600','30610','30650','30160','21001','21002','30710','30680','4079','30150','30740','30750','30760','50','30030','30020','30780','30120','30050','30060','30040','30130','30140','30080','30010','30700','4080','30690','30860','30870','30000','30730')
prscsx_trait<-c('Alanine aminotransferase','Albumin','Alkaline phosphatase','Aspartate transaminase','Basophil','Body mass index','Body weight','C-reactive protein','Calcium','Diastolic blood pressure','Eosinophil','Glucose','HbA1c','HDL-cholesterol','Height','Hematocrit','Hemoglobin','LDL-cholesterol','Lymphocyte','Mean corpuscular hemoglobin','Mean corpuscular hemoglobin concentration','Mean corpuscular volume','Monocyte','Neutrophil','Platelet','Red blood cell','Serum creatinine','Sytolic blood pressure','Total cholesterol','Total protein','Triglycerides','White blood cell','γ-glutamyl transpeptidase')
prscsx_labels<-c('ALT','ALB','ALP','AST','BAS','BMI','BWT','CRP','Ca','DBP','EOS','GLC','HbA1c','HDL','HT','HCT','HB','LDL','LYM','MCH','MCHC','MCV','MON','NEU','PLT','RBC','CR','SBP','TC','TP','TG','WBC','GGT')

prscsx_dat<-data.frame(
  trait=prscsx_trait,
  labels=prscsx_labels,
  field=prscsx_fields
)

dir.create('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx')
write.csv(prscsx_dat, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv', row.names = F)
write.table(prscsx_labels, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt', col.names=F, row.names = F, quote=F)

# Extract outcomes from UKB (project ukb82087)
project_dir <- "/datasets/ukbiobank/ukb82087"

system('rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt')
f <- bio_field(project_dir)
f %>%
    select(field, name) %>%
    filter(str_detect(field, paste(paste0("^", prscsx_dat$field, '-'), collapse='|'))) %>%
    bio_field_add("/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt")

bio_phen(
    project_dir,
    field = "/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.txt",
    out = "/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset"
)

system("ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds")
df <- readRDS("/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_field_subset.rds")

# Take the first observation of each outcome
library(tidyr)
df_long <- df %>%
  pivot_longer(cols = names(df)[!grepl('eid', names(df))], names_to = "variable", values_to = "outcome") %>%
  drop_na(outcome)
df_long$variable<-gsub('-.*','', df_long$variable)
df_long<-df_long[!duplicated(df_long[,c('eid','variable')]),]

library(data.table)

for(i in 1:nrow(prscsx_dat)){
  tmp <- df_long[df_long$variable == prscsx_dat$field[i],]
  tmp <- data.frame(
    eid = tmp$eid,
    outcome = tmp$outcome
  )
  
  fwrite(
    tmp,
    paste0(
      '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
      prscsx_dat$label[i],
      '.txt'
    ),
    row.names = F,
    quote = F,
    na = 'NA',
    sep = '\t'
  )
}

# Read in ancestry inference results to determine sample size per population
# Use ancestry information from GenoPred
keep_files<-list.files(path = '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/', pattern = '.keep')

pop_dat<-NULL
for(i in keep_files){
  tmp<-fread(paste0('/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/pcs/within_sample/', i))
  names(tmp)<-c('FID','IID')
  tmp$POP<-gsub('.keep','', gsub('ukb.outlier_detection.','',i))
  pop_dat<-rbind(pop_dat, tmp)
}

# Update row number IDs to project specific IDs
psam<-fread('/scratch/prj/ukbiobank/recovered/ukb82087/imputed/ukb82087_imp_chr1_MAF1_INFO4_v1.psam')
psam$rn<-1:nrow(psam)
psam<-psam[,c('IID','rn'), with = F]

pop_dat$FID<-NULL
pop_dat<-merge(pop_dat, psam, by.x='IID', by.y='rn')
pop_dat<-data.frame(
  eid=pop_dat$IID.y,
  POP=pop_dat$POP
)

# Merge ancestry info with phenotype data
df_short <- dcast(df_long, eid ~ variable, value.var = "outcome")
df_short<-merge(df_short, pop_dat, by='eid')

# Remove related individuals
greedy_related <- "/scratch/prj/ukbiobank/recovered/KCL_Data/Software/tools/GreedyRelated-master-v1.2.1/GreedyRelated"
rel<-bio_gen_related_remove(
      project_dir = project_dir,
      greedy_related = greedy_related,
      keep = df_short$eid,
      thresh = 0.044,
      seed = 1
    )$eid

df_short_unrel<-df_short[!(df_short$eid %in% rel),]

n_table<-NULL
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(pop_dat$POP[!is.na(pop_dat$POP)])){
    tmp<-data.frame(
      trait=prscsx_dat$trait[i],
      labels=prscsx_dat$label[i],
      field=prscsx_dat$field[i],
      population=j,
      n=sum(!is.na(df_short[[prscsx_dat$field[i]]][df_short$POP == j])),
      n_unrel=sum(!is.na(df_short_unrel[[prscsx_dat$field[i]]][df_short_unrel$POP == j]))
    )
    n_table<-rbind(n_table, tmp)
  }
}

write.csv(n_table, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table')

# Define training subset for EUR
df_short_unrel_eur<-df_short_unrel[df_short_unrel$POP == 'EUR',]
set.seed(1)
train_size <- floor(0.8 * nrow(df_short_unrel_eur))
train_indices <- sample(seq_len(nrow(df_short_unrel_eur)), size = train_size)

df_short_unrel_eur_train<-df_short_unrel_eur[train_indices,]
df_short_unrel_eur_test<-df_short_unrel_eur[-train_indices,]

n_table_eur<-NULL
for(i in 1:nrow(prscsx_dat)){
  tmp<-data.frame(
    trait=prscsx_dat$trait[i],
    labels=prscsx_dat$label[i],
    field=prscsx_dat$field[i],
    n_train=sum(!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]])),
    n_test=sum(!is.na(df_short_unrel_eur_test[[prscsx_dat$field[i]]]))
  )
  n_table_eur<-rbind(n_table_eur, tmp)
}

write.csv(n_table_eur, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/n_table_eur')

df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_train$eid]<-'EUR_train'
df_short_unrel$POP[df_short_unrel$eid %in% df_short_unrel_eur_test$eid]<-'EUR_test'

# Output phenotype data for each population
for(i in 1:nrow(prscsx_dat)){
  for(j in unique(df_short_unrel$POP)){
    tmp<-df_short_unrel[df_short_unrel$POP == j,]
    tmp <- data.frame(
      FID = tmp$eid,
      IID = tmp$eid,
      outcome = tmp[[prscsx_dat$field[i]]]
    )
    
    fwrite(
      tmp,
      paste0(
        '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
        prscsx_dat$label[i],
        '.unrel.', j, '.txt'
      ),
      row.names = F,
      quote = F,
      na = 'NA',
      sep = '\t'
    )
    
    # Write out with row number based IDs
    pheno<-merge(tmp, psam, by='IID')
    pheno<-data.frame(
      FID=pheno$rn,
      IID=pheno$rn,
      outcome=pheno$outcome
    )
  
    fwrite(
      pheno,
      paste0(
        '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
        prscsx_dat$label[i],
        '.unrel.', j, '.row_number.txt'
      ),
      row.names = F,
      quote = F,
      na = 'NA',
      sep = '\t'
    )
  }
}

# For the EUR training GWAS, normalise and regress covariates
# Use age, sex and PCs as covariates
# Read in PC data released by UKB
qc_dat<-bio_gen_sqc(project_dir)
qc_dat<-qc_dat[,c('eid',paste0('pc',1:20))]
df_short_unrel<-merge(df_short_unrel, qc_dat, by='eid')

# Read in sex and age information
system('rm /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt')
f <- bio_field(project_dir)
f %>%
    select(field, name) %>%
    filter(str_detect(field, "^21022-0.0|^31-0.0")) %>%
    bio_field_add("/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt")

bio_phen(
    project_dir,
    field = "/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.txt",
    out = "/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset"
)

system("ls -lh /users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds")
df <- readRDS("/users/k1806347/oliverpainfel/Data/ukb/phenotypes/age_sex_field_subset.rds")
names(df)<-gsub('-.*','',names(df))
names(df)[names(df) == '31']<-'sex'
names(df)[names(df) == '21022']<-'age'
df_short_unrel<-merge(df_short_unrel, df, by='eid')

# Within each population, normalise each outcome and regress out covariates
library(RNOmni)
covs<-c(paste0('pc',1:20), 'sex', 'age')
df_short_unrel_eur_train<-df_short_unrel[df_short_unrel$POP == 'EUR_train',]
for(i in 1:nrow(prscsx_dat)){
  tmp<-df_short_unrel_eur_train[!is.na(df_short_unrel_eur_train[[prscsx_dat$field[i]]]),]
  tmp$pheno_norm<-RNOmni::RankNorm(tmp[[prscsx_dat$field[i]]])
  mod<-lm(as.formula(paste0('pheno_norm ~ ', paste(covs, collapse=' + '))), data=tmp)
  tmp$pheno_norm_resid_scale<-as.numeric(scale(resid(mod)))
  tmp<-data.frame(
    FID=tmp$eid,
    IID=tmp$eid,
    outcome=tmp$pheno_norm_resid_scale
  )
  
  fwrite(
    tmp,
    paste0(
      '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
      prscsx_dat$label[i],
      '.unrel.EUR_train.norm_resid_scale.txt'
    ),
    row.names = F,
    quote = F,
    na = 'NA',
    sep = '\t'
  )
}

# Convert to row number based IDs so it will work with UKB geno data from GenoPred
for(i in 1:nrow(prscsx_dat)){
  pheno<-fread(paste0(
      '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
      prscsx_dat$label[i],
      '.unrel.EUR_train.norm_resid_scale.txt'
    ))
  
  pheno<-merge(pheno, psam, by='IID')
  pheno<-data.frame(
    FID=pheno$rn,
    IID=pheno$rn,
    outcome=pheno$outcome
  )
  
  fwrite(
    pheno,
    paste0(
      '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/',
      prscsx_dat$label[i],
      '.unrel.EUR_train.norm_resid_scale.row_number.txt'
    ),
    row.names = F,
    quote = F,
    na = 'NA',
    sep = '\t'
  )
}

```
</details>

***

## Run GWAS

<details><summary>Show code</summary>
```{bash, eval=F, echo=T}
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  mkdir -p /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}
  for chr in $(seq 1 22); do
      sbatch -p neurohack_cpu --wrap="/users/k1806347/oliverpainfel/Software/plink2 \
        --pfile /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/ukb/geno/ukb.ref.chr${chr} \
        --pheno /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.EUR_train.norm_resid_scale.row_number.txt \
        --linear omit-ref cols=+a1freq,+ax \
        --maf 0.01 \
        --geno 0.05 \
        --out /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}"
  done
done

# Once complete, merge results across chromosomes
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  head -n 1 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr1.outcome.glm.linear > /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    for chr in $(seq 1 22); do
      tail -n +2 /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.chr${chr}.outcome.glm.linear >> /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
    done
    
    # Remove REF and ALT columns and rename AX column to A2
    cut -f 4,5 --complement /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt | awk 'BEGIN{FS=OFS="\t"} NR==1 {$5="A2"} 1' > temp.txt && mv temp.txt /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt

    gzip /users/k1806347/oliverpainfel/Data/ukb/gwas/${pheno}/ukb.eur_train.${pheno}.GW.txt
done

# Delete per chromosome files
rm /users/k1806347/oliverpainfel/Data/ukb/gwas/*/*chr*

```
</details>

***

# Download relevant BBJ sumstats

<details><summary>Show code</summary>

```{r}
# Identify wget command for relevant phenotypes
library(data.table)

# Read in BBJ GWAS info from BBJ website
bbj_gwas<-fread('~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas.csv')

# Map BBJ trait names to those used for UKB
bbj_gwas$bbj_labels <-
  gsub("\\)", '', gsub(".*\\(", '', bbj_gwas$Phenotype))
bbj_gwas$trait <- gsub(" \\(.*", '', bbj_gwas$Phenotype)

bbj_gwas$Category<-NULL
bbj_gwas$Phenotype<-NULL

# Update trait labels to match what was used in prscsx paper
bbj_gwas$trait<-gsub(' count','', bbj_gwas$trait)
bbj_gwas$trait[bbj_gwas$trait == 'G-glutamyl transpeptidase']<-'γ-glutamyl transpeptidase'

# Merge the bbj trait info with the prscsx trait info
prscsx_dat<-fread('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv')
prscsx_dat <- merge(bbj_gwas, prscsx_dat, by='trait', all=T)

write.csv(prscsx_dat, '~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv', row.names = F)

# Create column showing what label is used in the wget command
prscsx_dat$wget_label <-
  gsub('.v1.zip', '', gsub('.*hum0197.v3.BBJ.', '', prscsx_dat$wget))

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c('labels', 'wget', 'wget_label'), with=F], '~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt', col.names = F, row.names = F, quote = F)

```

```{bash}
# wget and unzip sumstats
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  url=$(awk -v var="$pheno" '$1 == var {print $2}' ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
  sbatch -p neurohack_cpu --wrap="wget -O /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip ${url}
    unzip /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip -d /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx
    rm /users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/${pheno}.zip"
done

# Delete X chromosome sumstats and rename files to be consistent with prscsx sumstat info
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
  wget_label=$(awk -v var="$pheno" '$1 == var {print $3}' ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_wget.txt)
if [ "$pheno" == "HT" ]; then
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_Height_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.HT.txt.gz
  else
    mv ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1/GWASsummary_${wget_label}_Japanese_SakaueKanai2020.auto.txt.gz ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz
  fi
  rm -r ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/hum0197.v3.BBJ.${wget_label}.v1
done

# Format so BOLT P value is used by GenoPred
for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
sbatch -p neurohack_cpu --wrap="/users/k1806347/oliverpainfel/Software/pigz/pigz -dc ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.txt.gz | awk 'BEGIN {OFS=\"\t\"} {print \$2, \$3, \$4, \$6, \$7, \$8, \$9, \$12, \$13, \$15}' | sed '1s/P_BOLT_LMM_INF/P/' | /users/k1806347/oliverpainfel/Software/pigz/pigz -c > ~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.${pheno}.reformat.txt.gz"
done

```
</details>

***

# Download relevant UGR sumstats

<details><summary>Show code</summary>

```{r}
# Identify wget command for relevant phenotypes
library(data.table)

# Read in UGR GWAS info from GWAS catalogue
ugr_gwas<-fread('~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats.csv')

# Map UGR trait names to those used for UKB
ugr_gwas$trait<-gsub(' levels','', ugr_gwas$reportedTrait)
ugr_gwas$trait<-gsub(' count','', ugr_gwas$trait)

ugr_to_prscsx <- c(
  "Aspartate aminotransferase" = "Aspartate transaminase",
  "Bilirubin" = NA,  # No direct match
  "Eosinophils" = "Eosinophil",
  "Gamma glutamyl transferase" = "γ-glutamyl transpeptidase",
  "HDL cholesterol" = "HDL-cholesterol",
  "Hemoglobin A1c" = "HbA1c",
  "Hip circumference" = NA,  # No direct match
  "LDL cholesterol" = "LDL-cholesterol",
  "Red cell distribution width" = NA,  # No direct match
  "Serum albumin" = "Albumin",
  "Serum alkaline phosphatase" = "Alkaline phosphatase",
  "Systolic blood pressure" = "Sytolic blood pressure",
  "Triglyceride" = "Triglycerides",
  "Waist circumference" = NA,  # No direct match
  "Waist-hip ratio" = NA,  # No direct match
  "Weight" = "Body weight"
)

ugr_gwas$trait <- ifelse(ugr_gwas$trait %in% names(ugr_to_prscsx),
                                   ugr_to_prscsx[ugr_gwas$trait],
                                   ugr_gwas$trait)

# Merge the ugr trait info with the prscsx trait info
prscsx_dat<-fread('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv')
prscsx_dat <- merge(ugr_gwas, prscsx_dat, by='trait')

write.csv(prscsx_dat, '~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv', row.names = F)

# Create column indicating wget command
prscsx_dat$wget<-NA
for(i in 1:nrow(prscsx_dat)){
  if(!grepl('.txt', prscsx_dat$wget[i])){
    print(i)
    Sys.sleep(2)
    log<-system(paste0('curl --max-time 10 ', gsub('http:','ftp:', prscsx_dat$summaryStatistics[i]), '/'), intern = T)
    log<-log[grepl('annotated.txt.gz|annotated.txt', log)]
    log<-gsub('.* ','', log)
    prscsx_dat$wget[i]<-paste0(prscsx_dat$summaryStatistics[i], '/', log)
  }
}
# Note this has to be run a few times due to some requests being blocked.

# Write a table showing label matching prscsx info and wget url
write.table(prscsx_dat[, c('labels', 'wget'), with=F], '~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt', col.names = F, row.names = F, quote = F)

```

```{bash}
# wget and unzip sumstats
for pheno in $(cat ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt | cut -d' ' -f 1); do
  url=$(awk -v var="$pheno" '$1 == var {print $2}' ~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_wget.txt)
  sbatch -p cpu --wrap="wget -O ~/oliverpainfel/Data/GWAS_sumstats/UGR/${pheno}.txt.gz ${url}"
done

```

```{r}
library(future.batchtools)
library(furrr)
library(data.table)
ugr_data<-fread('~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv')

plan(batchtools_slurm(resources = list(
  time = "12:00:00",
  ntasks = 2,
  mem = "10g",
  partition = "neurohack_cpu"
)))

furrr::future_map_dfr(1:nrow(ugr_data), function(i) {
  print(i)
  sumstats <- fread(paste0("~/oliverpainfel/Data/GWAS_sumstats/UGR/", ugr_data$label[i], ".txt.gz"))
  sumstats <- sumstats[, names(sumstats) %in% c("snpid", "pval_fe", "se_fe") | grepl('^beta_|^af_|^no_', names(sumstats)), with=F]

  # Extract CHR, BP, A1, A2 from snpid
  snp_split <- tstrsplit(sumstats$snpid, ":", fixed = TRUE)
  sumstats[, `:=`(CHR = snp_split[[1]], BP = snp_split[[2]], A1 = snp_split[[3]], A2 = snp_split[[4]])]

  # Set no_ and af_ to NA if beta is NA
  cohorts <- gsub('^no_','', names(sumstats)[grepl('^no_', names(sumstats))])
  for (cohort in cohorts) {
    sumstats[[paste0('no_', cohort)]][is.na(sumstats[[paste0('beta_', cohort)]])] <- NA
    sumstats[[paste0('af_', cohort)]][is.na(sumstats[[paste0('beta_', cohort)]])] <- NA
  }

  # Calculate sample size weighted average for allele frequency
  for (cohort in cohorts) {
    sumstats[[paste0('af_', cohort, '_weighted')]] <- sumstats[[paste0('af_', cohort)]] * sumstats[[paste0('no_', cohort)]]
  }
  
  # Calculate total N and frequency
  sumstats[, N := rowSums(.SD, na.rm = TRUE), .SDcols = patterns("^no_")]
  sumstats[, FREQ := rowSums(.SD, na.rm = TRUE) / N, .SDcols = patterns("weighted$")]

  # Rename columns
  setnames(sumstats, old = c('beta_fe', 'se_fe', 'pval_fe'), new = c('BETA', 'SE', 'P'))

  # Select relevant columns and remove rows with missing data
  sumstats <- sumstats[, .(CHR, BP, A1, A2, BETA, SE, P, FREQ, N)]
  sumstats <- sumstats[complete.cases(sumstats)]
  
  fwrite(sumstats, paste0("~/oliverpainfel/Data/GWAS_sumstats/UGR/", ugr_data$label[i], ".reformat.txt.gz"), sep=' ', quote=F, na='NA')
  
})

```

</details>

***

# Estimate SNP-h2, polygenicity and rG across populations

We will estimate SNP-h2 using LD-score regression, and the rG using POPCORN.
POPCORN can estimate the SNP-h2, but it will vary according to the other GWAS included due to SNP overlap.
Use the sumstats QC'd by GenoPred.
To estimate polygenicity, lets use AVENGEME based on ptclump score association results. Lets generate those using GenoPred.

***

## Prepare configuration for GenoPred

<details><summary>Show code</summary>

```{r}
######
# gwas_list
######

dir.create('/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop')

prscsx_dat<-fread('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv')

gwas_list_eur<-data.frame(
  name=paste0(prscsx_dat$labels,'_UKB'),
  path=paste0('/users/k1806347/oliverpainfel/Data/ukb/gwas/',prscsx_dat$labels,'/ukb.eur_train.',prscsx_dat$labels,'.GW.txt.gz'),
  population='EUR',
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0('"', prscsx_dat$trait, ' (UKB)"')
)

bbj_info<-fread('~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv')
bbj_info<-bbj_info[bbj_info$labels %in% prscsx_dat$labels,]

gwas_list_eas<-data.frame(
  name=paste0(bbj_info$labels,'_BBJ'),
  path=paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj.',bbj_info$labels,'.reformat.txt.gz'),
  population='EAS',
  n=as.numeric(gsub(',','',bbj_info$`No. samples`)),
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0('"', prscsx_dat$trait, ' (BBJ)"')
)

ugr_data<-fread('~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv')
ugr_data<-ugr_data[ugr_data$labels %in% prscsx_dat$labels,]

gwas_list_afr<-data.frame(
  name=paste0(ugr_data$labels,'_UGR'),
  path=paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/UGR/',ugr_data$labels,'.reformat.txt.gz'),
  population='AFR',
  n=NA,
  sampling=NA,
  prevalence=NA,
  mean=0,
  sd=1,
  label=paste0('"', ugr_data$trait, ' (UGR)"')
)
gwas_list<-do.call(rbind, list(gwas_list_eur, gwas_list_eas, gwas_list_afr))

# Create file listing phenotypes in common between AFR, EAS and EUR
pheno <- gsub('_.*', '', gwas_list$name)
pheno_intersect <- Reduce(intersect, 
                           list(
                             pheno[gwas_list$population == 'EUR'],
                             pheno[gwas_list$population == 'EAS'],
                             pheno[gwas_list$population == 'AFR']
                             )
                           )

# Restrict gwas_list to intersecting phenotypes
gwas_list<-gwas_list[pheno %in% pheno_intersect,]

write.table(gwas_list, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt', col.names = T, row.names = F, quote = F)

write.table(pheno_intersect, '/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt', col.names = F, row.names = F, quote = F)

######
# config
######

config<-c(
  "outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output",
  "config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt",
  "target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt",
  "pgs_methods: ['ptclump']",
  "cores_prep_pgs: 1",
  "cores_target_pgs: 20"
)

write.table(config, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml', col.names = F, row.names = F, quote = F)

```
</details>

***

## Run pipeline

```{bash}
snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml \
  target_pgs -n
```

***

## Reformat for LDSC and POPCORN

<details><summary>Show code</summary>
```{r}
library(data.table)
dir.create('/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats', recursive = T)
gwas_list<-fread('/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt')

for(i in 1:nrow(gwas_list)){
  if(
    file.exists(
      paste0(
        "/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/",
        gwas_list$name[i], 
        ".sumstats.gz"))){
    next    
  }
  print(i)
  gwas_file <-
    paste0(
      "/users/k1806347/oliverpainfel/Data/ukb/GenoPred/output/reference/gwas_sumstat/",
      gwas_list$name[i],
      "/",
      gwas_list$name[i],
      "-cleaned.gz"
    )
  
  gwas_header <- fread(gwas_file, nrows = 1)
  cols_index <- which(names(gwas_header) %in% c('SNP','A1','A2','BETA','SE','P','N'))
  
  system(
    paste0(
      "zcat ",
      gwas_file,
      " | cut -f ", 
      paste0(cols_index, collapse = ','),
      " | sed -e '1s/BETA/beta/'",
      " | /users/k1806347/oliverpainfel/Software/pigz/pigz -f",
      " > /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/",
      gwas_list$name[i], 
      ".sumstats.gz"
      )
    )
}
```

</details>

***

## Run LDSC

<details><summary>Show code</summary>
```{bash}
conda activate ldsc

for pop in $(echo EUR EAS AFR);do
  if [ "$pop" == "EUR" ]; then
      samp="UKB"
  fi
  if [ "$pop" == "EAS" ]; then
      samp="BBJ"
  fi
  if [ "$pop" == "AFR" ]; then
      samp="UGR"
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap="/users/k1806347/oliverpainfel/Software/ldsc/munge_sumstats.py \
     --sumstats /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}"

  done
done

for pop in $(echo EUR EAS AFR);do
  if [ "$pop" == "EUR" ]; then
      samp="UKB"
  fi
  if [ "$pop" == "EAS" ]; then
      samp="BBJ"
  fi
  if [ "$pop" == "AFR" ]; then
      samp="UGR"
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}

    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap="/users/k1806347/oliverpainfel/Software/ldsc/ldsc.py \
     --h2 /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/sumstats/${pheno}_${samp}.sumstats.gz \
     --ref-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --w-ld /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ld_scores/UKBB.${pop}.rsid \
     --out /users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/${pheno}/${pop}/res"
     
  done
done

```

</details>

***

## Calculate CSCOREs

```{bash}

# Subset the reference data into relevant populations
for pop in $(echo EUR EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
  for chr in $(seq 1 22); do
    /users/k1806347/oliverpainfel/Software/plink2 \
      --pfile /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/ref.chr${chr} \
      --keep /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/keep_files/${pop}.keep \
      --make-bed \
      --out /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr}
    done
done

conda activate /scratch/prj/oliverpainfel/recovered/.conda/envs/popcorn
for pop in $(echo EAS AFR); do
  mkdir -p /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES
  for chr in $(seq 1 22); do
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap="popcorn \
      compute \
      -v 1 \
      --bfile1 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.EUR.chr${chr} \
      --bfile2 /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp/ref.${pop}.chr${chr} \
      /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr${chr}.txt"
  done
done

for pop in $(echo EAS AFR); do
  cat /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_chr*.txt > /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt
done

rm -r /users/k1806347/oliverpainfel/Data/POPCORN/1KG/temp
rm /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_*_CSCORES/*chr*.txt
```

***

## Run POPCORN

<details><summary>Show code</summary>
```{bash}
conda activate popcorn
for pop in $(echo EAS AFR);do
  if [ "$pop" == "EAS" ]; then
      samp="BBJ"
  fi
  if [ "$pop" == "AFR" ]; then
      samp="UGR"
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
    mkdir -p /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}
    sbatch --mem 10G -n 1 -p neurohack_cpu --wrap="popcorn \
       fit -v 3 \
       --cfile /users/k1806347/oliverpainfel/Data/POPCORN/1KG/EUR_${pop}_CSCORES/scores_all.txt \
       --sfile1 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_UKB.sumstats.gz \
       --sfile2 /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/sumstats/${pheno}_${samp}.sumstats.gz \
       --gen_effect \
       /users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/${pheno}/EUR_${pop}/rG_gen_effect"
  done
done

```

</details>

***

## Plot the LDSC and POPCORN results

<details><summary>Show code</summary>

```{r}

library(data.table)
library(ggplot2)
library(cowplot)

# Read in phenotypes
pheno_intersect <- read.table('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt', header=F)$V1

# Plot the heritability estimates
h2_res <- NULL

for(pop in c('AFR','EAS', 'EUR')){
  for(pheno in pheno_intersect){
    log <-
      readLines(
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results/',
          pheno,
          '/',
          pop,
          '/res.log'
        )
      )
    
    h2 <- log[grepl('Total Observed scale h2:', log)]
    h2_est <- as.numeric(gsub(' .*','', gsub('Total Observed scale h2: ', '', h2)))
    h2_se <- as.numeric(gsub("\\)",'', gsub(".* \\(", '', h2)))
    int <- log[grepl('Intercept:', log)]
    int_est <- as.numeric(gsub(' .*','', gsub('Intercept: ', '', int)))
    int_se <- as.numeric(gsub("\\)",'', gsub(".* \\(", '', int)))
    lambda <- log[grepl('Lambda GC:', log)]
    lambda <- as.numeric(gsub('.* ','', lambda))
    
    h2_res <- rbind(
      h2_res,
      data.table(
        Population = pop,
        Phenotype = pheno,
        h2_est = h2_est,
        h2_se = h2_se,
        int_est = int_est,
        int_se = int_se,
        lambda = lambda
      )
    )
  }
}

write.csv(h2_res, '/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv', row.names = F, quote = F)

ggplot(h2_res, aes(x = Phenotype, y = h2_est, fill = Population)) +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.7) +
  geom_errorbar(aes(ymin=h2_est-h2_se, ymax=h2_est+h2_se), width=.2, position=position_dodge(width = 0.7, preserve = "single")) +
  labs(y="SNP-based Heritability (SE)") +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

# Plot rG estimates
rg_res <- NULL
for(pop in c('AFR','EAS')){
  for(pheno in h2_res$Phenotype){
    pop_res_i<-fread(paste0('/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results/', pheno, '/EUR_', pop, '/rG_gen_effect'))
    names(pop_res_i) <- c('Test','Estimate','SE','Z','P')
    pop_res_i <- pop_res_i[pop_res_i$Test == 'pge',]
    pop_res_i$Population_1 <- 'EUR'
    pop_res_i$Population_2 <- pop
    pop_res_i$Phenotype <- pheno
    rg_res <- rbind(rg_res, pop_res_i)
  }
}

rg_res$Comparison <- paste0(rg_res$Population_1, ' vs. ', rg_res$Population_2)

write.csv(rg_res, '/users/k1806347/oliverpainfel/Analyses/crosspop/popcorn/results.csv', row.names = F, quote = F)

ggplot(rg_res, aes(x = Phenotype, y = Estimate, fill = Comparison)) +
  geom_bar(stat="identity", position=position_dodge(), width = 0.7) +
  geom_errorbar(aes(ymin=Estimate-SE, ymax=Estimate+SE), width=.2, position=position_dodge(width = 0.7)) +
  labs(y="SNP-based\nGenetic Correlation (SE)") +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

```
</details>

## AVENGEME

### Create predictor lists

<details><summary>Show code</summary>

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
source('../functions/misc.R')
source_all('../functions')
library(data.table)

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

# Read in phenotypes
pheno_intersect <- read.table('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt', header=F)$V1

# Create files for EAS and AFR targets
pop <- c('EUR','EAS','AFR')
for(trait_i in pheno_intersect){
  # Make a group containing both GWAS for each single source method
  # Make a group for each multisource method
  scores_i <- scores[grepl(paste0('^', trait_i, '_'), scores$name),]
  scores_i$group <- scores_i$method
  
  for(pop_i in pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(pop_i == 'EAS'){
      samp_i <- 'BBJ'
    }
    if(pop_i == 'AFR'){
      samp_i <- 'UGR'
    }
    if(pop_i == 'EUR'){
      samp_i <- c('UKB')
    }

    dir.create(
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
        pop_i,
        '.disc_',
        pop_i,
        '/',
        trait_i
      ),
      recursive = T
    )
    
    scores_i_j <- scores_i[grepl(samp_i, scores_i$name, ignore.case = T),]
    scores_i_j$predictor <- paste0(
      outdir,
      '/ukb/pgs/TRANS/',
      scores_i_j$method,
      '/',
      scores_i_j$name,
      '/ukb-',
      scores_i_j$name,
      '-TRANS.profiles'
    )
    
    predictors_i <- scores_i_j[, c('predictor', 'group'), with=F]
    
    write.table(
      predictors_i,
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
        pop_i,
        '.disc_',
        pop_i,
        '/',
        trait_i,
        '/predictor_list.ptclump.txt'
      ),
      col.names = T,
      row.names = F,
      quote = F
    )
  }
}

```
</details>

***

### Run model_builder

<details><summary>Show code</summary>

```{bash}
cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

for pop in $(echo EUR EAS AFR); do
  if [ "$pop" == "EUR" ]; then
      pop2="EUR_test"
  else
      pop2=$pop
  fi
  
  for pheno in $(cat /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt); do
    sbatch --mem 5G -n 5 -p neurohack_cpu --wrap="Rscript ../Scripts/model_builder/model_builder.R \
      --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${pop2}.row_number.txt \
      --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/predictor_list.ptclump.txt \
      --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${pop}.disc_${pop}/${pheno}/res.ptclump \
      --n_core 5 \
      --all_model F \
      --assoc T"
  done
done

```
</details>

***

### Plot assoc results

<details><summary>Show code</summary>

```{r}
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')

library(data.table)
library(ggplot2)
library(cowplot)

source('../functions/misc.R')
source_all('../functions')

# Read in phenotypes
pheno_intersect <- read.table('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt', header=F)$V1

# Read in results
pop = c('EUR','EAS','AFR')
res_all <- NULL
for(pheno_i in pheno_intersect){
  res_i<-NULL
  for(pop_i in pop){
    assoc_i <-
      fread(
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          pop_i,
          '.disc_',
          pop_i,
          '/',
          pheno_i,
          '/res.ptclump.assoc.txt'
        )
      )
      assoc_i$Population <- pop_i
      res_i<-rbind(res_i, assoc_i)
  }
  
  res_i$Phenotype <- pheno_i
  res_all<-rbind(res_all, res_i)
}

# Extract pT variable from Predictor
res_all$pT <- gsub('e.','e-', gsub('.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.', '', res_all$Predictor))
res_all$pT <- factor(res_all$pT, levels = unique(res_all$pT))

ggplot(res_all, aes(x = Phenotype, y = BETA, fill = pT)) +
  geom_hline(yintercept = 0, colour = 'darkgrey') +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.8) +
  geom_errorbar(aes(ymin=BETA-SE, ymax=BETA+SE), width=0, position=position_dodge(width = 0.8, preserve = "single")) +
  labs(y="BETA (SE)") +
  theme_half_open() +
  background_grid() +
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y') +
  scale_fill_manual(values = colorRampPalette(c("lightblue", "darkblue"))(length(unique(res_all$pT)))) +
  facet_grid(Population ~.)

```
</details>

### Run AVENGEME

```{r}

setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')

library(data.table)
library(ggplot2)
library(cowplot)
library(avengeme)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config_all.yaml'
outdir <- read_param(config = config, param = 'outdir', return_obj = F)
gwas_list <- read_param(config = config, param = 'gwas_list', return_obj = T)

# Read in phenotypes
pheno_intersect <- read.table('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/pheno_eur_eas_afr.txt', header=F)$V1

pop = c('EUR','EAS','AFR')

mod_res_all <- NULL
for(pop_i in pop){
  for(pheno_i in pheno_intersect){
    gwas_i<-gwas_list$name[gwas_list$population == pop_i & grepl(paste0('^', pheno_i, '_'),  gwas_list$name)]
      
    res_i <-
      fread(
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          pop_i,
          '.disc_',
          pop_i,
          '/',
          pheno_i,
          '/res.ptclump.assoc.txt'
        )
      )
    
    res_i$Z <- res_i$BETA / res_i$SE
    
    res_i$pT <- as.numeric(gsub('e.','e-', gsub('.*UKB\\.0\\.|.*BBJ\\.0\\.|.*UGR\\.0\\.', '', res_i$Predictor)))

    nsnp_log <-
      read.table(
        paste0(
          outdir,
          '/reference/pgs_score_files/ptclump/',
          gwas_i,
          '/ref-',
          gwas_i,
          '.NSNP_per_pT'
        ),
        header = T
      )
    
    nsnp<-nsnp_log$NSNP[nrow(nsnp_log)]
    
    disc_N <-
      median(
        fread(
          paste0(
            outdir,
            '/reference/gwas_sumstat/',
            gwas_i,
            '/',
            gwas_i,
            '-cleaned.gz'
          ), nrows = 10000
        )$N
      )
    
    targ_N <- res_i$N[1]
    
    mod_res <- estimatePolygenicModel(
      p = res_i$Z,
      nsnp = nsnp,
      n = c(disc_N, targ_N),
      pupper = c(0, res_i$pT),
      fixvg2pi02 = T,
      alpha = 0.05
    )
    
    mod_res_all <- rbind(
      mod_res_all,
      data.frame(
        Phenotype = pheno_i,
        Population = pop_i,
        GWAS = gwas_i,
        nsnp = nsnp,
        max_r2 = max(res_i$Obs_R2),
        n_disc = disc_N,
        n_targ = targ_N,
        vg_est = mod_res$vg[1],
        vg_lowCI = mod_res$vg[2],
        vg_highCI = mod_res$vg[3],
        pi0_est = mod_res$pi0[1],
        pi0_lowCI = mod_res$pi0[2],
        pi0_highCI = mod_res$pi0[3]
      )
    )
  }
}

dir.create('/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme')
write.csv(mod_res_all, '/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv', row.names = F, quote = F)

ggplot(mod_res_all, aes(x = Phenotype, y = vg_est, fill = Population)) +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.7) +
  geom_errorbar(aes(ymin=vg_lowCI, ymax=vg_highCI), width=.2, position=position_dodge(width = 0.7, preserve = "single")) +
  labs(y="SNP-based Heritability (95%CI)") +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

ggplot(mod_res_all, aes(x = Phenotype, y = 1 - pi0_est, fill = Population)) +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.7) +
  geom_errorbar(aes(ymin=1 - pi0_lowCI, ymax=1 - pi0_highCI), width=.2, position=position_dodge(width = 0.7, preserve = "single")) +
  labs(y="Proporition non-zero\neffects (95%CI)") +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

ggplot(mod_res_all, aes(x = Phenotype, y = max_r2, fill = Population)) +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.7) +
  labs(y="Max R2") +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

# 
hist(mod_res_all$max_r2)
hist(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])
hist(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])
hist(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])
summary(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])
summary(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])

```

***

### Select GWAS for downstream analyses

```{r}
#########
# Select 10 GWAS for downstream analysis
#########
# Criteria are that SNP-h2 > 0.01 in both AVENGEME and LDSC
# Then GWAS are selected to represent a range of polygenicity and heritability, as estimated in EUR since they are most accurate

library(data.table)

# Read in the AVENGEME results
avengeme <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv')

# Read in the LDSC results
ldsc <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv')

# Combine results
both <- merge(avengeme, ldsc, by = c('Population','Phenotype'))

# Remove GWAS that have negative SNP-h2 from LDSC in any population
both_h2 <- both[!(both$Phenotype %in% both$Phenotype[both$vg_est < 0.01 | both$h2_est < 0.01]),]

# Select GWAS representing a range of SNP-h2 from LDSC, and a range of polygenicity from AVENGEME.
both_eur<-both_h2[both_h2$Population == 'EUR',]
traits_data <- data.frame(trait = both_eur$Phenotype, heritability = both_eur$vg_est, polygenicity = both_eur$pi0_est)

# Number of bins (e.g., dividing into 5 bins each for heritability and polygenicity)
num_bins <- 5

# Create bins
traits_data$her_bin <- cut(traits_data$heritability, breaks = num_bins)
traits_data$poly_bin <- cut(traits_data$polygenicity, breaks = num_bins)

# Split data by unique bin combinations
split_data <- split(traits_data, list(traits_data$her_bin, traits_data$poly_bin), drop = TRUE)

set.seed(1)
# Randomly select one trait from each bin combination
selected_traits <- do.call(rbind, lapply(split_data, function(df) df[sample(nrow(df), 1), ]))

# Limit to 10 traits if more than 10 unique combinations
if (nrow(selected_traits) > 10) {
  selected_traits <- selected_traits[sample(nrow(selected_traits), 10), ]
}

write.table(selected_traits$trait, '/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', col.names = F, row.names = F, quote = F)

# Plot max R2 for selected traits
mod_res_all <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv')
mod_res_all_selected <- mod_res_all[mod_res_all$Phenotype %in% selected_traits$trait,]

ggplot(mod_res_all_selected, aes(x = Phenotype, y = max_r2, fill = Population)) +
  geom_bar(stat="identity", position=position_dodge(preserve = "single"), width = 0.7) +
  labs(y="Max R2") +
  theme_half_open() +
  coord_cartesian(ylim = c(0, 0.15)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y')

# 
hist(mod_res_all$max_r2)
hist(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])
hist(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])
hist(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])

summary(mod_res_all$max_r2)
summary(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])
summary(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])
summary(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])

round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == 'EUR'])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == 'EAS'])), 2)
round(sqrt(min(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])), 2)
round(sqrt(max(mod_res_all$max_r2[mod_res_all$Population == 'AFR'])), 2)

```

***

# Make a descriptives table of GWAS

```{r}
library(data.table)

#####
# Trait names, labels, and URLs
#####

###
# UKB
###
ukb <- fread('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv')
names(ukb) <- c('trait', 'labels','field')
trait_labels <- ukb[, c('trait','labels'), with=F]
ukb<-ukb[, c('trait','field'), with=F]
ukb$sample <- 'UKB'
ukb$population <- 'EUR'
ukb$url<-NA

###
# BBJ
###
bbj <- fread('~/oliverpainfel/Data/GWAS_sumstats/BBJ/prscsx/bbj_gwas_prscsx.csv')
bbj <- bbj[, c('trait', 'wget'), with = F]
names(bbj) <- c('trait', 'url')
bbj$sample <- 'BBJ'
bbj$population <- 'EAS'
bbj$field <- NA

###
# UGR
###
ugr <- fread('~/oliverpainfel/Data/GWAS_sumstats/UGR/ugr_sumstats_prscsx.csv')
ugr <- ugr[, c('trait', 'summaryStatistics'), with = F]
names(ugr) <- c('trait','url')
ugr$sample <- 'UGR'
ugr$population <- 'AFR'
ugr$field <- NA

info_all <- do.call(rbind, list(ukb, bbj, ugr))
info_all<-merge(info_all, trait_labels, by='trait')

#####
# Sample size, SNP-h2 and polygenicity
#####

# Read in the AVENGEME and LDSC results
avengeme <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/avengeme/results.csv')
ldsc <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/ldsc/results.csv')
both <- merge(avengeme, ldsc, by = c('Population','Phenotype'))

# Format for descriptives table
both$h2_avengeme<- paste0(
  round(both$vg_est,2), 
  " (95%CI = ", 
  round(both$vg_lowCI, 2), 
  " - " , 
  round(both$vg_highCI, 2), ")")

both$pi0_avengeme <- paste0(
  round(both$pi0_est,2), 
  " (95%CI = ", 
  round(both$pi0_lowCI, 2), 
  " - " , 
  round(both$pi0_highCI, 2), ")")

both$h2_ldsc <- paste0(
  round(both$h2_est,2), 
  " (SE = ", 
  round(both$h2_se, 2), 
  ")")

both$int_ldsc <- paste0(
  round(both$int_est,2), 
  " (SE = ", 
  round(both$int_se, 2), 
  ")")

both<-both[, c('Population','Phenotype','n_disc','n_targ','h2_avengeme','pi0_avengeme','h2_ldsc','int_ldsc','lambda'), with = F]
names(both)[1:2]<-c('population','labels')

info_all <- merge(info_all, both, by = c('labels','population'))
info_all$n_disc<-round(info_all$n_disc, 0)
info_all$n_targ<-round(info_all$n_targ, 0)

info_all<-info_all[, c('labels','trait','population','sample','n_disc','n_targ','h2_avengeme','pi0_avengeme','h2_ldsc','int_ldsc','lambda','field','url'), with=F]
names(info_all) <- c('Trait Label', 'Trait Description', 'Ancestry', 'GWAS Sample', 'GWAS N', 'Target N',"SNP-h2 (AVENGEME)","pi0 (AVENGEME)","SNP-h2 (LDSC)","Intercept (LDSC)",'Lambda', 'UKB Field', 'URL')

# Add in column indicating whether the trait was used in downstream PGS comparison
selected_traits <- fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1

info_all$`Selected` <- info_all$`Trait Label` %in% selected_traits

write.csv(info_all, '/users/k1806347/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv', row.names=F)

# Estimate the mean and SD of sample size within each population for selected traits
info_all_selected<-info_all[info_all$Selected == T,]
n_dat <- NULL
for(i in unique(info_all_selected$`GWAS Sample`)){
  n_dat <-rbind(
    n_dat,
    data.table(
      sample = i,
      gwas_n_median = round(median(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_mean = round(mean(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      gwas_n_sd = round(sd(info_all_selected$`GWAS N`[info_all_selected$`GWAS Sample` == i])),
      target_n_median = round(median(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_mean = round(mean(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i])),
      target_n_sd = round(sd(info_all_selected$`Target N`[info_all_selected$`GWAS Sample` == i]))
    )
  )
}

```

***

# Run GenoPred

## Prepare configuration for GenoPred

<details><summary>Show code</summary>

```{r}
######
# gwas_list
######
library(data.table)
# Subset original gwas_list to include selected traits
gwas_list<-fread('/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list_all.txt')
pheno<-gsub('_.*','', gwas_list$name)
selected_traits<-fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1
gwas_list<-gwas_list[pheno %in% selected_traits,]
gwas_list$label<-paste0('"', gwas_list$label, '"')

write.table(gwas_list, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt', col.names = T, row.names = F, quote = F)

######
# gwas_groups
######

gwas_groups_eas<-data.frame(
  name=paste0(selected_traits, '_UKB_BBJ'),
  gwas=sapply(selected_traits, function(x) paste0(x,'_UKB,',x,'_BBJ')),
  label=paste0('"', selected_traits, " (UKB+BBJ)", '"')
)

gwas_groups_afr<-data.frame(
  name=paste0(selected_traits, '_UKB_UGR'),
  gwas=sapply(selected_traits, function(x) paste0(x,'_UKB,',x,'_UGR')),
  label=paste0('"', selected_traits, " (UKB+UGR)", '"')
)

gwas_groups<-rbind(gwas_groups_eas, gwas_groups_afr)

write.table(gwas_groups, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt', col.names = T, row.names = F, quote = F)

######
# config
######

config<-c(
  "outdir: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/output",
  "config_file: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_list.txt",
  "target_list: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/basic/target_list.txt",
  "gwas_groups: /users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/gwas_groups.txt",
  "pgs_methods: ['ptclump','quickprs','quickprs_multi','dbslmm','lassosum','megaprs','prscs','ldpred2','sbayesrc','prscsx','xwing']",
#  "tlprs_methods: ['dbslmm','prscs','lassosum']",
  "leopard_methods: ['ptclump','quickprs','dbslmm','lassosum','megaprs','prscs','ldpred2','sbayesrc']",
  "cores_prep_pgs: 10", # xwing run with 20 cores
  "cores_target_pgs: 50",
  "ldpred2_inference: F",
  "ldpred2_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/ldpred2/hm3",
  "quickprs_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3",
  "quickprs_multi_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/quickprs/hm3_subset",
  "sbayesrc_ldref: /users/k1806347/oliverpainfel/Data/hgdp_1kg/sbayesrc/hm3"
)

write.table(config, '/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml', col.names = F, row.names = F, quote = F)

```
</details>

***

## Run pipeline

```{bash}
snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml \
  prep_pgs  -n
```

***

# Evaluate PGS

Lets use the model builder script which implements nested 10 fold cross validation. Similar set up to previous paper, evaluating a model containing the best PGS selected by 10-fold cross validation, a model containing the PGS selected by pseudovalidation (if available), and an elastic net model containing all PGS from a given method. We will need to update the model builder script to achieve this

***

## Compare all methods

We want to see:
- Performance of pseudo and top1 models for single-source methods
- Performance of pseudo and top1 models for multi-source methods
- Performance of multi-source methods:
  - Using crossval for tuning step 1 and 2
  - Using pseudoval for tuning step 1 and 2
  - Using pseudoval for tuning step 1 and crossval for tuning step 2

To achieve this. Will need to define groups of predictors for step 1 modelling, and groups that should then be linearly combined.

***

### Create predictor lists

<details><summary>Show code</summary>

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
source('../functions/misc.R')
source_all('../functions')
library(data.table)

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Read in list of outcomes 
selected_traits<-fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1

# Get a list of score files
scores <- list_score_files(config)

# Create files for EAS and AFR targets
targ_pop <- c('EUR','EAS','AFR')
for(trait_i in selected_traits){
  scores_i <- scores[grepl(trait_i, scores$name),]
  scores_i$multi <- scores_i$method
  
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'BBJ'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'UGR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('BBJ','UGR')
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == 'BBJ'){
        disc_pop_j_2 <- 'EAS'
      }
      if(disc_pop_j == 'UGR'){
        disc_pop_j_2 <- 'AFR'
      }

      dir.create(
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          targ_pop_i,
          '.disc_EUR_',
          disc_pop_j_2,
          '/',
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j <- scores_i[
        (grepl('UKB$', scores_i$name, ignore.case = F) | 
         grepl(paste0(disc_pop_j, '$'), scores_i$name, ignore.case = T)),]

      # Insert path to score file
      scores_i_j$predictor <- paste0(
        outdir,
        '/ukb/pgs/TRANS/',
        scores_i_j$method,
        '/',
        scores_i_j$name,
        '/ukb-',
        scores_i_j$name,
        '-TRANS.profiles'
      )
      
      ####
      # Make groups single source methods
      ####
      
      scores_i_j_single_top1 <-
        scores_i_j[!(scores_i_j$method %in% pgs_group_methods) &
                     !grepl('_multi$', scores_i_j$method), ]

      # Create top1 column indicating which predictors top1 models should be derived
      scores_i_j_single_top1$top1[grepl('UKB', scores_i_j_single_top1$name, ignore.case = F)] <- 'EUR'
      scores_i_j_single_top1$top1[grepl(disc_pop_j, scores_i_j_single_top1$name, ignore.case = F)] <- disc_pop_j_2
      
      ####
      # Make groups containing pseudo scores for single source methods
      ####

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_single_top1)) {
        param <- find_pseudo(
          config = config,
          gwas = scores_i_j_single_top1$name[i],
          pgs_method = scores_i_j_single_top1$method[i],
          target_pop = targ_pop_i
        )
        
        score_header <-
          fread(scores_i_j_single_top1$predictor[i], nrows = 1)
        score_cols <-
          which(names(score_header) %in% c('FID', 'IID', paste0(scores_i_j_single_top1$name[i], '_', param)))
        
        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols, collapse=','),
            " ", 
            scores_i_j_single_top1$predictor[i], 
            " > ", 
            gsub('.profiles',
                 paste0('.', targ_pop_i, '_pseudo.profiles'),
                 scores_i_j_single_top1$predictor[i])
          )
        )
      }
      
      scores_i_j_single_pseudo <- scores_i_j_single_top1
      scores_i_j_single_pseudo$multi <- paste0(scores_i_j_single_pseudo$multi, '.pseudo')

      scores_i_j_single_pseudo$predictor <- gsub('.profiles', 
                                    paste0('.', targ_pop_i, '_pseudo.profiles'),
                                    scores_i_j_single_pseudo$predictor)

      ####
      # Make groups for multi-single-source pseudo scores
      ####
      
      scores_i_j_multi_single_pseudo <- scores_i_j[grepl('_multi$', scores_i_j$method),]

      # Extract the pseudo score for each method and specify as a separate group
      for(i in 1:nrow(scores_i_j_multi_single_pseudo)) {
        param <- find_pseudo(
          config = config,
          gwas = scores_i_j_multi_single_pseudo$name[i],
          pgs_method = scores_i_j_multi_single_pseudo$method[i],
          target_pop = targ_pop_i
        )
        
        score_header <-
          fread(scores_i_j_multi_single_pseudo$predictor[i], nrows = 1)
        score_cols <-
          which(names(score_header) %in% c('FID', 'IID', paste0(scores_i_j_multi_single_pseudo$name[i], '_', param)))
        
        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols, collapse=','),
            " ", 
            scores_i_j_multi_single_pseudo$predictor[i], 
            " > ", 
            gsub('.profiles',
                 paste0('.', targ_pop_i, '_pseudo.profiles'),
                 scores_i_j_multi_single_pseudo$predictor[i])
          )
        )
      }
      
      scores_i_j_multi_single_pseudo$multi <- paste0(scores_i_j_multi_single_pseudo$multi, '.pseudo')

      scores_i_j_multi_single_pseudo$predictor <- gsub('.profiles', 
                                    paste0('.', targ_pop_i, '_pseudo.profiles'),
                                    scores_i_j_multi_single_pseudo$predictor)
      
      scores_i_j_multi_single_pseudo$top1<-paste0('EUR_', disc_pop_j_2)

      ####
      # Make groups for the Multi-Source methods
      ####
      
      scores_i_j_multi <- scores_i_j[(scores_i_j$method %in% pgs_group_methods),]

      # Split top1 scores by target population
      # This doesn't apply to xwing because it only has pop-specific pseudo scores
      scores_i_j_multi_top1<-NULL
      for(i in 1:which(scores_i_j_multi$method %in% c('prscsx'))){
        score_header<-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c('EUR', disc_pop_j_2)){
          
          if(scores_i_j_multi$method[i] == 'prscsx'){
            score_cols <-
              which(grepl(paste0('^FID$|^IID$|_', pop, '_phi'), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == 'xwing'){
            score_cols <-
              which(grepl(paste0('^FID$|^IID$|_targ_', pop, '_pst'), names(score_header)))
          }
          
          system(
            paste0(
              "cut -d' ' -f ", 
              paste0(score_cols, collapse=','),
              " ", 
              scores_i_j_multi$predictor[i], 
              " > ", 
              gsub('.profiles',
                   paste0('.', pop, '_grid.profiles'),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp <- scores_i_j_multi[i,]
          tmp$multi <- paste0(tmp$multi, '.grid')
          tmp$top1 <- pop
          tmp$predictor <-
              gsub('.profiles',
                   paste0('.', pop, '_grid.profiles'),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_top1 <- rbind(scores_i_j_multi_top1, tmp)
        }
      }

      # Split pop-specific pseudo scores by target population
      scores_i_j_multi_pop_pseudo<-NULL
      for(i in 1:nrow(scores_i_j_multi)){
        score_header<-fread(scores_i_j_multi$predictor[i], nrow = 1)
        
        for(pop in c('EUR', disc_pop_j_2)){
          if(scores_i_j_multi$method[i] == 'prscsx'){
            score_cols <-
              which(grepl(paste0('^FID$|^IID$|_', pop, '_phi_auto'), names(score_header)))
          }
          if(scores_i_j_multi$method[i] == 'xwing'){
            score_cols <-
              which(grepl(paste0('^FID$|^IID$|_targ_', pop, '_pst_', pop), names(score_header)))
          }
          
          system(
            paste0(
              "cut -d' ' -f ", 
              paste0(score_cols, collapse=','),
              " ", 
              scores_i_j_multi$predictor[i], 
              " > ", 
              gsub('.profiles',
                   paste0('.', pop, '_pseudo.profiles'),
                   scores_i_j_multi$predictor[i])
            )
          )
          
          tmp <- scores_i_j_multi[i,]
          tmp$multi <- paste0(tmp$multi, '.pop_pseudo')
          tmp$top1 <- pop
          tmp$predictor <-
              gsub('.profiles',
                   paste0('.', pop, '_pseudo.profiles'),
                   scores_i_j_multi$predictor[i])
          
          scores_i_j_multi_pop_pseudo <- rbind(scores_i_j_multi_pop_pseudo, tmp)
        }
      }
      
      # Create pseudo score for multi-source methods
      scores_i_j_multi_pseudo<-NULL
      for(i in 1:nrow(scores_i_j_multi)) {
        param <- find_pseudo(
          config = config,
          gwas = scores_i_j_multi$name[i],
          pgs_method = scores_i_j_multi$method[i],
          target_pop = targ_pop_i
        )
        
        score_header <-
          fread(scores_i_j_multi$predictor[i], nrows = 1)
        score_cols <-
          which(names(score_header) %in% c('FID', 'IID', paste0(scores_i_j_multi$name[i], '_', param)))

        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols, collapse=','),
            " ", 
            scores_i_j_multi$predictor[i], 
            " > ", 
            gsub('.profiles',
                 paste0('.pseudo.targ_', targ_pop_i,'.profiles'),
                 scores_i_j_multi$predictor[i])
          )
        )
        
        tmp <- scores_i_j_multi[i,]
        tmp$multi <- paste0(tmp$multi, '.pseudo')
        tmp$top1 <- paste0('EUR_', disc_pop_j_2)
        tmp$predictor <-
            gsub('.profiles',
                 paste0('.pseudo.targ_', targ_pop_i,'.profiles'),
                 scores_i_j_multi$predictor[i])
        
        scores_i_j_multi_pseudo <- rbind(scores_i_j_multi_pseudo, tmp)
      }
      
      ####
      # Combine the different predictor groups
      ####
      predictors_i<- do.call(rbind, list(
        scores_i_j_single_top1, 
        scores_i_j_single_pseudo, 
        scores_i_j_multi_single_pseudo,
        scores_i_j_multi_top1,
        scores_i_j_multi_pop_pseudo,
        scores_i_j_multi_pseudo
      ))
      
      predictors_i <- predictors_i[, c('predictor', 'multi','top1'), with=F]
      
      ####
      # Make a group that will combined all population specific PGS
      ####
      
      predictors_i_all <- predictors_i[predictors_i$top1 %in% c('EUR','AFR','EAS'),]
      predictors_i_all$multi <- 'all'
      predictors_i<-rbind(predictors_i, predictors_i_all)
      
      write.table(
        predictors_i,
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          targ_pop_i,
          '.disc_EUR_',
          disc_pop_j_2,
          '/',
          trait_i,
          '/predictor_list.txt'
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}

```
</details>

***

### Run model_builder

<details><summary>Show code</summary>

```{bash}
cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

#rm /users/k1806347/oliverpainfel/Analyses/crosspop/targ_*.disc_EUR_*/*/res*

for targ_pop in $(echo EUR EAS AFR); do
  if [ "$targ_pop" == "EUR" ]; then
      targ_pop2="EUR_test"
  else
      targ_pop2=$targ_pop
  fi
  
  if [ "$targ_pop" == "EUR" ]; then
    disc_pop=$(echo EAS AFR)
  fi
  
  if [ "$targ_pop" == "EAS" ]; then
    disc_pop="EAS"
  fi
  
  if [ "$targ_pop" == "AFR" ]; then
    disc_pop="AFR"
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(cat /users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt); do
      if [ ! -f "/users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.pred_comp.txt" ]; then
        sbatch --mem 10G -n 5 -p neurohack_cpu,interruptible_cpu -t 1:00:00 --wrap="Rscript ../Scripts/model_builder/model_builder_top1.R \
          --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
          --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.txt \
          --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res \
          --n_core 5"
      fi
    done
  done
done

```
</details>

***

### Plot results

<details><summary>Show code</summary>

```{r}
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')

library(data.table)
library(ggplot2)
library(cowplot)

source('../functions/misc.R')
source_all('../functions')

# Read in list of outcomes 
selected_traits<-fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1
info_all <- fread('~/oliverpainfel/Analyses/crosspop/gwas_descriptives.csv')

# Calculate correlation between all phenotypes in each target population
cors <- list()
for(pop_i in c('EUR','EAS','AFR','CSA','AMR')){
  if(pop_i == 'EUR'){
    pop_i_2 <- 'EUR_test'
  } else {
    pop_i_2 <- pop_i
  }
  pheno_pop_i <- list()
  for(pheno_i in selected_traits){
    pheno_pop_i[[pheno_i]] <- fread(paste0('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/', pheno_i, '.unrel.', pop_i_2, '.row_number.txt'))
    names(pheno_pop_i[[pheno_i]])[3] <- pheno_i
  }
  
  pheno_pop_i_merged <- merged_df <- Reduce(function(x, y) merge(x, y, all = TRUE, by = c('FID','IID')), pheno_pop_i)

  cors_i <- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use='p'))
  cors[[pop_i]] <- cors_i
}

# Read in results
targ_pop = c('EUR','EAS','AFR')
res_eval <- list()
for(pheno_i in selected_traits){
  res_eval_i<-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'EAS'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'AFR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('EAS','AFR')
    }
    for(disc_pop_i in disc_pop){
      eval_i <-
        fread(
          paste0(
            '/users/k1806347/oliverpainfel/Analyses/crosspop/',
            'targ_',
            targ_pop_i,
            '.disc_EUR_',
            disc_pop_i,
            '/',
            pheno_i,
            '/res.pred_eval.txt'
          )
        )
      eval_i$Target<-targ_pop_i
      eval_i$gwas_group<-paste0('EUR+', disc_pop_i)
      res_eval_i<-rbind(res_eval_i, eval_i)
    }
  }
  
  res_eval_i$Method<-sub('\\..*','',res_eval_i$Group)
  res_eval_i$Method<-gsub('-.*','', res_eval_i$Method)
  
  res_eval_i$Model[grepl('top1$', res_eval_i$Group) &
                   !grepl('pseudo', res_eval_i$Group)]<-'IndivTrain'
  res_eval_i$Model[grepl('top1$', res_eval_i$Group) &
                   grepl('pseudo', res_eval_i$Group)]<-'SumStatTrain'
  res_eval_i$Model[grepl('multi$', res_eval_i$Group) &
                   !grepl('pseudo', res_eval_i$Group)]<-'Multi-IndivTrain'
  res_eval_i$Model[grepl('multi$', res_eval_i$Group) &
                   grepl('pseudo', res_eval_i$Group)]<-'Multi-SumStatTrain'
  
  res_eval_i$Model[grepl('_multi', res_eval_i$Group)]<-'SumStatTrain'
  res_eval_i$Model[res_eval_i$Group == 'prscsx.pseudo.multi']<-'SumStatTrain'
  res_eval_i$Model[res_eval_i$Group == 'xwing.pseudo.multi']<-'SumStatTrain'
  
  res_eval_i$Source<-ifelse(
    res_eval_i$Method %in% pgs_group_methods | grepl('_multi$', res_eval_i$Method) | 
    !grepl('EUR|EAS|AFR', res_eval_i$Group), 'Multi', 'Single')
  
  res_eval_i$Discovery[grepl('EUR', res_eval_i$Group)] <- 'EUR'
  res_eval_i$Discovery[grepl('EAS', res_eval_i$Group)] <- 'EAS'
  res_eval_i$Discovery[grepl('AFR', res_eval_i$Group)] <- 'AFR'
  res_eval_i$Discovery[res_eval_i$Source == 'Multi'] <- res_eval_i$gwas_group[res_eval_i$Source == 'Multi']
  
  res_eval_i$Method<-factor(res_eval_i$Method, levels=unique(res_eval_i$Method))
  res_eval_i$Model<-factor(res_eval_i$Model, levels=c('IndivTrain','SumStatTrain','Multi-IndivTrain','Multi-SumStatTrain'))
  res_eval_i$Discovery<-factor(res_eval_i$Discovery, levels=c('AFR','EAS','EUR','EUR+AFR','EUR+EAS'))

  # Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
  res_eval_i <- res_eval_i[
    !(res_eval_i$Method %in%  c('quickprs','sbayesrc') & 
      res_eval_i$Model %in% c('IndivTrain','Multi-IndivTrain')),]
  
  # Remove pseudo model for methods that don't really have one 
  res_eval_i <- res_eval_i[
    !(res_eval_i$Method %in%  c('ptclump','ptclump_multi') & 
      res_eval_i$Model %in% c('SumStatTrain','Multi-SumStatTrain')),]

  # Remove top1 models for *-Multi, PRS-CSx, X-wing
  res_eval_i <- res_eval_i[
    !((res_eval_i$Method %in%  c('prscsx', 'xwing') | grepl('_multi$', res_eval_i$Method)) & 
      grepl('top1', res_eval_i$Group)),]
  
  # Remove any duplicate models
  res_eval_i <- res_eval_i[!duplicated(res_eval_i[, c(
    "Target", "Method", "Model", "Source", "Discovery","gwas_group"
  )]),]
  
  res_eval[[pheno_i]]<-res_eval_i
  
}

# Create vector defining or of methods in plots
model_order <- c("DBSLMM", "lassosum", "LDpred2", "MegaPRS", "PRS-CS", "pT+clump", "QuickPRS", "SBayesRC", "DBSLMM-multi", "lassosum-multi", "LDpred2-multi", "MegaPRS-multi", "PRS-CS-multi", "pT+clump-multi", "QuickPRS-multi", "SBayesRC-multi", "PRS-CSx", "X-Wing", "All") 

res_eval_simp <- NULL
for(pheno_i in selected_traits){
  tmp <- res_eval[[pheno_i]]
  tmp$Trait <- pheno_i
  
  # Insert nice PGS method names
  tmp <- merge(tmp, pgs_method_labels, by.x = 'Method', by.y = 'method', all.x = T)
  tmp$label[is.na(tmp$label)] <- 'All'
  tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'] <- paste0(tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'], '-multi')
  tmp$label <- factor(tmp$label, levels = model_order)
  
  # Simplify result to either SumStatTrain or IndivTrain
  tmp$Model[tmp$Model != 'SumStatTrain'] <- 'IndivTrain'
  tmp$Model[tmp$Model == 'SumStatTrain'] <- 'SumStatTrain'
  tmp <- tmp[!duplicated(tmp[, c('label','Target','Discovery','Model'), with=F]),]
  
  res_eval_simp <- rbind(res_eval_simp, tmp)
}

# Count the number of traits each method is best
tmp <- res_eval_simp[res_eval_simp$label != 'All',]
best_groups <-
  do.call(rbind, by(tmp, list(
    tmp$Target,
    tmp$gwas_group,
    tmp$Trait
  ), function(subset) {
    subset[which.max(subset$R),]  # Select row with max R
  }))

best_counts <- as.data.frame(table(paste0(best_groups$label,':', best_groups$Model), best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) <- c("label", "gwas_group", "Target", "count")
best_counts$Model<-gsub('.*:','',best_counts$label)
best_counts$label<-gsub(':.*','',best_counts$label)
best_counts$label <- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts <- best_counts[best_counts$count > 0, ]

# Create the plot
ggplot(best_counts[best_counts$Target != 'EUR',], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Target, scales = 'free_x') +
  theme_half_open() +
  background_grid(major = 'y', minor = 'y') + 
  panel_border() + 
  labs(
    title = "Number of times each method is the best",
    x = "Method",
    y = "Count",
    fill = "GWAS Group"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#############################
# Identify best methods that improved prediction over next best method by 2% for any trait
# Filter out 'All' from the data
tmp <- res_eval_simp[res_eval_simp$label != 'All',]

# Identify the best method for each trait, but only if it improves by >2%
best_groups <- do.call(rbind, by(tmp, list(tmp$Target, tmp$gwas_group, tmp$Trait), function(subset) {
  if (nrow(subset) > 1) {
    # Sort by R in descending order
    subset <- subset[order(-subset$R), ]
    # Check if the best method is more than 2% better than the second best
    if ((subset$R[1] - subset$R[2]) / subset$R[2] > 0.02) {
      return(subset[1, ])  # Return the best method if criteria met
    } 
  } else {
    return(subset[1, ])  # Handle cases with only one method
  }
  return(NULL)  # Return NULL if criteria not met
}))

# Create a count table with label and model combined
best_counts <- as.data.frame(table(paste0(best_groups$label,':', best_groups$Model), 
                                   best_groups$gwas_group, best_groups$Target))

# Rename columns
colnames(best_counts) <- c("label", "gwas_group", "Target", "count")
best_counts$Model <- gsub('.*:', '', best_counts$label)
best_counts$label <- gsub(':.*', '', best_counts$label)
best_counts$label <- factor(best_counts$label, levels = model_order)

# Remove zero counts to declutter the plot
best_counts <- best_counts[best_counts$count > 0, ]

# Create the plot
library(ggplot2)
ggplot(best_counts[best_counts$Target != 'EUR',], aes(x = label, y = count, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  facet_wrap(~ Target, scales = 'free_x') +
  theme_minimal() +
  labs(
    title = "Number of times each method is the best (with >2% improvement)",
    x = "Method",
    y = "Count",
    fill = "Model"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


#############################


# Plot results for each phenotype separately
dir.create('~/oliverpainfel/Analyses/crosspop/plots')

for(pheno_i in selected_traits){
  tmp <- res_eval_simp[res_eval_simp$Trait == pheno_i,]
  #tmp <- tmp[tmp$Target != 'EUR',]
  tmp$Discovery_clean <- as.character(tmp$Discovery)
  tmp$Discovery_clean <- paste0(tmp$Discovery_clean, ' GWAS')
  tmp$Target <- paste0(tmp$Target, ' Target')

  png(paste0('~/oliverpainfel/Analyses/crosspop/plots/', pheno_i,'.png'), res=300, width = 3400, height = 2000, units = 'px')
  plot_tmp<-ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype="dotted") +
    labs(y = "R (SE)", x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = "top",
          legend.key.spacing.x = unit(1, "cm"),
          legend.justification = "center")
  print(plot_tmp)
  dev.off()
}

# Compare performance of each method in each target population across values of GWAS sample size
# Because we cannot hold all other things constant, this plot is confusing. I think relative performance might be easier to read.
for(targ_pop_i in targ_pop){
    tmp <- res_eval_simp[res_eval_simp$Target == targ_pop_i,]
    for(disc_pop_i in unique(tmp$Discovery)){
      tmp2 <- tmp[tmp$Discovery == disc_pop_i,]
      
      ggplot(tmp2, aes(x=label, y=R , fill = Model)) +
        geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                      width = 0,
                      position = position_dodge(width = 1)) +
        geom_point(stat="identity", position=position_dodge(1), size=3, shape=23) +
        geom_vline(xintercept = seq(1.5, length(unique(tmp2$Trait))), linetype="dotted") +
        labs(y = "R (SE)", x=NULL, fill = NULL, title = info_all$`Trait Description`[info_all$`Trait Label` == pheno_i]) +
        facet_grid(. ~ Trait, scales='free', space = 'free_x') +
        theme_half_open() +
        background_grid(major = 'y', minor = 'y') + 
        panel_border() + 
        theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))
      
    }
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res_eval <- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == 'EAS'){
    disc_pop <- 'EAS'
  }
  if(targ_pop_i == 'AFR'){
    disc_pop <- 'AFR'
  }
  if(targ_pop_i == 'EUR'){
    disc_pop <- c('EAS','AFR')
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_eval for each scenario
    res_eval_i <- do.call(rbind, lapply(seq_along(res_eval), function(i) {
      x <- res_eval[[i]]
      x$pheno <- names(res_eval)[i]
      x <- x[x$Target == targ_pop_i]
      x <- x[x$gwas_group == paste0('EUR+', disc_pop_i)]
    }))
    
    # Average res_evalults for each test across phenotypes
    # Use MAd to account for correlation between them
    res_eval_i$Sample<-'A'
  
    for(group_i in unique(res_eval_i$Group)){
      res_eval_group_i <- res_eval_i[res_eval_i$Group == group_i,]
      missing_pheno <-
        colnames(cors[[targ_pop_i]])[!(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))]
      
      if (!all(colnames(cors[[targ_pop_i]]) %in% unique(res_eval_group_i$pheno))) {
        print(paste0(
          'res_evalults missing for ',
          targ_pop_i,
          ' ',
          group_i,
          ' ',
          paste0(missing_pheno, collapse = ' ')
        ))
      }
      
      cors_i <- cors[[targ_pop_i]][unique(res_eval_group_i$pheno), unique(res_eval_group_i$pheno)]
      
      meta_res_eval_i <-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = "BHHR",
          mod = NULL,
          data = res_eval_group_i
        )
      
      tmp <- data.table(Group = group_i,
                        Method = res_eval_group_i$Method[1],
                        Model = res_eval_group_i$Model[1],
                        Source = res_eval_group_i$Source[1],
                        Discovery = res_eval_group_i$Discovery[1],
                        gwas_group = res_eval_group_i$gwas_group[1],
                        Target = targ_pop_i,
                        R = meta_res_eval_i$es,
                        SE = sqrt(meta_res_eval_i$var))
      
      meta_res_eval <- rbind(meta_res_eval, tmp)
    }
  }
}

meta_res_eval$Model<-factor(meta_res_eval$Model, levels=c('IndivTrain','SumStatTrain','Multi-IndivTrain','Multi-SumStatTrain'))
meta_res_eval$Discovery<-factor(meta_res_eval$Discovery, levels=c('AFR','EAS','EUR','EUR+AFR','EUR+EAS'))

# Plot average performance across phenotypes for AFR and EAS targets
tmp <- meta_res_eval
tmp <- tmp[tmp$Target != 'EUR',]
tmp <- merge(tmp, pgs_method_labels, by.x = 'Method', by.y = 'method', all.x = T)
tmp$label[is.na(tmp$label)] <- 'All'
tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'] <- paste0(tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'], '-multi')
tmp$label <- factor(tmp$label, levels = model_order)
tmp$Discovery_clean <- as.character(tmp$Discovery)
tmp$Discovery_clean[tmp$Discovery == 'EUR'] <- 'EUR GWAS'
tmp$Discovery_clean[tmp$Discovery != 'EUR' & tmp$Source == 'Single'] <- 'Target-matched GWAS'
tmp$Discovery_clean[tmp$Discovery != 'EUR' & tmp$Source == 'Multi'] <- 'Both'
tmp$Discovery_clean <- factor(tmp$Discovery_clean, 
                              levels = c('Target-matched GWAS',
                                         'EUR GWAS',
                                         'Both'))
tmp$Target <- paste0(tmp$Target, ' Target')
tmp$Model[tmp$Model != 'SumStatTrain'] <- 'IndivTrain'
tmp$Model[tmp$Model == 'SumStatTrain'] <- 'SumStatTrain'
tmp <- tmp[!duplicated(tmp[, c('label','Target','Discovery_clean','Model'), with=F]),]

png(paste0('~/oliverpainfel/Analyses/crosspop/plots/average_r.png'), res=300, width = 3200, height = 2000, units = 'px')
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype="dotted") +
    labs(y = "R (SE)", x='Method') +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = "top",
          legend.key.spacing.x = unit(1, "cm"),
          legend.justification = "center")
dev.off()

# Plot average performance across phenotypes for EUR using AFR or EAS GWAS
tmp <- meta_res_eval
tmp <- tmp[tmp$Target == 'EUR',]
tmp <- merge(tmp, pgs_method_labels, by.x = 'Method', by.y = 'method', all.x = T)
tmp$label[is.na(tmp$label)] <- 'All'
tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'] <- paste0(tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods) & tmp$label != 'All'], '-multi')
tmp$label <- factor(tmp$label, levels = model_order)
tmp$Discovery_clean <- as.character(tmp$Discovery)
tmp$Discovery_clean <- paste0(tmp$Discovery_clean, ' GWAS')
tmp$Target <- paste0(tmp$Target, ' Target')
tmp$Model[tmp$Model != 'SumStatTrain'] <- 'IndivTrain'
tmp$Model[tmp$Model == 'SumStatTrain'] <- 'SumStatTrain'
tmp <- tmp[!duplicated(tmp[, c('label','Target','Discovery_clean','Model'), with=F]),]

png(paste0('~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.png'), res=300, width = 4000, height = 1500, units = 'px')
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype="dotted") +
    labs(y = "R (SE)", x='Method') +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = "top",
          legend.key.spacing.x = unit(1, "cm"),
          legend.justification = "center")
dev.off()

# Plot performance of -multi models trained using LEOPARD vs using indiv-level data
tmp <- meta_res_eval
tmp <- tmp[tmp$Target != 'EUR',]
tmp <- merge(tmp, pgs_method_labels, by.x = 'Method', by.y = 'method')
tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods)] <- paste0(tmp$label[grepl('Multi', tmp$Model) & !(tmp$Method %in% pgs_group_methods)], '-multi')
tmp$label <- factor(tmp$label, levels = unique(tmp$label[order(!(grepl('Multi', tmp$label)), tmp$label)]))
tmp<-tmp[grepl('multi', tmp$label),]
tmp <- tmp[tmp$Model != 'Multi-IndivTrain',]
tmp$Model<-as.character(tmp$Model)
tmp$Model[tmp$Model != 'SumStatTrain']<-'IndivTrain'
tmp$Model[tmp$Model == 'SumStatTrain']<-'LEOPARD'
tmp$Target <- paste0(tmp$Target, ' Target')

png(paste0('~/oliverpainfel/Analyses/crosspop/plots/average_r_leopard.png'), res=300, width = 1500, height = 2000, units = 'px')
ggplot(tmp, aes(x=label, y=R , fill = Model)) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=3, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$label))), linetype="dotted") +
    labs(y = "R (SE)", x='Method') +
    facet_grid(Target ~., scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1),
          legend.position = "top",
          legend.key.spacing.x = unit(1, "cm"),
          legend.justification = "center")
dev.off()

####
# Create heatmap showing difference between all methods and models
####

# Create a function to mirror pred_comp results
mirror_comp<-function(x){
  x_sym <- x
  x_sym$Model_1 <- x$Model_2
  x_sym$Model_2 <- x$Model_1
  x_sym$Model_1_R <- x$Model_2_R
  x_sym$Model_2_R <- x$Model_1_R
  x_sym$R_diff <- -x_sym$R_diff
  x_mirrored <- rbind(x, x_sym)
  x_diag<-data.frame(
      Model_1=unique(x_mirrored$Model_1),
      Model_2=unique(x_mirrored$Model_1),
      Model_1_R=x_mirrored$Model_1_R,
      Model_2_R=x_mirrored$Model_1_R,
      R_diff=NA,
      R_diff_pval=NA
    )
  x_comp<-rbind(x_mirrored, x_diag)
  return(x_comp)
}
  
# Read in results
targ_pop=c('EUR','EAS','AFR')
res_comp <- list()
for(pheno_i in selected_traits){
  res_comp_i<-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'EAS'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'AFR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('EAS','AFR')
    }
    for(disc_pop_i in disc_pop){
      comp_i <-
        fread(
          paste0(
            '/users/k1806347/oliverpainfel/Analyses/crosspop/',
            'targ_',
            targ_pop_i,
            '.disc_EUR_',
            disc_pop_i,
            '/',
            pheno_i,
            '/res.pred_comp.txt'
          )
        )
      comp_i<-mirror_comp(comp_i)
      comp_i$Target<-targ_pop_i
      comp_i$gwas_group<-paste0('EUR+', disc_pop_i)
      res_comp_i<-rbind(res_comp_i, comp_i)
    }
  }
  
  res_comp[[pheno_i]]<-res_comp_i
}

res_comp_all <- do.call(rbind, lapply(names(res_comp), function(name) {
  x <- res_comp[[name]]
  x$pheno <- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Annotate tests to get order correct
res_comp_all$Method1<-sub('\\..*','',res_comp_all$Model_1)
res_comp_all$Method1<-gsub('-.*','', res_comp_all$Method1)
res_comp_all$Method2<-sub('\\..*','',res_comp_all$Model_2)
res_comp_all$Method2<-gsub('-.*','', res_comp_all$Method2)

find_model<-function(x){
  mod <- x
  mod[grepl('top1$', x) & !grepl('pseudo', x)] <- 'IndivTrain'
  mod[grepl('top1$', x) & grepl('pseudo', x)] <- 'SumStatTrain'
  mod[grepl('multi$', x) & !grepl('pseudo', x)] <- 'Multi-IndivTrain'
  mod[grepl('multi$', x) & grepl('pseudo', x)] <- 'Multi-SumStatTrain'
  mod[grepl('_multi', x)] <- 'SumStatTrain'
  mod[x == 'prscsx.pseudo.multi'] <- 'SumStatTrain'
  mod[x == 'xwing.pseudo.multi'] <- 'SumStatTrain'
  
  return(mod)
}

res_comp_all$Model1<-find_model(res_comp_all$Model_1)
res_comp_all$Model2<-find_model(res_comp_all$Model_2)

res_comp_all$Source1<-ifelse(res_comp_all$Method1 %in% pgs_group_methods | grepl('_multi$', res_comp_all$Method1) | !grepl('AFR|EAS|EUR', res_comp_all$Model_1), 'Multi', 'Single')
res_comp_all$Source2<-ifelse(res_comp_all$Method2 %in% pgs_group_methods | grepl('_multi$', res_comp_all$Method2) | !grepl('AFR|EAS|EUR', res_comp_all$Model_2), 'Multi', 'Single')
  
for(i in c('EUR','EAS','AFR')){
  res_comp_all$Discovery1[grepl(i, res_comp_all$Model_1)] <- i
  res_comp_all$Discovery2[grepl(i, res_comp_all$Model_2)] <- i
}
res_comp_all$Discovery1[res_comp_all$Source1 == 'Multi'] <- res_comp_all$gwas_group[res_comp_all$Source1 == 'Multi']
res_comp_all$Discovery2[res_comp_all$Source2 == 'Multi'] <- res_comp_all$gwas_group[res_comp_all$Source2 == 'Multi']

res_comp_all$Method1<-factor(res_comp_all$Method1, levels=unique(res_comp_all$Method1))
res_comp_all$Method2<-factor(res_comp_all$Method2, levels=unique(res_comp_all$Method2))
res_comp_all$Model1<-factor(res_comp_all$Model1, levels=c('IndivTrain','SumStatTrain','Multi-IndivTrain','Multi-SumStatTrain'))
res_comp_all$Model2<-factor(res_comp_all$Model2, levels=c('IndivTrain','SumStatTrain','Multi-IndivTrain','Multi-SumStatTrain'))
res_comp_all$Discovery1<-factor(res_comp_all$Discovery1, levels=rev(c('AFR','EAS','EUR','EUR+AFR','EUR+EAS')))
res_comp_all$Discovery2<-factor(res_comp_all$Discovery2, levels=c('AFR','EAS','EUR','EUR+AFR','EUR+EAS'))

# Remove IndivTrain and Multi-IndivTrain model for groups that contain one score (aka QuickPRS and SBayesRC)
res_comp_all <- res_comp_all[
!(res_comp_all$Method1 %in%  c('quickprs','sbayesrc') & 
  res_comp_all$Model1 %in% c('IndivTrain','Multi-IndivTrain')),]
res_comp_all <- res_comp_all[
!(res_comp_all$Method2 %in%  c('quickprs','sbayesrc') & 
  res_comp_all$Model2 %in% c('IndivTrain','Multi-IndivTrain')),]

# Remove pseudo model for methods that don't really have one 
res_comp_all <- res_comp_all[
!(res_comp_all$Method1 %in%  c('ptclump','ptclump_multi') & 
  res_comp_all$Model1 %in% c('SumStatTrain','Multi-SumStatTrain')),]
res_comp_all <- res_comp_all[
!(res_comp_all$Method2 %in%  c('ptclump','ptclump_multi') & 
  res_comp_all$Model2 %in% c('SumStatTrain','Multi-SumStatTrain')),]

# Remove top1 models for PRS-CSx
res_comp_all <- res_comp_all[
!(grepl('prscsx|xwing|_multi', res_comp_all$Method1) & 
  grepl('top1', res_comp_all$Model_1)),]
res_comp_all <- res_comp_all[
!(grepl('prscsx|xwing|_multi', res_comp_all$Method2) & 
  grepl('top1', res_comp_all$Model_2)),]

# Remove any comparisons
res_comp_all <- res_comp_all[!duplicated(res_comp_all[, c("Target", "Method1", "Model1", "Source1", "Discovery1", "Method2", "Model2", "Source2", "Discovery2",'pheno')]),]

res_comp_all$r_diff_rel <- res_comp_all$R_diff / res_comp_all$Model_2_R

# Calculate relative improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 <- res_comp_all[res_comp_all$Model_1 == 'ldpred2.multi' & 
                    grepl('ldpred2-', res_comp_all$Model_2) &
                    res_comp_all$Target == 'AFR',]
tmp_ldpred2 <- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 <- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)

tmp_ldpred2 <- res_comp_all[res_comp_all$Model_1 == 'ldpred2.multi' & 
                    grepl('ldpred2-', res_comp_all$Model_2) &
                    res_comp_all$Target == 'EAS',]
tmp_ldpred2 <- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
tmp_ldpred2 <- tmp_ldpred2[!duplicated(tmp_ldpred2$pheno),]
round(min(tmp_ldpred2$r_diff_rel)*100, 1)
round(max(tmp_ldpred2$r_diff_rel)*100, 1)


library(MAd)

# Average R across phenotypes
meta_res_comp <- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == 'EAS'){
    disc_pop <- 'EAS'
  }
  if(targ_pop_i == 'AFR'){
    disc_pop <- 'AFR'
  }
  if(targ_pop_i == 'EUR'){
    disc_pop <- c('EAS','AFR')
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res_comp for each scenario
    res_comp_i <- res_comp_all[res_comp_all$Target == targ_pop_i & res_comp_all$gwas_group == paste0('EUR+', disc_pop_i)]
  
    # Calculate diff SE based on p-value
    res_comp_i$R_diff_pval[res_comp_i$R_diff == 0] <- 1-0.001
    res_comp_i$R_diff_pval[res_comp_i$R_diff_pval == 1]<-1-0.001
    res_comp_i$R_diff_z<-qnorm(res_comp_i$R_diff_pval/2)
    res_comp_i$R_diff_SE<-abs(res_comp_i$R_diff/res_comp_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_comp_i$Sample<-'A'
    res_comp_i$Group <- paste0(res_comp_i$Model_1, '_vs_', res_comp_i$Model_2)
  
    for(group_i in unique(res_comp_i$Group)){
      res_comp_group_i <- res_comp_i[res_comp_i$Group == group_i,]
      cors_i <- cors[[targ_pop_i]][unique(res_comp_group_i$pheno), unique(res_comp_group_i$pheno)]
      
      if(res_comp_group_i$Model_1[1] != res_comp_group_i$Model_2[1]){
        
        meta_res_comp_i <-
          agg(
            id = Sample,
            es = R_diff,
            var = R_diff_SE ^ 2,
            cor = cors_i,
            method = "BHHR",
            mod = NULL,
            data = res_comp_group_i
          )
        
        tmp <- res_comp_group_i[1,]
        tmp$pheno <- NULL
        tmp$Model_1_R <-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_1 &
                            meta_res_eval$Target == targ_pop_i &
                            meta_res_eval$gwas_group == paste0('EUR+', disc_pop_i)]
        tmp$Model_2_R <-
          meta_res_eval$R[meta_res_eval$Group == tmp$Model_2 &
                            meta_res_eval$Target == targ_pop_i &
                            meta_res_eval$gwas_group == paste0('EUR+', disc_pop_i)]
        tmp$R_diff <- meta_res_comp_i$es
        tmp$R_diff_SE <- sqrt(meta_res_comp_i$var)
        tmp$R_diff_z <- tmp$R_diff / tmp$R_diff_SE
        tmp$R_diff_p <- 2*pnorm(-abs(tmp$R_diff_z))
      } else {
        tmp <- res_comp_group_i[1,]
        tmp$pheno <- NULL
        tmp$R_diff <- NA
        tmp$R_diff_SE <- NA
        tmp$R_diff_z <- NA
        tmp$R_diff_p <- NA
      }
      meta_res_comp <- rbind(meta_res_comp, tmp)
    }
  }
}

meta_res_comp$R_diff_perc <- meta_res_comp$R_diff / meta_res_comp$Model_2_R
  
# Extract average improvement for ldpred2-multi vs ldpred2 as example
tmp_ldpred2 <- meta_res_comp[meta_res_comp$Model_1 == 'ldpred2.multi' & 
                    grepl('ldpred2-', meta_res_comp$Model_2) &
                    meta_res_comp$Target == 'AFR',]
tmp_ldpred2 <- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

tmp_ldpred2 <- meta_res_comp[meta_res_comp$Model_1 == 'ldpred2.multi' & 
                    grepl('ldpred2-', meta_res_comp$Model_2) &
                    meta_res_comp$Target == 'EAS',]
tmp_ldpred2 <- tmp_ldpred2[order(-tmp_ldpred2$Model_2_R),]
round(min(tmp_ldpred2$R_diff_perc)*100, 1)

# Compare QuickPRS-Multi vs QuickPRS to evaluate LEOPARD performance
tmp_quickprs <- meta_res_comp[meta_res_comp$Model_1 == 'quickprs_multi.pseudo.multi' & 
                                meta_res_comp$Model_2 == 'quickprs.pseudo.multi' &
                    meta_res_comp$Target == 'AFR',]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

tmp_quickprs <- meta_res_comp[meta_res_comp$Model_1 == 'quickprs_multi.pseudo.multi' & 
                                meta_res_comp$Model_2 == 'quickprs.pseudo.multi' &
                    meta_res_comp$Target == 'EAS',]
round(min(tmp_quickprs$R_diff_perc)*100, 1)

# Group differences
meta_res_comp$R_diff_catagory <- cut(
    meta_res_comp$R_diff,
    breaks = c(-Inf, -0.08, -0.025, -0.002, 0.002, 0.025, 0.08, Inf),
    labels = c('< -0.08', '-0.08 - -0.025', '-0.025 - -0.002', '-0.002 - 0.002', '0.002 - 0.025', '0.025 - 0.08', '> 0.08'),
    right = FALSE
)
meta_res_comp$R_diff_catagory <- factor(meta_res_comp$R_diff_catagory, levels = rev(levels(meta_res_comp$R_diff_catagory)))

# Assign significance stars
meta_res_comp$indep_star<-' '
meta_res_comp$indep_star[meta_res_comp$R_diff_p < 0.05]<-'*'
meta_res_comp$indep_star[meta_res_comp$R_diff_p < 1e-3]<-'**'
# meta_res_comp$indep_star[meta_res_comp$R_diff_p < 1e-6]<-'***'

meta_res_comp<-meta_res_comp[order(meta_res_comp$Discovery1, meta_res_comp$Discovery2, meta_res_comp$Method1),]

for(targ_pop_i in targ_pop){
  if(targ_pop_i == 'EAS'){
    disc_pop <- 'EAS'
  }
  if(targ_pop_i == 'AFR'){
    disc_pop <- 'AFR'
  }
  if(targ_pop_i == 'EUR'){
    disc_pop <- c('EAS','AFR')
  }
  for(disc_pop_i in disc_pop){

    tmp <- meta_res_comp[meta_res_comp$Target == targ_pop_i, ]

    tmp <- merge(tmp, pgs_method_labels, by.x = 'Method1', by.y = 'method', all.x = T)
    tmp$label[is.na(tmp$label)] <- 'All'
    names(tmp)[names(tmp) == 'label'] <- 'label1'
    tmp <- merge(tmp, pgs_method_labels, by.x = 'Method2', by.y = 'method', all.x = T)
    tmp$label[is.na(tmp$label)] <- 'All'
    names(tmp)[names(tmp) == 'label'] <- 'label2'
    
    tmp$label1[grepl('Multi', tmp$Model1) & !(tmp$Method1 %in% pgs_group_methods) & tmp$label1 != 'All'] <- paste0(tmp$label1[grepl('Multi', tmp$Model1) & !(tmp$Method1 %in% pgs_group_methods) & tmp$label1 != 'All'], '-multi')
    tmp$label2[grepl('Multi', tmp$Model2) & !(tmp$Method2 %in% pgs_group_methods) & tmp$label2 != 'All'] <- paste0(tmp$label2[grepl('Multi', tmp$Model2) & !(tmp$Method2 %in% pgs_group_methods) & tmp$label2 != 'All'], '-multi')
    
    tmp$Model1[tmp$Model1 != 'SumStatTrain'] <- 'IndivTrain'
    tmp$Model1[tmp$Model1 == 'SumStatTrain'] <- 'SumStatTrain'
    tmp$Model2[tmp$Model2 != 'SumStatTrain'] <- 'IndivTrain'
    tmp$Model2[tmp$Model2 == 'SumStatTrain'] <- 'SumStatTrain'
    
    tmp<-tmp[tmp$Model_1 %in% res_eval_simp$Group,]
    tmp<-tmp[tmp$Model_2 %in% res_eval_simp$Group,]

    tmp$label1 <- factor(tmp$label1, levels = model_order)
    tmp$label2 <- factor(tmp$label2, levels = model_order)

    tmp<-tmp[order(tmp$label1, tmp$label2),]
    
    tmp$label1 <- paste0(tmp$label1," (", ifelse(tmp$Model1 == 'SumStatTrain', 'ST', 'IT'), ")")
    tmp$label2 <- paste0(tmp$label2," (", ifelse(tmp$Model2 == 'SumStatTrain', 'ST', 'IT'), ")")

    tmp$label1 <- factor(tmp$label1, levels = unique(tmp$label1))
    tmp$label2 <- factor(tmp$label2, levels = unique(tmp$label2))
    
    tmp <- tmp[tmp$gwas_group == paste0('EUR+', disc_pop_i), ]
    
    plot_tmp <- ggplot(data = tmp, aes(label2, label1, fill = R_diff_catagory)) +
      geom_tile(color = "white", show.legend = TRUE) +
      labs(y = 'Test', x = 'Comparison', fill = 'R difference', title = paste0('Target: ', targ_pop_i)) +
      facet_grid(Discovery1 ~ Discovery2, scales = 'free', space = 'free', switch="both") +
      geom_text(
        data = tmp,
        aes(label2, label1, label = indep_star),
        color = "black",
        size = 4,
        angle = 0,
        vjust = 0.8
      ) +
      scale_fill_brewer(
        breaks = levels(tmp$R_diff_catagory),
        palette = "RdBu",
        drop = F,
        na.value = 'grey'
      ) +
      theme_half_open() +
      background_grid() +
      panel_border() +
      theme(axis.text.x = element_text(
        angle = 45,
        vjust = 1,
        hjust = 1
      ))
    
    png(paste0('~/oliverpainfel/Analyses/crosspop/plots/average_r_diff.Discovery_EUR_', disc_pop_i,'.Target_', targ_pop_i, '.png'), res=300, width = 4400, height = 3200, units = 'px')
      print(plot_tmp)
    dev.off()
  }
}

####
# Plot relative improvement of methods
####
# Use ptclump IndivTrain using EUR GWAS as the reference, as provides an interpretable scale

meta_res_comp_ptclump_top1<-meta_res_comp[meta_res_comp$Model2 == 'IndivTrain' & meta_res_comp$Method2 == 'ptclump' & meta_res_comp$Discovery2 == 'EUR',]
meta_res_comp_ptclump_top1$reference_point<-F
meta_res_comp_ptclump_top1$reference_point[meta_res_comp_ptclump_top1$Model1 == 'IndivTrain' & meta_res_comp_ptclump_top1$Method1 == 'ptclump' & meta_res_comp_ptclump_top1$Discovery1 == 'EUR']<-T
meta_res_comp_ptclump_top1$R_diff[is.na(meta_res_comp_ptclump_top1$R_diff)]<-0
meta_res_comp_ptclump_top1$Discovery1 <- factor(meta_res_comp_ptclump_top1$Discovery1, levels=rev(levels(meta_res_comp_ptclump_top1$Discovery1)))

res_comp_all_ptclump_top1<-res_comp_all[res_comp_all$Model2 == 'IndivTrain' & res_comp_all$Method2 == 'ptclump' & res_comp_all$Discovery2 == 'EUR',]
res_comp_all_ptclump_top1$Discovery1 <-  factor(res_comp_all_ptclump_top1$Discovery1, levels=levels(meta_res_comp_ptclump_top1$Discovery1))

# Create data to plot reference points
meta_res_comp_reference <- meta_res_comp_ptclump_top1
meta_res_comp_reference$R_diff[meta_res_comp_ptclump_top1$reference_point == F] <- NA
meta_res_comp_reference$R_diff_SE [meta_res_comp_ptclump_top1$reference_point == F] <- NA
res_comp_all_ptclump_top1$reference_point<-F

meta_tmp <- meta_res_comp_ptclump_top1
meta_tmp <- merge(meta_tmp, pgs_method_labels, by.x = 'Method1', by.y = 'method', all.x = T)
meta_tmp$label[is.na(meta_tmp$label)] <- 'All'
meta_tmp$label[grepl('Multi', meta_tmp$Model1) & !(meta_tmp$Method1 %in% pgs_group_methods) & meta_tmp$label != 'All'] <- paste0(meta_tmp$label[grepl('Multi', meta_tmp$Model1) & !(meta_tmp$Method1 %in% pgs_group_methods) & meta_tmp$label != 'All'], '-multi')
meta_tmp$label <- factor(meta_tmp$label, levels = model_order)
meta_tmp$Discovery_clean <- as.character(meta_tmp$Discovery1)
meta_tmp$Discovery_clean[meta_tmp$Discovery1 == 'EUR'] <- 'EUR GWAS'
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != 'EUR' & meta_tmp$Source1 == 'Single'] <- 'Target-matched GWAS'
meta_tmp$Discovery_clean[meta_tmp$Discovery1 != 'EUR' & meta_tmp$Source1 == 'Multi'] <- 'Both'
meta_tmp$Discovery_clean <- factor(meta_tmp$Discovery_clean, 
                              levels = c('Target-matched GWAS',
                                         'EUR GWAS',
                                         'Both'))
meta_tmp$Target <- paste0(meta_tmp$Target, ' Target')
meta_tmp$Model1 <- factor(meta_tmp$Model1, levels = names(model_palette))

meta_tmp_ref <- meta_res_comp_reference
meta_tmp_ref <- merge(meta_tmp_ref, pgs_method_labels, by.x = 'Method1', by.y = 'method', all.x = T)
meta_tmp_ref$label[is.na(meta_tmp_ref$label)] <- 'All'
meta_tmp_ref$label[grepl('Multi', meta_tmp_ref$Model1) & !(meta_tmp_ref$Method1 %in% pgs_group_methods) & meta_tmp_ref$label != 'All'] <- paste0(meta_tmp_ref$label[grepl('Multi', meta_tmp_ref$Model1) & !(meta_tmp_ref$Method1 %in% pgs_group_methods) & meta_tmp_ref$label != 'All'], '-multi')
meta_tmp_ref$label <- factor(meta_tmp_ref$label, levels = model_order)
meta_tmp_ref$Discovery_clean <- as.character(meta_tmp_ref$Discovery1)
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 == 'EUR'] <- 'EUR GWAS'
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != 'EUR' & meta_tmp_ref$Source1 == 'Single'] <- 'Target-matched GWAS'
meta_tmp_ref$Discovery_clean[meta_tmp_ref$Discovery1 != 'EUR' & meta_tmp_ref$Source1 == 'Multi'] <- 'Both'
meta_tmp_ref$Discovery_clean <- factor(meta_tmp_ref$Discovery_clean, 
                              levels = c('Target-matched GWAS',
                                         'EUR GWAS',
                                         'Both'))
meta_tmp_ref$Target <- paste0(meta_tmp_ref$Target, ' Target')
meta_tmp_ref$Model1 <- factor(meta_tmp_ref$Model1, levels = names(model_palette))

tmp <- res_comp_all_ptclump_top1
tmp <- merge(tmp, pgs_method_labels, by.x = 'Method1', by.y = 'method', all.x = T)
tmp$label[is.na(tmp$label)] <- 'All'
tmp$label[grepl('Multi', tmp$Model1) & !(tmp$Method1 %in% pgs_group_methods) & tmp$label != 'All'] <- paste0(tmp$label[grepl('Multi', tmp$Model1) & !(tmp$Method1 %in% pgs_group_methods) & tmp$label != 'All'], '-multi')
tmp$label <- factor(tmp$label, levels = model_order)
tmp$Discovery_clean <- as.character(tmp$Discovery1)
tmp$Discovery_clean[tmp$Discovery1 == 'EUR'] <- 'EUR GWAS'
tmp$Discovery_clean[tmp$Discovery1 != 'EUR' & tmp$Source1 == 'Single'] <- 'Target-matched GWAS'
tmp$Discovery_clean[tmp$Discovery1 != 'EUR' & tmp$Source1 == 'Multi'] <- 'Both'
tmp$Discovery_clean <- factor(tmp$Discovery_clean, 
                              levels = c('Target-matched GWAS',
                                         'EUR GWAS',
                                         'Both'))
tmp$Target <- paste0(tmp$Target, ' Target')
tmp$Model1 <- factor(tmp$Model1, levels = names(model_palette))

ggplot(meta_tmp, aes(x=label, y=R_diff , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff - R_diff_SE,
          ymax = R_diff + R_diff_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = "identity",
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff, fill = Model1),
        stat = "identity",
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype="dotted") +
    labs(y = "R_diff (SE)") +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))


# Plot as % change
meta_tmp$R_diff_perc <- meta_tmp$R_diff / meta_tmp$Model_2_R
meta_tmp_ref$R_diff_perc <- meta_tmp_ref$R_diff / meta_tmp_ref$Model_2_R
tmp$R_diff_perc <- tmp$R_diff / tmp$Model_2_R

meta_tmp$R_diff_perc_SE <- meta_tmp$R_diff_SE / meta_tmp$Model_2_R

library(scales)
ggplot(meta_tmp, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp,
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = "identity",
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = "identity",
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 3,    # Increase size for emphasis
        shape = 22,
        stroke = 1.5,
        show.legend=F
    ) +
    scale_y_continuous(labels = percent_format()) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp$label))), linetype="dotted") +
    labs(y = "R diff. (SE)") +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# Simplify results showing results only with or without training data
meta_tmp_simple <- meta_tmp
meta_tmp_simple$Model1[meta_tmp_simple$Model1 != 'SumStatTrain'] <- 'IndivTrain'
meta_tmp_simple$Model1[meta_tmp_simple$Model1 == 'SumStatTrain'] <- 'SumStatTrain'
meta_tmp_simple$Model2[meta_tmp_simple$Model2 != 'SumStatTrain'] <- 'IndivTrain'
meta_tmp_simple$Model2[meta_tmp_simple$Model2 == 'SumStatTrain'] <- 'SumStatTrain'
meta_tmp_simple<-meta_tmp_simple[meta_tmp_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_simple<-meta_tmp_simple[meta_tmp_simple$Model_2 %in% res_eval_simp$Group,]

meta_tmp_ref_simple <- meta_tmp_ref
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 != 'SumStatTrain'] <- 'IndivTrain'
meta_tmp_ref_simple$Model1[meta_tmp_ref_simple$Model1 == 'SumStatTrain'] <- 'SumStatTrain'
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 != 'SumStatTrain'] <- 'IndivTrain'
meta_tmp_ref_simple$Model2[meta_tmp_ref_simple$Model2 == 'SumStatTrain'] <- 'SumStatTrain'
meta_tmp_ref_simple<-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_1 %in% res_eval_simp$Group,]
meta_tmp_ref_simple<-meta_tmp_ref_simple[meta_tmp_ref_simple$Model_2 %in% res_eval_simp$Group,]

tmp_simple <- tmp
tmp_simple$Model1[tmp_simple$Model1 != 'SumStatTrain'] <- 'IndivTrain'
tmp_simple$Model1[tmp_simple$Model1 == 'SumStatTrain'] <- 'SumStatTrain'
tmp_simple$Model2[tmp_simple$Model2 != 'SumStatTrain'] <- 'IndivTrain'
tmp_simple$Model2[tmp_simple$Model2 == 'SumStatTrain'] <- 'SumStatTrain'
tmp_simple<-tmp_simple[tmp_simple$Model_1 %in% res_eval_simp$Group,]
tmp_simple<-tmp_simple[tmp_simple$Model_2 %in% res_eval_simp$Group,]

# Export plot for manuscript
png('~/oliverpainfel/Analyses/crosspop/plots/average_r.perc_improv.png', width = 3200, height = 2000, res= 300, units = 'px')
ggplot(meta_tmp_simple[meta_tmp_simple$Target != 'EUR Target',], aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_simple[tmp_simple$Target != 'EUR Target',],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = "identity",
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target != 'EUR Target',],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = "identity",
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype="dotted") +
    scale_y_continuous(labels = percent_format()) +
    labs(y = "Relative Improvement (SE)", fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = "top",
        legend.key.spacing.x = unit(2, "cm"),
        legend.justification = "center"
    )
dev.off()

# Plot for EUR
meta_tmp_simple$Discovery_clean <- paste0(meta_tmp_simple$Discovery1,' GWAS')
meta_tmp_ref_simple$Discovery_clean <- paste0(meta_tmp_ref_simple$Discovery1,' GWAS')
tmp_simple$Discovery_clean <- paste0(tmp_simple$Discovery1,' GWAS')

png('~/oliverpainfel/Analyses/crosspop/plots/average_r_eur.perc_improv.png', width = 4000, height = 1500, res= 300, units = 'px')
ggplot(meta_tmp_simple[meta_tmp_simple$Target == 'EUR Target',], aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_point(
        data = tmp_simple[tmp_simple$Target == 'EUR Target',],
        mapping = aes(x=label, y=R_diff_perc, colour=Model1),
        position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
        alpha = 0.3
      ) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = "identity",
      position = position_dodge(0.7),
      size = 3,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple[meta_tmp_ref_simple$Target == 'EUR Target',],
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = "identity",
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 4,
        shape = 22,
        show.legend=F
    ) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype="dotted") +
    scale_y_continuous(labels = percent_format()) +
    labs(y = "Relative Improvement (SE)", fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(
        axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        legend.position = "top",
        legend.key.spacing.x = unit(2, "cm"),
        legend.justification = "center"
    )
dev.off()

# Export plot for poster presentation
png('poster_plot1.png', width = 54, height = 36, res= 300, units = 'cm')
ggplot(meta_tmp_simple, aes(x=label, y=R_diff_perc , fill = Model1)) +
    geom_hline(yintercept = 0) +
      geom_errorbar(
        aes(
          ymin = R_diff_perc - R_diff_perc_SE,
          ymax = R_diff_perc + R_diff_perc_SE
        ),
        width = 0,
        size = 1,
        position = position_dodge(width = 0.7)
      ) +    
    geom_point(
      stat = "identity",
      position = position_dodge(0.7),
      size = 7,
      stroke = 1,
      shape = 23
    ) +
    geom_point(
        data = meta_tmp_ref_simple,
        aes(x = label, y = R_diff_perc, fill = Model1),
        stat = "identity",
        position = position_dodge(0.7), # Ensure same dodge as other points
        size = 7,    # Increase size for emphasis
        shape = 22,
        stroke = 1,
        show.legend=F
    ) +
   scale_fill_manual(values = c(
        "IndivTrain" = "#F8766D",   # Red
        "SumStatTrain" = "#00BFC4", # Green
        "IndivTrain of SumStatTrain" = "#CCFFFF" # Purple
    )) +
    geom_vline(xintercept = seq(1.5, length(unique(meta_tmp_simple$label))), linetype="dotted", size = 1) +
    scale_y_continuous(labels = percent_format()) +
    labs(y = "Relative Improvement (SE)", fill = NULL, colour = NULL, x = NULL) +
    facet_grid(Target ~ Discovery_clean, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid(major = 'y', minor = 'y') + 
    panel_border() + 
    theme(
        axis.text.x = element_text(size = 24, angle = 45, vjust = 1, hjust = 1),  # Increase x-axis labels
        axis.text.y = element_text(size = 24),  # Increase y-axis labels
        axis.title = element_text(size = 24),  # Increase axis titles
        strip.text = element_text(size = 24),  # Increase facet labels
        legend.text = element_text(size = 24, hjust = 0.5),  # Increase legend text
        legend.position = "top",
        legend.key.spacing.x = unit(5, "cm"),
        legend.justification = "center"
    )
dev.off()

```
</details>

***

### Check LEOPARD weights

Here we will compare the LEOPARD estimated weights for population specific PGS, to the weights estimated using observed data in the UKB target sample.

```{r}
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')

library(data.table)
library(ggplot2)
library(cowplot)

source('../functions/misc.R')
source_all('../functions')

# Read in list of outcomes 
selected_traits<-fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml'
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

###
# Read in weights estimated by LEOPARD
###
# Currently, we are only using LEOPARD to estimate the weights for QuickPRS PGS.
# Read in the weights adjusted to account for standardised PGS (SD = 1).
# Read in the weights for the non-EUR target sample (i.e. either AFR or EAS).

leopard_weights<-NULL
scores_quickprs <- scores$name[scores$method == 'quickprs_multi']
for(i in selected_traits){
  scores_i <- scores_quickprs[grepl(paste0('^', i,'_'), scores_quickprs)]
  for(j in scores_i){
      log <- readLines(paste0(outdir, '/reference/pgs_score_files/quickprs_multi/', j, '/ref-', j, '.log'))
      populations <- unlist(strsplit(gsub('populations| ','', log[grepl('^ populations', log)]), ','))
      
      weight_row <- which(grepl(paste0('Adjusted LEOPARD weights - ', populations[populations != 'EUR'],' target'), log))
      weight_row <- weight_row + 1:2
      log <- log[weight_row]
      log <- as.numeric(gsub('.* ', '', log))
      
      weights <-
        data.table(
          Target =  populations[populations != 'EUR'],
          Discovery = populations,
          Weight = round(log, 3),
          Trait = i,
          Method = 'quickprs_multi'
        )
      
      leopard_weights <- rbind(leopard_weights, weights)
  }
}

#####
# Read in the PGS weights estimated using UKB data
#####
# Read in the final model coefficients for models containing pseudo PGS from single-source methods

obs_weights<-NULL
for(method_i in unique(scores$method)[!(unique(scores$method) %in% pgs_group_methods)]){
  scores_method<-scores$name[scores$method == method_i]

  for(i in selected_traits){
    for(j in c('EAS','AFR')){
      model <- fread(paste0('~/oliverpainfel/Analyses/crosspop/targ_', j, '.disc_EUR_', j, '/', i, '/final_models/', method_i, '.pseudo.multi.final_model.txt'))
      model<-model[-1,]
      names(model) <- c('x', 'BETA')
      model$Discovery[grepl('UKB', model$x)]<-'EUR'
      model$Discovery[grepl('BBJ', model$x)]<-'EAS'
      model$Discovery[grepl('UGR', model$x)]<-'AFR'
      model$Target <- j
      model$Weight <- model$BETA/sum(model$BETA)
      model$Trait <- i
      model$Method <- method_i
      model<-model[,c('Target','Discovery','Weight','Method','Trait'), with=F]
      obs_weights<-rbind(obs_weights, model)
    }
  }
}

###
# Combine and compare
###

leopard_weights$Method <- 'LEOPARD'
both <- do.call(rbind, list(obs_weights, leopard_weights))
both <- both[both$Discovery != 'EUR',]
both$Target <- paste0('Target = ', both$Target)

# Plot the estimated and observed weights
ggplot(both, aes(x = Trait, y = Weight, fill = Method)) +
  geom_bar(position="dodge", stat="identity") +
  facet_grid(. ~ Target) +
  theme_half_open() +
  background_grid(major = 'y', minor = 'y') + 
  panel_border()

# Calculate correlation between weights from each method
both$Discovery<-NULL
both_wide <- reshape(both, 
                     idvar = c("Trait", "Target"), 
                     timevar = "Method", 
                     direction = "wide")
names(both_wide) <- gsub('Weight.', '', names(both_wide))

cor_matrix_EAS <- cor(both_wide[both_wide$Target == 'Target = EAS', -1:-2])
cor_matrix_AFR <- cor(both_wide[both_wide$Target == 'Target = AFR', -1:-2])

# Convert correlation matrix to long format for ggplot
cor_df_EAS <- melt(cor_matrix_EAS)
cor_df_AFR <- melt(cor_matrix_AFR)
cor_df_EAS$Target <- 'Target = EAS'
cor_df_AFR$Target <- 'Target = AFR'
cor_df <- rbind(cor_df_AFR, cor_df_EAS)

# Create ggplot correlation heatmap with text inside
ggplot(cor_df, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +  # Tile plot with white borders
  geom_text(aes(label = round(value, 2)), color = "black") +  # Add correlation values
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +  # Color scale
  theme_half_open() +
  panel_border() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title = element_blank()
  ) +
  facet_grid(. ~ Target) +
  labs(fill = "Correlation")

# Plot comparison between observed and LEOPARD weights
obvs_vs_leopard <- merge(obs_weights, leopard_weights, by=c('Target','Discovery','Trait'))

ggplot(obvs_vs_leopard, aes(x=Weight.x, y=Weight.y, colour = Method.x)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  geom_point() +
  theme_half_open() +
  panel_border() + 
  facet_grid(. ~ Target) +
  labs(y = 'LEOPARD weight', x = 'Observed weight') +
  xlim(c(0,1)) +
  ylim(c(0,1))

mean_abs_diff <- aggregate(abs(obvs_vs_leopard$Weight.x - obvs_vs_leopard$Weight.y),
                           by = list(Method = obvs_vs_leopard$Method.x, Population = obvs_vs_leopard$Target),
                           FUN = mean)

# Rename columns
colnames(mean_abs_diff) <- c("Method", "Target", "Mean_Absolute_Difference")

#    Method                   Target  Mean_Absolute_Difference
#    dbslmm                      AFR                0.19474126
#  lassosum                      AFR                0.30388943
#   ldpred2                      AFR                0.16107677
#   megaprs                      AFR                0.22283358
#     prscs                      AFR                0.17876755
#   ptclump                      AFR                0.17443263
#  quickprs                      AFR                0.18643385
#  sbayesrc                      AFR                0.19114802
#    dbslmm                      EAS                0.09235866
#  lassosum                      EAS                0.09133249
#   ldpred2                      EAS                0.09829542
#   megaprs                      EAS                0.12050745
#     prscs                      EAS                0.08538271
#   ptclump                      EAS                0.10710789
#  quickprs                      EAS                0.11950164
#  sbayesrc                      EAS                0.10211742

# The adjusted LEOPARD weights look good. It is less accurate for the AFR target, probably due to limited GWAS sample size and LD reference mismatch. The correlation between the observed pgs weights is quite consistent across methods as well. Given how fast QuickPRS is, and that preliminary analysis shows other methods might be more sensitive to small reference data, I think we should use the QuickPRS-based LEOPARD weights for other PGS methods as well.

```

***

## Evaluate TLPRS
### Create predictor lists

<details><summary>Show code</summary>

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
source('../functions/misc.R')
source_all('../functions')
library(data.table)

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml'
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Read in list of outcomes 
selected_traits<-fread('/users/k1806347/oliverpainfel/Analyses/crosspop/trait_subset.txt', header=F)$V1

# Get a list of score files
scores <- list_score_files(config)

# Subset to TLPRS scores and pseudo scores for corresponding methods
pgs_methods <- unique(scores$method[grepl('^tlprs', scores$method)])
pgs_methods <- c(pgs_methods, gsub('tlprs_','',pgs_methods))
scores <- scores[scores$method %in% pgs_methods,]

# Create files for EAS and AFR targets
targ_pop <- c('EUR','EAS','AFR')
for(trait_i in selected_traits){
  scores_i <- scores[grepl(trait_i, scores$name),]
  scores_i$group <- scores_i$method
  
  for(targ_pop_i in targ_pop){
    # Subset GWAS based on EUR and/or targ_pop_i
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'BBJ'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'UGR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('BBJ','UGR')
    }
    
    for(disc_pop_j in disc_pop){
      if(disc_pop_j == 'BBJ'){
        disc_pop_j_2 <- 'EAS'
      }
      if(disc_pop_j == 'UGR'){
        disc_pop_j_2 <- 'AFR'
      }

      dir.create(
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          targ_pop_i,
          '.disc_EUR_',
          disc_pop_j_2,
          '/',
          trait_i
        ),
        recursive = T
      )
      
      scores_i_j <- scores_i[grepl('UKB', scores_i$name, ignore.case = F) |
                             grepl(disc_pop_j, scores_i$name, ignore.case = T),]
      
      # Insert the pseudo score for the non-TLPRS methods
      scores_i_j_pseudo <- scores_i_j[which(!grepl('^tlprs', scores_i_j$method)), ]
      scores_i_j_pseudo$group <- paste0(scores_i_j_pseudo$group,'.pseudo')

      scores_i_j_pseudo$predictor <- paste0(
        outdir,
        '/ukb/pgs/',
        targ_pop_i,
        '/',
        scores_i_j_pseudo$method,
        '/',
        scores_i_j_pseudo$name,
        '/ukb-',
        scores_i_j_pseudo$name,
        '-',
        targ_pop_i,
        '.pseudo.profiles'
      )
      
      for(i in 1:nrow(scores_i_j_pseudo)) {
        tmp <- scores_i_j_pseudo[i,]
        param <- find_pseudo(
          config = config,
          gwas = tmp$name,
          pgs_method = tmp$method,
          target_pop = targ_pop_i
        )
        
        score_header <-
          fread(gsub('.pseudo', '', tmp$predictor), nrows = 1)
        score_cols <-
          which(names(score_header) %in% c('FID', 'IID', paste0(tmp$name, '_', param)))
        
        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols, collapse=','),
            " ", 
            gsub('.pseudo', '', tmp$predictor), 
            " > ", tmp$predictor
          )
        )
      }
      
      # Create disc_pop specific groups
      scores_i_j_pseudo_disc_pop <- scores_i_j_pseudo
      scores_i_j_pseudo_disc_pop$group[grepl('UKB', scores_i_j_pseudo_disc_pop$name)] <- paste0(scores_i_j_pseudo_disc_pop$group[grepl('UKB', scores_i_j_pseudo_disc_pop$name)], '.EUR')
      scores_i_j_pseudo_disc_pop$group[!grepl('UKB', scores_i_j_pseudo_disc_pop$name)] <- paste0(scores_i_j_pseudo_disc_pop$group[!grepl('UKB', scores_i_j_pseudo_disc_pop$name)], '.', disc_pop_j_2)
      
      # Insert groups for TLPRS scores for both target populations, and target specific
      scores_i_j_multi <- scores_i_j[which(grepl('^tlprs', scores_i_j$method)), ]
      
      # Insert path to score file
      scores_i_j_multi$predictor <- paste0(
        outdir,
        '/ukb/pgs/',
        targ_pop_i,
        '/',
        scores_i_j_multi$method,
        '/',
        scores_i_j_multi$name,
        '/ukb-',
        scores_i_j_multi$name,
        '-',
        targ_pop_i,
        '.profiles'
      )
      
      scores_i_j_multi_targ_pop <- scores_i_j_multi
      scores_i_j_multi_targ_pop_both<-NULL
      for(i in 1:nrow(scores_i_j_multi_targ_pop)){
        score_header <-
          fread(gsub('.pseudo', '', scores_i_j_multi_targ_pop$predictor[i]), nrows = 1)
        score_cols_EUR <-
          which(names(score_header) %in% c('FID', 'IID', names(score_header)[grepl('targ_EUR', names(score_header))]))
        score_cols_targ <-
          which(names(score_header) %in% c('FID', 'IID', names(score_header)[grepl(paste0('targ_', targ_pop_i), names(score_header))]))
        
        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols_EUR, collapse=','),
            " ", 
            scores_i_j_multi_targ_pop$predictor[i], 
            " > ", 
            paste0(
              outdir,
              '/ukb/pgs/',
              targ_pop_i,
              '/',
              scores_i_j_multi_targ_pop$method[i],
              '/',
              scores_i_j_multi_targ_pop$name[i],
              '/ukb-',
              scores_i_j_multi_targ_pop$name[i],
              '-',
              targ_pop_i,
              '.targ_EUR.profiles'
            )
          )
        )
        
        system(
          paste0(
            "cut -d' ' -f ", 
            paste0(score_cols_targ, collapse=','),
            " ", 
            scores_i_j_multi_targ_pop$predictor[i], 
            " > ", 
            paste0(
              outdir,
              '/ukb/pgs/',
              targ_pop_i,
              '/',
              scores_i_j_multi_targ_pop$method[i],
              '/',
              scores_i_j_multi_targ_pop$name[i],
              '/ukb-',
              scores_i_j_multi_targ_pop$name[i],
              '-',
              targ_pop_i,
              '.targ_',
              targ_pop_i,
              '.profiles'
            )
          )
        )
        
        tmp<-scores_i_j_multi_targ_pop[i,]
        tmp <- rbind(tmp, tmp)
        tmp$predictor[1] <- paste0(
            outdir,
            '/ukb/pgs/',
            targ_pop_i,
            '/',
            scores_i_j_multi_targ_pop$method[i],
            '/',
            scores_i_j_multi_targ_pop$name[i],
            '/ukb-',
            scores_i_j_multi_targ_pop$name[i],
            '-',
            targ_pop_i,
            '.targ_EUR.profiles'
          )
        tmp$group[1] <- paste0(tmp$group[1], '.EUR')
        
        tmp$predictor[2] <- paste0(
            outdir,
            '/ukb/pgs/',
            targ_pop_i,
            '/',
            scores_i_j_multi_targ_pop$method[i],
            '/',
            scores_i_j_multi_targ_pop$name[i],
            '/ukb-',
            scores_i_j_multi_targ_pop$name[i],
            '-',
            targ_pop_i,
            '.targ_',
            targ_pop_i,
            '.profiles'
          )
        tmp$group[2] <- paste0(tmp$group[2], '.', targ_pop_i)

        scores_i_j_multi_targ_pop_both <- rbind(
          scores_i_j_multi_targ_pop_both,
          tmp)
      }
      
      predictors_i<- do.call(rbind, list(
        scores_i_j_multi, scores_i_j_multi_targ_pop_both, scores_i_j_pseudo, scores_i_j_pseudo_disc_pop
      ))
      
      predictors_i <- predictors_i[, c('predictor', 'group'), with=F]
      
      write.table(
        predictors_i,
        paste0(
          '/users/k1806347/oliverpainfel/Analyses/crosspop/targ_',
          targ_pop_i,
          '.disc_EUR_',
          disc_pop_j_2,
          '/',
          trait_i,
          '/predictor_list.tlprs.txt'
        ),
        col.names = T,
        row.names = F,
        quote = F
      )
    }
  }
}

```

</details>

***

### Run model_builder

<details><summary>Show code</summary>

```{bash}
cd /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline
conda activate model_builder

for targ_pop in $(echo EUR EAS AFR); do
  if [ "$targ_pop" == "EUR" ]; then
      targ_pop2="EUR_test"
  else
      targ_pop2=$targ_pop
  fi
  
  if [ "$targ_pop" == "EUR" ]; then
    disc_pop=$(echo AFR EAS)
  fi
  
  if [ "$targ_pop" == "EAS" ]; then
    disc_pop="EAS"
  fi
  
  if [ "$targ_pop" == "AFR" ]; then
    disc_pop="AFR"
  fi
  
  for disc_pop_i in ${disc_pop}; do
    for pheno in $(head -n 5 /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_labels.txt); do
      sbatch --mem 20G -n 10 -p neurohack_cpu --wrap="Rscript ../Scripts/model_builder/model_builder.R \
        --outcome /users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/${pheno}.unrel.${targ_pop2}.row_number.txt \
        --predictors /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/predictor_list.tlprs.txt \
        --out /users/k1806347/oliverpainfel/Analyses/crosspop/targ_${targ_pop}.disc_EUR_${disc_pop_i}/${pheno}/res.tlprs \
        --n_core 10 \
        --top1 T \
        --all_model F \
        --assoc T"
    done
  done
done

```
</details>

***

### Plot results

<details><summary>Show code</summary>

```{r}

setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')

library(data.table)
library(ggplot2)
library(cowplot)

source('../functions/misc.R')
source_all('../functions')

# Read in list of outcomes 
prscsx_dat<-fread('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/prscsx_data.csv')
prscsx_dat<-prscsx_dat[1:5,]

config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml'
  
# Define pgs_methods used
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)

# Define gwas_list used
gwas_list<-read_param(config = config, param = 'gwas_list')

# Define gwas_groups used
gwas_groups<-read_param(config = config, param = 'gwas_groups')

# Calculate corelation between all phenotypes in each target population
cors <- list()
for(pop_i in c('EUR','EAS','AFR','CSA','AMR')){
  if(pop_i == 'EUR'){
    pop_i_2 <- 'EUR_test'
  } else {
    pop_i_2 <- pop_i
  }
  pheno_pop_i <- list()
  for(pheno_i in prscsx_dat$labels){
    pheno_pop_i[[pheno_i]] <- fread(paste0('/users/k1806347/oliverpainfel/Data/ukb/phenotypes/prscsx/', pheno_i, '.unrel.', pop_i_2, '.row_number.txt'))
    names(pheno_pop_i[[pheno_i]])[3] <- pheno_i
  }
  
  pheno_pop_i_merged <- merged_df <- Reduce(function(x, y) merge(x, y, all = TRUE, by = c('FID','IID')), pheno_pop_i)

  cors_i <- abs(cor(as.matrix(pheno_pop_i_merged[,-1:-2, with=F]), use='p'))
  cors[[pop_i]] <- cors_i
}

# Read in results
targ_pop = c('EUR','EAS','AFR')
res <- list()
for(pheno_i in prscsx_dat$labels){
  res_i<-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'EAS'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'AFR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('EAS','AFR')
    }
    for(disc_pop_i in disc_pop){
      eval_i <-
        fread(
          paste0(
            '/users/k1806347/oliverpainfel/Analyses/crosspop/',
            'targ_',
            targ_pop_i,
            '.disc_EUR_',
            disc_pop_i,
            '/',
            pheno_i,
            '/res.tlprs.pred_eval.txt'
          )
        )
      eval_i$Target<-targ_pop_i
      eval_i$gwas_group<-paste0('EUR+', disc_pop_i)
      res_i<-rbind(res_i, eval_i)
    }
  }
  
  res_i$Method<-sub('\\..*','',res_i$Group)
  res_i$Method_short<-sub('.*_','',res_i$Method)
  res_i<-res_i[order(res_i$Method_short, res_i$Method),]
  
  res_i$Model[grepl('pseudo', res_i$Group)]<-'Pseudo'
  res_i$Model[grepl('top1', res_i$Group)]<-'Top1'
  res_i$Model[!grepl('top1|pseudo', res_i$Group)]<-'Multi'
  res_i$Model[!grepl('tlprs', res_i$Group) & !grepl('EUR|EAS|AFR', res_i$Group) & !grepl('top1', res_i$Group)]<-'Multi'
  
  res_i$Source[!grepl('tlprs', res_i$Group)] <- 'Single'
  res_i$Source[grepl('tlprs', res_i$Group)] <- 'Multi'
  res_i$Source[!grepl('tlprs', res_i$Group) & !grepl('EUR|EAS|AFR', res_i$Group)] <- 'Multi'
  
  res_i$Discovery <- res_i$gwas_group
  res_i$Discovery[grepl('EUR', res_i$Group) & res_i$Source == 'Single'] <- 'EUR'
  res_i$Discovery[grepl('EAS', res_i$Group) & res_i$Source == 'Single'] <- 'EAS'
  res_i$Discovery[grepl('AFR', res_i$Group) & res_i$Source == 'Single'] <- 'AFR'

  res_i$Method <- gsub('tlprs_','tlprs - ', res_i$Method)
  res_i$Method[grepl('tlprs', res_i$Method) & grepl('EUR', res_i$Group)] <- paste0(res_i$Method[grepl('tlprs', res_i$Method) & grepl('EUR', res_i$Group)], " (EUR)")
  res_i$Method[grepl('tlprs', res_i$Method) & grepl('EAS', res_i$Group)] <- paste0(res_i$Method[grepl('tlprs', res_i$Method) & grepl('EAS', res_i$Group)], " (EAS)")
  res_i$Method[grepl('tlprs', res_i$Method) & grepl('AFR', res_i$Group)] <- paste0(res_i$Method[grepl('tlprs', res_i$Method) & grepl('AFR', res_i$Group)], " (AFR)")
  res_i$Method[grepl('tlprs', res_i$Method) & !grepl('EUR|EAS|AFR', res_i$Group)] <- paste0(res_i$Method[grepl('tlprs', res_i$Method) & !grepl('EUR|EAS|AFR', res_i$Group)], " (Both)")

  res_i$Method<-factor(res_i$Method, levels=unique(res_i$Method))
  res_i$Model<-factor(res_i$Model, levels=c('Top1','Pseudo','Multi'))
  res_i$Discovery<-factor(res_i$Discovery, levels=c('AFR','EAS','EUR','EUR+AFR','EUR+EAS'))

  res[[pheno_i]]<-res_i
  
}

####
# Average results across phenotypes
####

library(MAd)

# Average R across phenotypes
meta_res <- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == 'EAS'){
    disc_pop <- 'EAS'
  }
  if(targ_pop_i == 'AFR'){
    disc_pop <- 'AFR'
  }
  if(targ_pop_i == 'EUR'){
    disc_pop <- c('EAS','AFR')
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res for each scenario
    res_i <- do.call(rbind, lapply(seq_along(res), function(i) {
      x <- res[[i]]
      x$pheno <- names(res)[i]
      x <- x[x$Target == targ_pop_i]
      x <- x[x$gwas_group == paste0('EUR+', disc_pop_i)]
    }))
    
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_i$Sample<-'A'
  
    for(group_i in unique(res_i$Group)){
      res_group_i <- res_i[res_i$Group == group_i,]
      cors_i <- cors[[targ_pop_i]][unique(res_group_i$pheno), unique(res_group_i$pheno)]
      
      meta_res_i <-
        agg(
          id = Sample,
          es = R,
          var = SE ^ 2,
          cor = cors_i,
          method = "BHHR",
          mod = NULL,
          data = res_group_i
        )
      
      meta_res <- rbind(meta_res,
                        data.table(
                          Group = group_i,
                          Method = res_group_i$Method[1],
                          Model = res_group_i$Model[1],
                          Source = res_group_i$Source[1],
                          Discovery = res_group_i$Discovery[1],
                          gwas_group = res_group_i$gwas_group[1],
                          Target = targ_pop_i,
                          R = meta_res_i$es,
                          SE = sqrt(meta_res_i$var)
                        ))
    }
  }
}

meta_res$Model<-factor(meta_res$Model, levels=c('Top1','Pseudo','Multi'))
meta_res$Discovery<-factor(meta_res$Discovery, levels=c('AFR','EAS','EUR','EUR+AFR','EUR+EAS'))

####
# Compare TLPRS to unadjusted PGS
####

meta_res_multi_pop <- meta_res[!(meta_res$Discovery %in% c('EUR','EAS','AFR')),]
meta_res_multi_pop$original_method <- gsub(' .*', '', gsub('tlprs - ', '', meta_res_multi_pop$Method))
meta_res_multi_pop$test[!grepl('tlprs', meta_res_multi_pop$Method)] <- 'Unadjusted'
meta_res_multi_pop$test[grepl('tlprs', meta_res_multi_pop$Method)] <- gsub('.* ', 'TLPRS ', meta_res_multi_pop$Method[grepl('tlprs', meta_res_multi_pop$Method)])
meta_res_multi_pop$test <- factor(meta_res_multi_pop$test, levels=unique(meta_res_multi_pop$test))
meta_res_multi_pop$test <- gsub('AFR', 'target pop', meta_res_multi_pop$test)
meta_res_multi_pop$test <- gsub('EAS', 'target pop', meta_res_multi_pop$test)

tmp <- meta_res_multi_pop[meta_res_multi_pop$Target %in% c('EAS', 'AFR'),]

ggplot(tmp, aes(x=test, y=R , fill = Model)) +
    #geom_hline(yintercept = 0) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=2, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$Method))), linetype="dotted") +
    labs(y = "R (SE)") +
    facet_grid(Target ~ original_method, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

tmp <- meta_res_multi_pop[meta_res_multi_pop$Target %in% c('EAS', 'AFR'),]
tmp <- tmp[grepl('Unadj|Both', tmp$test),]
tmp$test <- gsub(' .*', '', tmp$test)
tmp$test <- factor(tmp$test, levels=c('Unadjusted','TLPRS'))

ggplot(tmp, aes(x=test, y=R , fill = Model)) +
    #geom_hline(yintercept = 0) +
    geom_errorbar(aes(ymin = R - SE, ymax = R + SE),
                  width = 0,
                  position = position_dodge(width = 1)) +
    geom_point(stat="identity", position=position_dodge(1), size=2, shape=23) +
    geom_vline(xintercept = seq(1.5, length(unique(tmp$Method))), linetype="dotted") +
    labs(y = "R (SE)", x = NULL) +
    facet_grid(Target ~ original_method, scales='free', space = 'free_x') +
    theme_half_open() +
    background_grid() + 
    panel_border() + 
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

####
# Create heatmap showing difference between all methods and models
####

# Read in results
targ_pop=c('EUR','EAS','AFR')
res <- list()
for(pheno_i in prscsx_dat$labels){
  res_i<-NULL
  for(targ_pop_i in targ_pop){
    if(targ_pop_i == 'EAS'){
      disc_pop <- 'EAS'
    }
    if(targ_pop_i == 'AFR'){
      disc_pop <- 'AFR'
    }
    if(targ_pop_i == 'EUR'){
      disc_pop <- c('EAS','AFR')
    }
    for(disc_pop_i in disc_pop){
      eval_i <-
        fread(
          paste0(
            '/users/k1806347/oliverpainfel/Analyses/crosspop/',
            'targ_',
            targ_pop_i,
            '.disc_EUR_',
            disc_pop_i,
            '/',
            pheno_i,
            '/res.tlprs.pred_comp.txt'
          )
        )
      eval_i$Target<-targ_pop_i
      eval_i$gwas_group<-paste0('EUR+', disc_pop_i)
      res_i<-rbind(res_i, eval_i)
    }
  }
  
  res[[pheno_i]]<-res_i
}

#####
# Create a plot showing relative R from TLPRS vs Unadjusted
#####

res_all <- do.call(rbind, lapply(names(res), function(name) {
  x <- res[[name]]
  x$pheno <- name  # Add a new column with the name of the element
  x  # Return the updated dataframe
}))

# Mirror results to fill in gaps
res_all_symmetric <- res_all
res_all_mirrored <- res_all
res_all_mirrored$Model_1 <- res_all$Model_2
res_all_mirrored$Model_2 <- res_all$Model_1
res_all_mirrored$Model_1_R <- res_all$Model_2_R
res_all_mirrored$Model_2_R <- res_all$Model_1_R
res_all_mirrored$R_diff <- -res_all_mirrored$R_diff
res_all <- rbind(res_all_symmetric, res_all_mirrored)

# Subset tests where top1 TLPRS is being compared to top1 unadjusted
res_all$Method_1 <- gsub('.*_', '', gsub('\\..*', '', res_all$Model_1))
res_all$Method_2 <- gsub('.*_', '', gsub('\\..*', '', res_all$Model_2))

res_all$TLPRS_1 <- grepl('tlprs', res_all$Model_1)
res_all$TLPRS_2 <- grepl('tlprs', res_all$Model_2)

res_all$Test_1[grepl('pseudo', res_all$Model_1)]<-'Pseudo'
res_all$Test_1[grepl('top1', res_all$Model_1)]<-'Top1'
res_all$Test_1[!grepl('top1|pseudo', res_all$Model_1)]<-'Multi'
res_all$Test_1[!grepl('tlprs', res_all$Model_1) & !grepl('EUR|EAS|AFR', res_all$Model_1) & !grepl('top1', res_all$Model_1)]<-'Multi'

res_all$Test_2[grepl('pseudo', res_all$Model_2)]<-'Pseudo'
res_all$Test_2[grepl('top1', res_all$Model_2)]<-'Top1'
res_all$Test_2[!grepl('top1|pseudo', res_all$Model_2)]<-'Multi'
res_all$Test_2[!grepl('tlprs', res_all$Model_2) & !grepl('EUR|EAS|AFR', res_all$Model_2) & !grepl('top1', res_all$Model_2)]<-'Multi'

res_all$Source_1[!grepl('tlprs', res_all$Model_1)] <- 'Single'
res_all$Source_1[grepl('tlprs', res_all$Model_1)] <- 'Multi'
res_all$Source_1[!grepl('tlprs', res_all$Model_1) & !grepl('EUR|EAS|AFR', res_all$Model_1)] <- 'Multi'

res_all$Source_2[!grepl('tlprs', res_all$Model_2)] <- 'Single'
res_all$Source_2[grepl('tlprs', res_all$Model_2)] <- 'Multi'
res_all$Source_2[!grepl('tlprs', res_all$Model_2) & !grepl('EUR|EAS|AFR', res_all$Model_2)] <- 'Multi'

res_all$Discovery_1 <- res_all$gwas_group
res_all$Discovery_1[grepl('EUR', res_all$Model_1) & res_all$Source_1 == 'Single'] <- 'EUR'
res_all$Discovery_1[grepl('EAS', res_all$Model_1) & res_all$Source_1 == 'Single'] <- 'EAS'
res_all$Discovery_1[grepl('AFR', res_all$Model_1) & res_all$Source_1 == 'Single'] <- 'AFR'

res_all$Discovery_2 <- res_all$gwas_group
res_all$Discovery_2[grepl('EUR', res_all$Model_2) & res_all$Source_2 == 'Single'] <- 'EUR'
res_all$Discovery_2[grepl('EAS', res_all$Model_2) & res_all$Source_2 == 'Single'] <- 'EAS'
res_all$Discovery_2[grepl('AFR', res_all$Model_2) & res_all$Source_2 == 'Single'] <- 'AFR'

res_all$TLPRS_target_1[grepl('EUR', res_all$Model_1) & res_all$TLPRS_1] <- 'EUR'
res_all$TLPRS_target_1[grepl('EAS', res_all$Model_1) & res_all$TLPRS_1] <- 'EAS'
res_all$TLPRS_target_1[grepl('AFR', res_all$Model_1) & res_all$TLPRS_1] <- 'AFR'
res_all$TLPRS_target_1[!grepl('EUR|AFR|EAS', res_all$Model_1) & res_all$TLPRS_1] <- 'Both'
res_all$TLPRS_target_1[res_all$TLPRS_target_1 == res_all$Target] <- 'Target Pop.'

res_all$TLPRS_target_2[grepl('EUR', res_all$Model_2) & res_all$TLPRS_2] <- 'EUR'
res_all$TLPRS_target_2[grepl('EAS', res_all$Model_2) & res_all$TLPRS_2] <- 'EAS'
res_all$TLPRS_target_2[grepl('AFR', res_all$Model_2) & res_all$TLPRS_2] <- 'AFR'
res_all$TLPRS_target_2[!grepl('EUR|AFR|EAS', res_all$Model_2) & res_all$TLPRS_2] <- 'Both'
res_all$TLPRS_target_2[res_all$TLPRS_target_2 == res_all$Target] <- 'Target Pop.'

# Subset to tests comparing to the Unadjusted models
res_all <- res_all[res_all$Method_1 == res_all$Method_2, ]
res_all <- res_all[res_all$Source_2 == 'Multi', ]
res_all <- res_all[res_all$Test_1  == res_all$Test_2, ]
res_all <- res_all[res_all$TLPRS_2  == F, ]
res_all <- res_all[res_all$Target %in% c('EAS', 'AFR'),]

ggplot(res_all, aes(x = Method_2, y = R_diff, colour = Test_1)) +
  geom_point(position=position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7), alpha=0.5) +
  labs(y = "Difference in\nCorrelations (SE)", x = '') +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = 'y', minor = 'y') +
  facet_grid(Target ~ TLPRS_target_1, scales='free', space = 'free_x')


######
# Average R across phenotypes
######

library(MAd)

meta_res <- NULL
for(targ_pop_i in targ_pop){
  if(targ_pop_i == 'EAS'){
    disc_pop <- 'EAS'
  }
  if(targ_pop_i == 'AFR'){
    disc_pop <- 'AFR'
  }
  if(targ_pop_i == 'EUR'){
    disc_pop <- c('EAS','AFR')
  }
  for(disc_pop_i in disc_pop){
  
    # Subset res for each scenario
    res_i <- res_all[res_all$Target == targ_pop_i & res_all$gwas_group == paste0('EUR+', disc_pop_i), ]
  
    # Calculate diff SE based on p-value
    res_i$R_diff_pval[res_i$R_diff == 0] <- 1-0.001
    res_i$R_diff_pval[res_i$R_diff_pval == 1]<-1-0.001
    res_i$R_diff_z<-qnorm(res_i$R_diff_pval/2)
    res_i$R_diff_SE<-abs(res_i$R_diff/res_i$R_diff_z)
        
    # Average results for each test across phenotypes
    # Use MAd to account for correlation between them
    res_i$Sample<-'A'
    res_i$Group <- paste0(res_i$Model_1, '_vs_', res_i$Model_2)
  
    for(group_i in unique(res_i$Group)){
      res_group_i <- res_i[res_i$Group == group_i,]
      cors_i <- cors[[targ_pop_i]][unique(res_group_i$pheno), unique(res_group_i$pheno)]
      
      meta_res_i <-
        agg(
          id = Sample,
          es = R_diff,
          var = R_diff_SE ^ 2,
          cor = cors_i,
          method = "BHHR",
          mod = NULL,
          data = res_group_i
        )
      
      group_info <- res_group_i[1, !(names(res_group_i[1,]) %in% c('Model_1_R', 'Model_2_R', 'R_diff', 'R_diff_pval', 'R_diff_z', 'R_diff_SE')), with=F]
      meta_res <- rbind(meta_res,
                        data.table(
                          group_info,
                          R_diff = meta_res_i$es,
                          R_diff_SE = sqrt(meta_res_i$var)
                        ))
    }
  }
}
meta_res$R_diff_z <- meta_res$R_diff / meta_res$R_diff_SE
meta_res$R_diff_p <- 2*pnorm(-abs(meta_res$R_diff_z))

# Plot the results
ggplot(meta_res, aes(x=Method_1, y=R_diff, fill=Test_1)) +
  geom_hline(yintercept = 0, colour = 'darkgrey') +
  geom_point(
    data = res_all,
    mapping = aes(x=Method_1, y=R_diff, colour=Test_1),
    position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
    alpha = 0.3
  ) +
  geom_errorbar(
    aes(
      ymin = R_diff - R_diff_SE,
      ymax = R_diff + R_diff_SE
    ),
    width = 0,
    position = position_dodge(width = 0.7)
  ) +
  geom_point(
    stat = "identity",
    position = position_dodge(0.7),
    size = 2,
    shape = 23,
    colour = 'black'
  ) +
  labs(y = "Difference in\nCorrelations (SE)", x = '', fill = 'Model', colour = 'Model') +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = 1.5, linetype = "dotted") +
  geom_vline(xintercept = 2.5, linetype = "dotted") +
  geom_vline(xintercept = 3.5, linetype = "dotted") +
  background_grid(major = 'y', minor = 'y') +
  facet_grid(Target ~ TLPRS_target_1, scales='free', space = 'free_x') +
  panel_border()



# Plot the results
ggplot(meta_res[meta_res$TLPRS_target_1 == 'Both',], aes(x=Method_1, y=R_diff, fill=Test_1)) +
  geom_hline(yintercept = 0, colour = 'darkgrey') +
  geom_point(
    data = res_all[res_all$TLPRS_target_1 == 'Both',],
    mapping = aes(x=Method_1, y=R_diff, colour=Test_1),
    position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
    alpha = 0.3
  ) +
  geom_errorbar(
    aes(
      ymin = R_diff - R_diff_SE,
      ymax = R_diff + R_diff_SE
    ),
    width = 0,
    position = position_dodge(width = 0.7)
  ) +
  geom_point(
    stat = "identity",
    position = position_dodge(0.7),
    size = 2,
    shape = 23,
    colour = 'black'
  ) +
  labs(y = "Difference in\nCorrelations (SE)", x = '', fill = 'Model', colour = 'Model') +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = 1.5, linetype = "dotted") +
  geom_vline(xintercept = 2.5, linetype = "dotted") +
  geom_vline(xintercept = 3.5, linetype = "dotted") +
  background_grid(major = 'y', minor = 'y') +
  facet_grid(Target ~ ., scales='free', space = 'free_x') +
  panel_border()


# Plot the results
ggplot(meta_res[meta_res$TLPRS_target_1 == 'Both',], aes(x=Method_1, y=R_diff, fill=Test_1)) +
  geom_hline(yintercept = 0, colour = 'darkgrey') +
  geom_point(
    data = res_all[res_all$TLPRS_target_1 == 'Both',],
    mapping = aes(x=Method_1, y=R_diff, colour=Test_1),
    position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.7),
    alpha = 0.3
  ) +
  geom_errorbar(
    aes(
      ymin = R_diff - R_diff_SE,
      ymax = R_diff + R_diff_SE
    ),
    width = 0,
    position = position_dodge(width = 0.7)
  ) +
  geom_point(
    stat = "identity",
    position = position_dodge(0.7),
    size = 2,
    shape = 23,
    colour = 'black'
  ) +
  labs(y = "Difference in\nCorrelations (SE)", x = '', fill = 'Model', colour = 'Model') +
  theme_half_open() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = 1.5, linetype = "dotted") +
  geom_vline(xintercept = 2.5, linetype = "dotted") +
  geom_vline(xintercept = 3.5, linetype = "dotted") +
  background_grid(major = 'y', minor = 'y') +
  facet_grid(Target ~ ., scales='free', space = 'free_x') +
  panel_border()


```
</details>

***

# Computational resoures

```{r}
library(data.table)
library(ggplot2)
library(cowplot)

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Data/ukb/GenoPred/configs/crosspop/config.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Read in configuration specific benchmark files
bm_files_i <- list.files(paste0(outdir, '/reference/benchmarks/'), full.names = T)

# Subset benchmarks for pgs_methods
bm_files_i <- bm_files_i[grepl('prep_pgs_|leopard_quickprs_', bm_files_i)]

# Subset to benchmarks for gwas/gwas_groups in config
scores <- list_score_files(config)
bm_files_i <- bm_files_i[grepl(paste0('-', unique(scores$name),'.txt', collapse = '|'), bm_files_i)]

# Read in benchmark files
bm_dat_all <- do.call(rbind, lapply(bm_files_i, function(file) {
  tmp <- fread(file)
  tmp$file <- basename(file)
  return(tmp)
}))

# Create rule column
bm_dat_all$rule <- gsub('-.*','',bm_dat_all$file)

# Create method column
bm_dat_all$method <-
  gsub('_i', '', gsub('prep_pgs_', '', bm_dat_all$rule))

bm_dat_all <- merge(bm_dat_all, pgs_method_labels, by = 'method', all.x=T)

bm_dat_all$label[bm_dat_all$method == 'leopard_quickprs']<-"LEOPARD (QuickPRS)"

# Calculate average time taken for each method
method_avg <- NULL
for(i in unique(bm_dat_all$label)){
  method_avg <- rbind(
    method_avg,
    data.frame(
      method = bm_dat_all$method[bm_dat_all$label == i][1],
      Method = i,
      Time = mean(bm_dat_all$s[bm_dat_all$label == i])
    )
  )
}

# Times X-Wing time by two since it used 20 cores, but other methods used 10
method_avg$Time[method_avg$method == 'xwing'] <- method_avg$Time[method_avg$method == 'xwing'] * 2

# Calculate average max_rss for each method
method_avg_mem <- NULL
for(i in unique(bm_dat_all$label)){
  method_avg_mem <- rbind(
    method_avg_mem,
    data.frame(
      method = pgs_method_labels$method[pgs_method_labels$label == i],
      Method = i,
      Memory = mean(bm_dat_all$max_rss[bm_dat_all$label == i])
    )
  )
}

# Divide X-Wing memory by two, since it used 20 cores, but other methods used 10
method_avg$Memory[method_avg$method == 'xwing'] <- method_avg$Memory[method_avg$method == 'xwing'] /2

# Format the time taken nicely
method_avg$Time_clean[method_avg$Time < 60] <-
  paste0(round(method_avg$Time[method_avg$Time < 60], 1), ' sec')
method_avg$Time_clean[method_avg$Time > 60] <-
  paste0(round(method_avg$Time[method_avg$Time > 60] / 60, 1), ' min')
method_avg$Time_clean[method_avg$Time > 3600] <-
  paste0(round(method_avg$Time[method_avg$Time > 3600] / 60 / 60, 1), ' hr')

# Convert time in seconds to hours
method_avg$Time_hour <- method_avg$Time / 60/60

# Seperate methods by single or multi source
method_avg$Type[!(method_avg$method %in% pgs_group_methods)]<-'Single-source'
method_avg$Type[method_avg$method %in% pgs_group_methods]<-'Multi-source'
method_avg$Type[method_avg$method == 'leopard_quickprs']<-'Tuning'

method_avg$Type<-factor(method_avg$Type, levels = c('Single-source','Multi-source','Tuning'))
method_avg$Method <- factor(method_avg$Method, levels = c("DBSLMM", "lassosum", "LDpred2", "MegaPRS", "PRS-CS", "pT+clump", "QuickPRS", "SBayesRC", "QuickPRS-Multi", "PRS-CSx", "X-Wing","LEOPARD (QuickPRS)"))

ggplot(method_avg, aes(x = Method, y = Time_hour, fill = Method)) +
  geom_bar(stat = "identity", position="dodge") +
  geom_text(aes(label = Time_clean), vjust = 0.5, angle = 90, hjust = -0.2, position = position_dodge(width = 0.9)) +
  labs(x = NULL, y = "Time (hours)") +
  ylim(0, max(method_avg$Time_hour) + (max(method_avg$Time_hour)/5)) +
  facet_grid(~ Type, scales='free', space = 'free_x') +
  theme_half_open() +
  background_grid(major = 'y', minor = 'y') + 
  panel_border() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none")




time <- ggplot(method_avg, aes(x = Method, y = Time_hour, fill = Method)) +
  geom_bar(stat = "identity", position="dodge") +
  geom_text(aes(label = Time_clean), vjust = 0.5, angle = 90, hjust = -0.2, position = position_dodge(width = 0.9), size = 7) +
  labs(x = NULL, y = "Time (hours)") +
  ylim(0, max(method_avg$Time_hour) + (max(method_avg$Time_hour)/5)) +
  facet_grid(~ Type, scales='free', space = 'free_x') +
  theme_half_open() +
  background_grid(major = 'y', minor = 'y') + 
  panel_border() + 
  theme(axis.text.x = element_text(size = 24, angle = 45, hjust = 1), legend.position="none",
        axis.text.y = element_text(size = 24),  # Increase y-axis labels
        axis.title = element_text(size = 24),  # Increase axis titles
        strip.text = element_text(size = 24))

png('poster_plot2.png', width = 22, height = 31.5, res= 300, units = 'cm')
  time
dev.off()

ggplot(method_avg, aes(x = Method, y = Time, fill = Method)) +
  geom_bar(stat = "identity", position="dodge") +
  geom_text(aes(label = Time_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = "PGS Method", y = "Time (s)") +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none")

# Format the Memory nicely
method_avg_mem$Memory_clean <-
  paste0(round(method_avg_mem$Memory/1000, 2), ' Gb')

ggplot(method_avg_mem, aes(x = Method, y = Memory, fill = Method)) +
  geom_bar(stat = "identity", position="dodge") +
  geom_text(aes(label = Memory_clean), vjust = -0.5, position = position_dodge(width = 0.9)) +
  labs(x = "PGS Method", y = "Memory (Mb)") +
  theme_half_open() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position="none")

```

