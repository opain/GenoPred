---
title: "Mind the Gap: Quantifying and Recovering Polygenic Score Signal Lost to Variant Missingness"
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
    toc_depth: 2
    css: styles/styles.css
    includes:
      in_header: header.html
      after_body: footer.html

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
library(knitr)
```

***

# Overview

## Introduction

Polygenic scores (PGS) are increasingly used to stratify individuals by genetic risk for complex traits. However, their predictive performance depends not only on how well the score was trained, but also on how well the target dataset matches the score’s SNP content — in terms of variant availability, imputation quality, and linkage disequilibrium (LD) structure.

In practice, many variants in published score files are either missing or poorly imputed in real-world target datasets. This variant mismatch leads to reduced PGS performance, yet it is rarely quantified or addressed systematically. In this project, we evaluate how SNP availability and imputation quality affect polygenic score accuracy, and we implement LD-based methods to redistribute signal from missing variants to those that are available.

We benchmark theoretical and empirical approaches for estimating the relative performance of variant-restricted or imputation-filtered PGS, and show that LD-aware redistribution can recover a substantial portion of lost predictive power — without requiring phenotype data.

## Analysis Overview

### 1. Setup and Resources
- Define SNP sets: HapMap3, SBayesRC.
- Load score files from the PGS Catalog and GenoPred.
- Load or generate genotype data for OpenSNP, UK Biobank (target), and 1KG+HGDP (reference).
- Download imputation R² values from RSQ Browser and match to score files.

### 2. Variant Availability and Imputation Quality
- Quantify variant overlap between PGS and target genotypes.
- Visualise distributions of imputation R².
- Summarise missingness and mean imputation quality by method and dataset.

### 3. Theoretical R² Loss Estimation
- Estimate expected score variance using:
  - Marginal: \( \beta^2 \cdot 2f(1-f) \cdot R^2 \)
  - LD-aware: \( \beta^\top R \beta \)
- Compare retained R² across SNP sets and imputation thresholds.

### 4. LD-based Signal Redistribution
- Use LD projection to reassign weights from missing/low-R² SNPs to observed SNPs.
- Scale redistributed weights by imputation quality.
- Compare adjusted vs. original weights and resulting scores.

### 5. Empirical Validation of Relative Score Accuracy
- Compute scores in OpenSNP, UKB, and 1KG+HGDP:
  - Full vs. restricted vs. LD-adjusted scores.
- Estimate relative R² by score-score correlation:
  - \( R^2 = \text{cor}(PGS_{adjusted}, PGS_{full})^2 \)
- If phenotypes available (OpenSNP/UKB), compute score–trait correlation (optional).

### 6. Summary and Visualisation
- Plot relative R² loss and recovery across methods and datasets.
- Summarise tradeoffs between variant density, imputation quality, and performance.
- Highlight scenarios where LD-based adjustment is most beneficial.

### 7. Optional: Integration with GenoPred
- Use GenoPred pipeline to generate new scores using different SNP sets.
- Benchmark portability and performance using standardised outputs.

***

# Download and harmonise SNP lists

We need to combine the various lists of SNPs in some way. They are different dbSNP builds or genome builds. Lets harmonise them using the full dbSNP 151 dataset for non-ambiguous autosomal SNPs.

***

## HapMap3 

<details><summary>Show code</summary>

```{r}

setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
source('../functions/misc.R')
source_all('../functions')

# Read in the SNP data from the default GenoPred reference (1KG+HGDP HapMap3)
hm3 <- read_pvar('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref/ref.chr')
nrow(hm3) # 1204449

# Store snplist
dir.create('~/oliverpainfel/Analyses/mind_the_gap/snp_data', recursive = T)
saveRDS(hm3, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/hm3.rds')

```

</details>

***

## SBayesRC

<details><summary>Show code</summary>

```{bash}
# Download SBayesRC EUR LD reference with 7 million variants
cd ~/oliverpainfel/Data/SBayesRC/
gdown 1mKQ3uU_XD6zlNefxEWMl1M42I0gTyOs3 # ukbEUR_Imputed.tar.xz

# Extract snp.info file
tar -xvf ukbEUR_Imputed.tar.xz ukbEUR_Imputed/snp.info

# Download height PGS from SBayesRC paper
wget https://gctbhub.cloud.edu.au/data/SBayesRC/share/v1.0/PGS/HT.txt.gz

```

```{r}
library(data.table)
library(GenoUtils)

# Read in SBayesRC snp.info file
sbayesrc_snpinfo <- fread('~/oliverpainfel/Data/SBayesRC/ukbEUR_Imputed/snp.info') # Build GRCh37

# Delete information we don't need
sbayesrc_snpinfo <- sbayesrc_snpinfo[, c('Chrom', 'PhysPos', 'ID', 'A1', 'A2'), with=F]
names(sbayesrc_snpinfo) <- c('CHR','BP','SNP','A1','A2')

# Remove ambiguous variants
sbayesrc_snpinfo$IUPAC <- snp_iupac(sbayesrc_snpinfo$A1, sbayesrc_snpinfo$A2)
sbayesrc_snpinfo <- sbayesrc_snpinfo[sbayesrc_snpinfo$IUPAC != 'S' & sbayesrc_snpinfo$IUPAC != 'W',]
nrow(sbayesrc_snpinfo) # 6253944

# Insert RSIDs by merging with dbSNP reference based on CHR BP A1 A2 information (they are both GRCh37)
sbayesrc_snpinfo_harm <- NULL
for(i in 1:22){
  print(i)
  # Read in dbSNP data
  ref_i <- readRDS(paste0('~/oliverpainfel/Data/dbSNP/00-All.snps.nonambiguous.chr',i,'.rds'))
  
  # Insert IUPAC codes
  ref_i$IUPAC <- snp_iupac(ref_i$A1, ref_i$A2)

  # Rename columns prior to merging with target
  names(ref_i)<-paste0('REF.',names(ref_i))
  ref_i$BP<-ref_i[[paste0('REF.BP_GRCh37')]]
  ref_i<-ref_i[, c('REF.CHR','REF.SNP','BP','REF.A1','REF.A2','REF.IUPAC'), with=F]

  # Subset sbayesrc_snpinfo to chr == i
  target_i <- sbayesrc_snpinfo[sbayesrc_snpinfo$CHR == i,]
  
  # Merge by BP
  ref_target<-merge(target_i, ref_i, by = 'BP')
  
  # Identify targ-ref strand flips, and flip target
  flip_logical<-detect_strand_flip(targ = ref_target$IUPAC, ref = ref_target$REF.IUPAC)

  flipped<-ref_target[flip_logical,]
  flipped$A1<-snp_allele_comp(flipped$A1)
  flipped$A2<-snp_allele_comp(flipped$A2)
  flipped$IUPAC<-snp_iupac(flipped$A1, flipped$A2)
  
  # Identify SNPs that have matched IUPAC
  matched<-ref_target[ref_target$IUPAC == ref_target$REF.IUPAC,]
  matched<-rbind(matched, flipped)
  
  # Set REF.SNP to SNP column
  matched$SNP <- NULL
  names(matched)[names(matched) == 'REF.SNP']<-'SNP'

  sbayesrc_snpinfo_harm <- rbind(sbayesrc_snpinfo_harm, matched)
}

# Check number of variant in SBayesRC remaining after reference harmonisation
nrow(sbayesrc_snpinfo_harm) # 6254034 of 6253944

# Update column names
sbayesrc_snpinfo_harm <- sbayesrc_snpinfo_harm[, c('CHR', 'BP', 'SNP', 'A1', 'A2'), with = F]

# Store snplist for sbayesrc '7M' reference.
dir.create('~/oliverpainfel/Analyses/mind_the_gap/snp_data', recursive = T)
saveRDS(sbayesrc_snpinfo_harm, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/sbayesrc_7m.rds')

```

</details>

Interestingly, there are ~1M ambiguous variants in the SBayesRC reference. This limits the generalisability of the score files as hard to know which strand we are looking at. 

***

## RsqBrowser2

<details><summary>Show code</summary>

```{bash}
# Download imputation data across arrays and populations from Rsq Browser
cd ~/oliverpainfel/Data/RsqBrowser2
wget https://rsq-browser.i-med.ac.at/downloads/1/mlof.bi.snv.tab.gz
```

```{r}
library(data.table)
library(GenoUtils)

# Read in RsqBrowser data (Build GRCh38)
rsq <- fread('~/oliverpainfel/Data/RsqBrowser2/mlof.bi.snv.tab.gz')

# Remove columns we don't want
rsq <- rsq[,!grepl('_in$', names(rsq)), with=F]

# Update column names
names(rsq)[1:5] <- c('CHR', 'BP', 'A2', 'A1','FREQ')

# Remove 'chr' string from CHR
rsq$CHR <- as.numeric(gsub('chr', '', rsq$CHR))
  
# Remove ambiguous variants
rsq$IUPAC <- snp_iupac(rsq$A1, rsq$A2)
rsq <- rsq[rsq$IUPAC != 'S' & rsq$IUPAC != 'W',]
nrow(rsq) # 48306483

# Insert RSIDs by merging with dbSNP reference based on CHR BP A1 A2 information (they are both GRCh37)
rsq_harm <- NULL
for(i in 1:22){
  print(i)
  # Read in dbSNP data
  ref_i <- readRDS(paste0('~/oliverpainfel/Data/dbSNP/00-All.snps.nonambiguous.chr',i,'.rds'))
  
  # Insert IUPAC codes
  ref_i$IUPAC <- snp_iupac(ref_i$A1, ref_i$A2)

  # Rename columns prior to merging with target
  names(ref_i)<-paste0('REF.',names(ref_i))
  ref_i$BP<-ref_i[[paste0('REF.BP_GRCh38')]]
  ref_i<-ref_i[, c('REF.CHR','REF.SNP','BP','REF.BP_GRCh37','REF.A1','REF.A2','REF.IUPAC'), with=F]

  # Subset rsq to chr == i
  target_i <- rsq[rsq$CHR == i,]
  
  # Merge by BP
  ref_target<-merge(target_i, ref_i, by = 'BP')
  
  # Identify targ-ref strand flips, and flip target
  flip_logical<-detect_strand_flip(targ = ref_target$IUPAC, ref = ref_target$REF.IUPAC)

  flipped<-ref_target[flip_logical,]
  flipped$A1<-snp_allele_comp(flipped$A1)
  flipped$A2<-snp_allele_comp(flipped$A2)
  flipped$IUPAC<-snp_iupac(flipped$A1, flipped$A2)
  
  # Identify SNPs that have matched IUPAC
  matched<-ref_target[ref_target$IUPAC == ref_target$REF.IUPAC,]
  matched<-rbind(matched, flipped)

  # Set BP to GRCh37
  matched$BP <- NULL
  names(matched)[names(matched) == 'REF.BP_GRCh37']<-'BP'

  # Set REF.SNP to SNP column
  names(matched)[names(matched) == 'REF.SNP']<-'SNP'

  rsq_harm <- rbind(rsq_harm, matched)
}

# Check number of variant in SBayesRC remaining after reference harmonisation
nrow(rsq_harm) # 43991073 of 48306483

rsq_harm <- rsq_harm[, !(names(rsq_harm) %in% c('REF.CHR', 'REF.A1', 'REF.A2', 'REF.IUPAC', 'IUPAC')), with = F]

rsq_harm <- rsq_harm[, c('CHR','BP','SNP','A1','A2', names(rsq_harm)[!(names(rsq_harm) %in% c('CHR','BP','SNP','A1','A2'))]), with=F] 
  
# Store snplist for rsq reference.
saveRDS(rsq_harm, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# Reduce size of rsq by restricting to variants present in either hm3 or sbayesr
hm3 <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/hm3.rds')
sbayesrc <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/sbayesrc_7m.rds')
both <- rbind(hm3, sbayesrc)
both <- both[!duplicated(both),]

rsq_harm_subset <- rsq_harm[rsq_harm$SNP %in% both$SNP,]
rsq_harm_subset <- rsq_harm_subset[paste0(rsq_harm_subset$SNP, ':', rsq_harm_subset$A1, ':', rsq_harm_subset$A2) %in% paste0(both$SNP, ':', both$A1, ':', both$A2),]

saveRDS(rsq_harm_subset, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.rds')
```

</details>

***

# Download and harmonise PGSC score files

Download all score files for CAD from PGSC as an example. Harmonise with the reference using GenoPred.

```{bash}
# Make a temp directory containing GenoPred reference plink files, but dense .rds files, so we can use the external_score_processor script to harmonise.

mkdir ~/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp
for chr in $(seq 1 22);do
  for file in $(echo pvar pgen psam);do
  ln -s /users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred_dense/ref/ref.chr${chr}.${file} /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp/ref.chr${chr}.${file}
  done
  ln -s /users/k1806347/oliverpainfel/Data/dbSNP/00-All.snps.nonambiguous.chr${chr}.rds /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp/ref.chr${chr}.rds
done
ln -s /users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred_dense/ref/ref.pop.txt /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp/ref.pop.txt
ln -s /users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred_dense/ref/keep_files /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp/keep_files
ln -s /users/k1806347/oliverpainfel/Data/hgdp_1kg/genopred_dense/ref/freq_files /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp/freq_files

```

```{r}
######
# score_list
######
# Donwload a csv listing all PGS for CAD
library(data.table)
pgsc_cad <- fread('~/oliverpainfel/Analyses/mind_the_gap/pgsc/pgs_scores_data_cad.csv')

score_ids<-gsub(' .*','', pgsc_cad$`Polygenic Score ID & Name`)
score_list<- data.table(
  name = score_ids,
  path = NA,
  label = score_ids)

dir.create('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config', recursive = T)

write.table(score_list, '~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt', col.names = T, row.names = F, quote = F)

######
# config
######

config<-c(
  "outdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output",
  "refdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/dense_ref_tmp",
  "config_file: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_cad.yaml",
  "score_list: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt",
  "min_overlap_external: 0"
)

write.table(config, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_cad.yaml', col.names = F, row.names = F, quote = F)

```

```{bash}
snakemake \
  -j 20 \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_cad.yaml \
  prep_pgs_external -n
```

***

# Variant Availability and Imputation Quality

## Across SNP-lists

Check the number and imputation quality of HapMap3 and SBayesRC variants available across across arrays and imputation panels.

<details><summary>Show code</summary>

```{r}
library(data.table)

# Read in snplist and rsq information
hm3 <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/hm3.rds')
sbayesrc <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/sbayesrc_7m.rds')
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
hm3$CHR <- NULL
hm3$BP <- NULL
sbayesrc$CHR <- NULL
sbayesrc$BP <- NULL
rsq$CHR <- NULL
rsq$BP <- NULL

# Merge with hm3 and sbayesrc snplists
hm3_rsq <- merge(hm3, rsq, by = c('SNP','A1','A2'), all.x = T)
hm3_rsq <-melt(hm3_rsq, id.vars = c('SNP','A1','A2','FREQ'))
hm3_rsq$snplist <- 'hm3'
sbayesrc_rsq <- merge(sbayesrc, rsq, by = c('SNP','A1','A2'), all.x = T)
sbayesrc_rsq <-melt(sbayesrc_rsq, id.vars = c('SNP','A1','A2','FREQ'))
sbayesrc_rsq$snplist <- 'sbayesrc'
both_rsq <- rbind(hm3_rsq, sbayesrc_rsq)

both_rsq$array <- gsub('_.*','', both_rsq$variable)
both_rsq$panel <- gsub('.*_','', both_rsq$variable)

# Recode panels
both_rsq$panel <- factor(
  both_rsq$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
both_rsq$array <- factor(
  both_rsq$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

# assuming both_rsq is already a data.table
summary_tab <- both_rsq[, .(
  n            = .N,
  prop_non_na  = mean(!is.na(value)),
  prop_gt_0.5  = mean(value > 0.5,  na.rm = TRUE),
  prop_gt_0.9  = mean(value > 0.9,  na.rm = TRUE),
  prop_gt_0.95 = mean(value > 0.95, na.rm = TRUE),
  prop_gt_0.99 = mean(value > 0.99, na.rm = TRUE),
  mean_rsq     = mean(value,  na.rm = TRUE),
  median_rsq   = median(value, na.rm = TRUE)
), by = .(snplist, array, panel)]

library(ggplot2)
library(cowplot)

prop_long <- melt(
  summary_tab,
  id.vars = c("snplist","array","panel"),
  measure.vars = c("prop_non_na","prop_gt_0.5","prop_gt_0.9","prop_gt_0.95","prop_gt_0.99"),
  variable.name = "metric", value.name = "prop"
)

prop_long$metric <- factor(
  prop_long$metric,
  levels = c(
    'prop_non_na',
    'prop_gt_0.5',
    'prop_gt_0.9',
    'prop_gt_0.95',
    'prop_gt_0.99'
  ),
  labels = c('Missing', 'RSQ > 0.5', 'RSQ > 0.9', 'RSQ > 0.95', 'RSQ > 0.99')
)

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(prop_long, aes(x = array, y = prop, fill = snplist)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  facet_grid(metric ~ panel) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Genotyping array", y = "Proportion", fill = "SNP list",
       title = "Proportion metrics by SNP list, array, and reference panel") +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
dev.off()

# Make a boxplot
boxplot<- ggplot(both_rsq, aes(x = snplist, y = value, fill = snplist)) +
  geom_boxplot(outliers = FALSE) +
  labs(
    x = "SNP list",
    y = expression(Imputation~r^2),
    title = "Distribution of imputation r² across SNP list, array, and panel"
  ) +
  theme_classic() +
  theme_half_open() +
  background_grid() +
  panel_border() +
  facet_grid(array ~ panel, scales = "free_y") +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_boxplot.png',
    units = 'px',
    width = 3000,
    height = 3000,
    res = 300)

  boxplot

dev.off()

# Make a boxplot with outliers
boxplot<- ggplot(both_rsq, aes(x = snplist, y = value, fill = snplist)) +
  geom_boxplot() +
  labs(
    x = "SNP list",
    y = expression(Imputation~r^2),
    title = "Distribution of imputation r² across SNP list, array, and panel"
  ) +
  theme_classic() +
  theme_half_open() +
  background_grid() +
  panel_border() +
  facet_grid(array ~ panel, scales = "free_y") +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_boxplot_with_outliers.png',
    units = 'px',
    width = 3000,
    height = 3000,
    res = 300)

  boxplot

dev.off()

```

</details>

<details><summary>Show results</summary>

<div class="centered-container">
<div class="rounded-image-container" style="width: 60%;">
![](~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics.png)
</div>
</div>

<div class="centered-container">
<div class="rounded-image-container" style="width: 60%;">
![](~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_boxplot.png)
</div>
</div>

</details>

There is slightly worse imputation quality for the SBayesRC variants, but actually the Rsq is very high for both when using a typical array and TopMed imputation.

***

## PGSC score files

```{r}
# Read in the log files from the harmonisation log to check the number of variants originally and after harmonisation
library(tidyr)
library(dplyr)
score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

nsnps<-NULL
for(i in score_list$name){
  log <-
    readLines(
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        i,
        '/ref-',
        i,
        '.log'
      )
    )
  
  original <- log[grepl('Original score file contains', log)]
  original <- gsub('Original score file contains ', '', original)
  original <- gsub(' variants.', '', original)

  unmapped <- log[grepl('after removing variants that were not mapped ', log)]
  unmapped <- gsub('Score file contains ', '', unmapped)
  unmapped <- gsub(' variants after removing variants that were not mapped.*', '', unmapped)

  a2 <- log[grepl(' variants after removing multi-allelic', log)]
  a2 <- gsub('Score file contains ', '', a2)
  a2 <- gsub(' variants after removing multi-allelic.*', '', a2)

  non_auto <- log[grepl(' variants after removing those with chromosome not in:', log)]
  non_auto <- gsub('Score file contains ', '', non_auto)
  non_auto <- gsub(' variants after removing those with chromosome not in:.*', '', non_auto)
  
  nodup <- log[grepl('variants after removing duplicates.', log)]
  nodup <- gsub('Score file contains ', '', nodup)
  nodup <- gsub(' variants after removing duplicates.', '', nodup)

  n_ambig <- log[grepl('ambiguous variants\\.', log)]
  n_ambig <- gsub('Score file contains ', '', n_ambig)
  n_ambig <- gsub(' ambiguous variants.', '', n_ambig)
  nonambig_snp <- as.character(as.numeric(nodup) - as.numeric(n_ambig))
    
  n_flip <- log[grepl('non-ambiguous variants were flipped', log)]
  n_flip <- gsub(' non-ambiguous variants were flipped.*', '', n_flip)
  if(any(grepl('No variants were flipped', log))) n_flip <- '0'
  
  inref <- log[grepl('After matching variants to the reference', log)]
  inref <- gsub('After matching variants to the reference, ', '', inref)
  inref <- gsub(' variants remain.', '', inref)

  nsnps<-rbind(nsnps,
             data.table(
               ID = i,
               original = original,
               unmapped = unmapped,
               a2 = a2,
               non_auto = non_auto,
               nodup = nodup,
               n_ambig = n_ambig,
               nonambig_snp = nonambig_snp,
               n_flip = n_flip,
               inref = inref
             ))
}

nsnps$original <- as.numeric(nsnps$original)
nsnps$unmapped <- as.numeric(nsnps$unmapped)
nsnps$a2 <- as.numeric(nsnps$a2)
nsnps$non_auto <- as.numeric(nsnps$non_auto)
nsnps$nodup <- as.numeric(nsnps$nodup)
nsnps$n_ambig <- as.numeric(nsnps$n_ambig)
nsnps$nonambig_snp <- as.numeric(nsnps$nonambig_snp)
nsnps$n_flip <- as.numeric(nsnps$n_flip)
nsnps$inref <- as.numeric(nsnps$inref)

# Very few variants are being removed due to being autosomal, but this is a limitation of GenoPred, so discount the effect of this filter.
nsnps$original <- nsnps$original - (nsnps$a2 - nsnps$non_auto)
nsnps$unmapped <- nsnps$unmapped - (nsnps$a2 - nsnps$non_auto)
nsnps$a2 <- nsnps$a2 - (nsnps$a2 - nsnps$non_auto)

write.csv(nsnps, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/n_snp.csv', row.names = F, quote= F)

# Calculate loss at each stage
step_loss <- nsnps %>%
  transmute(
    ID,
    `Unmapped`       = (original - unmapped) / original,
    `Unknown A2`       = (unmapped - a2) / original,
    `Duplicated`       = (non_auto - nodup) / original,
    `Strand\nAmbiguous`   = (nodup - nonambig_snp) / nodup,
    `Not in dbSNP`   = (nonambig_snp - inref) / nonambig_snp,
    `All criteria`   = (original - inref) / original,
    `All criteria\n(excl. ambiguous)`   = (original - (inref + n_ambig)) / original
  ) %>%
  pivot_longer(-ID, names_to = "step", values_to = "lost_prop")

# There are no variants lost due to being duplicates
step_loss <- step_loss[step_loss$step != 'Duplicated',]

# Count number of PGS loosing >2% of variants
sum(step_loss$lost_prop[step_loss$step == "All criteria"] > 0.05) # 41
sum(step_loss$lost_prop[step_loss$step == "All criteria\n(excl. ambiguous)"] > 0.05) # 22
length(unique(step_loss$ID)) # 78

step_loss$step <- factor(step_loss$step, levels = unique(step_loss$step))

# Make plots
png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_violin.png',
    units = 'px', width = 2500, height = 1500, res = 300)
ggplot(step_loss, aes(step, lost_prop)) +
  geom_violin(fill = "steelblue", alpha = 0.6, trim = FALSE, bw = 0.005) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0, NA)) +
  labs(x = NULL, y = "Proportion of variants lost") +
  theme_half_open() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_hist_excl_ambig.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  step_loss[step_loss$step == "All criteria\n(excl. ambiguous)", ], 
  aes(x = lost_prop)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Proportion of variants lost', y = 'Number of PGS') +
  theme_half_open() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_hist_all.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  step_loss[step_loss$step == "All criteria", ], 
  aes(x = lost_prop)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Proportion of variants lost', y = 'Number of PGS') +
  theme_half_open() +
  background_grid()
dev.off()

sum_bar <- step_loss %>%
  group_by(step) %>%
  summarise(mean_loss = mean(lost_prop, na.rm = TRUE), .groups = "drop")
sum_bar$step <- as.character(sum_bar$step)
sum_bar$step[sum_bar$step == "Strand\nAmbiguous"] <- "Strand Ambiguous"
sum_bar$step<-factor(sum_bar$step, levels = unique(sum_bar$step), labels = sum_bar$step)

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_stacked.png',
    units = 'px', width = 1500, height = 1500, res = 300)
ggplot(sum_bar[sum_bar$step != "All criteria\n(excl. ambiguous)" & sum_bar$step != "All criteria",], aes(x = "All PGS", y = mean_loss, fill = step)) +
  geom_bar(stat = "identity", width = 0.6, colour = 'black') +
  scale_y_continuous() +
  scale_fill_brewer(palette = "Blues", direction = 1) +
  labs(x = NULL, y = "Proportion of variants lost (mean)", fill = "Filter") +
  theme_half_open() +
  background_grid()
dev.off()

# The vast majority of non-ambiguous variants are present in the reference. Some variants are not in the dbSNP file I downloaded, and they will not be in the 1KG+HGDP reference either.

# 15 of the 78 score files required non-ambiguous variants to be flipped to the positive strand. In some cases just 1 of 6M variants had to be flipped. The maximum proportion of non-ambiguous variants that had to be flipped was 5%, but usually it is a tiny percentage. I suppose this means it is fairly safe to assume the ambiguous variants will also be on the positive strand more often than not.

nsnps$prop_flip <- nsnps$n_flip/nsnps$nonambig_snp

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_hist_strandambig.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  nsnps, 
  aes(x = prop_flip)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Proportion of non-ambiguous on reverse strand', y = 'Number of PGS') +
  theme_half_open() +
  background_grid()
dev.off()

# It is hard to understand why the strand flips would have occured. Some of the score files with flips are from PRS-CS which should align everything to the PRS-CS reference, which is presumably on the forward strand. To make GenoPred fully flexible, it should probably allow for strand ambiguous variants, and just report the proportion of strand flips among non-ambiguous variants. Then user can use ambiguous variants if they are sure their data is on the forward strand, and set keep ambiguous in the config, like pgsc_calc. This will make the reference data much larger than it is now. This will allow for the SBayesRC 7M variant reference, and PGSC score files better.

# Make a histogram showing distribution of original nsnp
png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_hist_original.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  nsnps, 
  aes(x = original)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'N SNP', y = 'Number of PGS') +
  theme_half_open() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/pgsc_filtering_hist_original_low.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  nsnps[nsnps$original < 20000,], 
  aes(x = original)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'N SNP', y = 'Number of PGS') +
  theme_half_open() +
  background_grid()
dev.off()

```

```{r}
library(data.table)

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL
rsq$IUPAC <- snp_iupac(rsq$A1, rsq$A2)
rsq$A1 <- NULL
rsq$A2 <- NULL

summary_tab <- NULL
for(i in score_list$name){
  
  # Read in score file
  score_i <- fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        i,
        '/ref-',
        i,
        '.harmonised.gz'
      ))
  
  # We will merge by SNP, A1 and A2 information, so delete other information
  score_i$CHR <- NULL
  score_i$BP <- NULL
  #score_i$effect_weight <- NULL
  
  # Merge rsq with score file
  score_i$IUPAC <- snp_iupac(score_i$A1, score_i$A2)
  score_i$A1 <- NULL
  score_i$A2 <- NULL
  score_i_rsq <- merge(score_i, rsq, by = c('SNP','IUPAC'), all.x = T)
  score_i_rsq$IUPAC <- NULL
  score_i_rsq <-melt(score_i_rsq, id.vars = c('SNP'))
  score_i_rsq$ID <- i
  
  score_i_rsq$array <- gsub('_.*','', score_i_rsq$variable)
  score_i_rsq$panel <- gsub('.*_','', score_i_rsq$variable)

  summary_tab_i <- score_i_rsq[, .(
    n            = .N,
    prop_non_na  = mean(!is.na(value)),
    prop_gt_0.5  = mean(value > 0.5,  na.rm = TRUE),
    prop_gt_0.9  = mean(value > 0.9,  na.rm = TRUE),
    prop_gt_0.95 = mean(value > 0.95, na.rm = TRUE),
    prop_gt_0.99 = mean(value > 0.99, na.rm = TRUE),
    mean_rsq     = mean(value,  na.rm = TRUE),
    median_rsq   = median(value, na.rm = TRUE)
  ), by = .(ID, array, panel)]

  summary_tab <- rbind(summary_tab, summary_tab_i)
}

# Recode panels
summary_tab$panel <- factor(
  summary_tab$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
summary_tab$array <- factor(
  summary_tab$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

library(ggplot2)
library(cowplot)

prop_long <- melt(
  summary_tab,
  id.vars = c("ID","array","panel"),
  measure.vars = c("prop_non_na","prop_gt_0.5","prop_gt_0.9","prop_gt_0.95","prop_gt_0.99"),
  variable.name = "metric", value.name = "prop"
)

prop_long$metric <- factor(
  prop_long$metric,
  levels = c(
    'prop_non_na',
    'prop_gt_0.5',
    'prop_gt_0.9',
    'prop_gt_0.95',
    'prop_gt_0.99'
  ),
  labels = c('Non-missing', 'RSQ > 0.5', 'RSQ > 0.9', 'RSQ > 0.95', 'RSQ > 0.99')
)

saveRDS(prop_long, '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics_pgs.rds')
prop_long<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics_pgs.rds')

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics_pgs.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(prop_long[prop_long$ID %in% unique(prop_long$ID)[1:5],], aes(x = array, y = prop, fill = ID)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  facet_grid(metric ~ panel) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Genotyping array", y = "Proportion", fill = "SNP list",
       title = "Proportion metrics by SNP list, array, and reference panel") +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) 
dev.off()


ggplot(prop_long, aes(x = array, y = prop, fill = panel)) +
  geom_boxplot(width = 0.15) +
  facet_wrap(~ metric, ncol = 1, scales = "free_y") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Proportion", title = "Distribution by metric, array, and panel") +
  theme_minimal(base_size = 12)

```

***

# Estimate PGS performance drop

Here we will estimate the relative decrease in PGS R2 due to removal of ambiguous variants, and poor imputation of non-ambiguous variants. We will use the PGSC CAD score files as an example, estimating the impact of missing variants based on the effect size and allele frequency of the variants. This will only be done for the non-ambiguous variants, and then extrapolated to ambiguous variants (since they will follow the same distribution of effect size and allele frequency).

```{r}
library(data.table)
library(dplyr)
library(purrr)
library(tidyr)

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL
rsq$IUPAC <- snp_iupac(rsq$A1, rsq$A2)
rsq$A1 <- NULL
rsq$A2 <- NULL

# Insert genotype variance
rsq$vg <- 2 * rsq$FREQ * (1 - rsq$FREQ)

# Make function for estimating relative PGS R2
rel_pgs_r2 <- function(beta, vg, rsq){
  # Calculate variance of PGS without missingness
  denom <- sum(beta^2 * vg)

  # Calculate variance of PGS allowing for imputation rsq
  num <- sum(beta^2 * vg * rsq) 
  
  # Calculate relative R2
  return(num / denom)
}

# --- Relative R^2 retained when masking a subset of variants (uses vg only) ---
.rel_r2_with_mask_vg <- function(dat, vg_col = "vg", mask_idx = integer(0)) {
  stopifnot(vg_col %in% names(dat))
  vg_all <- dat[[vg_col]]
  denom  <- sum(vg_all, na.rm = TRUE)
  if (!is.finite(denom) || denom <= 0) return(NA_real_)
  if (length(mask_idx)) vg_keep <- vg_all[-mask_idx] else vg_keep <- vg_all
  num <- sum(vg_keep, na.rm = TRUE)
  num / denom
}

# --- 1) Learn missingness -> relative-R^2 curve (non-ambiguous variants only) ---
pgs_r2_vs_missingness_vg <- function(dat_nonambig,
                                     vg_col = "vg",
                                     m_grid = seq(0, 0.6, by = 0.05),
                                     n_sims = 50,
                                     seed = 1) {
  stopifnot(vg_col %in% names(dat_nonambig))
  dat_nonambig <- dat_nonambig %>% filter(is.finite(.data[[vg_col]]))
  stopifnot(nrow(dat_nonambig) > 10)
  set.seed(seed)

  sims <- map_dfr(m_grid, function(m) {
    S <- nrow(dat_nonambig)
    k <- floor(m * S)
    rels <- replicate(n_sims, {
      idx <- if (k > 0) sample.int(S, size = k, replace = FALSE) else integer(0)
      .rel_r2_with_mask_vg(dat_nonambig, vg_col, idx)
    })
    tibble(missing_prop = m,
           rel_mean = mean(rels, na.rm = TRUE),
           rel_median = median(rels, na.rm = TRUE),
           rel_sd = sd(rels, na.rm = TRUE),
           rel_q05 = quantile(rels, 0.05, na.rm = TRUE),
           rel_q95 = quantile(rels, 0.95, na.rm = TRUE))
  })

  # Often close to linear: loss ≈ slope * missing_prop
  fit <- lm(I(1 - rel_mean) ~ 0 + missing_prop, data = sims)
  list(curve = sims, slope = unname(coef(fit)[1]), model = fit)
}

pgs_r2 <- NULL
for(i in score_list$name){
  
  # Read in score file
  score_i <- fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        i,
        '/ref-',
        i,
        '.harmonised.gz'
      ))
  
  # We will merge by SNP, A1 and A2 information, so delete other information
  score_i$CHR <- NULL
  score_i$BP <- NULL
  #score_i$effect_weight <- NULL
  
  # Merge rsq with score file
  score_i$IUPAC <- snp_iupac(score_i$A1, score_i$A2)
  score_i$A1 <- NULL
  score_i$A2 <- NULL
  score_i_rsq <- merge(score_i, rsq, by = c('SNP','IUPAC'), all.x = T)
  
  # Set rsq of missing variants as 0
  score_i_rsq[is.na(score_i_rsq)]<-0
  
  # Calculate relative PRS R2 across arrays and panels
  for(j in c("HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")){
    pgs_r2<-rbind(pgs_r2, data.table(
      ID = i,
      group = j,
      rel_r2 = rel_pgs_r2(beta=score_i_rsq$effect_weight, vg=score_i_rsq$vg, rsq = score_i_rsq[[j]])
    ))
  }
}

# For the last score files looked estimate relationship between missingness and PGS R2
curve_fit <- pgs_r2_vs_missingness_vg(
  dat_nonambig = score_i_rsq,
  vg_col = "vg",
  m_grid = seq(0, 0.6, by = 0.05),
  n_sims = 20
)

plot(curve_fit$curve$missing_prop, curve_fit$curve$rel_mean)
# This shows the relationship is linear when missingness is random.

pgs_r2$array <- gsub('_.*','', pgs_r2$group)
pgs_r2$panel <- gsub('.*_','', pgs_r2$group)

# Recode panels
pgs_r2$panel <- factor(
  pgs_r2$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
pgs_r2$array <- factor(
  pgs_r2$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

library(ggplot2)
library(cowplot)

saveRDS(pgs_r2, '~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs.rds')
pgs_r2<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs.rds')

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2[pgs_r2$ID %in% unique(pgs_r2$ID)[1:5],], aes(x = array, y = rel_r2, fill = ID)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  facet_grid(. ~ panel) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Genotyping array", y = "Proportion", fill = "SNP list",
       title = "Relative PGS performance by platform and array") +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) 
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2, aes(x = array, y = rel_r2, fill = panel)) +
  geom_boxplot(width = 0.15) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Proportion", title = "Distribution by metric, array, and panel") +
  theme_minimal(base_size = 12)
dev.off()

```

After talking with Naomi I have realised that this variance only (diagonal-only / 2pq) approach for estimating the relative decrease in PGS does not take into account covariance between SNPs, which will make the relative PGS R2 estimate less accurate. We can use the SBayesRC eigen decomposed LD matrices to account for the covariance properly.

Another point that was made by Naomi, is that for an individual it is more about the genotype probabilities than the sample-level info. Often genotype probabilities are not available, and often we only have hard calls, so imputation quality is not available either. This PGS uncertainty due to imputation certainty can only be computed for some genotype data formats. If it is just hard calls then the relative PGS R2 can only account for missing variants, and assume variants that are present are well imputed. Calculating INFO will only be possible for samples with >100 individuals. 

Steps forward, make GenoPred better for using external score files by including a denser reference, then include a relative PGS R2 estimator (using INFO if available - bgen,plink2,vcf and N > 100), and PGS R2 recovery method.

Make a reference only including common variants, but include the ambiguous variants to be more inclusive and assume everything on positive strand unless evidence of otherwise.

Question for Naomi, the QS metric should be specific to a given target ancestry?

***

# Estimate PGS performance drop accounting for LD

Same as before but this time allowing for LD when estimating relative R2.

```{r}

setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(ggplot2)
library(cowplot)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL

# Restrict to variants in the dense SBayesRC reference
sbayesrc_info<-fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR/snp.info')
rsq_subset <- rsq[rsq$SNP %in% sbayesrc_info$ID,]

# Read in score list
score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Combine all the score files
ref <- sbayesrc_info[, c('ID','A1','A2'), with =F]
names(ref) <- c('SNP','A1','A2')

betas <- foreach(i = 1:nrow(score_list), .combine = cbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
  tmp <-  fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[i],
        '/ref-',
        score_list$name[i],
        '.unmapped.score.gz'
      ), nThread= 1)
  
  tmp$CHR <- NULL
  tmp$BP <- NULL
  tmp <- map_score(ref = ref, score = tmp)
  print(i)
  print(nrow(tmp))
  tmp
}

betas <- betas[, names(betas) == 'SCORE_external', with = F]
colnames(betas)<-score_list$name
score_file<-data.table(ref, betas)

# Restrict score file to rows with non-zero betas
score_file <- score_file[apply(betas, 1, function(x) !all(x == 0)),]

for(panel_i in c(
      "HC_1kg",
      "HC_hrc",
      "HC_top",
      "OE_1kg",
      "OE_hrc",
      "OE_top",
      "IO_1kg",
      "IO_hrc",
      "IO_top",
      "MG_1kg",
      "MG_hrc",
      "MG_top"
    )){
  
  # Subset rsqbrowser panel
  rsq_subset_j <- rsq_subset[, c('SNP', panel_i), with = F]
  rsq_subset_j$F_MISS <- 1 - rsq_subset_j[[panel_i]]

  # Calculate relative R2
  rel_r2 <- rel_pgs_r2_missing_eigen(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
      score_df = score_file,
      f_miss = rsq_subset_j)
  
  write.table(
    rel_r2, 
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      panel_i,
      '.rsq.txt'
    ), col.names = T, row.names = F, quote = F)
}

```

```{r}
library(data.table)
library(tidyr)
library(dplyr)
library(ggplot2)
library(cowplot)

panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

pgs_r2 <- NULL
for(i in panels){
  tmp <- fread(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      i,
      '.rsq.txt'
    )
  )
  tmp$group <- i
  pgs_r2 <- rbind(pgs_r2, tmp)
}

pgs_r2$array <- gsub('_.*','', pgs_r2$group)
pgs_r2$panel <- gsub('.*_','', pgs_r2$group)

# Recode panels
pgs_r2$panel <- factor(
  pgs_r2$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
pgs_r2$array <- factor(
  pgs_r2$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

saveRDS(pgs_r2, '~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_ldaware.rds')

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_eigen.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2, aes(x = array, y = relative_R2, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Relative R2", title = "Distribution by metric, array, and panel") +
  theme_half_open() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/var_metrics_eigen.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2, aes(x = array, y = relative_variance, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Relative Variance", title = "Distribution by metric, array, and panel") +
  theme_half_open() +
  background_grid()
dev.off()


# Plot histogram of relative R2 for bets array and panel
png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rel_r2_omni_topmed_hist.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  pgs_r2[pgs_r2$group == 'IO_top',], 
  aes(x = relative_R2)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Relative PGS R2', y = 'N PGS') +
  theme_half_open() +
  background_grid()
dev.off()

# Read in the number of non-zero variants that were not in the eigen LD data
nsnps <- fread('~/oliverpainfel/Analyses/mind_the_gap/snp_data/n_snp.csv')
nsnps <- nsnps[, c('ID','inref'), with = F]
names(nsnps) <- c('beta_set','n_nz')

# Plot number of variants not in eigen reference
pgs_r2 <- merge(pgs_r2, nsnps, by = 'beta_set')
pgs_r2$n_miss <- pgs_r2$n_nz - pgs_r2$n_in_ref
pgs_r2$prop_miss <- pgs_r2$n_miss / pgs_r2$n_nz

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/prop_miss_eigen_hist.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  pgs_r2[pgs_r2$group == 'HC_1kg',], 
  aes(x = prop_miss)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Missing from LD reference', y = 'N PGS') +
  theme_half_open() +
  background_grid()
dev.off()

# Calculate medians
median_table <- pgs_r2 %>%
  group_by(panel, array) %>%
  summarise(median_prop_miss = median(prop_miss, na.rm = TRUE),
            median_rel_r2 = median(relative_R2, na.rm = TRUE),
            median_rel_var = median(relative_variance, na.rm = TRUE),
            .groups = "drop") %>%
  arrange(panel, array)

mean_table <- pgs_r2 %>%
  group_by(panel, array) %>%
  summarise(mean_prop_miss = mean(prop_miss, na.rm = TRUE),
            mean_rel_r2 = mean(relative_R2, na.rm = TRUE),
            mean_rel_var = mean(relative_variance, na.rm = TRUE),
            .groups = "drop") %>%
  arrange(panel, array)
```

The main limitation of this analysis is that it only considers SNPs in the SBayesRC matrix, well imputed common variants.

***

# Evaluate method for estimating relative PGS R2 given missingness and imperfect imputation

Lets remove variants with INFO below certain thresholds, and see whether the observed decrease in R2 can be predicted using our estimator. To make this computationally efficient, remove variants with INFO below certain threshold from the score file.

***

## Calculate baseline PGS

No missingness.

```{r}
# Subset the 1KG+HGDP reference to EUR individuals with variants in SBayesRC reference and RsqBrowser
dir.create('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target', recursive = T)

merge_list <- paste0('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr', 1:22)
write.table(merge_list, '~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/merge_list.txt', col.names = F, row.names = F, quote = F)

sbayesrc_snpinfo <- fread('~/oliverpainfel/Data/SBayesRC/ukbEUR_Imputed/snp.info') # Build GRCh37
ref<-NULL
for(i in 1:22){
  ref <- rbind(ref, readRDS(paste0('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr', i,'.rds')))
}

ref_subset <- merge(
  ref[, c('CHR', 'SNP', 'BP_GRCh37', 'A1', 'A2'), with = F], 
  sbayesrc_snpinfo[, c('Chrom', 'PhysPos', 'A1', 'A2')],
  by.x = c('CHR','BP_GRCh37'), by.y = c('Chrom', 'PhysPos'))

ref_subset <- ref_subset[ (A1.x == A1.y & A2.x == A2.y) |
                          (A1.x == A2.y & A2.x == A1.y),]

rsqtab  <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')
ref_subset <- ref_subset[ref_subset$SNP %in% rsqtab$SNP,]

write.table(ref_subset$SNP, '~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/extract.txt', col.names = F, row.names = F, quote = F)
```

```{bash}
# Merge chromosome 1-22
# Subset to SBayesRC reference variants
# Subset to EURmodule add plink2
plink2 \
  --pmerge-list ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/merge_list.txt \
  --extract ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/extract.txt \
  --keep /users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep \
  --freq \
  --make-pgen \
  --out ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target

```

```{bash}
# Calculate PGS in target using CAD PGS files
mkdir -p ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline

for id in $(tail -n+2 ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt | cut -f 1 -d ' '); do
  sbatch --mem 2G -n 1 -p neurohack_cpu -t 1:00:00 --wrap="
  zcat ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.gz \
    | awk 'NR==1 || \$4 != 0' \
    | gzip > ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz"
done

for id in $(tail -n+2 ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt | cut -f 1 -d ' '); do
  sbatch --mem 2G -n 1 -p neurohack_cpu -t 1:00:00 --wrap="
  plink2 \
    --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
    --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums center \
    --out ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/${id}"
done

```

***

## Calculate PGS with missingness

```{r}
# List variants with RSQ > x
dir.create('~/oliverpainfel/Analyses/mind_the_gap/sim/masking')

library(data.table)
freq    <- fread("~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target.afreq")
freq <- freq[, c('ID','REF','ALT','ALT_FREQS'), with = F]
names(freq)<-c('SNP','A2','A1','FREQ')
rsqtab  <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')
rsqtab_subset <- rsqtab[, c('SNP','HC_1kg'), with = F]
names(rsqtab_subset) <- c('SNP','call')
rsqtab_subset <- rsqtab_subset[rsqtab_subset$SNP %in% freq$SNP,]

info_thresh <- c(0.5, 0.6, 0.7, 0.8)
for(i in info_thresh){
  fwrite(rsqtab_subset[call > i, 'SNP', with = F], paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p',i,'.list'), col.names=F, quote = F)
}

```

```{bash}
mkdir -p ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked

for rsq in $(echo 0.5 0.6 0.7 0.8); do
for id in $(tail -n+2 ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt | cut -f 1 -d ' '); do
  sbatch --mem 2G -n 1 -p neurohack_cpu -t 1:00:00 --wrap="
  plink2 \
    --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
    --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums center \
    --extract ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p${rsq}.list \
    --out ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/${id}.rsq_p${rsq}"
done
done

```

***

## Calculate observed relative PGS R2

```{r}
# Test variance explained between baseline and masked PGS
# Read in PGS
info_thresh <- c(0.5, 0.6, 0.7, 0.8)
score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

results <- NULL
for(rsq in info_thresh){
  for(i in score_list$name){
    if(!file.exists(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', i,'.sscore'))){
      next
    }
    
    baseline_pgs <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', i,'.sscore'))
    baseline_pgs <- baseline_pgs[,c('#IID', 'SCORE1_SUM'), with=F]

    masked_pgs <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/',i,'.rsq_p', rsq, '.sscore'))
    masked_pgs <- masked_pgs[,c('#IID', 'SCORE1_SUM'), with=F]

    results <- rbind(
      results,
      data.frame(
        ID = i,
        rsq = rsq,
        var_baseline = var(baseline_pgs$SCORE1_SUM),
        var_masked = var(masked_pgs$SCORE1_SUM),
        rel_r2_var = var(masked_pgs$SCORE1_SUM) / var(baseline_pgs$SCORE1_SUM),
        rel_r2_cor = cor(baseline_pgs$SCORE1_SUM, masked_pgs$SCORE1_SUM)^2
      )
    )
  }
}

write.table(
  results,
  '~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/relative_r2_no_pheno.txt',
  col.names = T, row.names = F, quote = F)

```

***

## Estimate relative PGS R2

```{r}
# Now estimate the relative R2 of PGS after masking variants
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(ggplot2)
library(cowplot)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

info_thresh <- c(0.5, 0.6, 0.7, 0.8)

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Combine all the score files
ref <- fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[1],
        '/ref-',
        score_list$name[1],
        '.score.gz'
      ))[, c('SNP','A1','A2'), with=F]

betas <- foreach(i = 1:nrow(score_list), .combine = cbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
  tmp <-  fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[i],
        '/ref-',
        score_list$name[i],
        '.score.gz'
      ), nThread= 1) [,-1:-3, with = F]
  print(nrow(tmp))
  tmp
}

colnames(betas)<-score_list$name
score_file<-data.table(ref, betas)

# Restrict score file to rows with non-zero betas
score_file <- score_file[apply(betas, 1, function(x) !all(x == 0)),]

# Restrict score files to variants present in target sample for comparability
freq    <- fread("~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target.afreq")
freq <- freq[, c('ID','REF','ALT','ALT_FREQS'), with = F]
names(freq)<-c('SNP','A2','A1','FREQ')

score_file <- score_file[score_file$SNP %in% freq$SNP,]

for(i in info_thresh){
  # Create call rate data.frame
  snplist <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p',i,'.list'), header=F)$V1
  call_rate <- data.table(
    SNP = score_file$SNP
  )
  call_rate$F_MISS <- 1
  call_rate$F_MISS[call_rate$SNP %in% snplist] <- 0

  # Calculate relative R2 (on each chromosome like in GenoPred)
  rel_r2 <- rel_pgs_r2_missing_eigen(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
      score_df = score_file,
      f_miss = call_rate)
  
  write.table(
    rel_r2,
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/relative.rsq_p',
      i,
      '.txt'
    ),
    col.names = T,
    row.names = F,
    quote = F
  )
}

```

***

## Compare estimated and masking 'observed' relative R2

```{r}
# Compare estimated and observed relative R2
obs_rel_r2 <- fread('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/relative_r2_no_pheno.txt')
setnames(obs_rel_r2, 'rel_r2_cor', 'obs_rel_r2')
setnames(obs_rel_r2, 'rel_r2_var', 'obs_rel_var')

info_thresh <- c(0.5, 0.6, 0.7, 0.8)

est_rel_r2 <- NULL
for(i in info_thresh){
  tmp <- fread(paste0('/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/relative.rsq_p', i,'.txt'))
  setnames(tmp, 'beta_set', 'ID')
  tmp$rsq <- i
  est_rel_r2 <- rbind(est_rel_r2, tmp)
}

both <- merge(obs_rel_r2, est_rel_r2, by = c('ID','rsq'))
both$rsq <- paste0('Masked RSQ < ', both$rsq)

library(dplyr)

N <- nrow(both)

# Compare estimated and observed relative R2
metrics <- both %>%
  group_by(rsq) %>%
  summarise(
    pearson_r = cor(relative_R2, obs_rel_r2, use="complete.obs"),
    spearman_rho = cor(relative_R2, obs_rel_r2, method="spearman", use="complete.obs"),
    # Fisher z CI for Pearson r
    z = atanh(pearson_r),
    se_z = 1 / sqrt(N - 3),
    r_low = tanh(z - 1.96 * se_z),
    r_high = tanh(z + 1.96 * se_z),
    # Regression slope + CI
    slope = coef(lm(obs_rel_r2 ~ relative_R2))[2],
    slope_ci_low = confint(lm(obs_rel_r2 ~ relative_R2))[2,1],
    slope_ci_high = confint(lm(obs_rel_r2 ~ relative_R2))[2,2],
    .groups = "drop"
  )

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

png('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/obs_est_rel_r2_validation.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(both, aes(x = both$relative_R2, y = both$obs_rel_r2)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_wrap(. ~ rsq) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = 'Estimated relative R2', y = 'Observed relative R2') +
  geom_text(data = metrics, aes(x = 0.3, y = 0.95, label = text), inherit.aes = FALSE, size = 4)

dev.off()

# Compare estimated and observed relative variance
metrics <- both %>%
  group_by(rsq) %>%
  summarise(
    pearson_r = cor(relative_variance, obs_rel_var, use="complete.obs"),
    spearman_rho = cor(relative_variance, obs_rel_var, method="spearman", use="complete.obs"),
    # Fisher z CI for Pearson r
    z = atanh(pearson_r),
    se_z = 1 / sqrt(N - 3),
    r_low = tanh(z - 1.96 * se_z),
    r_high = tanh(z + 1.96 * se_z),
    # Regression slope + CI
    slope = coef(lm(obs_rel_var ~ relative_variance))[2],
    slope_ci_low = confint(lm(obs_rel_var ~ relative_variance))[2,1],
    slope_ci_high = confint(lm(obs_rel_var ~ relative_variance))[2,2],
    .groups = "drop"
  )

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

png('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/obs_est_rel_var_validation.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(both, aes(x = both$relative_variance, y = both$obs_rel_var)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_wrap(. ~ rsq) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = 'Estimated relative variance', y = 'Observed relative variance') +
  geom_text(data = metrics, aes(x = 0.3, y = 0.95, label = text), inherit.aes = FALSE, size = 4)

dev.off()

# Compare observed relative R2 and observed relative variance
metrics <- both %>%
  group_by(rsq) %>%
  summarise(
    pearson_r = cor(obs_rel_r2, obs_rel_var, use="complete.obs"),
    spearman_rho = cor(obs_rel_r2, obs_rel_var, method="spearman", use="complete.obs"),
    # Fisher z CI for Pearson r
    z = atanh(pearson_r),
    se_z = 1 / sqrt(N - 3),
    r_low = tanh(z - 1.96 * se_z),
    r_high = tanh(z + 1.96 * se_z),
    # Regression slope + CI
    slope = coef(lm(obs_rel_var ~ obs_rel_r2))[2],
    slope_ci_low = confint(lm(obs_rel_var ~ obs_rel_r2))[2,1],
    slope_ci_high = confint(lm(obs_rel_var ~ obs_rel_r2))[2,2],
    .groups = "drop"
  )

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

png('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/obs_rel_var_rel_r2_comparison.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(both, aes(x = both$obs_rel_var, y = both$obs_rel_r2)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_wrap(. ~ rsq) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1.01)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1.01)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = 'Observed relative variance', y = 'Observed relative R2') +
  geom_text(data = metrics, aes(x = 0.7, y = 0.05, label = text), inherit.aes = FALSE, size = 4)

dev.off()

# Try and understand why they differ
both$obs_diff <- both$obs_rel_r2 - both$obs_rel_var
ggplot(both, aes(x = log10(both$n_in_ref), y = both$obs_diff)) +
  geom_point() +
  facet_wrap(. ~ rsq) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "log10(N SNP)", y = 'Difference between relative R2 and variance')

# Compare estimated relative R2 and estimated relative variance
metrics <- both %>%
  group_by(rsq) %>%
  summarise(
    pearson_r = cor(relative_R2, relative_variance, use="complete.obs"),
    spearman_rho = cor(relative_R2, relative_variance, method="spearman", use="complete.obs"),
    # Fisher z CI for Pearson r
    z = atanh(pearson_r),
    se_z = 1 / sqrt(N - 3),
    r_low = tanh(z - 1.96 * se_z),
    r_high = tanh(z + 1.96 * se_z),
    # Regression slope + CI
    slope = coef(lm(relative_variance ~ relative_R2))[2],
    slope_ci_low = confint(lm(relative_variance ~ relative_R2))[2,1],
    slope_ci_high = confint(lm(relative_variance ~ relative_R2))[2,2],
    .groups = "drop"
  )

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

png('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/est_rel_var_rel_r2_comparison.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(both, aes(x = both$relative_variance, y = both$relative_R2)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_wrap(. ~ rsq) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1.01)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1.01)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = 'Estimated relative variance', y = 'Estimated relative R2') +
  geom_text(data = metrics, aes(x = 0.7, y = 0.05, label = text), inherit.aes = FALSE, size = 4)

dev.off()
```

***

## Understand impact of variance-standardize flag

As far as I can tell, my estimator works perfectly when I use the variance standardise flag when running plink to calculate the scores in the target sample. But when I don't they seem to deviate. Do a sanity check here.

```{bash}
id=PGS004197

sbatch --mem 2G -n 1 -p cpu -t 1:00:00 --wrap="
plink2 \
  --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
  --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums variance-standardize \
  --out ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/${id}.var"
  
sbatch --mem 2G -n 1 -p cpu -t 1:00:00 --wrap="
plink2 \
  --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
  --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums center \
  --out ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/${id}.cen"
  
rsq=0.7

sbatch --mem 2G -n 1 -p cpu -t 1:00:00 --wrap="
plink2 \
  --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
  --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums center \
  --extract ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p${rsq}.list \
  --out ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/${id}.cen.rsq_p${rsq}"
  
sbatch --mem 2G -n 1 -p cpu -t 1:00:00 --wrap="
plink2 \
  --pfile ~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target \
  --score ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/${id}/ref-${id}.score.nonzero.gz 1 2 4 header cols=+scoresums variance-standardize \
  --extract ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p${rsq}.list \
  --out ~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/${id}.var.rsq_p${rsq}"
```

```{r}
id='PGS004197'
rsq=0.7

baseline_pgs_cen <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', id, '.cen.sscore'))
baseline_pgs_var <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', id, '.var.sscore'))
masked_pgs_cen <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/', id, '.cen.rsq_p', rsq, '.sscore'))
masked_pgs_var <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/', id, '.var.rsq_p', rsq, '.sscore'))

cor(baseline_pgs_cen$SCORE1_SUM, masked_pgs_cen$SCORE1_SUM)^2 # 0.7707398
cor(baseline_pgs_var$SCORE1_SUM, masked_pgs_var$SCORE1_SUM)^2 # 0.5970076

est_rel_r2 <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/rsq_metrics_pgs_eigen.rds')
est_rel_r2$rel_r2[est_rel_r2$group == rsq & est_rel_r2$ID == id] # 0.5616335

# This shows that using the variance-standardise function changes the correlation between the baseline and masked PGS. Our estimation method is much closer to the result when using the variance standardised flag. In this example, the observed correlation is much higher between the scores that have not been variance-standardised. Given PGS methods do not assume standardised genotypes, it is not appropriate to include the variance-standardise flag, and we need to update our method to be accurate in this scenario.

```

***

## Validated using simulated phenotype

Here we will simulate a phenotype based on the baseline PGS, and then check relative variance explained by the masked PGS. This can also be a oppurtunity to play out the impact of reduced PGS variance on calibration.

```{r}
score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

results <- NULL
for(i in score_list$name[1:20]){
  if(!file.exists(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', i,'.sscore'))){
    next
  }
  
  # Read in baseline PGS
  baseline_pgs <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/pgs/baseline/', i,'.sscore'))[['SCORE1_SUM']]

  # Read in masked PGS
  masked_pgs <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/',i,'.rsq_p0.8.sscore'))[['SCORE1_SUM']]

  r <- cor(baseline_pgs, masked_pgs)
  var_baseline <- var(baseline_pgs)
  var_masked <- var(masked_pgs)

  # Simulate phenotype with R2 of 0.2
  R2_star <- 0.20 
  sigma_eps <- sqrt(var_baseline * ((1 - R2_star) / R2_star))
  set.seed(1)
  
  # Do some repeats to make the results more precise
  reps <- 1000
  
  ratios <- replicate(reps, {
    Y <- baseline_pgs + rnorm(length(baseline_pgs), 0, sigma_eps)
    m_star <- lm(Y ~ baseline_pgs)
    m_imp  <- lm(Y ~ masked_pgs)
    
    # restore variance in masked PGS
    masked_pgs_rescaled <- masked_pgs * (r * sqrt(var_baseline/var_masked))
    m_imp_rescaled  <- lm(Y ~ masked_pgs_rescaled)

    c(
      slope_star = coef(m_star)[2],
      slope_imp  = coef(m_imp)[2],
      slope_imp_rescaled  = coef(m_imp_rescaled)[2],
      slope_ratio = coef(m_imp)[2]/coef(m_star)[2],
      slope_ratio_rescaled = coef(m_imp_rescaled)[2]/coef(m_star)[2],
      R2_star = summary(m_star)$r.squared,
      R2_imp  = summary(m_imp)$r.squared,
      R2_imp_rescaled  = summary(m_imp_rescaled)$r.squared,
      R2_ratio = summary(m_imp)$r.squared/summary(m_star)$r.squared,
      R2_ratio_rescaled = summary(m_imp_rescaled)$r.squared/summary(m_star)$r.squared,
      r = r, 
      r2 = r^2,
      est_slope_ratio = r*sqrt(var_baseline/var_masked),
      var_star = var_baseline,
      var_imp = var_masked,
      var_imp_rescaled = var(masked_pgs_rescaled))
  })
  
  results<-rbind(results,
                 data.table(id = i, t(colMeans(t(ratios)))))

}
results
names(results)<-gsub('\\..*','', names(results))

results_long <- melt(
  results,
  id.vars = c("id"),
  measure.vars = c("slope_ratio", "slope_ratio_rescaled"),
  variable.name = "type",
  value.name = "slope_ratio_value"
)

ggplot(results_long, aes(x = id, y = slope_ratio_value, fill = type)) +
  geom_col(position = "dodge") +
  geom_hline(yintercept = 1, linetype = "dashed") +
  labs(
    x = "PGS ID",
    y = "Slope ratio (masked / baseline)",
    title = "Calibration before and after rescaling"
  ) +
  scale_fill_manual(values = c("#E69F00", "#56B4E9"),
                    labels = c("Uncorrected", "Rescaled")) +
  theme_bw(base_size = 13) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggplot(results, aes(x = var_imp / var_star, y = slope_ratio)) +
  geom_point(size = 3, colour = "#009E73") +
  geom_smooth(method = "lm", se = FALSE, colour = "black", linetype = "dotted") +
  labs(
    x = expression(paste("Relative variance (Var"[masked], "/Var"[baseline], ")")),
    y = "Observed slope ratio",
    title = "Variance shrinkage leads to slope inflation"
  ) +
  theme_bw(base_size = 13)


```

***

# Compare LD-naive and LD-aware estimates

The LD naive approach does not estimate relative R2, it estimate relative variance. This is not the same thing, particularly when scores contains variants in LD.

***

## Validate LD-naive approach

Use the same set up as the validation against observed data with masking. This will allow us to see if accounting for LD improves estimate of relative variance.

```{r}

# Now estimate the relative R2 of PGS after masking variants
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(ggplot2)
library(cowplot)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

info_thresh <- c(0.5, 0.6, 0.7, 0.8)

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Combine all the score files
ref <- fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[1],
        '/ref-',
        score_list$name[1],
        '.score.gz'
      ))[, c('SNP','A1','A2'), with=F]

betas <- foreach(i = 1:nrow(score_list), .combine = cbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
  tmp <-  fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[i],
        '/ref-',
        score_list$name[i],
        '.score.gz'
      ), nThread= 1) [,-1:-3, with = F]
  print(nrow(tmp))
  tmp
}

colnames(betas)<-score_list$name
score_file<-data.table(ref, betas)

# Restrict score file to rows with non-zero betas
score_file <- score_file[apply(betas, 1, function(x) !all(x == 0)),]

# Restrict score files to variants present in target sample for comparability
freq    <- fread("~/oliverpainfel/Analyses/mind_the_gap/sim/emp/target/target.afreq")
freq <- freq[, c('ID','REF','ALT','ALT_FREQS'), with = F]
names(freq)<-c('SNP','A2','A1','FREQ')

score_file <- score_file[score_file$SNP %in% freq$SNP,]

foreach(i = info_thresh, .options.multicore = list(preschedule = FALSE)) %dopar% {
  # Create call rate data.frame
  snplist <- fread(paste0('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/rsq_p',i,'.list'), header=F)$V1
  call_rate <- data.table(
    SNP = score_file$SNP
  )
  call_rate$F_MISS <- 1
  call_rate$F_MISS[call_rate$SNP %in% snplist] <- 0

  # Calculate relative R2 (on each chromosome like in GenoPred)
  rel_r2 <- rel_pgs_r2_missing_af(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
      score_df = score_file,
      f_miss = call_rate)
  
  write.table(
    rel_r2,
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/relative.rsq_p',
      i,
      '.rsq_ld_naive.txt'
    ),
    col.names = T,
    row.names = F,
    quote = F
  )
}

```


```{r}
setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(ggplot2)
library(cowplot)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL

# Restrict to variants in the dense SBayesRC reference
sbayesrc_info<-fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR/snp.info')
rsq_subset <- rsq[rsq$SNP %in% sbayesrc_info$ID,]

# Read in score list
score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

# Combine all the score files
ref <- sbayesrc_info[, c('ID','A1','A2'), with =F]
names(ref) <- c('SNP','A1','A2')

betas <- foreach(i = 1:nrow(score_list), .combine = cbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
  tmp <-  fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        score_list$name[i],
        '/ref-',
        score_list$name[i],
        '.unmapped.score.gz'
      ), nThread= 1)
  
  tmp$CHR <- NULL
  tmp$BP <- NULL
  tmp <- map_score(ref = ref, score = tmp)
  print(i)
  print(nrow(tmp))
  tmp[,'SCORE_external', with =F]
}

colnames(betas)<-score_list$name
score_file<-data.table(ref, betas)

# Restrict score file to rows with non-zero betas
score_file <- score_file[apply(betas, 1, function(x) !all(x == 0)),]

foreach(panel_i = c(
      "HC_1kg",
      "HC_hrc",
      "HC_top",
      "OE_1kg",
      "OE_hrc",
      "OE_top",
      "IO_1kg",
      "IO_hrc",
      "IO_top",
      "MG_1kg",
      "MG_hrc",
      "MG_top"
    ), .options.multicore = list(preschedule = FALSE)) %dopar% {
  # Subset rsqbrowser panel
  rsq_subset_j <- rsq_subset[, c('SNP', panel_i), with = F]
  rsq_subset_j$F_MISS <- 1 - rsq_subset_j[[panel_i]]

  # Calculate relative R2
  rel_r2 <- rel_pgs_r2_missing_af(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
      score_df = score_file,
      f_miss = rsq_subset_j)
  
  write.table(
    rel_r2, 
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      panel_i,
      '.rsq_ld_naive.txt'
    ), col.names = T, row.names = F, quote = F)
}

```

```{r}
panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

pgs_r2 <- NULL
for(i in panels){
  tmp <- fread(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      i,
      '.rsq_ld_naive.txt'
    )
  )
  tmp$group <- i
  pgs_r2 <- rbind(pgs_r2, tmp)
}

pgs_r2$array <- gsub('_.*','', pgs_r2$group)
pgs_r2$panel <- gsub('.*_','', pgs_r2$group)

# Recode panels
pgs_r2$panel <- factor(
  pgs_r2$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
pgs_r2$array <- factor(
  pgs_r2$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

saveRDS(pgs_r2, '~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_ldnaive.rds')
```

***

## Compare results

```{r}
# Compare estimated and observed relative R2
obs_rel_r2 <- fread('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/relative_r2_no_pheno.txt')
setnames(obs_rel_r2, 'rel_r2_cor', 'obs_rel_r2')
setnames(obs_rel_r2, 'rel_r2_var', 'obs_rel_var')

info_thresh <- c(0.5, 0.6, 0.7, 0.8)

est_rel_r2 <- NULL
for(i in info_thresh){
  tmp <- fread(paste0('/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/relative.rsq_p', i,'.txt'))
  setnames(tmp, 'beta_set', 'ID')
  tmp$rsq <- i
  est_rel_r2 <- rbind(est_rel_r2, tmp)
}

est_rel_r2_ld_naive <- NULL
for(i in info_thresh){
  tmp <- fread(paste0('/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/relative.rsq_p', i,'.rsq_ld_naive.txt'))
  setnames(tmp, 'beta_set', 'ID')
  tmp$rsq <- i
  est_rel_r2_ld_naive <- rbind(est_rel_r2_ld_naive, tmp)
}

setnames(est_rel_r2_ld_naive, 'relative_R2', 'relative_variance_ldnaive')

both <- merge(obs_rel_r2[, c('ID','obs_rel_var','rsq'), with = F], est_rel_r2[, c('ID','relative_variance','rsq'), with = F], by = c('ID','rsq'))
both <- merge(both, est_rel_r2_ld_naive[, c('ID','relative_variance_ldnaive','rsq'), with = F], by = c('ID','rsq'))
both$rsq <- paste0('Masked RSQ < ', both$rsq)

# Compare estimated and observed relative R2
metrics <- both %>%
  group_by(rsq) %>%
  summarise(
    pearson_r = cor(relative_variance_ldnaive, obs_rel_var , use="complete.obs"),
    spearman_rho = cor(relative_variance_ldnaive, obs_rel_var , method="spearman", use="complete.obs"),
    # Fisher z CI for Pearson r
    z = atanh(pearson_r),
    se_z = 1 / sqrt(N - 3),
    r_low = tanh(z - 1.96 * se_z),
    r_high = tanh(z + 1.96 * se_z),
    # Regression slope + CI
    slope = coef(lm(obs_rel_var  ~ relative_variance_ldnaive))[2],
    slope_ci_low = confint(lm(obs_rel_var  ~ relative_variance_ldnaive))[2,1],
    slope_ci_high = confint(lm(obs_rel_var  ~ relative_variance_ldnaive))[2,2],
    .groups = "drop"
  )

metrics$text <- paste0("r = ", round(metrics$pearson_r, 2),
                       " [", round(metrics$r_low, 2), ", ", round(metrics$r_high, 2), "]",
                       "\nβ = ", round(metrics$slope, 2),
                       " [", round(metrics$slope_ci_low, 2), ", ", round(metrics$slope_ci_high, 2), "]")

png('~/oliverpainfel/Analyses/mind_the_gap/sim/masking/target/pgs/masked/obs_est_rel_var_ldnaive_validation.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(both, aes(x = both$relative_variance_ldnaive, y = both$obs_rel_var)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_wrap(. ~ rsq) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Estimated relative variance (LD-naive)", y = 'Observed relative variance') +
  geom_text(data = metrics, aes(x = 0.3, y = 0.95, label = text), inherit.aes = FALSE, size = 4)

dev.off()


```

```{r}
no_ld_res<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_ldnaive.rds')
with_ld_res<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_ldaware.rds')

ggplot(with_ld_res, aes(x = relative_variance, y = relative_R2)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_grid(panel ~ array) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Estimated relative variance", y = "Estimated relative R2")

pgs_r2 <- merge(no_ld_res, with_ld_res, by = c('beta_set','group','array','panel'))

ggplot(pgs_r2, aes(x = relative_R2.x, y = relative_R2.y)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_grid(panel ~ array) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Estimated relative R2 (LD-naive)", y = "Estimated relative R2 (LD-aware)")

ggplot(pgs_r2, aes(x = relative_R2.x, y = relative_variance)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_grid(panel ~ array) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Estimated relative R2 (LD-naive)", y = "Estimated relative variance (LD-aware)")


no_ld_res <- no_ld_res[, c('beta_set','relative_R2','group','array','panel'), with = F]
with_ld_res <- with_ld_res[, c('beta_set','relative_R2','group','array','panel'), with = F]

no_ld_res$method <- 'LD-naive'
with_ld_res$method <- 'LD-aware'

pgs_r2_melt <- rbind(no_ld_res, with_ld_res)
pgs_r2 <- merge(no_ld_res, with_ld_res, by = c('beta_set','group','array','panel'))

ggplot(pgs_r2, aes(x = relative_R2.x, y = relative_R2.y)) +
  geom_abline(colour = 'red') +
  geom_point() +
  facet_grid(panel ~ array) +
  coord_fixed() +
  theme_half_open() +
  panel_border() +
  background_grid() +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1), limits = c(0.5,1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "Estimated relative R2 (LD-naive)", y = "Estimated relative R2 (LD-aware)")

# The LD naive approach seems to really over estimate the decrease in relative R2 due to poor imputation. I am not sure we can use it for the PGS catalogue scores. We could potentially use it for some ptclump scores that I create though.

```

***

# Estimate PGS R2 with more dense LD eigen data



***

# Estimate relative R2 of SBayesRC PGS

## Download MVP EUR sumstats

Download MVP GWAS for the traits used in the cross population study, and run SBayesRC using sparse and dense reference, and assess relative PGS R2 across arrays and imputation panels.

```{r}
library(data.table)

mvp <- fread('~/oliverpainfel/Data/GWAS_sumstats/MVP/MVP_sumstats.txt')
mvp_eur <- mvp[grepl('Eur', mvp$discoverySampleAncestry),]
mvp_eur <- mvp_eur[!grepl('Afr|Asi|His', mvp_eur$discoverySampleAncestry),]

# Subset MVP to selected traits
mvp <- mvp[
  mvp$accessionId %in% 
    c(
      'GCST90475361', 'GCST90475375', 'GCST90476298', 'GCST90475155', 'GCST90476462', 'GCST90475457', 'GCST90476423', 'GCST90475528', 'GCST90475351', 'GCST90476402'
    )
, ]

mvp_eur <- mvp_eur[mvp_eur$reportedTrait %in% mvp$reportedTrait,]

# Insert labels
mvp_eur$labels <- NA
mvp_eur$labels[mvp_eur$efoTraits == 'body mass index'] <- 'BMI'
mvp_eur$labels[mvp_eur$efoTraits == 'body weight'] <- 'BWT'
mvp_eur$labels[mvp_eur$efoTraits == 'high density lipoprotein cholesterol measurement'] <- 'HDL'
mvp_eur$labels[mvp_eur$efoTraits == 'body height'] <- 'HT'
mvp_eur$labels[mvp_eur$efoTraits == 'hemoglobin measurement'] <- 'HB'
mvp_eur$labels[mvp_eur$efoTraits == 'mean corpuscular hemoglobin concentration'] <- 'MCHC'
mvp_eur$labels[mvp_eur$efoTraits == 'neutrophil count'] <- 'NEU'
mvp_eur$labels[mvp_eur$efoTraits == 'platelet count'] <- 'PLT'
mvp_eur$labels[mvp_eur$efoTraits == 'systolic blood pressure'] <- 'SBP'
mvp_eur$labels[mvp_eur$efoTraits == 'total cholesterol measurement'] <- 'TC'

mvp_eur$url <-paste0(mvp_eur$summaryStatistics, '/', mvp_eur$accessionId, '.tsv.gz')

dir.create('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR')

write.table(
  mvp_eur[, c('url', 'labels'), with = F],
  '~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/urls.txt',
  row.names = F,
  quote = F,
  col.names = F
)

write.table(
  mvp_eur,
  '~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/info.txt',
  row.names = F,
  quote = T,
  col.names = T
)

```

```{bash}
for pheno in $(cat ~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/urls.txt | cut -d' ' -f 2); do
  url=$(awk -v var="$pheno" '$2 == var {print $1}' ~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/urls.txt)
  sbatch -p interruptible_cpu -t 1:00:00 --wrap="wget -O ~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/${pheno}.txt.gz ${url}"
done
```

```{r}
# Subset GWAS to variants considered by sbayesrc to make ptclump PGS comparable
sbayesrc_snpinfo <- fread('~/oliverpainfel/Data/SBayesRC/ukbEUR_Imputed/snp.info') # Build GRCh37

traits <- fread('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/info.txt')$labels
for(i in traits){
  print(i)
  ss <- fread(paste0('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/',i,'.txt.gz'))
  ss <- ss[ss$rsid %in% sbayesrc_snpinfo$ID, ]
  fwrite(
    ss,
    paste0(
      '~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/',
      i,
      '.sbayesrc.txt.gz'
    ),
    sep = ' ',
    quote = F,
    na = 'NA'
  )
}

```

***

## Run SBayesRC

Include ptclump as well for comparison.

```{r}
library(data.table)

#####
# gwas_list
#####

traits <- fread('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/info.txt')$labels

gwas_list <- data.table(
  name = traits,
  path = paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/', traits,'.sbayesrc.txt.gz'),
  population = 'EUR',
  n = NA,
  sampling = NA,
  prevalence = NA,
  mean = NA, 
  sd = NA,
  label = traits
)

write.table(gwas_list, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_mvp.txt', col.names = T, row.names = F, quote = F)

######
# config
######

config_sparse<-c(
  "outdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse",
  "config_file: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_mvp.txt",
  "pgs_methods: ['sbayesrc','ptclump']",
  "cores_prep_pgs: 10",
  "dense_reference: F"
)

write.table(config_sparse, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse.yaml', col.names = F, row.names = F, quote = F)

config_dense<-c(
  "outdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense",
  "config_file: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_mvp.txt",
  "pgs_methods: ['sbayesrc','ptclump']",
  "cores_prep_pgs: 10",
  "dense_reference: T",
  "keep_ambiguous: T"
)

write.table(config_dense, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml', col.names = F, row.names = F, quote = F)

```

```{bash}
snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse.yaml \
  prep_pgs -n

snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml \
  prep_pgs -n
```

***

## Estimate relative PGS R2

Across arrays and imputation.

***

### SBayesRC

#### Sparse

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)
refdir <- read_param(config = config, param = 'refdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

source('../functions/misc.R')
source_all('../functions')

###
# Read in score files
###
# Combine all the score files
ref <- read_pvar(paste0(refdir,'/ref.chr'))
ref <- ref[, c('SNP','A1','A2'), with = F]

betas <-
  foreach(
    i = 1:nrow(scores),
    .combine = cbind,
    .options.multicore = list(preschedule = FALSE)
  ) %dopar% {
    tmp <-  fread(
      paste0(
        outdir,
        '/reference/pgs_score_files/',
        scores$method[i],
        '/',
        scores$name[i],
        '/ref-',
        scores$name[i],
        '.score.gz'
      ),
      nThread = 1
    ) [, -1:-3, with = F, drop = F]
    names(tmp) <- gsub('SCORE', paste0(scores$name[i],'_',scores$method[i]), names(tmp))
    print(nrow(tmp))
    tmp
  }

score_file<-data.table(ref, betas)

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL

# Restrict to variants in the dense SBayesRC reference
sbayesrc_info<-fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR/snp.info')
rsq_subset <- rsq[rsq$SNP %in% sbayesrc_info$ID,]

# Restrict score file to variants in the rsq browser
score_file <- score_file[score_file$SNP %in% rsq_subset$SNP,]

panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

for(panel_i in panels){
  if(file.exists(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/',
      panel_i,
      '.rsq.txt'
    ))){
    next
  }
  
  print(panel_i)
  
  # Subset rsqbrowser panel
  rsq_subset_j <- rsq_subset[, c('SNP', panel_i), with = F]
  rsq_subset_j$F_MISS <- 1 - rsq_subset_j[[panel_i]]

  # Calculate relative R2 (on each chromosome like in GenoPred)
  rel_r2 <- rel_pgs_r2_missing_eigen(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR',
      score_df = score_file,
      f_miss = rsq_subset_j)
  
  write.table(
    rel_r2, 
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/',
      panel_i,
      '.rsq.txt'
    ), col.names = T, row.names = F, quote = F)
}

```

***

#### Dense

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)
refdir <- read_param(config = config, param = 'refdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

source('../functions/misc.R')
source_all('../functions')

###
# Read in score files
###
# Combine all the score files
ref <- read_pvar(paste0(refdir,'/ref.chr'))
ref <- ref[, c('SNP','A1','A2'), with = F]

betas <-
  foreach(
    i = 1:nrow(scores),
    .combine = cbind,
    .options.multicore = list(preschedule = FALSE)
  ) %dopar% {
    tmp <-  fread(
      paste0(
        outdir,
        '/reference/pgs_score_files/',
        scores$method[i],
        '/',
        scores$name[i],
        '/ref-',
        scores$name[i],
        '.score.gz'
      ),
      nThread = 1
    ) [, -1:-3, with = F, drop = F]
    names(tmp) <- gsub('SCORE', paste0(scores$name[i],'_',scores$method[i]), names(tmp))
    print(nrow(tmp))
    tmp
  }

score_file<-data.table(ref, betas)

# Read in rsq information
rsq<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
rsq$CHR <- NULL
rsq$BP <- NULL

# Restrict to variants in the dense SBayesRC reference
sbayesrc_info<-fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR/snp.info')
rsq_subset <- rsq[rsq$SNP %in% sbayesrc_info$ID,]

# Restrict score file to variants in the rsq browser
score_file <- score_file[score_file$SNP %in% rsq_subset$SNP,]

panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

for(panel_i in panels){
  if(file.exists(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/',
      panel_i,
      '.rsq.txt'
    ))){
    next
  }
  
  print(panel_i)
  
  # Subset rsqbrowser panel
  rsq_subset_j <- rsq_subset[, c('SNP', panel_i), with = F]
  rsq_subset_j$F_MISS <- 1 - rsq_subset_j[[panel_i]]

  # Calculate relative R2 (on each chromosome like in GenoPred)
  rel_r2 <- rel_pgs_r2_missing_eigen(
      ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
      score_df = score_file,
      f_miss = rsq_subset_j)
  
  write.table(
    rel_r2, 
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/',
      panel_i,
      '.rsq.txt'
    ), col.names = T, row.names = F, quote = F)
}

```

***

## Plot results

```{r}
library(data.table)
library(ggplot2)
library(cowplot)

panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

rel_r2_sparse <- NULL
for(i in panels){
  tmp <- fread(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/sbayesrc/',
      i,
      '.rsq.txt'
    )
  )
  tmp$group <- i
  tmp$snplist <- 'sparse'
  rel_r2_sparse <- rbind(rel_r2_sparse, tmp)
}

rel_r2_dense <- NULL
for(i in panels){
  tmp <- fread(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/sbayesrc/',
      i,
      '.rsq.txt'
    )
  )
  tmp$group <- i
  tmp$snplist <- 'dense'
  rel_r2_dense <- rbind(rel_r2_dense, tmp)
}

rel_r2 <- rbind(rel_r2_sparse, rel_r2_dense)

rel_r2$array <- gsub('_.*','', rel_r2$group)
rel_r2$panel <- gsub('.*_','', rel_r2$group)

# Recode panels
rel_r2$panel <- factor(
  rel_r2$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
rel_r2$array <- factor(
  rel_r2$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

# Recode snplist
rel_r2$snplist <- factor(
  rel_r2$snplist,
  levels = c('sparse','dense'),
  labels = c('Sparse','Dense')
)

dir.create('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc', showWarnings = F)

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/rsq_metrics_eigen.png',
    units = 'px',
    width = 3000,
    height = 1750,
    res = 300)

ggplot(rel_r2, aes(x = array, y = relative_R2, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Relative R2", title = "Distribution by metric, array, and panel") +
  facet_grid(. ~ snplist) +
  theme_half_open() +
  panel_border() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/var_metrics_eigen.png',
    units = 'px',
    width = 3000,
    height = 1750,
    res = 300)

ggplot(rel_r2, aes(x = array, y = relative_variance, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Array", y = "Relative Variance", title = "Distribution by metric, array, and panel") +
  facet_grid(. ~ snplist) +
  theme_half_open() +
  panel_border() +
  background_grid()
dev.off()

```

***



***

# Multi-Ancestry Estimation of PGS Portability

Objective: To quantify and compare the expected decay in PGS performance across European, African, Hispanic/Latino, and Finnish populations, demonstrating the generalisability of your findings and highlighting ancestry-specific differences.

For your 10 trait PGS (derived from MVP), use the RsqBrowser2 database to obtain the imputation quality (RSQ) data for the four genotyping arrays (Core, OmniExpress, MEGA, Omni 2.5M) and three imputation panels (1000G, HRC, TOPMed) across all four available ancestry groups: European (EUR), African (AFR), Hispanic/Latino (AMR), and Finnish (FIN).

***

## Download additional rsqbrowser data

```{bash}
# Download imputation data across arrays and populations from Rsq Browser
cd ~/oliverpainfel/Data/RsqBrowser2
# The additional files are here:
# biome.bi.snv.tab.gz
# inpsyght.bi.snv.tab.gz
# metsim.bi.snv.tab.gz
```

```{r}
library(data.table)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

populations <- c('AMR','AFR','FIN')
files <- c('biome.bi.snv.tab.gz',
           'inpsyght.bi.snv.tab.gz',
           'metsim.bi.snv.tab.gz')

# Read in dbSNP data
ref <- foreach(i = 1:22, .combine = rbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
  print(i)
  readRDS(paste0('~/oliverpainfel/Data/dbSNP/00-All.snps.nonambiguous.chr',i,'.rds'))
}

# Insert IUPAC codes
ref$IUPAC <- snp_iupac(ref$A1, ref$A2)

# Rename columns prior to merging with target
names(ref)<-paste0('REF.',names(ref))
ref$BP<-ref[[paste0('REF.BP_GRCh38')]]
ref<-ref[, c('REF.CHR','REF.SNP','BP','REF.BP_GRCh37','REF.A1','REF.A2','REF.IUPAC'), with=F]

# Reduce size of rsq by restricting to variants present in either hm3 or sbayesr
hm3 <-
  readRDS(paste0(
    '~/oliverpainfel/Analyses/mind_the_gap/snp_data/hm3.rds'
  ))
sbayesrc <-
  readRDS(paste0(
    '~/oliverpainfel/Analyses/mind_the_gap/snp_data/sbayesrc_7m.rds'
  ))
  
for(pop in 1:length(populations)){
  print(pop)
  
  # Read in RsqBrowser data (Build GRCh38)
  rsq <- fread(paste0('~/oliverpainfel/Data/RsqBrowser2/',files[pop]))
  
  # Remove columns we don't want
  rsq <- rsq[,!grepl('_in$', names(rsq)), with=F]
  
  # Update column names
  names(rsq)[1:5] <- c('CHR', 'BP', 'A2', 'A1','FREQ')
  
  # Remove 'chr' string from CHR
  rsq$CHR <- as.numeric(gsub('chr', '', rsq$CHR))
    
  # Remove ambiguous variants - Not really necessary - Won't change results though
  rsq$IUPAC <- snp_iupac(rsq$A1, rsq$A2)
  rsq <- rsq[rsq$IUPAC != 'S' & rsq$IUPAC != 'W',]
  nrow(rsq)

  # Insert RSIDs by merging with dbSNP reference based on CHR BP A1 A2 information (they are both GRCh37)
  rsq_harm <- foreach(i = 1:22, .combine = rbind, .options.multicore = list(preschedule = FALSE)) %dopar% {
    print(i)
    # Read in dbSNP data
    ref_i <- ref[ref$REF.CHR == i,]
  
    # Subset rsq to chr == i
    target_i <- rsq[rsq$CHR == i,]
    
    # Merge by BP
    ref_target<-merge(target_i, ref_i, by = 'BP')
    
    # Identify targ-ref strand flips, and flip target
    flip_logical<-detect_strand_flip(targ = ref_target$IUPAC, ref = ref_target$REF.IUPAC)
  
    flipped<-ref_target[flip_logical,]
    flipped$A1<-snp_allele_comp(flipped$A1)
    flipped$A2<-snp_allele_comp(flipped$A2)
    flipped$IUPAC<-snp_iupac(flipped$A1, flipped$A2)
    
    # Identify SNPs that have matched IUPAC
    matched<-ref_target[ref_target$IUPAC == ref_target$REF.IUPAC,]
    matched<-rbind(matched, flipped)
  
    # Set BP to GRCh37
    matched$BP <- NULL
    names(matched)[names(matched) == 'REF.BP_GRCh37']<-'BP'
  
    # Set REF.SNP to SNP column
    names(matched)[names(matched) == 'REF.SNP']<-'SNP'
  
    matched
  }
  
  rsq_harm <- rsq_harm[, !(names(rsq_harm) %in% c('REF.CHR', 'REF.A1', 'REF.A2', 'REF.IUPAC', 'IUPAC')), with = F]
  
  rsq_harm <- rsq_harm[, c('CHR','BP','SNP','A1','A2', names(rsq_harm)[!(names(rsq_harm) %in% c('CHR','BP','SNP','A1','A2'))]), with=F] 
    
  # Store snplist for rsq reference.
  saveRDS(
    rsq_harm,
    paste0(
      '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.',populations[pop],'.rds'
    )
  )
    
  both <- rbind(hm3, sbayesrc)
  both <- both[!duplicated(both),]
  
  rsq_harm_subset <- rsq_harm[rsq_harm$SNP %in% both$SNP,]
  rsq_harm_subset <- rsq_harm_subset[paste0(rsq_harm_subset$SNP, ':', rsq_harm_subset$A1, ':', rsq_harm_subset$A2) %in% paste0(both$SNP, ':', both$A1, ':', both$A2),]
  
  saveRDS(
    rsq_harm_subset,
    paste0(
      '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.',
      populations[pop],
      '.rds'
    )
  )
}

```

***

## Estimate relative PGS R2

Across arrays and imputation. We will rerun for EUR as well, this time not restricting the analysis to variants in the EUR RSQ browser data - This will avoid the PGS performance being artificially high in the EUR population.

***

### Sparse

```{r}

setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)
refdir <- read_param(config = config, param = 'refdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

source('../functions/misc.R')
source_all('../functions')

###
# Read in score files
###
# Combine all the score files
ref <- read_pvar(paste0(refdir,'/ref.chr'))
ref <- ref[, c('SNP','A1','A2'), with = F]

betas <-
  foreach(
    i = 1:nrow(scores),
    .combine = cbind,
    .options.multicore = list(preschedule = FALSE)
  ) %dopar% {
    tmp <-  fread(
      paste0(
        outdir,
        '/reference/pgs_score_files/',
        scores$method[i],
        '/',
        scores$name[i],
        '/ref-',
        scores$name[i],
        '.score.gz'
      ),
      nThread = 1
    ) [, -1:-3, with = F, drop = F]
    names(tmp) <- gsub('SCORE', paste0(scores$name[i],'_',scores$method[i]), names(tmp))
    print(nrow(tmp))
    tmp
  }

score_file<-data.table(ref, betas)

populations <- c('EUR','AMR','AFR','FIN')
for(pop in populations){
  print(pop)
  
  # Read in rsq information
  if(pop == 'EUR'){
    rsq<-readRDS(
      paste0(
        '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.rds'
      ))
  } else {
    rsq<-readRDS(
      paste0(
        '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.',
        pop,
        '.rds'
      ))
  }

  # We will merge by SNP, A1 and A2 information, so delete other information
  rsq$CHR <- NULL
  rsq$BP <- NULL
  
  panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")
  
  for(panel_i in panels){
    if(file.exists(
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/',
        panel_i,
        '.rsq.',
        pop,
        '.txt'
      ))){
      next
    }
    
    print(panel_i)
    
    # Subset rsqbrowser panel
    rsq_subset_j <- rsq[, c('SNP', panel_i), with = F]
    rsq_subset_j$F_MISS <- 1 - as.numeric(rsq_subset_j[[panel_i]])
  
    # Calculate relative R2 (on each chromosome like in GenoPred)
    rel_r2 <- rel_pgs_r2_missing_eigen(
        ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR',
        score_df = score_file,
        f_miss = rsq_subset_j)
    
    write.table(
      rel_r2, 
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/',
        panel_i,
        '.rsq.',
        pop,
        '.txt'
      ), col.names = T, row.names = F, quote = F)
  }
}

```

***

### Dense

```{r}
setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(20)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)
outdir <- read_param(config = config, param = 'outdir', return_obj = F)
refdir <- read_param(config = config, param = 'refdir', return_obj = F)

# Get a list of score files
scores <- list_score_files(config)

source('../functions/misc.R')
source_all('../functions')

###
# Read in score files
###
# Combine all the score files
ref <- read_pvar(paste0(refdir,'/ref.chr'))
ref <- ref[, c('SNP','A1','A2'), with = F]

betas <-
  foreach(
    i = 1:nrow(scores),
    .combine = cbind,
    .options.multicore = list(preschedule = FALSE)
  ) %dopar% {
    tmp <-  fread(
      paste0(
        outdir,
        '/reference/pgs_score_files/',
        scores$method[i],
        '/',
        scores$name[i],
        '/ref-',
        scores$name[i],
        '.score.gz'
      ),
      nThread = 1
    ) [, -1:-3, with = F, drop = F]
    names(tmp) <- gsub('SCORE', paste0(scores$name[i],'_',scores$method[i]), names(tmp))
    print(nrow(tmp))
    tmp
  }

score_file<-data.table(ref, betas)

populations <- c('EUR','AMR','AFR','FIN')
for(pop in populations){
  print(pop)
  
  # Read in rsq information
  if(pop == 'EUR'){
    rsq<-readRDS(
      paste0(
        '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.rds'
      ))
  } else {
    rsq<-readRDS(
      paste0(
        '~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_browser.hm3_sbayesrc.',
        pop,
        '.rds'
      ))
  }

  # We will merge by SNP, A1 and A2 information, so delete other information
  rsq$CHR <- NULL
  rsq$BP <- NULL
  
  panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")
  
  for(panel_i in panels){
    if(file.exists(
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/',
        panel_i,
        '.rsq.',
        pop,
        '.txt'
      ))){
      next
    }
    
    print(panel_i)
    
    # Subset rsqbrowser panel
    rsq_subset_j <- rsq[, c('SNP', panel_i), with = F]
    rsq_subset_j$F_MISS <- 1 - as.numeric(rsq_subset_j[[panel_i]])
  
    # Calculate relative R2 (on each chromosome like in GenoPred)
    rel_r2 <- rel_pgs_r2_missing_eigen(
        ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR',
        score_df = score_file,
        f_miss = rsq_subset_j)
    
    write.table(
      rel_r2, 
      paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/',
        panel_i,
        '.rsq.',
        pop,
        '.txt'
      ), col.names = T, row.names = F, quote = F)
  }
}

```

***

### Plot results

```{r}
setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml'
pgs_methods <- read_param(config = config, param = 'pgs_methods', return_obj = F)

populations <- c('EUR','AMR','AFR','FIN')
panels <- c( "HC_1kg", "HC_hrc", "HC_top", "OE_1kg", "OE_hrc", "OE_top", "IO_1kg", "IO_hrc", "IO_top", "MG_1kg", "MG_hrc", "MG_top")

rel_r2 <- NULL
for(i in panels){
  for(j in populations){
    for(k in c('sparse','dense')){
      tmp <- fread(
        paste0(
            '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_', k, '/reference/pgs_score_files/',
            i,
            '.rsq.',
            j,
            '.txt'
          )
      )
      tmp$group <- i
      tmp$population <- j
      tmp$snplist <- k
      rel_r2 <- rbind(rel_r2, tmp)
    }
  }
}

rel_r2$trait <- gsub('_.*','',rel_r2$beta_set)
rel_r2$pgs_method <- sub("^[^_]*_([^_]*)_.*$", "\\1", rel_r2$beta_set)
rel_r2$param <- sub("^[^_]*_[^_]*_(.*)$", "\\1", rel_r2$beta_set)
rel_r2$param[rel_r2$pgs_method != 'ptclump'] <- NA
rel_r2$param <- as.numeric(gsub('0_','', rel_r2$param))

rel_r2$array <- gsub('_.*','', rel_r2$group)
rel_r2$panel <- gsub('.*_','', rel_r2$group)

# Recode panels
rel_r2$panel <- factor(
  rel_r2$panel,
  levels = c("1kg", "hrc", "top"),
  labels = c("1000 Genomes", "HRC", "TOPMed")
)

# Recode arrays
rel_r2$array <- factor(
  rel_r2$array,
  levels = c("HC", "OE", "MG", "IO"),
  labels = c("Core", "OmniExpress", "MEGA", "Omni 2.5M")
)

# Recode snplist
rel_r2$snplist <- factor(
  rel_r2$snplist,
  levels = c('sparse','dense'),
  labels = c('Sparse','Dense')
)

dir.create('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc', showWarnings = F)

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/rsq_metrics_eigen_crosspop.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$pgs_method == 'sbayesrc',], aes(x = array, y = relative_R2, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative R2") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/var_metrics_eigen_crosspop.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$pgs_method == 'sbayesrc',], aes(x = array, y = relative_variance, fill = panel)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative Variance") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
dev.off()

rel_r2$param[is.na(rel_r2$param)]<-rel_r2$pgs_method[is.na(rel_r2$param)]
rel_r2$param<-factor(rel_r2$param, levels = unique(rel_r2$param))

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/rsq_metrics_eigen_crosspop_topmed_ptclump.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$panel == 'TOPMed' & rel_r2$population == 'EUR',], aes(x = array, y = relative_R2, fill = param)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative R2") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/var_metrics_eigen_crosspop_topmed_ptclump.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$panel == 'TOPMed' & rel_r2$population == 'EUR',], aes(x = array, y = relative_variance, fill = param)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative Variance") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/rsq_metrics_eigen_crosspop_topmed.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$panel == 'TOPMed',], aes(x = array, y = relative_R2, fill = pgs_method)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative R2") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/sbayesrc/var_metrics_eigen_crosspop_topmed.png',
    units = 'px',
    width = 4000,
    height = 1750,
    res = 300)

ggplot(rel_r2[rel_r2$panel == 'TOPMed',], aes(x = array, y = relative_variance, fill = pgs_method)) +
  geom_boxplot() +
  scale_y_continuous(labels = scales::percent, limits = c(NA, 1)) +
  labs(x = "Array", y = "Relative Variance") +
  facet_grid(. ~ snplist + population) +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
dev.off()

# As predicted the relative R2 and variance is lower for ptclump scores than sbayesrc.
# Can we plot some loci to get a sense of why this?
```

***

# Plot informational redundancy

```{r}
setwd('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(GenoUtils)
library(ggplot2)
library(scales)
library(cowplot)

source('../functions/misc.R')
source_all('../functions')

# Get some key variables from config
config<-'/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense.yaml'
outdir <- read_param(config = config, param = 'outdir', return_obj = F)

# Read in PGS for BMI as an example
dense_ptclump <- fread(paste0(outdir,'/reference/pgs_score_files/ptclump/TC/ref-TC.score.gz'))
dense_sbayesrc <- fread(paste0(outdir,'/reference/pgs_score_files/sbayesrc/TC/ref-TC.score.gz'))

dense_both <-
  merge(dense_sbayesrc[, c('SNP', 'SCORE_SBayesRC'), with = T], dense_ptclump[, c('SNP', 'SCORE_0_1'), with = T], by = 'SNP')
names(dense_both)<-c('SNP','sbayesrc','ptclump')

# Find top locus
TC_gwas <- fread(paste0(outdir,'/reference/gwas_sumstat/TC/TC-cleaned.gz'))
top_hit <- TC_gwas[which.min(TC_gwas$P),]
top_locus <- TC_gwas[TC_gwas$CHR == top_hit$CHR & TC_gwas$BP > top_hit$BP - 0.5e6 & TC_gwas$BP < top_hit$BP + 0.5e6,]

# Subset PGS to locus
dense_both_top_locus <- merge(top_locus[, c('SNP','BP','P','FREQ'), with = F], dense_both, by = 'SNP')
dense_both_top_locus$sbayesrc <- 2 * dense_both_top_locus$FREQ * (1 - dense_both_top_locus$FREQ) * dense_both_top_locus$sbayesrc^2
dense_both_top_locus$ptclump <- 2 * dense_both_top_locus$FREQ * (1 - dense_both_top_locus$FREQ) * dense_both_top_locus$ptclump^2

top_hit_ptclump<-dense_both_top_locus$SNP[which.max(dense_both_top_locus$ptclump^2)]
top_hit_sbayesrc<-dense_both_top_locus$SNP[which.max(dense_both_top_locus$sbayesrc^2)]

# Calculate ld
system(
  paste0(
    "~/oliverpainfel/Software/plink2_linux_avx2_20241011/plink2 ",
      "--pfile ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr", top_hit$CHR, " ",
      "--keep ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep ",
      "--r2-phased ",
      "--ld-snp ", top_hit_ptclump, " ",
      "--ld-window-kb 1000 ",
      "--ld-window 999999 ",
      "--ld-window-r2 0 ",
      "--out ~/test//top_locus_lds_ptclump"
  )
)

system(
  paste0(
    "~/oliverpainfel/Software/plink2_linux_avx2_20241011/plink2 ",
      "--pfile ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr", top_hit$CHR, " ",
      "--keep ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep ",
      "--r2-phased ",
      "--ld-snp ", top_hit_sbayesrc, " ",
      "--ld-window-kb 1000 ",
      "--ld-window 999999 ",
      "--ld-window-r2 0 ",
      "--out ~/test//top_locus_lds_sbayesrc"
  )
)

# Read in LD for that variant
ld_ptclump<-fread('/users/k1806347/test//top_locus_lds_ptclump.vcor')
ld_sbayesrc<-fread('/users/k1806347/test//top_locus_lds_sbayesrc.vcor')
ld<-rbind(ld_ptclump, ld_sbayesrc)
ld <- ld[, c('ID_A', 'ID_B', 'PHASED_R2'), with = F]

ld <- rbind(ld,
            data.table(ID_A = c(top_hit_ptclump, top_hit_sbayesrc),
                       ID_B = c(top_hit_ptclump, top_hit_sbayesrc),
                       PHASED_R2 = 1))

dense_both_top_locus_melt <- melt(dense_both_top_locus, id.vars = c('SNP','BP','P','FREQ'))

dense_both_top_locus_melt <-
  merge(dense_both_top_locus_melt,
        ld,
        by.x = 'SNP',
        by.y = 'ID_B', all.x = T)

dense_both_top_locus_melt <- dense_both_top_locus_melt[
    (dense_both_top_locus_melt$variable == 'sbayesrc' & 
    (dense_both_top_locus_melt$ID_A == top_hit_sbayesrc)) |
    (dense_both_top_locus_melt$variable == 'ptclump' & 
    (dense_both_top_locus_melt$ID_A == top_hit_ptclump)), ]

dense_both_top_locus_melt$ld_bin <- cut(dense_both_top_locus_melt$PHASED_R2,
                        breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1.0),
                        labels = c("0-0.2", "0.2-0.4", "0.4-0.6", "0.6-0.8", "0.8-1.0"), include.lowest = T)

pgs_plot <- ggplot(dense_both_top_locus_melt[dense_both_top_locus_melt$PHASED_R2 > 0.2,], aes(x = BP, y = value, color = ld_bin)) +
  geom_point(size = 2) +
  scale_color_brewer(palette = "Reds", name = "LD (r²)") +
  facet_wrap(~ variable, ncol = 1, scales = "free_y") +
  labs(title = "B) Derived PGS Weights", x = paste("Genomic Position on Chromosome", top_hit$CHR), y = "Absolute Scaled Beta") +
  theme_minimal()

# This doesn't support the informational redundancy explanation. It could be that there is too much certainty in this locus. Try looping through weak top independent loci.

for(i in 1:22){
  system(
    paste0(
      "~/oliverpainfel/Software/plink2_linux_avx2_20241011/plink2 ",
        "--pfile ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr", i, " ",
        "--keep ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep ",
        "--clump ", outdir, "/reference/gwas_sumstat/TC/TC-cleaned.gz ",
        "--clump-p1 1e-5 ",
        "--clump-r2 0.1 ",
        "--clump-kb 500 ",
        "--out ~/test//gwas_clump_", i
    )
  )
}

clump <- NULL
for(i in 1:22){
  clump<-rbind(clump, fread(paste0("~/test//gwas_clump_", i,".clumps")))
}

# Sort by p-value and take the weakest 20 to find ones with more uncertainty
clump <- clump[rev(order(P))][1:20,]

# 2. Loop through each independent lead SNP
for (i in 1:nrow(clump)) {
    lead_snp_info <- clump[i, ]
    
    # 3. Define the locus window
    top_locus <- TC_gwas[
      CHR == lead_snp_info$`#CHROM` & 
      BP > lead_snp_info$POS - 500000 & 
      BP < lead_snp_info$POS + 500000, ]
    
    # Subset PGS to locus
    dense_both_top_locus <- merge(top_locus[, c('SNP','BP','P','FREQ'), with = F], dense_both, by = 'SNP')
    dense_both_top_locus$sbayesrc <- 2 * dense_both_top_locus$FREQ * (1 - dense_both_top_locus$FREQ) * dense_both_top_locus$sbayesrc^2
    dense_both_top_locus$ptclump <- 2 * dense_both_top_locus$FREQ * (1 - dense_both_top_locus$FREQ) * dense_both_top_locus$ptclump^2
    
    top_hit_ptclump<-dense_both_top_locus$SNP[which.max(dense_both_top_locus$ptclump^2)]
    top_hit_sbayesrc<-dense_both_top_locus$SNP[which.max(dense_both_top_locus$sbayesrc^2)]
    
    dense_both_top_locus$sbayesrc <- scale(dense_both_top_locus$sbayesrc)
    dense_both_top_locus$ptclump <- scale(dense_both_top_locus$ptclump)
    
    # Calculate ld
    system(
      paste0(
        "~/oliverpainfel/Software/plink2_linux_avx2_20241011/plink2 ",
          "--pfile ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr", lead_snp_info$`#CHROM`, " ",
          "--keep ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep ",
          "--r2-phased ",
          "--ld-snp ", top_hit_ptclump, " ",
          "--ld-window-kb 1000 ",
          "--ld-window 999999 ",
          "--ld-window-r2 0 ",
          "--out ~/test//top_locus_lds_ptclump"
      )
    )
    
    system(
      paste0(
        "~/oliverpainfel/Software/plink2_linux_avx2_20241011/plink2 ",
          "--pfile ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/ref.chr", lead_snp_info$`#CHROM`, " ",
          "--keep ~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/ref_dense_incl_ambig/keep_files/EUR.keep ",
          "--r2-phased ",
          "--ld-snp ", top_hit_sbayesrc, " ",
          "--ld-window-kb 1000 ",
          "--ld-window 999999 ",
          "--ld-window-r2 0 ",
          "--out ~/test//top_locus_lds_sbayesrc"
      )
    )
    
    # Read in LD for that variant
    ld_ptclump<-fread('/users/k1806347/test//top_locus_lds_ptclump.vcor')
    ld_sbayesrc<-fread('/users/k1806347/test//top_locus_lds_sbayesrc.vcor')
    ld<-rbind(ld_ptclump, ld_sbayesrc)
    ld <- ld[, c('ID_A', 'ID_B', 'PHASED_R2'), with = F]
    
    ld <- rbind(ld,
                data.table(ID_A = c(top_hit_ptclump, top_hit_sbayesrc),
                           ID_B = c(top_hit_ptclump, top_hit_sbayesrc),
                           PHASED_R2 = 1))
    
    dense_both_top_locus_melt <- melt(dense_both_top_locus, id.vars = c('SNP','BP','P','FREQ'))
    
    dense_both_top_locus_melt <-
      merge(dense_both_top_locus_melt,
            ld,
            by.x = 'SNP',
            by.y = 'ID_B', all.x = T)
    
    dense_both_top_locus_melt <- dense_both_top_locus_melt[
        (dense_both_top_locus_melt$variable == 'sbayesrc' & 
        (dense_both_top_locus_melt$ID_A == top_hit_sbayesrc)) |
        (dense_both_top_locus_melt$variable == 'ptclump' & 
        (dense_both_top_locus_melt$ID_A == top_hit_ptclump)), ]
    
    dense_both_top_locus_melt$ld_bin <- cut(dense_both_top_locus_melt$PHASED_R2,
                            breaks = c(0.1, 0.2, 0.4, 0.6, 0.8, 1.0),
                            labels = c("0.1-0.2", "0.2-0.4", "0.4-0.6", "0.6-0.8", "0.8-1.0"), include.lowest = T)
    
    pgs_plot <- ggplot(dense_both_top_locus_melt[!is.na(dense_both_top_locus_melt$ld_bin),], aes(x = BP, y = value, color = ld_bin)) +
      geom_point(size = 2) +
      scale_color_brewer(palette = "Reds", name = "LD (r²)") +
      facet_wrap(~ variable, ncol = 1, scales = "free_y") +
      labs(title = paste0('Index variant: ', lead_snp_info$ID), x = paste("Position on Chromosome", lead_snp_info$`#CHROM`, "(Mb)"), y = "Standardised Per-SNP\nVariance Contribution") +
      scale_x_continuous(labels = label_number(scale = 1e-6)) +
      theme_half_open() +
      panel_border() +
      background_grid()


    png(paste0('~/test//',lead_snp_info$`#CHROM`,':',lead_snp_info$POS,':',lead_snp_info$ID,'.png'), res = 300, width = 2250, height = 2000, units = 'px')
    print(pgs_plot)
    dev.off()
}

# The index variant 'rs76924512' is a nice example.


```

***

# Empirical evaluation in UK Biobank

Phenotype data was extracted using the table exporter app. File ids: project-Gx7VQQ8JbZj8yPqKFF1bFZxy:file-J3gk16jJbZj3yBK1qv3f9BZg

```{}
eid
p30600_i0
p30610_i0
p30620_i0
p30650_i0
p30160_i0
p21001_i0
p21002_i0
p4079_i0_a0
p4079_i0_a1
p30150_i0
p30730_i0
p30020_i0
p30030_i0
p30760_i0
p50_i0
p30750_i0
p30780_i0
p30120_i0
p30050_i0
p30060_i0
p30040_i0
p30130_i0
p30140_i0
p30080_i0
p30010_i0
p4080_i0_a0
p4080_i0_a1
p30690_i0
p30870_i0
p30000_i0
p21022
p31

```

We will subset the UKB genetic data by population, remove recommended exclusion, remove individuals without phenotype, remove individuals that are related, and retain a maximum of 10K individuals per population. We will also only retain variants that are in either the sparse or dense SBayesRC PGS. We will use plink2 to do this, but export as bgen files so we can then calculate the INFO within each population.

```{r}
# Create a list of variants in sparse or dense SBayesRC PGS
sparse <- fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref/EUR/snp.info')
dense <- fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR/snp.info')

snplist <- unique(c(sparse$ID, dense$ID))
fwrite(data.table(ID = snplist), '~/test/snplist.txt', col.names = F, quote = F, sep=' ')
```

Upload the MVP score files for SBayesRC and pT+clump

```{bash}
dx upload /reference/pgs_score_files/ptclump/TC/ref-TC.score.gz
```

***

## Generate PGS models for WGS GWAS

We have run GWAS using the WGS UKB data. Ru SBayesRC and ptclump on those GWAS.

```{bash}
# Download sumstats
cd /users/k1806347/oliverpainfel/Data/GWAS_sumstats/mind_the_gap
dx download -r mind_the_gap/gwas/*.txt.gz
```

```{r}
# Subset GWAS to variants considered by sbayesrc to make ptclump PGS comparable
sbayesrc_snpinfo <- fread('~/oliverpainfel/Data/SBayesRC/ukbEUR_Imputed/snp.info') # Build GRCh37

traits <- fread('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/info.txt')$labels
for(i in traits){
  print(i)
  ss <- fread(paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/mind_the_gap/',i,'.gw.txt.gz'))
  ss <- ss[ss$ID %in% sbayesrc_snpinfo$ID, ]
  fwrite(
    ss,
    paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/mind_the_gap/',i,'.gw.sbayesrc.txt.gz'),
    sep = ' ',
    quote = F,
    na = 'NA'
  )
}

```

```{r}
library(data.table)

#####
# gwas_list
#####

traits <- fread('~/oliverpainfel/Data/GWAS_sumstats/MVP/EUR/info.txt')$labels

gwas_list <- data.table(
  name = paste0('UKB_WGS_',traits),
  path = paste0('/users/k1806347/oliverpainfel/Data/GWAS_sumstats/mind_the_gap/',traits,'.gw.sbayesrc.txt.gz'),
  population = 'EUR',
  n = NA,
  sampling = NA,
  prevalence = NA,
  mean = NA, 
  sd = NA,
  label = paste0('UKB_WGS_',traits)
)

write.table(gwas_list, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_ukb_wgs.txt', col.names = T, row.names = F, quote = F)

######
# config
######

config_sparse<-c(
  "outdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse",
  "config_file: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse_ukb_wgs.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_ukb_wgs.txt",
  "pgs_methods: ['sbayesrc','ptclump']",
  "cores_prep_pgs: 10",
  "dense_reference: F"
)

write.table(config_sparse, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse_ukb_wgs.yaml', col.names = F, row.names = F, quote = F)

config_dense<-c(
  "outdir: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense",
  "config_file: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense_ukb_wgs.yaml",
  "gwas_list: /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_ukb_wgs.txt",
  "pgs_methods: ['sbayesrc','ptclump']",
  "cores_prep_pgs: 10",
  "dense_reference: T",
  "keep_ambiguous: T"
)

write.table(config_dense, '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense_ukb_wgs.yaml', col.names = F, row.names = F, quote = F)

```

```{bash}
snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_sparse_ukb_wgs.yaml \
  prep_pgs -n

snakemake \
  --profile slurm \
  --use-conda \
  --configfile=/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/config_sbayesrc_dense_ukb_wgs.yaml \
  prep_pgs -n
```

```{bash}
# Started using upload agent as dx upload was freezing
for pheno in $(cut -f 1 -d' ' /users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/gwas_list_mvp.txt | tail -n +2); do
  ./ua --progress --do-not-resume --project Oliver_Pain_Fellowship --folder /mind_the_gap/score_files/dense/sbayesrc/ ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/sbayesrc/UKB_WGS_${pheno}/ref-UKB_WGS_${pheno}.score.gz

  ./ua --progress --do-not-resume --project Oliver_Pain_Fellowship --folder /mind_the_gap/score_files/dense/ptclump/ ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_dense/reference/pgs_score_files/ptclump/UKB_WGS_${pheno}/ref-UKB_WGS_${pheno}.score.gz

  ./ua --progress --do-not-resume --project Oliver_Pain_Fellowship --folder /mind_the_gap/score_files/sparse/sbayesrc/ ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/sbayesrc/UKB_WGS_${pheno}/ref-UKB_WGS_${pheno}.score.gz

  ./ua --progress --do-not-resume --project Oliver_Pain_Fellowship --folder /mind_the_gap/score_files/sparse/ptclump/ ~/oliverpainfel/Analyses/mind_the_gap/GenoPred/output_sbayesrc_sparse/reference/pgs_score_files/ptclump/UKB_WGS_${pheno}/ref-UKB_WGS_${pheno}.score.gz
done
```

***

# Test denoising hypothesis

Florian says imputation not taken into account properly. effect size is inflated by low imputation quality, and so is SE.

```{r}
library(ggplot2)

# ----- Peter's imputation models -----
simulate_imputed <- function(X_true, R2, mode = c("BG","DS")) {
  mode <- match.arg(mode)
  n <- nrow(X_true); m <- ncol(X_true)
  E <- matrix(rnorm(n*m), n, m)
  if (mode == "BG") {
    rho <- sqrt(R2)
    sweep(X_true, 2, rho, `*`) + sweep(E, 2, sqrt(1 - rho^2), `*`)     # Var = 1
  } else { # DS
    sweep(X_true, 2, R2, `*`) + sweep(E, 2, sqrt(R2*(1-R2)), `*`)      # Var = R2
  }
}

# ----- Main simulation per Peter's advice -----
simulate_denoise <- function(
  m_snps   = 2000,        # number of unlinked SNPs
  n_train  = 3000,        # GWAS sample size
  n_test   = 5000,        # validation sample size
  h2       = 0.5,         # SNP-heritability for SBLUP lambda
  R2_min   = 0.3,         # INFO range
  R2_max   = 1.0,
  imp_mode = c("BG","DS"),
  score_on = c("TRUE","IMPUTED"),   # TRUE isolates effect in GWAS only
  info_cor = FALSE,
  seed     = 1
){
  set.seed(seed)
  imp_mode <- match.arg(imp_mode)
  score_on <- match.arg(score_on)

  # 1) True effects and INFO
  beta_true <- rnorm(m_snps, 0, sqrt(h2 / m_snps))   # per-SD effects; SNPs indep.
  INFO      <- runif(m_snps, R2_min, R2_max)
  rho       <- sqrt(INFO)

  # 2) Simulate TRAIN & TEST true genotypes; impute per Peter
  Xtr_true <- matrix(rnorm(n_train*m_snps), n_train, m_snps)
  Xte_true <- matrix(rnorm(n_test *m_snps), n_test,  m_snps)

  Xtr_imp  <- simulate_imputed(Xtr_true, INFO, imp_mode)
  Xte_imp  <- simulate_imputed(Xte_true, INFO, imp_mode)

  # Estimate info in training data
  var_obs <- apply(Xtr_imp, 2, var)
  if (imp_mode == "DS") {
    INFO_use <- pmin(pmax(var_obs, 0), 1)   # ≈ Var = INFO
  } else { # BG: variance ~ 1, cannot infer INFO from variance alone
    INFO_use <- rep(NA_real_, m_snps)
  }
      
  # 3) Phenotypes from TRUE genotypes (both sets)
  g_tr <- as.vector(Xtr_true %*% beta_true)
  ytr  <- scale(g_tr) * sqrt(h2) + rnorm(n_train, 0, sqrt(1 - h2))

  g_te <- as.vector(Xte_true %*% beta_true)
  yte  <- scale(g_te) * sqrt(h2) + rnorm(n_test,  0, sqrt(1 - h2))

  # --- GWAS on imputed training genotypes (NO predictor scaling) ---
  # center X by column and y by mean
  Xc <- sweep(Xtr_imp, 2, colMeans(Xtr_imp), FUN = "-")   # n x m
  yc <- ytr - mean(ytr)                                   # n
  
  # per-SNP covariance and variance
  xcov <- as.numeric(crossprod(Xc, yc))                   # m x 1
  xvar <- colSums(Xc^2)                                   # length m
  
  # guard against zero-variance columns
  xvar[xvar == 0] <- NA_real_
  
  # marginal OLS betas on raw imputed dosages
  beta_hat <- xcov / xvar
  
  # Optionally correct BETA for INFO
  if(info_cor){
    beta_hat <- beta_hat * sqrt(INFO_use)
  }
  
  # SBLUP shrinkage with external lambda
  lambda    <- m_snps * ((1 / h2) - 1)
  beta_blup <- beta_hat / (1 + lambda)
  
  # 5) Validation scores
  if (score_on == "TRUE") {
    Xte <- scale(Xte_true, center = TRUE, scale = TRUE)  # perfect WGS-like
  } else {
    Xte <- scale(Xte_imp,  center = TRUE, scale = TRUE)  # imputed in target too
  }

  s_all  <- as.vector(Xte %*% beta_blup)
  r2_all <- cor(s_all, yte)^2

  # Masking by INFO thresholds
  thr_grid <- seq(min(INFO), 0.95, by = 0.05)
  results <- data.frame(threshold = thr_grid,
                        obs_rel_r2 = NA_real_,
                        est_rel_r2 = NA_real_)

  for (i in seq_along(thr_grid)) {
    keep <- INFO >= thr_grid[i]
    beta_mask <- beta_blup
    beta_mask[!keep] <- 0

    s_keep <- as.vector(Xte %*% beta_mask)

    r2_keep <- if (sd(s_keep) > 0) cor(s_keep, yte)^2 else 0
    results$obs_rel_r2[i] <- r2_keep / r2_all
    results$est_rel_r2[i] <- if (sd(s_keep) > 0) cor(s_all, s_keep)^2 else NA_real_
  }

  list(results = results,
       INFO = INFO,
       beta_true = beta_true,
       beta_hat = beta_hat,
       beta_blup = beta_blup,
       lambda = lambda,
       imp_mode = imp_mode,
       score_on = score_on)
}

sim_DS_true <- simulate_peter(imp_mode="DS", score_on="TRUE", info_cor = F, seed=5)

ggplot(sim_DS_true$results, aes(est_rel_r2, obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3) +
  scale_color_viridis_c(option = "C") +
  coord_equal(xlim = c(0,1), ylim = c(0,1.1)) +
  labs(x = "corr² between baseline & masked PGS",
       y = "R²(masked)/R²(all)",
       color = "INFO\nthreshold") +
  theme_minimal(base_size = 13)

sim_BG_true <- simulate_peter(imp_mode="BG", score_on="TRUE", info_cor = F, seed=5)

ggplot(sim_DS_true$results, aes(est_rel_r2, obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3) +
  scale_color_viridis_c(option = "C") +
  coord_equal(xlim = c(0,1), ylim = c(0,1.1)) +
  labs(x = "corr² between baseline & masked PGS",
       y = "R²(masked)/R²(all)",
       color = "INFO\nthreshold") +
  theme_minimal(base_size = 13)

sim_DS_true <- simulate_peter(imp_mode="DS", score_on="TRUE", info_cor = T, seed=5)

ggplot(sim_DS_true$results, aes(est_rel_r2, obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3) +
  scale_color_viridis_c(option = "C") +
  coord_equal(xlim = c(0,1), ylim = c(0,1.1)) +
  labs(x = "corr² between baseline & masked PGS",
       y = "R²(masked)/R²(all)",
       color = "INFO\nthreshold") +
  theme_minimal(base_size = 13)
```


```{r}
# Simulate imputed training genotypes from true X and INFO=R2
# BG:  x_bg = R * x + e,     Var=1
# DS:  x_d  = R^2 * x + e,   Var=R^2
simulate_imputed <- function(X_true, R2, mode = c("BG","DS")) {
  mode <- match.arg(mode)
  n <- nrow(X_true); m <- ncol(X_true)
  E <- matrix(rnorm(n*m), n, m)
  if (mode == "BG") {
    R <- sqrt(R2)
    X_imp <- sweep(X_true, 2, R, `*`) + sweep(E, 2, sqrt(1 - R2), `*`)
  } else {
    X_imp <- sweep(X_true, 2, R2, `*`) + sweep(E, 2, sqrt(R2*(1 - R2)), `*`)
  }
  X_imp
}

# ----- One full run -----

run_once <- function(m_snps = 2000,
                     n_train = 5000,
                     n_test  = 2000,
                     h2 = 0.5,
                     R2_min = 0.3,
                     R2_max = 1.0,
                     mode = c("BG","DS"),
                     seed = 1) {
  set.seed(seed)
  mode <- match.arg(mode)

  # True effects and INFO per SNP
  beta_true <- rnorm(m_snps, 0, sqrt(h2 / m_snps))
  R2 <- runif(m_snps, R2_min, R2_max)
  rho <- sqrt(R2)                    # Corr(true, imputed) for both BG & DS

  # Training: true and imputed genotypes
  Xtr_true <- matrix(rnorm(n_train * m_snps), n_train, m_snps)
  Xtr_imp  <- simulate_imputed(Xtr_true, R2, mode)

  # Phenotypes from true genotypes
  g_tr <- as.vector(Xtr_true %*% beta_true)
  ytr  <- scale(g_tr) * sqrt(h2) + rnorm(n_train, 0, sqrt(1 - h2))

  # BLUP (ridge) on *imputed* X; standardise columns for stable ridge
  Xtr <- scale(Xtr_imp, center = TRUE, scale = TRUE)
  ytr <- scale(ytr,     center = TRUE, scale = TRUE)

  lambda <- m_snps * (1 - h2) / h2
  XtX <- crossprod(Xtr)
  Xty <- crossprod(Xtr, ytr)
  beta_imp <- solve(XtX + diag(lambda, m_snps), Xty)    # fitted on imputed scale

  # ---- Map fitted betas onto the TRUE-genotype scale for scoring ----
  # For independent SNPs, best linear mapping is alpha = rho * beta_imp
  # Replace the "perfect mapping":
  # alpha_true <- as.numeric(rho) * as.numeric(beta_imp)
  
  # With "no correction" (realistic miscalibration):
  alpha_true <- as.numeric(beta_imp)

  # Test set: TRUE (perfect) genotypes only
  Xte_true <- matrix(rnorm(n_test * m_snps), n_test, m_snps)
  # Standardise columns to unit variance for scoring on true scale
  Xte <- scale(Xte_true, center = TRUE, scale = TRUE)

  # Phenotypes in test from true genotypes
  g_te <- as.vector(Xte_true %*% beta_true)
  yte  <- scale(g_te) * sqrt(h2) + rnorm(n_test, 0, sqrt(1 - h2))

  # Baseline PGS with all SNPs (on true scale)
  s_all <- as.vector(Xte %*% alpha_true)
  r2_all <- cor(s_all, yte)^2

  # Grid of INFO thresholds
  thr_grid <- seq(min(R2), 0.95, by = 0.05)

  # Theoretical independent-SNPs estimate on TRUE scale
  a2 <- alpha_true^2
  denom <- sum(a2)

  results <- data.frame(
    mode = mode, threshold = thr_grid,
    obs_rel_r2 = NA_real_,
    est_rel_r2 = NA_real_,
    est_rel_r2_theory = NA_real_
  )

  for (i in seq_along(thr_grid)) {
    thr <- thr_grid[i]
    keep <- R2 >= thr

    alpha_mask <- alpha_true
    alpha_mask[!keep] <- 0
    s_keep <- as.vector(Xte %*% alpha_mask)

    r2_keep <- if (sd(s_keep) > 0) cor(s_keep, yte)^2 else 0
    results$obs_rel_r2[i] <- r2_keep / r2_all

    results$est_rel_r2[i] <- if (sd(s_keep) > 0) cor(s_all, s_keep)^2 else NA_real_

    results$est_rel_r2_theory[i] <- sum(a2[keep]) / denom
  }

  list(results = results, R2 = R2, alpha_true = alpha_true)
}

# ----- Run both imputation models but score on PERFECT target genotypes -----

sim_BG <- run_once(mode = "BG", seed = 11)
sim_DS <- run_once(mode = "DS", seed = 12)

res <- rbind(sim_BG$results, sim_DS$results)

# ----- Plots -----

# Observed vs Estimated (empirical), with 45° line, facet by mode
p1 <- ggplot(res, aes(x = est_rel_r2, y = obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3, alpha = 0.9) +
  scale_color_viridis_c(option = "C") +
  coord_equal(xlim = c(0,1), ylim = c(0,1)) +
  labs(title = "Observed relative R² vs Estimated (corr² of scores)",
       subtitle = "GWAS trained on imputed X (BG/DS); target scored on PERFECT (true) genotypes",
       x = "Estimated relative R² (corr² between baseline & masked PGS)",
       y = "Observed relative R² (R²_masked / R²_baseline)",
       color = "INFO\nthreshold") +
  facet_wrap(~ mode) +
  theme_minimal(base_size = 13)

print(p1)

```

```{r}
make_ld <- function(m, block=50, rho=0.8) {
  R <- diag(m)
  for (b in seq(1, m, by = block)) {
    e <- min(m, b + block - 1)
    k <- e - b + 1
    G <- rho ^ abs(outer(1:k, 1:k, "-"))   # AR(1) within block
    R[b:e, b:e] <- G
  }
  R
}

# draw true standardized genotypes with LD
rnorm_ld <- function(n, R) {
  m <- ncol(R)
  U <- chol(R)
  matrix(rnorm(n*m), n, m) %*% U
}

run_with_ld <- function(m_snps=4000, n_train=3000, n_test=2000, h2=0.5,
                        R2_min=.3, R2_max=1, mode=c("BG","DS"), seed=1,
                        block=50, rho_ld=.8) {
  set.seed(seed); mode <- match.arg(mode)
  R2  <- runif(m_snps, R2_min, R2_max); rho <- sqrt(R2)
  beta_true <- rnorm(m_snps, 0, sqrt(h2/m_snps))

  Rld <- make_ld(m_snps, block=block, rho=rho_ld)

  Xtr_true <- rnorm_ld(n_train, Rld)
  Xte_true <- rnorm_ld(n_test,  Rld)

  # Peter’s imputation models
  simulate_imputed <- function(X, R2, mode) {
    n <- nrow(X); m <- ncol(X); E <- matrix(rnorm(n*m), n, m)
    if (mode=="BG") {
      R <- sqrt(R2); sweep(X,2,R,`*`) + sweep(E,2,sqrt(1-R2),`*`)
    } else {
      sweep(X,2,R2,`*`) + sweep(E,2,sqrt(R2*(1-R2)),`*`)
    }
  }
  Xtr_imp <- simulate_imputed(Xtr_true, R2, mode)

  g_tr <- as.vector(Xtr_true %*% beta_true)
  ytr  <- scale(g_tr) * sqrt(h2) + rnorm(n_train, 0, sqrt(1-h2))
  g_te <- as.vector(Xte_true %*% beta_true)
  yte  <- scale(g_te) * sqrt(h2) + rnorm(n_test, 0, sqrt(1-h2))

  # Ridge on imputed X (standardised for stability)
  Xtr <- scale(Xtr_imp, center=TRUE, scale=TRUE)
  ytr <- scale(ytr,     center=TRUE, scale=TRUE)
  lambda <- m_snps * (1-h2)/h2
  beta_imp <- solve(crossprod(Xtr) + diag(lambda, m_snps), crossprod(Xtr, ytr))

  # Score on TRUE target without per-SNP rho correction (intentional miscalibration)
  Xte <- scale(Xte_true, center=TRUE, scale=TRUE)
  alpha <- as.numeric(beta_imp)

  s_all <- as.vector(Xte %*% alpha)
  r2_all <- cor(s_all, yte)^2

  thr_grid <- seq(min(R2), 0.95, by=.05)
  res <- data.frame(threshold = thr_grid, obs_rel_r2 = NA, est_rel_r2 = NA)
  for (i in seq_along(thr_grid)) {
    keep <- R2 >= thr_grid[i]
    alpha_k <- alpha; alpha_k[!keep] <- 0
    s_k <- as.vector(Xte %*% alpha_k)
    r2_k <- cor(s_k, yte)^2
    res$obs_rel_r2[i] <- r2_k / r2_all
    res$est_rel_r2[i] <- cor(s_all, s_k)^2
  }
  res
}

res_BG <- run_with_ld(mode="BG", seed=1)
res_DS <- run_with_ld(mode="DS", seed=11)

library(ggplot2)
res_BG$mode <- "BG"; res_DS$mode <- "DS"
res <- rbind(res_BG, res_DS)
ggplot(res, aes(est_rel_r2, obs_rel_r2, color=threshold)) +
  geom_abline(slope=1, intercept=0, linetype="dashed") +
  geom_point(size=3) + scale_color_viridis_c() +
  coord_equal(xlim=c(0,1), ylim=c(0,1)) +
  facet_wrap(~mode) +
  labs(title="Observed rel R² vs corr² with LD (block AR(1))",
       subtitle="Train on imputed X; target scored on perfect X; no rho correction",
       x="corr²(s_all, s_keep)", y="R²_keep / R²_all")
```

```{r}
simulate_denoising <- function(
  m_snps   = 2000,
  n_train  = 10000,     # GWAS sample size
  n_test   = 5000,     # validation sample size
  h2       = 0.5,      # SNP-heritability used for SBLUP lambda
  R2_min   = 0.3,      # INFO range
  R2_max   = 1.0,
  lambda   = NULL,     # if NULL, use SBLUP: m * (1/h2 - 1)
  seed     = 1
){
  set.seed(seed)

  ## 1) True effects and INFO per SNP
  beta_true <- rnorm(m_snps, 0, sqrt(h2 / m_snps))   # per-SD effects; SNPs independent
  INFO      <- runif(m_snps, R2_min, R2_max)

  ## 2) GWAS summary statistics on imputed training data (unbiased, INFO-dependent SE)
  sigma2 <- 1.0  # noise scale (doesn't need to match anything exactly)
  gwas_noise <- rnorm(m_snps, 0, sqrt(sigma2 / (n_train * INFO)))
  beta_hat   <- beta_true + gwas_noise

  ## 3) BLUP / ridge shrinkage with SBLUP lambda
  if (is.null(lambda)) lambda <- m_snps * ((1 / h2) - 1)   # COJO-SBLUP
  c_shrink   <- 1 / (1 + lambda)                           # R = I  =>  (I+λI)^{-1}
  beta_blup  <- c_shrink * beta_hat

  ## 4) Target: PERFECT (WGS-like) genotypes, independent SNPs
  Xte_true <- matrix(rnorm(n_test * m_snps), nrow = n_test, ncol = m_snps)
  Xte <- scale(Xte_true, center = TRUE, scale = TRUE)

  ## Phenotype from true genetic component
  g_te <- as.vector(Xte_true %*% beta_true)
  yte  <- scale(g_te) * sqrt(h2) + rnorm(n_test, 0, sqrt(1 - h2))

  ## 5) Baseline PGS with all SNPs
  s_all  <- as.vector(Xte %*% beta_blup)
  r2_all <- cor(s_all, yte)^2

  ## 6) Mask by INFO thresholds
  thr_grid <- seq(min(INFO), 0.95, by = 0.05)
  results <- data.frame(threshold = thr_grid,
                        obs_rel_r2 = NA_real_,
                        est_rel_r2 = NA_real_)

  for (i in seq_along(thr_grid)) {
    keep <- INFO >= thr_grid[i]

    beta_mask <- beta_blup
    beta_mask[!keep] <- 0

    s_keep <- as.vector(Xte %*% beta_mask)

    r2_keep <- if (sd(s_keep) > 0) cor(s_keep, yte)^2 else 0
    results$obs_rel_r2[i] <- r2_keep / r2_all
    results$est_rel_r2[i] <- if (sd(s_keep) > 0) cor(s_all, s_keep)^2 else NA_real_
  }

  list(results = results, INFO = INFO,
       beta_true = beta_true, beta_hat = beta_hat, beta_blup = beta_blup,
       lambda = lambda, shrink = c_shrink)
}

sim <- simulate_denoising(seed = 1)

res <- sim$results

ggplot(res, aes(x = est_rel_r2, y = obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3) +
  scale_color_viridis_c(option = "C") +
  coord_equal(xlim = c(0, 1), ylim = c(0, 1.1)) +
  labs(title = "Observed relative R² vs Estimated (corr² of scores) — no LD",
       subtitle = "GWAS betas unbiased but less precise when INFO is low; BLUP uses global λ (external)",
       x = "Estimated relative R² (corr² between baseline & masked PGS)",
       y = "Observed relative R² (R²_masked / R²_all)",
       color = "INFO\nthreshold") +
  theme_minimal(base_size = 13)
```

```{r}
# -----------------------------
# Simulation: Imputation quality, BLUP, masking by R^2
# Implements Peter Visscher's BG and DS definitions.
# -----------------------------

suppressPackageStartupMessages({
  library(ggplot2)
})

simulate_imputed <- function(X_true, R2, mode = c("BG","DS")) {
  mode <- match.arg(mode)
  n <- nrow(X_true); m <- ncol(X_true)
  E <- matrix(rnorm(n*m), n, m)
  if (mode == "BG") {
    R <- sqrt(R2)
    X_imp <- sweep(X_true, 2, R, `*`) + sweep(E, 2, sqrt(1 - R2), `*`)   # Var = 1
  } else {
    X_imp <- sweep(X_true, 2, R2, `*`) + sweep(E, 2, sqrt(R2 * (1 - R2)), `*`) # Var = R2
  }
  X_imp
}

run_once <- function(m_snps = 1000,
                     n_train = 5000,
                     n_test  = 2000,
                     h2 = 0.5,
                     R2_min = 0.1,
                     R2_max = 1.0,
                     mode = c("BG","DS"),
                     seed = 1) {
  set.seed(seed)
  mode <- match.arg(mode)

  # 1) True effects
  beta_true <- rnorm(m_snps, 0, sqrt(h2 / m_snps))
  R2 <- runif(m_snps, R2_min, R2_max)

  # 2) Training X (true) and imputed X' (BG or DS)
  Xtr_true <- matrix(rnorm(n_train * m_snps), n_train, m_snps)
  Xtr_imp  <- simulate_imputed(Xtr_true, R2, mode)

  # 3) Phenotype from true genetic component
  g_tr <- as.vector(Xtr_true %*% beta_true)
  ytr  <- scale(g_tr) * sqrt(h2) + rnorm(n_train, 0, sqrt(1 - h2))

  # 4) BLUP / Ridge on *imputed* X (fit and score on same scale!)
  # Standardise columns of Xtr_imp; keep scaling to apply to test set
  Xtr <- scale(Xtr_imp, center = TRUE, scale = TRUE)
  ytr <- scale(ytr, center = TRUE, scale = TRUE)

  lambda <- m_snps * (1 - h2) / h2
  XtX <- crossprod(Xtr)
  Xty <- crossprod(Xtr, ytr)
  beta_hat <- solve(XtX + diag(lambda, m_snps), Xty)  # m x 1

  # 5) Test set (true and imputed), score with same scaling as training
  Xte_true <- matrix(rnorm(n_test * m_snps), n_test, m_snps)
  Xte_imp  <- simulate_imputed(Xte_true, R2, mode)
  Xte <- scale(Xte_true,
               center = attr(Xtr, "scaled:center"),
               scale  = attr(Xtr, "scaled:scale"))
  #Xte <- Xte_true
  
  g_te <- as.vector(Xte_true %*% beta_true)
  yte  <- scale(g_te) * sqrt(h2) + rnorm(n_test, 0, sqrt(1 - h2))

  # Baseline score with all SNPs
  s_all <- as.vector(Xte %*% beta_hat)
  r2_all <- cor(s_all, yte)^2

  # Threshold grid
  thr_grid <- seq(min(R2), 0.95, by = 0.05)

  # For independent SNPs, the theoretical corr^2(s_all, s_keep) equals:
  # Var(s_keep)/Var(s_all) = sum_kept a_j^2 Var(Z'_j) / sum_all a_j^2 Var(Z'_j)
  # where a_j are the learned coefficients after standardising Xtr_imp.
  # Var(Z'_j) is 1 for BG, R2_j for DS.
  var_col <- if (mode == "BG") rep(1, m_snps) else R2
  a2V <- as.numeric(beta_hat)^2 * var_col
  denom <- sum(a2V)

  results <- data.frame(
    mode = mode,
    threshold = thr_grid,
    obs_rel_r2 = NA_real_,
    est_rel_r2 = NA_real_,
    est_rel_r2_theory = NA_real_
  )

  for (i in seq_along(thr_grid)) {
    thr <- thr_grid[i]
    keep <- R2 >= thr

    beta_mask <- beta_hat
    beta_mask[!keep] <- 0
    s_keep <- as.vector(Xte %*% beta_mask)

    # Observed relative R^2 (vs phenotype)
    r2_keep <- if (sd(s_keep) > 0) cor(s_keep, yte)^2 else 0
    results$obs_rel_r2[i] <- r2_keep / r2_all

    # Estimated relative R^2 proxy (corr^2 of scores)
    results$est_rel_r2[i] <- if (sd(s_keep) > 0) cor(s_all, s_keep)^2 else NA_real_

    # Independent-SNPs theoretical corr^2(s_all, s_keep)
    results$est_rel_r2_theory[i] <- sum(a2V[keep]) / denom
  }

  list(results = results, beta_hat = beta_hat, R2 = R2)
}

# ---- Run both modes and plot ----

sim_BG <- run_once(mode = "BG", seed = 42)
sim_DS <- run_once(mode = "DS", seed = 43)

res <- rbind(sim_BG$results, sim_DS$results)

# Plot: Observed vs Estimated (empirical), with 45° line; color by threshold, facet by mode
p1 <- ggplot(res, aes(x = est_rel_r2, y = obs_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  geom_point(size = 3, alpha = 0.9) +
  scale_color_viridis_c(option = "C") +
  labs(title = "Observed relative R² vs Estimated (corr² of scores)",
       subtitle = "BLUP trained on imputed X; masking by INFO (R²) threshold",
       x = "Estimated relative R² (corr² between baseline & masked PGS)",
       y = "Observed relative R² (R²_masked / R²_baseline)",
       color = "INFO\nthreshold") +
  facet_wrap(~ mode) +
  theme_minimal(base_size = 13)

p1

# Optional: compare empirical estimated vs independent-SNPs theory (should align closely)
p2 <- ggplot(res, aes(x = est_rel_r2_theory, y = est_rel_r2, color = threshold)) +
  geom_abline(slope = 1, intercept = 0, linetype = "dotted") +
  geom_point(size = 3, alpha = 0.9) +
  scale_color_viridis_c(option = "C") +
  labs(title = "Empirical corr² vs independent-SNPs theory",
       subtitle = "Theory: sum_kept (a_j² Var(Z'_j)) / sum_all (a_j² Var(Z'_j))",
       x = "Theoretical corr²(s_all, s_keep)",
       y = "Empirical corr²(s_all, s_keep)",
       color = "INFO\nthreshold") +
  facet_wrap(~ mode) +
  theme_minimal(base_size = 13)

print(p1)
print(p2)
```


```{r}
# R Code to Simulate and Test the "Denoising" Theory
#
# --- VERSION 2 (Cleaner Test) ---
#
# This version implements the user's suggestion to use "perfect" (true)
# genotypes in the test/validation set.
#
# This isolates the source of error to *only* the noisy GWAS betas
# from the training step, providing a cleaner test of the "denoising" theory.

library(ggplot2)

set.seed(42) # For reproducible results

# --- 1. Simulation Parameters ---
m_snps <- 1000   # Number of unlinked SNPs
n_train <- 5000  # Individuals in GWAS (training)
n_test <- 2000   # Individuals in PGS validation (test)
h2 <- 0.5        # Phenotype heritability

cat("--- Starting Simulation (v2: Clean Test Set) ---\n")
cat(sprintf("SNPs: %d, Training N: %d, Test N: %d, h²: %.2f\n", m_snps, n_train, n_test, h2))

# --- 2. Create the "True" World (Betas, Imputation R²) ---
# (Step 1 from email)
true_beta <- rnorm(m_snps, 0, sqrt(h2 / m_snps))
snp_imputation_r2 <- runif(m_snps, 0.3, 1.0)

# --- 3. Create Training Set (GWAS) ---
# (This section is identical to v1)

# Simulate true, standardized genotypes ~ N(0,1)
x_train_true <- matrix(rnorm(n_train * m_snps), nrow = n_train, ncol = m_snps)

# Simulate imputed dosages (x_d)
cat("Simulating training set imputed dosages...\n")
x_train_imputed <- matrix(NA, nrow = n_train, ncol = m_snps)
for (j in 1:m_snps) {
  R2 <- snp_imputation_r2[j]
  true_x_j <- x_train_true[, j]
  error_var_j <- R2 * (1 - R2)
  if (error_var_j < 0) error_var_j <- 0 
  error_j <- rnorm(n_train, 0, sqrt(error_var_j))
  x_train_imputed[, j] <- R2 * true_x_j + error_j
}

# Simulate phenotype (y) based on *TRUE* genotypes
# (Step 2 from email)
true_pgs_train <- x_train_true %*% true_beta
true_pgs_train_scaled <- scale(true_pgs_train) * sqrt(h2)
error_train <- rnorm(n_train, 0, sqrt(1 - h2))
y_train <- true_pgs_train_scaled + error_train

# --- 4. Mimic GWAS ---
# (This section is identical to v1)
# Regress y_train on *IMPUTED* genotypes (x_train_imputed)
# This creates the "noisy" beta estimates (beta_hat)
cat("Running simulated GWAS...\n")
beta_hat_noisy <- numeric(m_snps)
for (j in 1:m_snps) {
  model <- lm(y_train ~ x_train_imputed[, j])
  beta_hat_noisy[j] <- coef(model)[2]
}

# --- 5. Create Test Set (Validation) ---
# (Step 1, repeated for test sample)

# Simulate true, standardized genotypes ~ N(0,1)
# *** NOTE: We will use THIS for the PGS calculation ***
x_test_true <- matrix(rnorm(n_test * m_snps), nrow = n_test, ncol = m_snps)

# Simulate phenotype (y) based on *TRUE* genotypes
# (Step 2, repeated for test sample)
true_pgs_test <- x_test_true %*% true_beta
true_pgs_test_scaled <- scale(true_pgs_test) * sqrt(h2)
error_test <- rnorm(n_test, 0, sqrt(1 - h2))
y_test <- true_pgs_test_scaled + error_test

# --- 6. Perform Out-of-Sample Validation & Test Theory ---
# (Step 5 from email)
# *** MODIFIED SECTION ***

cat("Calculating metrics across INFO thresholds (using TRUE test genotypes)...\n")
info_thresholds <- seq(min(snp_imputation_r2), 0.95, by = 0.05)
results <- data.frame(
  threshold = info_thresholds,
  obs_rel_r2 = NA_real_,
  est_rel_r2 = NA_real_
)

# Calculate the "baseline" PGS using ALL noisy betas
# This is our 's' (the "noisy" score)
beta_baseline <- beta_hat_noisy

# *** CHANGE ***
# Apply betas to TRUE genotypes, not imputed ones
s_baseline <- x_test_true %*% beta_baseline 

# Calculate its R² against the phenotype. This is our denominator (R²_baseline).
r2_baseline_vs_pheno <- cor(s_baseline, y_test)^2

for (i in 1:length(info_thresholds)) {
  thresh <- info_thresholds[i]
  
  # Create the mask for "denoising"
  mask <- snp_imputation_r2 >= thresh
  
  # Create the masked (denoised) beta vector
  beta_masked <- beta_hat_noisy
  beta_masked[!mask] <- 0
  
  # Create the masked PGS (s')
  # *** CHANGE ***
  # Apply masked betas to TRUE genotypes
  s_masked <- x_test_true %*% beta_masked
  
  # --- Calculate the two metrics ---
  
  # 1. "Observed Relative R²" (Y-axis)
  #    This is R²(s', Y) / R²(s_baseline, Y)
  r2_masked_vs_pheno <- cor(s_masked, y_test)^2
  results$obs_rel_r2[i] <- r2_masked_vs_pheno / r2_baseline_vs_pheno
  
  # 2. "Estimated Relative R²" (X-axis)
  #    This is cor(s_baseline, s_masked)²
  if (var(s_masked) == 0 || var(s_baseline) == 0) {
    results$est_rel_r2[i] <- NA
  } else {
    results$est_rel_r2[i] <- cor(s_baseline, s_masked)^2
  }
}

# --- 7. Plot the Results ---
cat("Generating plot...\n")
print(results)

denoising_plot_v2 <- ggplot(results, aes(x = est_rel_r2, y = obs_rel_r2)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
  geom_point(aes(color = threshold), size = 4, alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", threshold)), vjust = -1, size = 3.5, color = "black") +
  labs(
    title = "Simulation Test of 'Denoising' Theory (v2: Clean Test Set)",
    subtitle = "Isolating the effect of noisy GWAS betas. Points above the red line support the theory.",
    x = "Estimated Relative R² ( cor(s_baseline, s_masked)² )",
    y = "Observed Relative R² ( R²(s_masked, Y) / R²(s_baseline, Y) )",
    color = "INFO Threshold"
  ) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme_minimal(base_size = 14) +
  xlim(0, 1) +
  ylim(min(results$obs_rel_r2, 0, na.rm = TRUE), max(results$obs_rel_r2, 1.2, na.rm = TRUE)) # Allow Y to go > 1

print(denoising_plot_v2)
```

```{r}
# R Code to Simulate and Test the "Denoising" Theory
#
# --- VERSION 3 (BLUP/Ridge Regression) ---
#
# This version implements the user's request to incorporate Step 4
# from the email: "Estimate SNP effects using BLUP".
#
# We replace the single-SNP regressions with a single, joint
# BLUP (Ridge Regression) model. This is a more realistic
# model of how modern PGS weights are estimated.
#
# This will test if the "denoising" theory holds even when the
# estimation method already shrinks weights based on variance.

# Install/load libraries
# You may need to install 'MASS' if you don't have it: install.packages("MASS")
library(ggplot2)
library(MASS) # For lm.ridge

set.seed(42) # For reproducible results

# --- 1. Simulation Parameters ---
m_snps <- 1000   # Number of unlinked SNPs
n_train <- 20000  # Individuals in GWAS (training)
n_test <- 5000   # Individuals in PGS validation (test)
h2 <- 0.5        # Phenotype heritability

cat("--- Starting Simulation (v3: BLUP/Ridge Regression) ---\n")
cat(sprintf("SNPs: %d, Training N: %d, Test N: %d, h²: %.2f\n", m_snps, n_train, n_test, h2))

# --- 2. Create the "True" World (Betas, Imputation R²) ---
true_beta <- rnorm(m_snps, 0, sqrt(h2 / m_snps))
snp_imputation_r2 <- runif(m_snps, 0.1, 0.9)

# --- 3. Create Training Set (GWAS) ---
# Simulate true, standardized genotypes ~ N(0,1)
x_train_true <- matrix(rnorm(n_train * m_snps), nrow = n_train, ncol = m_snps)

# Simulate imputed dosages (x_d)
cat("Simulating training set imputed dosages...\n")
x_train_imputed <- matrix(NA, nrow = n_train, ncol = m_snps)
for (j in 1:m_snps) {
  R2 <- snp_imputation_r2[j]
  true_x_j <- x_train_true[, j]
  error_var_j <- R2 * (1 - R2)
  if (error_var_j < 0) error_var_j <- 0 
  error_j <- rnorm(n_train, 0, sqrt(error_var_j))
  x_train_imputed[, j] <- R2 * true_x_j + error_j
}

# Simulate phenotype (y) based on *TRUE* genotypes
true_pgs_train <- x_train_true %*% true_beta
true_pgs_train_scaled <- scale(true_pgs_train) * sqrt(h2)
error_train <- rnorm(n_train, 0, sqrt(1 - h2))
y_train <- true_pgs_train_scaled + error_train

# --- 4. Estimate SNP Effects using BLUP ---
# (This replaces the old Step 4)
# We will use Ridge Regression, which is equivalent to BLUP
# for SNP effect estimation.
# y = Xb + e
# The BLUP solution shrinks betas: b_hat = (X'X + lambda*I)^-1 * X'y
# The shrinkage parameter lambda = (m_snps * (1-h2) / h2)
cat("Running BLUP (Ridge Regression) to get noisy betas...\n")

# Center data (to avoid fitting an intercept)
X_train_imputed_centered <- scale(x_train_imputed, center = TRUE, scale = FALSE)
X_train_true_centered <- scale(x_train_true, center = TRUE, scale = FALSE)
y_train_centered <- scale(y_train, center = TRUE, scale = FALSE)

# Calculate lambda
lambda_blup <- m_snps * (1 - h2) / h2

# Calculate GBLUP/Ridge Regression estimates
# Note: solve(A, b) is the efficient way to solve A*x = b for x
# We want to solve (X'X + lambda*I) * b = X'y
XtX <- t(X_train_true_centered) %*% X_train_true_centered
Xty <- t(X_train_imputed_centered) %*% y_train_centered
lambda_I <- diag(lambda_blup, m_snps)

# These are the "noisy" (but shrunken) beta estimates
beta_hat_noisy_blup <- solve(XtX + lambda_I) %*% Xty
beta_hat_noisy_blup <- as.vector(beta_hat_noisy_blup)

# --- 5. Create Test Set (Validation) ---
# (Identical to v2)
x_test_true <- matrix(rnorm(n_test * m_snps), nrow = n_test, ncol = m_snps)
true_pgs_test <- x_test_true %*% true_beta
true_pgs_test_scaled <- scale(true_pgs_test) * sqrt(h2)
error_test <- rnorm(n_test, 0, sqrt(1 - h2))
y_test <- true_pgs_test_scaled + error_test

# --- 6. Perform Out-of-Sample Validation & Test Theory ---
cat("Calculating metrics across INFO thresholds (using BLUP betas)...\n")
info_thresholds <- seq(min(snp_imputation_r2), 0.95, by = 0.05)
results <- data.frame(
  threshold = info_thresholds,
  obs_rel_r2 = NA_real_,
  est_rel_r2 = NA_real_
)

# Center the true test genotypes using the *training* data's mean
# (This is the correct procedure for applying the model)
x_test_centered <- scale(x_test_true, center = colMeans(x_train_imputed), scale = FALSE)

# Calculate the "baseline" PGS using ALL noisy BLUP betas
beta_baseline <- beta_hat_noisy_blup
s_baseline <- x_test_centered %*% beta_baseline 
r2_baseline_vs_pheno <- cor(s_baseline, y_test)^2

for (i in 1:length(info_thresholds)) {
  thresh <- info_thresholds[i]
  mask <- snp_imputation_r2 >= thresh
  
  beta_masked <- beta_hat_noisy_blup
  beta_masked[!mask] <- 0
  
  s_masked <- x_test_centered %*% beta_masked
  
  # 1. "Observed Relative R²" (Y-axis)
  r2_masked_vs_pheno <- cor(s_masked, y_test)^2
  results$obs_rel_r2[i] <- r2_masked_vs_pheno / r2_baseline_vs_pheno
  
  # 2. "Estimated Relative R²" (X-axis)
  if (var(s_masked) == 0 || var(s_baseline) == 0) {
    results$est_rel_r2[i] <- NA
  } else {
    results$est_rel_r2[i] <- cor(s_baseline, s_masked)^2
  }
}

# --- 7. Plot the Results ---
cat("Generating plot...\n")
print(results)

denoising_plot_v3_blup <- ggplot(results, aes(x = est_rel_r2, y = obs_rel_r2)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
  geom_point(aes(color = threshold), size = 4, alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", threshold)), vjust = -1, size = 3.5, color = "black") +
  labs(
    title = "Simulation Test of 'Denoising' Theory (v3: BLUP Model)",
    subtitle = "Using BLUP/Ridge Regression to estimate betas. Points above the red line support the theory.",
    x = "Estimated Relative R² ( cor(s_baseline, s_masked)² )",
    y = "Observed Relative R² ( R²(s_masked, Y) / R²(s_baseline, Y) )",
    color = "INFO Threshold"
  ) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme_minimal(base_size = 14) +
  xlim(0, 1) +
  ylim(min(results$obs_rel_r2, 0, na.rm = TRUE), max(results$obs_rel_r2, 1.2, na.rm = TRUE))

print(denoising_plot_v3_blup)

```

```{r}
# R Code to Simulate and Test the "Denoising" Theory
#
# --- VERSION 5 (Realistic "Decoupled" BLUP Model) ---
#
# This version correctly implements the full, decoupled process:
#
# 1. (Step 3) A "realistic" GWAS is run (single-SNP `lm(y ~ x_d)`),
#    which creates "noisy betas" (`beta_hat_noisy`).
# 2. (Step 4.5) A BLUP model is applied to these noisy betas,
#    simulating a method (like LDPred) that is "blind" to the
#    GWAS imputation quality. In our unlinked case, this
#    simplifies to a uniform shrinkage of all noisy betas.
# 3. (Step 6) These new, shrunken BLUP betas are used to build the PGS.

library(ggplot2)

set.seed(42) # For reproducible results

# --- 1. Simulation Parameters ---
m_snps <- 1000   # Number of unlinked SNPs
n_train <- 5000  # Individuals in GWAS (training)
n_test <- 2000   # Individuals in PGS validation (test)
h2 <- 0.5        # Phenotype heritability

cat("--- Starting Simulation (v5: Realistic Decoupled BLUP) ---\n")
cat(sprintf("SNPs: %d, Training N: %d, Test N: %d, h²: %.2f\n", m_snps, n_train, n_test, h2))

# --- 2. Create the "True" World (Betas, Imputation R²) ---
true_beta <- rnorm(m_snps, 0, sqrt(h2 / m_snps))
snp_imputation_r2 <- runif(m_snps, 0.3, 1.0)

# --- 3. Create Training Set (GWAS) ---
# Simulate true, standardized genotypes ~ N(0,1)
x_train_true <- matrix(rnorm(n_train * m_snps), nrow = n_train, ncol = m_snps)

# Simulate imputed dosages (x_d)
cat("Simulating training set imputed dosages...\n")
x_train_imputed <- matrix(NA, nrow = n_train, ncol = m_snps)
for (j in 1:m_snps) {
  R2 <- snp_imputation_r2[j]
  true_x_j <- x_train_true[, j]
  error_var_j <- R2 * (1 - R2)
  if (error_var_j < 0) error_var_j <- 0 
  error_j <- rnorm(n_train, 0, sqrt(error_var_j))
  x_train_imputed[, j] <- R2 * true_x_j + error_j
}

# Simulate phenotype (y) based on *TRUE* genotypes
true_pgs_train <- x_train_true %*% true_beta
true_pgs_train_scaled <- scale(true_pgs_train) * sqrt(h2)
error_train <- rnorm(n_train, 0, sqrt(1 - h2))
y_train <- true_pgs_train_scaled + error_train

# --- 4. Estimate "Noisy" SNP Effects (Realistic GWAS) ---
# (This is Step 3 from the email)
# Regress y_train on *IMPUTED* genotypes (x_train_imputed)
# This creates the "noisy" beta estimates
cat("Running simulated GWAS (single-SNP regressions)...\n")
beta_hat_noisy <- numeric(m_snps)
for (j in 1:m_snps) {
  model <- lm(y_train ~ x_train_imputed[, j])
  beta_hat_noisy[j] <- coef(model)[2]
}

# --- 4.5 Apply "Decoupled" BLUP Shrinkage ---
# (This is Step 4 from the email)
# We apply BLUP shrinkage to the noisy betas from Step 4.
# The external LD reference (R_ref) is the Identity matrix (I)
# The BLUP formula is: beta_blup = (R_ref + lambda*I)^-1 * beta_hat
# This simplifies to: beta_blup = (I + lambda*I)^-1 * beta_hat
# This becomes: beta_blup = (1 / (1 + lambda)) * beta_hat
# This is a *uniform* shrinkage of the noisy betas.

cat("Applying decoupled BLUP (uniform shrinkage) to noisy betas...\n")
# Calculate lambda (the shrinkage parameter)
lambda_blup <- m_snps * (1 - h2) / h2
shrinkage_factor <- 1 / (1 + lambda_blup)

# Apply uniform shrinkage
beta_blup <- beta_hat_noisy * shrinkage_factor

# --- 5. Create Test Set (Validation) ---
# (Identical to v4)
x_test_true <- matrix(rnorm(n_test * m_snps), nrow = n_test, ncol = m_snps)
true_pgs_test <- x_test_true %*% true_beta
true_pgs_test_scaled <- scale(true_pgs_test) * sqrt(h2)
error_test <- rnorm(n_test, 0, sqrt(1 - h2))
y_test <- true_pgs_test_scaled + error_test

# --- 6. Perform Out-of-Sample Validation & Test Theory ---
cat("Calculating metrics across INFO thresholds (using BLUP-shrunken betas)...\n")
info_thresholds <- seq(min(snp_imputation_r2), 0.95, by = 0.05)
results <- data.frame(
  threshold = info_thresholds,
  obs_rel_r2 = NA_real_,
  est_rel_r2 = NA_real_
)

# Calculate the "baseline" PGS using ALL BLUP betas
# This is our 's' (the "noisy" score)
beta_baseline <- beta_blup
s_baseline <- x_test_true %*% beta_baseline 

# Calculate its R² against the phenotype. This is our denominator (R²_baseline).
r2_baseline_vs_pheno <- cor(s_baseline, y_test)^2

for (i in 1:length(info_thresholds)) {
  thresh <- info_thresholds[i]
  
  # Create the mask for "denoising"
  mask <- snp_imputation_r2 >= thresh
  
  # Create the masked (denoised) beta vector
  beta_masked <- beta_blup
  beta_masked[!mask] <- 0
  
  # Create the masked PGS (s')
  s_masked <- x_test_true %*% beta_masked
  
  # --- Calculate the two metrics ---
  
  # 1. "Observed Relative R²" (Y-axis)
  #    This is R²(s', Y) / R²(s_baseline, Y)
  r2_masked_vs_pheno <- cor(s_masked, y_test)^2
  results$obs_rel_r2[i] <- r2_masked_vs_pheno / r2_baseline_vs_pheno
  
  # 2. "Estimated Relative R²" (X-axis)
  #    This is cor(s_baseline, s_masked)²
  if (var(s_masked) == 0 || var(s_baseline) == 0) {
    results$est_rel_r2[i] <- NA
  } else {
    results$est_rel_r2[i] <- cor(s_baseline, s_masked)^2
  }
}

# --- 7. Plot the Results ---
cat("Generating plot...\n")
print(results)

denoising_plot_v5 <- ggplot(results, aes(x = est_rel_r2, y = obs_rel_r2)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
  geom_point(aes(color = threshold), size = 4, alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", threshold)), vjust = -1, size = 3.5, color = "black") +
  labs(
    title = "Simulation Test of 'Denoising' Theory (v5: Realistic Decoupled BLUP)",
    subtitle = "Using single-SNP betas + uniform BLUP shrinkage. Points above the red line support the theory.",
    x = "Estimated Relative R² ( cor(s_baseline, s_masked)² )",
    y = "Observed Relative R² ( R²(s_masked, Y) / R²(s_baseline, Y) )",
    color = "INFO Threshold"
  ) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme_minimal(base_size = 14) +
  xlim(0, 1) +
  ylim(min(results$obs_rel_r2, 0, na.rm = TRUE), max(results$obs_rel_r2, 1.2, na.rm = TRUE)) # Allow Y to go > 1

print(denoising_plot_v5)
```

```{r}
# R Code to Simulate and Test the "Denoising" Theory
#
# --- VERSION 6 (SE-Aware Shrinkage Model) ---
#
# This version *correctly* implements the user's insight.
#
# 1. (Step 3) A "realistic" GWAS is run (single-SNP `lm(y ~ x_d)`)
#    to generate *both* "noisy betas" (`beta_hat_noisy`) AND
#    their "noisy Standard Errors" (`SE_noisy`).
# 2. (Step 4) We implement a Bayesian shrinkage model (like a simple
#    SBayesRC) that *uses* the per-SNP SE to shrink the noisy betas.
# 3. (Step 6) We test if filtering *these* "smart-shrunk" betas
#    by their original INFO score *still* produces a denoising effect.
#
# This tests the hypothesis that SBayesRC-like models can be
# "fooled" by the model violation from low-INFO SNPs.

library(ggplot2)

set.seed(42) # For reproducible results

# --- 1. Simulation Parameters ---
m_snps <- 1000   # Number of unlinked SNPs
n_train <- 10000  # Individuals in GWAS (training)
n_test <- 5000   # Individuals in PGS validation (test)
h2 <- 0.5        # Phenotype heritability
h2_snp <- h2 / m_snps # Prior variance for a single SNP

cat("--- Starting Simulation (v6: SE-Aware Shrinkage) ---\n")
cat(sprintf("SNPs: %d, Training N: %d, Test N: %d, h²: %.2f\n", m_snps, n_train, n_test, h2))

# --- 2. Create the "True" World (Betas, Imputation R²) ---
true_beta <- rnorm(m_snps, 0, sqrt(h2_snp))
snp_imputation_r2 <- runif(m_snps, 0.1, 1.0)

# --- 3. Create Training Set (GWAS) ---
x_train_true <- matrix(rnorm(n_train * m_snps), nrow = n_train, ncol = m_snps)
x_train_imputed <- matrix(NA, nrow = n_train, ncol = m_snps)
for (j in 1:m_snps) {
  R2 <- snp_imputation_r2[j]
  true_x_j <- x_train_true[, j]
  error_var_j <- R2 * (1 - R2)
  if (error_var_j < 0) error_var_j <- 0 
  error_j <- rnorm(n_train, 0, sqrt(error_var_j))
  x_train_imputed[, j] <- R2 * true_x_j + error_j
}

true_pgs_train <- x_train_true %*% true_beta
true_pgs_train_scaled <- scale(true_pgs_train) * sqrt(h2)
error_train <- rnorm(n_train, 0, sqrt(1 - h2))
y_train <- true_pgs_train_scaled + error_train

# --- 4. Estimate "Noisy" Betas and SEs (Realistic GWAS) ---
# (This is Step 3 from the email)
cat("Running simulated GWAS (getting noisy betas and SEs)...\n")
beta_hat_noisy <- numeric(m_snps)
se_hat_noisy <- numeric(m_snps)
for (j in 1:m_snps) {
  model_summary <- summary(lm(y_train ~ x_train_imputed[, j]))
  beta_hat_noisy[j] <- model_summary$coefficients[2, 1]
  se_hat_noisy[j] <- model_summary$coefficients[2, 2]
}

# --- 4.5 Apply "SE-Aware" Bayesian Shrinkage ---
# (This simulates Step 4, a simple SBayesRC-like model)
#
# We use a standard Bayesian shrinkage formula (Normal-Normal model):
# beta_shrunk = beta_hat * (prior_var / (prior_var + se^2))
# This model *explicitly* uses the SE to shrink the beta.

cat("Applying SE-Aware (SBayesRC-like) shrinkage to noisy betas...\n")
prior_var <- h2_snp # Use the true per-SNP variance as our prior
beta_shrunk <- beta_hat_noisy * (prior_var / (prior_var + se_hat_noisy^2))
beta_shrunk <- beta_hat_noisy

# --- 5. Create Test Set (Validation) ---
x_test_true <- matrix(rnorm(n_test * m_snps), nrow = n_test, ncol = m_snps)
true_pgs_test <- x_test_true %*% true_beta
true_pgs_test_scaled <- scale(true_pgs_test) * sqrt(h2)
error_test <- rnorm(n_test, 0, sqrt(1 - h2))
y_test <- true_pgs_test_scaled + error_test

# --- 6. Perform Out-of-Sample Validation & Test Theory ---
cat("Calculating metrics across INFO thresholds (using SE-shrunk betas)...\n")
info_thresholds <- seq(min(snp_imputation_r2), 0.95, by = 0.05)
results <- data.frame(
  threshold = info_thresholds,
  obs_rel_r2 = NA_real_,
  est_rel_r2 = NA_real_
)

# Calculate the "baseline" PGS using ALL SE-shrunk betas
# This is our 's_baseline'
beta_baseline <- beta_shrunk
s_baseline <- x_test_true %*% beta_baseline 

r2_baseline_vs_pheno <- cor(s_baseline, y_test)^2
if (r2_baseline_vs_pheno == 0) r2_baseline_vs_pheno <- 1e-9 # Avoid division by zero

for (i in 1:length(info_thresholds)) {
  thresh <- info_thresholds[i]
  
  # Create the mask for "denoising"
  mask <- snp_imputation_r2 >= thresh
  
  # Create the masked (denoised) beta vector
  beta_masked <- beta_shrunk
  beta_masked[!mask] <- 0
  
  # Create the masked PGS (s')
  s_masked <- x_test_true %*% beta_masked
  
  # --- Calculate the two metrics ---
  
  # 1. "Observed Relative R²" (Y-axis)
  r2_masked_vs_pheno <- cor(s_masked, y_test)^2
  results$obs_r2[i] <- r2_baseline_vs_pheno
  results$est_r2[i] <- r2_masked_vs_pheno
  results$obs_rel_r2[i] <- r2_masked_vs_pheno / r2_baseline_vs_pheno
  
  # 2. "Estimated Relative R²" (X-axis)
  if (var(s_masked) == 0 || var(s_baseline) == 0) {
    results$est_rel_r2[i] <- NA
  } else {
    results$est_rel_r2[i] <- cor(s_baseline, s_masked)^2
  }
}

# --- 7. Plot the Results ---
cat("Generating plot...\n")
print(results)

denoising_plot_v6 <- ggplot(results, aes(x = est_rel_r2, y = obs_rel_r2)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red", linewidth = 1) +
  geom_point(aes(color = threshold), size = 4, alpha = 0.8) +
  geom_text(aes(label = sprintf("%.2f", threshold)), vjust = -1, size = 3.5, color = "black") +
  labs(
    title = "Simulation Test of 'Denoising' Theory (v6: SE-Aware Model)",
    subtitle = "Using SE-aware shrinkage to mimic SBayesRC. Points above the red line support the theory.",
    x = "Estimated Relative R² ( cor(s_baseline, s_masked)² )",
    y = "Observed Relative R² ( R²(s_masked, Y) / R²(s_baseline, Y) )",
    color = "INFO Threshold"
  ) +
  scale_color_gradient(low = "blue", high = "orange") +
  theme_minimal(base_size = 14) +
  xlim(0, 1) +
  ylim(min(results$obs_rel_r2, 0, na.rm = TRUE), max(results$obs_rel_r2, 1.2, na.rm = TRUE)) # Allow Y to go > 1

print(denoising_plot_v6)

```
***

# Find set of well imputed variants

Using data from the rsq browser, find a subset of variants with high imputation quality across arrays, imputation panels, and ancestries. Drop the HC chip as not representative, and also drop the 1KG panel as most datasets are HRC or topmed imputed these days.

```{r}
library(data.table)

populations <- c('EUR','AMR','AFR','FIN')
n <- c(2429, 3141, 7169, 2703)
files <-
  c(
    'mlof.bi.snv.tab.gz',
    'biome.bi.snv.tab.gz',
    'inpsyght.bi.snv.tab.gz',
    'metsim.bi.snv.tab.gz'
  )

for(i in 1:length(populations)){
  rsq <- fread(paste0('~/oliverpainfel/Data/RsqBrowser2/', files[i]))
  rsq$MAF <- rsq$AF
  rsq$MAF[rsq$AF > 0.5] <- 1 - rsq$AF[rsq$AF > 0.5]
  rsq$MAC <- 2*n[i]*rsq$MAF
  
  # Remove rows with MAC < 20 to avoid inaccurate rsq
  rsq <- rsq[rsq$MAC > 20,]
  
  # Subset rsq columns for relevant arrays and panels
  rsq_metrics <-
    rsq[, grepl('^OE|^IO|^MG', names(rsq)) &
          grepl('hrc$|top$', names(rsq)) &
          !grepl('_in$', names(rsq)), with = F]
  
  # Set NA to 0
  rsq_metrics[is.na(rsq_metrics)] <- 0
  
  # Identify to rsq > 0.95
  rsq_95 <- apply(rsq_metrics, 1, function(x) min(x) > 0.95)
  
  # Identify MAF > 0.001 - Relaxed threshold, but removes dodgy rsq estimates.
  fwrite(
    rsq[rsq_95, c('CHR', 'POS', 'REF', 'ALT', 'AF'), with = F],
    paste0(
      '~/oliverpainfel/Data/RsqBrowser2/',
      populations[i],
      '.min_rsq_95.mac_20.txt.gz'
    ),
    sep = ' ',
    quote = F,
    na = 'NA'
  )
}

rsq_95_all <- list()
for(i in 1:length(populations)){
  tmp <- fread(paste0(
    '~/oliverpainfel/Data/RsqBrowser2/',
    populations[i],
    '.min_rsq_95.mac_20.txt.gz'
  ))
  tmp$ID <- paste0(tmp$CHR,':',tmp$POS,':',tmp$REF,':',tmp$ALT)
  
  rsq_95_all[[populations[i]]] <- tmp$ID
}

library(VennDiagram)

display_venn <- function(x, ...){
  library(VennDiagram)
  grid.newpage()
  venn_object <- venn.diagram(x, filename = NULL, ...)
  grid.draw(venn_object)
}

display_venn(rsq_95_all)

# There are ~3M variants that are well imputed in all populations.
# There are ~6M variants that are well imputed in EUR

library(UpSetR)
upset(fromList(rsq_95_all), order.by = "freq")

```

***

# Real world example: PGC ADR

I have downloaded the imputation info scores across PGC antidepressant response datasets that have been imputed using the HRC imputation panel. Check the info of HapMap3 and SBayesRC variants. Then calculate relative PGS R2 of CAD PGS.

***

## SNP-list availability

```{r}
library(data.table)

# Read in snplist and rsq information
hm3 <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/hm3.rds')
sbayesrc <- readRDS('~/oliverpainfel/Analyses/mind_the_gap/snp_data/sbayesrc_7m.rds')

# We will merge by SNP, A1 and A2 information, so delete other information
hm3$CHR <- NULL
hm3$BP <- NULL
sbayesrc$CHR <- NULL
sbayesrc$BP <- NULL

cohorts <- c('gsk','dast','genpod','gendep','pfz','gods','mayo')
all_rsq <- NULL
for(cohort in cohorts){
  print(cohort)
  dat <- fread(paste0('~/oliverpainfel/Data/mind_the_gap/pgc_adr/', cohort,'.info.gz'))
  dat <- dat[, c('SNP','a1','a2','info'), with=F]
  names(dat)<-c('SNP','A1','A2','INFO')

  # Merge with hm3 and sbayesrc snplists
  hm3_rsq <- merge(hm3, dat, by = 'SNP', all.x = T)
  hm3_rsq <- hm3_rsq[
    (hm3_rsq$A1.x == hm3_rsq$A1.y & hm3_rsq$A2.x == hm3_rsq$A2.y) |
    (hm3_rsq$A1.x == hm3_rsq$A2.y & hm3_rsq$A2.x == hm3_rsq$A1.y) |
    is.na(hm3_rsq$A2.y),]
  hm3_rsq<-hm3_rsq[, c('SNP','A1.x','A2.x','INFO'), with = F]
  names(hm3_rsq) <- c('SNP','A1','A2','INFO')
  hm3_rsq$INFO[is.na(hm3_rsq$INFO)] <- 0
  hm3_rsq$snplist <- 'hm3'
  
  sbayesrc_rsq <- merge(sbayesrc, dat, by = 'SNP', all.x = T)
  sbayesrc_rsq <- sbayesrc_rsq[
    (sbayesrc_rsq$A1.x == sbayesrc_rsq$A1.y & sbayesrc_rsq$A2.x == sbayesrc_rsq$A2.y) |
    (sbayesrc_rsq$A1.x == sbayesrc_rsq$A2.y & sbayesrc_rsq$A2.x == sbayesrc_rsq$A1.y) |
    is.na(sbayesrc_rsq$A2.y),]
  sbayesrc_rsq<-sbayesrc_rsq[, c('SNP','A1.x','A2.x','INFO'), with = F]
  names(sbayesrc_rsq) <- c('SNP','A1','A2','INFO')
  sbayesrc_rsq$INFO[is.na(sbayesrc_rsq$INFO)] <- 0
  sbayesrc_rsq$snplist <- 'sbayesrc'

  both_rsq <- rbind(hm3_rsq, sbayesrc_rsq)
  both_rsq$cohort <- cohort
  
  all_rsq <- rbind(all_rsq, both_rsq)
}

# Cap info to 1
all_rsq$INFO[all_rsq$INFO > 1] <- 1

# assuming both_rsq is already a data.table
summary_tab <- all_rsq[, .(
  n            = .N,
  prop_non_na  = mean(!is.na(INFO)),
  prop_gt_0.5  = mean(INFO > 0.5,  na.rm = TRUE),
  prop_gt_0.9  = mean(INFO > 0.9,  na.rm = TRUE),
  prop_gt_0.95 = mean(INFO > 0.95, na.rm = TRUE),
  prop_gt_0.99 = mean(INFO > 0.99, na.rm = TRUE),
  mean_rsq     = mean(INFO,  na.rm = TRUE),
  median_rsq   = median(INFO, na.rm = TRUE)
), by = .(snplist, cohort)]

library(ggplot2)
library(cowplot)

prop_long <- melt(
  summary_tab,
  id.vars = c("snplist","cohort"),
  measure.vars = c("prop_non_na","prop_gt_0.5","prop_gt_0.9","prop_gt_0.95","prop_gt_0.99"),
  variable.name = "metric", value.name = "prop"
)

prop_long$metric <- factor(
  prop_long$metric,
  levels = c(
    'prop_non_na',
    'prop_gt_0.5',
    'prop_gt_0.9',
    'prop_gt_0.95',
    'prop_gt_0.99'
  ),
  labels = c('Missing', 'RSQ > 0.5', 'RSQ > 0.9', 'RSQ > 0.95', 'RSQ > 0.99')
)

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_metrics_pgc.png',
    units = 'px',
    width = 2500,
    height = 2500,
    res = 300)

ggplot(prop_long, aes(x = cohort, y = prop, fill = snplist)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  facet_grid(metric ~ .) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Cohort", y = "Proportion", fill = "SNP-list") +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
dev.off()

# Make a boxplot
boxplot<- ggplot(all_rsq, aes(x = snplist, y = INFO, fill = snplist)) +
  geom_boxplot(outliers = FALSE) +
  labs(
    x = "SNP list",
    y = expression(Imputation~r^2)) +
  theme_classic() +
  theme_half_open() +
  background_grid() +
  panel_border() +
  facet_grid(. ~ cohort, scales = "free_y") +
  theme(
    legend.position = "none",
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

png('~/oliverpainfel/Analyses/mind_the_gap/snp_data/rsq_boxplot_pgc.png',
    units = 'px',
    width = 3000,
    height = 2000,
    res = 300)

  boxplot

dev.off()


```

***

## Relative PGS R2


Same as before but this time allowing for LD when estimating relative R2.

```{r}

setwd('/users/k1806347/oliverpainfel/Software/MyGit/GenoPred/pipeline/')
library(data.table)
library(ggplot2)
library(cowplot)
library(GenoUtils)
library(foreach)
library(doMC)
registerDoMC(80)

source('../functions/misc.R')
source_all('../functions')

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

cohorts <- c('gsk','dast','genpod','gendep','pfz','gods','mayo')

# Restrict to variants in the dense SBayesRC reference
sbayesrc_info<-fread('~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR/snp.info')

jobs <-
  CJ(
    id = score_list$name,
    test = cohorts,
    unique = TRUE
  )

foreach(i = 1:nrow(jobs), .combine = c, .options.multicore = list(preschedule = FALSE)) %dopar% {
  if(file.exists(
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      jobs$id[i],
      '/ref-',
      jobs$id[i],
      '.', 
      jobs$test[i],
      '.rsq.txt'
    ))){
    return(NULL)
  }
  
  print(paste0(jobs$id[i],':', jobs$test[i]))
  
  # Read in score file
  score_i <- fread(paste0(
        '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
        jobs$id[i],
        '/ref-',
        jobs$id[i],
        '.unmapped.score.gz'
      ))
  
  names(score_i)[names(score_i) == 'SCORE_external'] <- 'BETA'
  score_i <- score_i[, c('SNP','A1','A2','BETA'), with=F]
  
  # Calculate relative PRS R2
  dat <- fread(paste0('~/oliverpainfel/Data/mind_the_gap/pgc_adr/', jobs$test[i],'.info.gz'))
  dat <- dat[, c('SNP','a1','a2','info'), with=F]
  names(dat)<-c('SNP','A1','A2','INFO')
  dat$F_MISS <- 1 - dat$INFO
  dat <- dat[dat$SNP %in% sbayesrc_info$ID,]

  rel_r2 <- rel_pgs_r2_missing_eigen(
    ld_dir = '~/oliverpainfel/Software/MyGit/GenoPred/pipeline/resources/data/sbayesrc_ref_dense/EUR',
    score_df = score_i,
    f_miss = dat, 
    metric = 'correlation')
  
  res <- data.table(
    ID = jobs$id[i],
    group = jobs$test[i],
    n_nz = sum(score_i$BETA != 0),
    n_in_eig = rel_r2$n_in_ref,
    rel_r2 = rel_r2$relative_R2
  )
  
  write.table(
    res, 
    paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      jobs$id[i],
      '/ref-',
      jobs$id[i],
      '.', 
      jobs$test[i],
      '.rsq.txt'
    ), col.names = T, row.names = F, quote = F)
  
  NULL
}

```

```{r}
library(data.table)
library(ggplot2)
library(cowplot)
cohorts <- c('gsk','dast','genpod','gendep','pfz','gods','mayo')

score_list<-fread('~/oliverpainfel/Analyses/mind_the_gap/GenoPred/config/score_list_cad.txt')

jobs <-
  CJ(
    id = score_list$name,
    test = cohorts,
    unique = TRUE
  )

pgs_r2 <- NULL
for(i in 1:nrow(jobs)){
  pgs_r2 <- rbind(
    pgs_r2,
    fread(
      paste0(
      '/users/k1806347/oliverpainfel/Analyses/mind_the_gap/GenoPred/output/reference/pgs_score_files/external/',
      jobs$id[i],
      '/ref-',
      jobs$id[i],
      '.', 
      jobs$test[i],
      '.rsq.txt'
      )
    )
  )
}

saveRDS(pgs_r2, '~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_eigen_pgc.rds')
pgs_r2<-readRDS('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_eigen_pgc.rds')

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_pgs_eigen_pgc.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2[pgs_r2$ID %in% unique(pgs_r2$ID)[1:5],], aes(x = group, y = rel_r2, fill = ID)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  labs(x = "Cohort", y = "Proportion", fill = "SNP list") +
  theme_half_open() +
  panel_border() +
  background_grid() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) 
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rsq_metrics_eigen_pgc.png',
    units = 'px',
    width = 2500,
    height = 1500,
    res = 300)

ggplot(pgs_r2, aes(x = group, y = rel_r2)) +
  geom_boxplot(fill = 'steelblue') +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Cohort", y = "Relative R2") +
  theme_half_open() +
  background_grid()
dev.off()

# Plot number of variants not in eigen reference
pgs_r2$n_miss <- pgs_r2$n_nz - pgs_r2$n_in_eig
pgs_r2$prop_miss <- pgs_r2$n_miss / pgs_r2$n_nz

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/prop_miss_eigen_hist_pgc.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  pgs_r2[pgs_r2$group == 'dast',], 
  aes(x = prop_miss)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_histogram(bins = 60, width = 0.1, fill = "steelblue", alpha = 0.6, colour = 'black') +
  labs(x = 'Missing from LD reference', y = 'N PGS') +
  theme_half_open() +
  background_grid()
dev.off()

png('~/oliverpainfel/Analyses/mind_the_gap/pgsc/rel_r2_omni_topmed_hist_pgc.png',
    units = 'px', width = 1750, height = 1000, res = 300)
ggplot(
  pgs_r2, 
  aes(x = rel_r2, fill = group)) +
  scale_x_continuous(labels = scales::percent_format(accuracy = 1)) +
  geom_density(alpha = 0.6, colour = 'black') +
  labs(x = 'Relative PGS R2', y = 'N PGS') +
  theme_half_open() +
  background_grid()
dev.off()

```

*** 

# To do:

I think the 'gap' I had hypothesised is currently being hidden by my method using LD data for variant with MAF > 0.01 and RSQ > 0.6. We should quanitfy how many variants do not fufill this criteria, and that ignoring these variants will inflate the relative PGS R2. Two approaches to demonstrate this, derive eigen LD data for chromosome 22 without MAF and INFO restrictions, and use an LD-naive approach.

