<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>GenoPred Pipeline - Instructions</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />
<link rel="shortcut icon" href="Images/logo/favicon.ico">

<link rel="stylesheet" href="styles/night-mode.css" id="nightModeStylesheet">

<script>
function toggleNightMode() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (stylesheet.disabled) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
}
</script>

<label class="switch">
  <input type="checkbox" id="toggleNightMode" checked>
  <span class="slider round"></span>
</label>

<script>
document.getElementById('toggleNightMode').addEventListener('change', function() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (this.checked) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
});
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YR18ZB3PR3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YR18ZB3PR3');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img class="logo-img" src="Images/logo/Horizontal_white.png" style="height: 42px;" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pipeline
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="pipeline_overview.html">Overview</a>
    </li>
    <li>
      <a href="pipeline_readme.html">Instructions</a>
    </li>
    <li>
      <a href="pipeline_technical.html">Technical documentation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="research_index.html">Overview</a>
    </li>
    <li>
      <a href="comparison_of_methods_summary.html">Polygenic Scoring Methods Comparison</a>
    </li>
    <li>
      <a href="Functionally_informed_prediction.html">Quantifying Polygenic Signal Mediated by Altered Gene Expression</a>
    </li>
    <li>
      <a href="Absolute_Conversion.html">Translating Polygenic Scores onto the Absolute Scale</a>
    </li>
  </ul>
</li>
<li>
  <a href="more_index.html">More</a>
</li>
<li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">GenoPred Pipeline - Instructions</h1>

</div>


<hr />
<p>This document will provides instructions for the GenoPred pipeline.
It covers the following topics:</p>
<ul>
<li><a href="#installation">Installation</a></li>
<li><a href="#containers">Containers</a></li>
<li><a href="#pipeline-configuration">Pipeline configuration</a></li>
<li><a href="#run-using-test-data">Run using test data</a></li>
<li><a href="#a-little-about-snakemake">A little about
Snakemake</a></li>
<li><a href="#running-on-an-hpc">Running on an HPC</a></li>
<li><a href="#requesting-outputs">Requesting outputs</a></li>
<li><a href="#computational-resources">Computational resources</a></li>
<li><a href="#additional-parameters">Additional parameters</a></li>
<li><a href="#running-in-offline-environment">Running in offline
environment</a></li>
</ul>
<p>For a general overview of the GenoPred pipeline, click <a
href="pipeline_overview.html">here</a>. For a technical details of the
GenoPred pipeline, click <a href="pipeline_technical.html">here</a>.</p>
<hr />
<p><strong>Citations</strong></p>
<p>Please cite our paper describing the reference-standardised approach
used by the GenoPred pipeline:</p>
<ul>
<li>Pain, Oliver, et al. “Evaluation of polygenic prediction methodology
within a reference-standardized framework.” PLoS genetics 17.5 (2021):
e1009021.</li>
</ul>
<p>Please also cite the relevant studies for the tools and data used by
the GenoPred pipeline.</p>
<hr />
<div id="video-tutorials" class="section level1">
<h1>Video tutorials</h1>
<div class="centered-container">
<div style="flex: 1 1 auto; align-items: center; text-align: center;">
<p><strong>Tutorial 1: Installation</strong></p>
<iframe width="250px" height="auto" src="https://www.youtube.com/embed/X-ST5qb4mF0?si=AD6Gt8dh-UrEpbj6" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
</div>
<div style="flex: 1 1 auto; align-items: center; text-align: center;">
<p><strong>Tutorial 2: Pipeline configuration</strong></p>
<iframe width="250px" height="auto" src="https://www.youtube.com/embed/MrOWa0sgxkg?si=nPAZXAtnKph-4L8o" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
</div>
<div style="flex: 1 1 auto; align-items: center; text-align: center;">
<p><strong>Tutorial 3: Running the pipeline</strong></p>
<iframe width="250px" height="auto" src="https://www.youtube.com/embed/lqhNK8VVDC0?si=2eOgz658AMakXffX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
</div>
<div style="flex: 1 1 auto; align-items: center; text-align: center;">
<p><strong>Tutorial 4: Running on an HPC</strong></p>
<iframe width="250px" height="auto" src="https://www.youtube.com/embed/Lw_DMiZWLkQ?si=g2S9SJGQDf2OZq9u" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
</div>
<div style="flex: 1 1 auto; align-items: center; text-align: center;">
<p><strong>Tutorial 5: Requesting and Finding Outputs</strong></p>
<iframe width="250px" height="auto" src="https://www.youtube.com/embed/muTKkPk620I?si=52iXjdhthVo-MkdX" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>
</iframe>
</div>
</div>
<p>The videos can be watched on YouTube
<a href="https://www.youtube.com/playlist?list=PLZwmskofEu7W-wqCdqFGRHc8m6NH0HZ2h" target="_blank">here</a>!</p>
<hr />
</div>
<div id="installation" class="section level1">
<h1>Installation</h1>
<p>There are three steps:</p>
<ol style="list-style-type: decimal">
<li>Download GenoPred repository</li>
<li>Create conda environment</li>
<li>Download dependencies</li>
</ol>
<hr />
<div id="step-1-download-genopred-repository" class="section level2">
<h2>Step 1: Download GenoPred repository</h2>
<p>First, you will need to download the GenoPred repository from GitHub.
Open your terminal, go to the directory where you would like the
repository to be stored, and clone the repository.</p>
<div class="note-box">
<p><strong>Note:</strong> If you are using an high performance cluster
(HPC), it is best run the setup in an interactive session (see <a
href="#dont-run-on-the-login-node">here</a>).</p>
</div>
<pre class="bash"><code>git clone https://github.com/opain/GenoPred.git</code></pre>
<hr />
</div>
<div id="step-2-create-conda-environment-for-pipeline"
class="section level2">
<h2>Step 2: Create conda environment for pipeline</h2>
<p>Conda is a software environment management system which is great way
for easily downloading and storing software. We will use conda to create
an environment that the GenoPred pipeline will run in.</p>
<p>If you don’t already have conda installed, we will install it using
miniconda.</p>
<pre class="bash"><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
sh Miniconda3-latest-Linux-x86_64.sh</code></pre>
<p>I would say <code>yes</code> to the default options. You may then
need to refresh your workspace to initiate conda, by running
<code>source ~/.bashrc</code>. You should see <code>(base)</code>
written in the bottom left of the terminal. Once miniconda installation
is complete, you can then delete the
<code>Miniconda3-latest-Linux-x86_64.sh</code> file.</p>
<p>Now create the conda environment based on the
<code>GenoPred/pipeline/envs/pipeline.yaml</code> file. This will create
an environment called <code>genopred</code> with some essential packages
installed.</p>
<pre class="bash"><code>conda env create -f GenoPred/pipeline/envs/pipeline.yaml</code></pre>
<p>Now activate the new <code>genopred</code> environment.</p>
<pre class="bash"><code>conda activate genopred</code></pre>
<hr />
</div>
<div id="step-3-download-dependencies" class="section level2">
<h2>Step 3: Download dependencies</h2>
<p>Now, we will download some additional dependencies of the pipeline.
First, go into the <code>pipeline</code> folder within the GenoPred
repo. Now we are in the pipeline folder, we can use our first Snakemake
command to download the dependencies of the GenoPred pipeline.</p>
<pre class="bash"><code>cd GenoPred/pipeline

snakemake -j 1 --use-conda --conda-frontend mamba install_r_packages</code></pre>
<p>This will start by building other conda environments, which the
pipeline uses to perform certain analyses. Then it will download a few
other dependencies of the pipeline. In total this process may take ~10
minutes.</p>
<div class="note-box">
<p><strong>Note:</strong> Check out advice <a
href="#running-jobs-in-parallel">here</a> for running in parallel on an
HPC. The command might take some time, so run it via a compute node, and
if run interactively, I would suggest using a terminal multiplexer (like
tmux) to avoid connection issues (see <a
href="#avoid-connection-issues">here</a>).</p>
</div>
<details>
<summary>
See explanation of Snakemake command
</summary>
<ul>
<li><code>-j 1</code>- This parameter tells Snakemake how many jobs can
be run in parallel.</li>
<li><code>--use-conda</code> - This tells Snakemake to use conda
environments as specified in the pipeline. This parameter should always
be included when using GenoPred.</li>
<li><code>--conda-frontend mamba</code> - This tells Snakemake to use
mamba when creating new conda environments, which is a faster version of
conda. This parameter is only required when running the GenoPred
Snakemake for the first time, as the environment only needs to be built
once.</li>
<li><code>install_r_packages</code> - This is the <em>rule</em> we want
Snakemake to run. Other useful in GenoPred are described <a
href="#requesting-specific-outputs">here</a>. rules The rules included
in GenoPred will be described</li>
</ul>
<p>For more information on Snakemake commands see <a
href="#basic-Snakemake-commands">here</a>.</p>
</details>
<hr />
</div>
</div>
<div id="containers" class="section level1">
<h1>Containers</h1>
<p>We have made docker and singularity containers with GenoPred
pre-installed. We provide an example of using the pipeline within the
container <a href="pipeline_23andMe.html">here</a>. We also provide an
example running the pipeline in an offline environment, using a
container with pre-downloaded dependencies (see <a
href="#running-in-offline-environment">here</a>). The containers can
avoid some installation issues, and allow the pipeline to be used on
non-linux based systems.</p>
<pre class="bash"><code># Docker
docker pull opaino/genopred_pipeline:v0.2

# Singularity
singularity pull --arch amd64 library://opain/genopred/genopred_pipeline:v0.2</code></pre>
<div class="note-box">
<p><strong>Note:</strong> When running the pipeline in the container,
you must mount a home directory. Additionally, specify the
<code>resdir</code> and <code>outdir</code> configfile parameters
outside of the container to ensure that the pipeline’s resources and
outputs are stored persistently for subsequent sessions.</p>
</div>
<hr />
</div>
<div id="pipeline-configuration" class="section level1">
<h1>Pipeline configuration</h1>
<p>The pipeline is configured using a configfile, which tells the
pipeline what to do, and the location of the input data listed in the
target_list, gwas_list, and score_list files.</p>
<div class="centered-container">
<div class="rounded-image-container" style="width: 75%;">
<p><img src="Images/pipeline_readme/input_schematic_wide.png"></p>
</div>
</div>
<hr />
<div id="configfile" class="section level2">
<h2><code>configfile</code></h2>
<p>Snakemake reads the default <code>config.yaml</code> file located in
the <code>pipeline</code> directory to obtain its default parameters.
When using your own data, it’s recommended to create a new
<code>configfile</code> rather than modifying the default one. You can
then specify this custom <code>configfile</code> when running Snakemake
using the <code>--configfile</code> option.</p>
<p>This approach allows you to use the GenoPred pipeline with multiple
configurations. Importantly, only parameters that differ from the
defaults need to be included in your custom <code>configfile</code>. Any
parameter not explicitly defined in the custom <code>configfile</code>
will be automatically sourced from the default
<code>pipeline/config.yaml</code> file. This ensures that Snakemake only
overrides the parameters you specify, while continuing to use the
default settings for all others.</p>
<pre class="bash"><code>snakemake -j1 --use-conda --configfile=misc/23andMe/config.yaml output_all</code></pre>
<details>
<summary>
View configfile parameters
</summary>
<table>
<colgroup>
<col width="4%" />
<col width="19%" />
<col width="11%" />
<col width="63%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Parameter</th>
<th align="left">Description</th>
<th align="left">Example</th>
<th align="left">Note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>outdir</code></td>
<td align="left">Directory to save pipeline outputs</td>
<td align="left"><code>test_data/output/test1</code></td>
<td align="left">Required. I recommend using an absolute path starting
from the root of the file system (starting with <code>/</code>)</td>
</tr>
<tr class="even">
<td align="left"><code>resdir</code></td>
<td align="left">Directory to save pipeline resources</td>
<td align="left"><code>genopred_resources</code></td>
<td align="left">Optional. Default is the <code>resources</code> folder
within the <code>GenoPred/pipeline</code> folder. I recommend using an
absolute path starting from the root of the file system (starting with
<code>/</code>)</td>
</tr>
<tr class="odd">
<td align="left"><code>config_file</code></td>
<td align="left">Location of the config file itself</td>
<td align="left"><code>config.yaml</code></td>
<td align="left">Required</td>
</tr>
<tr class="even">
<td align="left"><code>gwas_list</code></td>
<td align="left">Path to <code>gwas_list</code> file, listing GWAS
sumstats</td>
<td align="left"><code>example_input/gwas_list.txt</code></td>
<td align="left">Set to NA if you don’t want to include and GWAS
sumstats</td>
</tr>
<tr class="odd">
<td align="left"><code>score_list</code></td>
<td align="left">Path to <code>score_list</code> file, listing external
score files</td>
<td align="left"><code>example_input/score_list.txt</code></td>
<td align="left">Set to NA if you don’t want to include any external
score files</td>
</tr>
<tr class="even">
<td align="left"><code>target_list</code></td>
<td align="left">Path to <code>target_list</code> file, listing target
datasets</td>
<td align="left"><code>example_input/target_list.txt</code></td>
<td align="left">Set to NA if you don’t want to include any target
datasets</td>
</tr>
<tr class="odd">
<td align="left"><code>pgs_methods</code></td>
<td align="left">List of polygenic scoring methods to run</td>
<td align="left"><code>['ptclump','dbslmm']</code></td>
<td align="left">Options are: <code>ptclump</code>, <code>dbslmm</code>,
<code>prscs</code>, <code>sbayesr</code>, <code>lassosum</code>,
<code>ldpred2</code>, <code>megaprs</code>. <strong>Note.</strong>
<code>sbayesr</code> and <code>ldpred2</code> are only implemented for
GWAS of EUR ancestry.</td>
</tr>
<tr class="even">
<td align="left"><code>testing</code></td>
<td align="left">Controls testing mode</td>
<td align="left"><code>chr22</code></td>
<td align="left">Set to NA to turn off test mode. Set to
<code>chr22</code> if you want to run the pipeline using only chromosome
22.</td>
</tr>
</tbody>
</table>
<div class="note-box">
<p><strong>Note:</strong> If you do not provide a target_list, then only
rules that do not require a target_list can be performed, such as GWAS
sumstat QC. Similarly, if you do not provide a gwas_list or score_list,
only rules that do not require these files can be performed, such as
target sample ancestry inference.</p>
</div>
</details>
<hr />
</div>
<div id="gwas_list" class="section level2">
<h2><code>gwas_list</code></h2>
<p>The <code>gwas_list</code> is a white-space delimited text file,
providing information of the GWAS summary statistics to be used by the
pipeline.</p>
<details>
<summary>
View gwas_list format
</summary>
<table>
<colgroup>
<col width="2%" />
<col width="6%" />
<col width="90%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Column</th>
<th align="left">Example</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">name</td>
<td align="left"><code>COAD01</code></td>
<td align="left">ID for the GWAS sumstats. Cannot contain spaces (’ ‘)
or hyphens (’-’)</td>
</tr>
<tr class="even">
<td align="left">path</td>
<td align="left"><code>gwas_sumstats/COAD01.gz</code></td>
<td align="left">File path to the GWAS summary statistics (uncompressed
or gzipped).</td>
</tr>
<tr class="odd">
<td align="left">population</td>
<td align="left"><code>EUR</code></td>
<td align="left">Reference population that the GWAS sample matches best.
Options are <code>AFR</code> - African, <code>AMR</code> = Admixed
American, <code>EAS</code> = East Asian, <code>EUR</code> = European,
<code>CSA</code> = Central and South Asian, and <code>MID</code> =
Middle Eastern. If you are using a mixed ancestry GWAS, though there are
limitations, I would suggest specifying the population that matches the
majority of the GWAS sample.</td>
</tr>
<tr class="even">
<td align="left">n</td>
<td align="left"><code>10000</code></td>
<td align="left">The total sample size of the GWAS. This is required if
there is no column indicating sample size in the sumstats. Otherwise, it
can be set to <code>NA</code></td>
</tr>
<tr class="odd">
<td align="left">sampling</td>
<td align="left"><code>0.5</code></td>
<td align="left">The proportion of the GWAS sample that were cases (if
outcome is binary - otherwise specify <code>NA</code>)</td>
</tr>
<tr class="even">
<td align="left">prevalence</td>
<td align="left"><code>0.1</code></td>
<td align="left">The prevalence of the phenotype in the general
population (if outcome is binary - otherwise specify
<code>NA</code>)</td>
</tr>
<tr class="odd">
<td align="left">mean</td>
<td align="left"><code>100</code></td>
<td align="left">The phenotype mean in the general population (if
outcome is continuous, otherwise specify <code>NA</code>)</td>
</tr>
<tr class="even">
<td align="left">sd</td>
<td align="left"><code>15</code></td>
<td align="left">The phenotype sd in the general population (if outcome
is continuous, otherwise specify <code>NA</code>)</td>
</tr>
<tr class="odd">
<td align="left">label</td>
<td align="left"><code>"Coronary Artery Disease"</code></td>
<td align="left">A human readable name for the GWAS phenotype. Wrap in
double quotes if multiple words. For example,
<code>"Body Mass Index"</code>.</td>
</tr>
</tbody>
</table>
<div class="note-box">
<p><strong>Note: </strong> The <code>prevalence</code> and
<code>sampling</code> values are used to estimate the SNP-based
heritability on the liability scale, as requested by some PGS methods.
Furthermore, <code>prevalence</code> and <code>sampling</code>, or
<code>mean</code> and <code>sd</code> values are used to interpret the
polygenic scores on the absolute scale.</p>
</div>
</details>
<details>
<summary>
View GWAS sumstat format
</summary>
<p></br></p>
<p>The pipeline can accept GWAS sumstats with a range of header formats.
It uses a dictionary to interpret the meaning of certain column names.
This is useful but potentially risky. You have two options to ensure the
columns are being interpreted correctly:</p>
<ol style="list-style-type: decimal">
<li>Hope for the best and check the sumstat QC log file to see whether
header we correctly interpreted (lazy option but fine in most
cases).</li>
<li>Check whether the headers in your sumstats correspond to the correct
values in the sumstat header dictionary (<a
href="https://github.com/opain/GenoUtils/blob/main/R/constants.R#L6">here</a>),
and update as necessary in advance of running the pipeline.</li>
</ol>
<p>The sumstats must contain either RSIDs or chromosome and basepair
position information. The sumstats must also contain an effect size,
either BETA, odds ratio, log(OR), or a signed Z-score. Either P-values
or standard errors must also be present. It is also best if the
following are present: sample size per variant, GWAS sample allele
frequencies (for the effect allele), and imputation quality metrics.</p>
<p>I would suggest checking the sumstat QC log files, to check the
number of SNPs after QC is expected.</p>
</details>
<hr />
</div>
<div id="score_list" class="section level2">
<h2><code>score_list</code></h2>
<p>The <code>score_list</code> is a white-space delimited text file,
providing information of externally generated score files for polygenic
scoring are to be used by the pipeline. The <code>score_list</code>
should have <code>name</code>, <code>path</code> and <code>label</code>
columns, that the <code>gwas_list</code> has, except the
<code>path</code> column should indicate the location of the score
file.</p>
<p>PGS Catalogue score files can be directly downloaded by GenoPred, by
using the PGS ID in the <code>name</code> column, and setting the
<code>path</code> column to <code>NA</code>.</p>
<div class="note-box">
<p><strong>Note:</strong> Externally derived PGS score files may have a
poor variant overlap with the default GenoPred reference data, which is
restricted to HapMap3 variants. Score files with &lt;75% of variants
present in the reference are excluded from downstream target scoring.
Several popular PGS methods restrict to HapMap3 variants, so this is not
always an issue.</p>
</div>
<details>
<summary>
View score file format
</summary>
<p></br></p>
<p>The format of the score files should be consistent with the PGS
Catalogue header format (<a
href="https://www.pgscatalog.org/downloads/#scoring_header"
class="uri">https://www.pgscatalog.org/downloads/#scoring_header</a>).
GenoPred can read the harmonised and unharmonised column names from PGS
Catalogue. It will preferentially use the harmonised columns if they are
present. The PGS Catalogue format comments are not required by GenoPred,
though they are useful so don’t actively remove them. GenoPred allows
only one column of effect sizes per score file. GenoPred is lenient, and
only requires either the RSIDs, or chromosome and basepair position
columns to be present.</p>
<ul>
<li><code>rsID</code> or <code>hm_rsID</code> - RSID</li>
<li><code>chr_name</code> or <code>hm_chr</code> - Chromosome
number</li>
<li><code>chr_position</code> or <code>hm_pos</code> - Basepair
position</li>
<li><code>effect_allele</code> - Allele corresponding to
<code>effect_weight</code> column</li>
<li><code>other_allele</code> - The other allele</li>
<li><code>effect_weight</code> - The effect size of
<code>effect_allele</code></li>
</ul>
</details>
<hr />
</div>
<div id="target_list" class="section level2">
<h2><code>target_list</code></h2>
<p>The <code>target_list</code> is a white-space delimited text file,
providing information of the target datasets to be used by the pipeline.
The file must have the following columns:</p>
<details>
<summary>
View target_list format
</summary>
<p></br></p>
<table>
<colgroup>
<col width="2%" />
<col width="6%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Column</th>
<th align="left">Example</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>name</code></td>
<td align="left"><code>test_data/output/test1</code></td>
<td align="left">ID for the target dataset. Cannot contain spaces (’ ‘)
or hyphens (’-’)</td>
</tr>
<tr class="even">
<td align="left"><code>path</code></td>
<td align="left"><code>imputed_sample_plink1/example</code></td>
<td align="left">Path to the target genotype data. For type
<code>23andMe</code>, provide full file path either zipped
(<code>.zip</code>) or uncompressed (<code>.txt</code>). For
<code>type</code> <code>plink1</code>, <code>plink2</code>,
<code>bgen</code>, and <code>vcf</code>, per-chromosome genotype data
should be provided with the following filename format:
<code>&lt;prefix&gt;.chr&lt;1-22&gt;.&lt;.bed/ .bim/ .fam/ .pgen/ .pvar/ .psam/ .bgen/ .vcf.gz&gt;</code>.
If <code>type</code> is <code>samp_imp_bgen</code>, the sample file
should be called <code>&lt;prefix&gt;.sample</code>, and each
<code>.bgen</code> file should have a corresponding <code>.bgi</code>
file</td>
</tr>
<tr class="odd">
<td align="left"><code>type</code></td>
<td align="left"><code>plink1</code></td>
<td align="left">Format of the target genotype dataset. Either
<code>23andMe</code>, <code>plink1</code>, <code>plink2</code>,
<code>bgen</code>, or <code>vcf</code>. <code>23andMe</code> = 23andMe
formatted data for an individual. <code>plink1</code> = Preimputed
PLINK1 binary format data (.bed/.bim/.fam). <code>plink2</code> =
Preimputed PLINK2 binary format data (.pgen/.pvar/.psam).
<code>bgen</code> = Preimputed Oxford format data (.bgen/.sample).
<code>vcf</code> = Preimputed gzipped VCF format data
(<code>.vcf.gz</code>) for a group of individuals.</td>
</tr>
<tr class="even">
<td align="left"><code>indiv_report</code></td>
<td align="left"><code>T</code></td>
<td align="left">Logical indicating whether reports for each individual
should be generated. Either <code>T</code> or <code>F</code>. Use with
caution if target data contains many individuals, as it will create an
.html report for each individual.</td>
</tr>
</tbody>
</table>
<div class="note-box">
<p><strong>Note:</strong> If prefix of your target genetic data files do
not meet the requirements of GenoPred, you can create symlinks (like a
shortcut) to the original genetic data, and then specify these symlinks
in the <code>target_list</code>.</p>
</div>
</details>
<hr />
</div>
</div>
<div id="run-using-test-data" class="section level1">
<h1>Run using test data</h1>
<p>Once you have installed GenoPred, we can run the pipeline using the
test data.</p>
<hr />
<div id="step-1-download-the-test-data" class="section level2">
<h2>Step 1: Download the test data</h2>
<p>First, we need to download and decompress the test data. Do this
within the <code>GenoPred/pipeline</code> folder.</p>
<pre class="bash"><code># Download from Zenodo
wget -O test_data.tar.gz https://zenodo.org/records/10640650/files/test_data.tar.gz?download=1

# Decompress
tar -xf test_data.tar.gz

# Once decompressed, delete compressed version to save space
rm test_data.tar.gz</code></pre>
<hr />
</div>
<div id="step-2-run-the-pipeline" class="section level2">
<h2>Step 2: Run the pipeline</h2>
<p>To run the pipeline with the test_data, we will use the
<code>example_input/config.yaml</code>. It specifies some basic options
and specifies the <code>target_list</code>, <code>gwas_list</code> and
<code>score_list</code> in the <code>example_input</code> folder. The
<code>testing</code> parameter is set to <code>chr22</code> so only
chromosome 22.</p>
<details>
<summary>
See contents of default configfile
</summary>
<pre class="bash"><code># Specify output directory
outdir: test_data/output/test1

# Location of this config file
config_file: example_input/config.yaml

# Specify location of gwas_list file
gwas_list: example_input/gwas_list.txt

# Specify location of target_list file
target_list: example_input/target_list.txt

# Specify location of score_list file
score_list: example_input/score_list.txt

# Specify pgs_methods (&#39;ptclump&#39;,&#39;dbslmm&#39;,&#39;prscs&#39;,&#39;sbayesr&#39;,&#39;lassosum&#39;,&#39;ldpred2&#39;,&#39;megaprs&#39;)
pgs_methods: [&#39;ptclump&#39;,&#39;dbslmm&#39;]

# Specify if you want test mode. Set to NA if you don&#39;t want test mode
testing: chr22</code></pre>
</details>
<details>
<summary>
See contents of example target_list
</summary>
<table>
<colgroup>
<col width="18%" />
<col width="57%" />
<col width="8%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="left">path</th>
<th align="left">type</th>
<th align="left">indiv_report</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">example_plink1</td>
<td align="left">test_data/target/imputed_sample_plink1/example</td>
<td align="left">plink1</td>
<td align="left">T</td>
</tr>
</tbody>
</table>
</details>
<details>
<summary>
See contents of example gwas_list
</summary>
<table>
<colgroup>
<col width="5%" />
<col width="36%" />
<col width="9%" />
<col width="2%" />
<col width="7%" />
<col width="9%" />
<col width="4%" />
<col width="2%" />
<col width="21%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="left">path</th>
<th align="left">population</th>
<th align="left">n</th>
<th align="right">sampling</th>
<th align="right">prevalence</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="left">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">BODY04</td>
<td align="left">test_data/reference/gwas_sumstats/BODY04.gz</td>
<td align="left">EUR</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">“Body Mass Index”</td>
</tr>
<tr class="even">
<td align="left">COAD01</td>
<td align="left">test_data/reference/gwas_sumstats/COAD01.gz</td>
<td align="left">EUR</td>
<td align="left">NA</td>
<td align="right">0.33</td>
<td align="right">0.03</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="left">“Coronary Artery Disease”</td>
</tr>
</tbody>
</table>
</details>
<details>
<summary>
See contents of example score_list
</summary>
<table>
<colgroup>
<col width="12%" />
<col width="62%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="left">path</th>
<th align="left">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">PGS002804</td>
<td align="left">test_data/reference/score_files/PGS002804.txt.gz</td>
<td align="left">“Height Yengo EUR”</td>
</tr>
<tr class="even">
<td align="left">PGS003980</td>
<td align="left">NA</td>
<td align="left">“BMI”</td>
</tr>
<tr class="odd">
<td align="left">PGS000001</td>
<td align="left">NA</td>
<td align="left">“Breast Cancer”</td>
</tr>
</tbody>
</table>
</details>
<hr />
<p>To run the pipeline with the example configfile and test data, we
just need to specify the number of jobs we want to run in parallel
(<code>-j</code>), the <code>--use-conda</code> parameter, and then the
rule we want the pipeline to run (<code>output_all</code>). See <a
href="#requesting-outputs">here</a> to see what this rule will output,
and for information on other rules that can be run.</p>
<p>Executing the <code>output_all</code> rule will run many steps in the
pipeline. If you want to check what will happen before you run the
pipeline, it is often useful to use the <code>-n</code> parameter, which
will do a dry-run, printing out all the steps it would run, without
actually running it.</p>
<pre class="bash"><code># Remember to activate the genopred environment and go into to the GenoPred/pipeline directory before running the pipeline
conda activate genopred
cd ~/GenoPred/pipeline

# Do a dry run to see what would happen
snakemake -n --configfile=example_input/config.yaml output_all

# Run the pipeline running one step at a time 
snakemake -j1 --configfile=example_input/config.yaml --use-conda output_all</code></pre>
<p>Once the pipeline is complete, you can check that there is nothing
else to do by doing another dry run, and it should say ‘Nothing to be
done’.</p>
<hr />
</div>
<div id="step-3-look-through-the-output" class="section level2">
<h2>Step 3: Look through the output</h2>
<p>There is detailed information <a href="#requesting-outputs">here</a>.
When using the default <code>config.yaml</code>, the <code>outdir</code>
parameter is <code>test_data/output/test1</code>.</p>
<p>For example, if you wanted to find the sample-level report,
summarising what the pipeline did, it can be found here:
<code>test_data/output/test1/example_plink1/reports/example_plink1-report.html</code>.</p>
<p>Or, if you wanted to find the DBSLMM PGS based on the COAD01 GWAS in
European target individuals, the file can be found here:
<code>test_data/output/test1/example_plink1/pgs/EUR/dbslmm/COAD01/example_plink1-COAD01-EUR.profiles</code></p>
<pre><code>FID IID COAD01_DBSLMM
1_EUR 1_EUR -1.782
2_EUR 2_EUR -1.104</code></pre>
<hr />
</div>
<div id="step-4-how-to-modify-the-configuration" class="section level2">
<h2>Step 4: How to modify the configuration</h2>
<p>After running the pipeline, it is often useful to update the
configuration of our analysis, for example to added a new GWAS to the
gwas_list. This is not a problem - GenoPred uses Snakemake to only rerun
analyses that are affected by the changes in configuration, rather than
running the full pipeline from scratch.</p>
<p>I will demonstrate by adding a new GWAS, but its a similar process
when adding new score files or target samples, or when changing certain
parameters in <code>configfile</code>. We simply add a new row to the
<code>gwas_list</code>, rerun GenoPred, and it will rerun the required
steps. As an example, I will add a row with the name ‘COAD02’, which
uses the same sumstats file as COAD01.</p>
<details>
<summary>
Code updating gwas_list
</summary>
<pre class="r"><code># Read in gwas_list
gwas_list &lt;- fread(&#39;../pipeline/example_input/gwas_list.txt&#39;)

# Add new gwas (for demonstration I will reuse the sumstats for COAD01, but will name it &#39;COAD02&#39;)
gwas_list &lt;- rbind(gwas_list, gwas_list[gwas_list$name == &#39;COAD01&#39;,])
gwas_list$name[3] &lt;- &#39;COAD02&#39;

# Put quotes around the label column
gwas_list$label &lt;- paste0(&quot;\&quot;&quot;, gwas_list$label, &quot;\&quot;&quot;)

# Save file
fwrite(gwas_list, &#39;../pipeline/example_input/gwas_list.txt&#39;, quote = F, sep = &#39; &#39;, na=&#39;NA&#39;)</code></pre>
<table>
<colgroup>
<col width="5%" />
<col width="36%" />
<col width="9%" />
<col width="2%" />
<col width="7%" />
<col width="9%" />
<col width="4%" />
<col width="2%" />
<col width="21%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">name</th>
<th align="left">path</th>
<th align="left">population</th>
<th align="left">n</th>
<th align="right">sampling</th>
<th align="right">prevalence</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="left">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">BODY04</td>
<td align="left">test_data/reference/gwas_sumstats/BODY04.gz</td>
<td align="left">EUR</td>
<td align="left">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">“Body Mass Index”</td>
</tr>
<tr class="even">
<td align="left">COAD01</td>
<td align="left">test_data/reference/gwas_sumstats/COAD01.gz</td>
<td align="left">EUR</td>
<td align="left">NA</td>
<td align="right">0.33</td>
<td align="right">0.03</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="left">“Coronary Artery Disease”</td>
</tr>
<tr class="odd">
<td align="left">COAD02</td>
<td align="left">test_data/reference/gwas_sumstats/COAD01.gz</td>
<td align="left">EUR</td>
<td align="left">NA</td>
<td align="right">0.33</td>
<td align="right">0.03</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="left">“Coronary Artery Disease”</td>
</tr>
</tbody>
</table>
</details>
<hr />
<p>Now, we have edited the <code>gwas_list</code>, if I rerun the
pipeline using the <code>-n</code> parameter, I can see what new jobs
the pipeline would run.</p>
<pre class="bash"><code>snakemake -n --configfile=example_input/config.yaml output_all</code></pre>
<p>It will output all the rules it would run, with inputs and outputs,
summarising the steps in a table like this:</p>
<pre><code>Job stats:
job                      count    min threads    max threads
---------------------  -------  -------------  -------------
indiv_report_all_id          1              1              1
indiv_report_i              10              1              1
output_all                   1              1              1
prep_pgs_dbslmm_i            1              1              1
prep_pgs_lassosum_i          1              1              1
prep_pgs_ptclump_i           1              1              1
sample_report_i              1              1              1
sumstat_prep_i               1              1              1
target_pgs_all_gwas         10              1              1
target_pgs_all_method        5              1              1
target_pgs_all_pop           1              1              1
target_pgs_i                10              1              1
total                       43              1              1</code></pre>
<p>This output is expected - The new GWAS will need to undergo sumstat
QC (<code>sumstat_qc</code>), downstream processing using PGS methods
(<code>prep_pgs_ptclump_i</code>,<code>prep_pgs_dbslmm_i</code>,<code>prep_pgs_lassosum_i</code>),
then target sample scoring (<code>target_pgs_i</code>), and finally
update the sample- and individual-level reports
(<code>sample_report_i</code> and <code>indiv_report_i</code>).</p>
<p>After seeing the expected jobs will be run, I would then run the
pipeline:</p>
<pre class="bash"><code>snakemake -j1 --use-conda --configfile=example_input/config.yaml output_all</code></pre>
<hr />
</div>
</div>
<div id="a-little-about-snakemake" class="section level1">
<h1>A little about Snakemake</h1>
<p>There is full documentation of Snakemake <a
href="https://snakemake.readthedocs.io/en/v7.32.3/">here</a>, but in
this section I will give a brief overview and outline a few commands
that are particularly useful.</p>
<p>Snakemake is a python based pipeline tool. It contains lists of
<strong>rules</strong> - Each rule is like a set of instructions,
telling Snakemake to create certain outputs given certain inputs. If the
user requests an output, Snakemake will run all the rules that are
needed to create that output.</p>
<p>Importantly, Snakemake checks the timestamps of input and output
files, and parameters applied, ensuring the output file is created after
the input file, using the latest parameters. This helps if you need to
rerun your analysis after some changes, and want to make sure the output
has been correctly updated.</p>
<hr />
<div id="useful-snakemake-options" class="section level2">
<h2>Useful Snakemake options</h2>
<p>Here are some useful Snakemake options/commands to run the
pipeline:</p>
<hr />
<div id="use-conda" class="section level3">
<h3><code>--use-conda</code></h3>
<p>This command tells Snakemake to create and use the conda environment
specified for each rule. This is a handy and reproducible way of
installing and running code in a tightly controlled software
environment.</p>
<p>This command should always be used when running GenoPred. All rules
in GenoPred use the same conda environment, so it only has to be build
once.</p>
</div>
<div id="j" class="section level3">
<h3><code>-j</code></h3>
<p>This command allows to set the number of jobs that can run
simultaneously. E.g. <code>-j 1</code> will run one job at a time. This
is most often what you want if you are running interactively.</p>
</div>
<div id="n" class="section level3">
<h3><code>-n</code></h3>
<p>This command performs a dry run, where Snakemake prints out all the
jobs it would run, without actually running them. This is particularly
useful if you want to see what would happen if you were to specify a
certain output or rule. This helps avoid accidentally triggering 100s of
unwanted jobs.</p>
</div>
<div id="configfile-1" class="section level3">
<h3><code>--configfile</code></h3>
<p>This parameter can be used to specify the .yaml file you want
Snakemake to use as the configuration file. This file is described above
(see <a href="#configfile">here</a>).</p>
<pre class="bash"><code>snakemake -j1 --use-conda --configfile=new_config.yaml output_all</code></pre>
</div>
<div id="p" class="section level3">
<h3><code>-p</code></h3>
<p>This will print the command Snakemake will run beneath of the jobs.
This is handy if you want to see what the jobs are doing. This is mainly
useful when debugging.</p>
<hr />
</div>
</div>
</div>
<div id="running-on-an-hpc" class="section level1">
<h1>Running on an HPC</h1>
<p>The GenoPred pipeline can be easily run in parallel using an HPC.
Here I outline a few suggestions on how to do this.</p>
<hr />
<div id="dont-run-on-the-login-node" class="section level2">
<h2>Don’t run on the login node</h2>
<p>HPC’s are a shared resource, and the login node is for logging in,
not for running analyses. Instead, connect interactively to a compute
node before setting up or using the GenoPred pipeline, or submit your
Snakemake command as a batch job. There are likely time and memory
restrictions on the login node, leading to errors, or unhappy
colleagues. Read the documentation for your HPC for more
information.</p>
<hr />
</div>
<div id="running-jobs-in-parallel" class="section level2">
<h2>Running jobs in parallel</h2>
<p>Snakemake pipelines (such as GenoPred) can be easily parallelised. If
you have access to multiple cores, then you can increase the
<code>-j</code> parameter. Or if you have access to an HPC, then you can
tell Snakemake to submit jobs to the HPC (this is the most powerful
approach and I would recommend if possible). To submit jobs to the
cluster, I use the <code>--profile</code> flag. This flag points
Snakemake to a specific .yaml file, specifying Snakemake parameters,
including those that instruct it to use the HPC. I have provided an
example profile file (<code>example_input/slurm.yaml</code>), with
parameters telling Snakemake how to submit jobs to a SLURM scheduler.
SLURM users should create a folder called <code>slurm</code> in
<code>$HOME/.config/snakemake</code>, and then copy in the
<code>slurm.yaml</code>, renaming it to <code>config.yaml</code>. More
information about profiles in Snakemake can be found <a
href="https://snakemake.readthedocs.io/en/stable/executing/cli.html#profiles">here</a>.</p>
<p>Once you have set up a .yaml for your scheduler, you can tell
Snakemake to submit jobs to the scheduler by using the
<code>--profile slurm</code> parameter, instead of the <code>-j1</code>
parameter. E.g.</p>
<pre class="bash"><code>snakemake --profile slurm --use-conda output_all</code></pre>
<p>Although, running the Snakemake command with the
<code>--profile</code> flag uses very little memory, I would still
suggest running it on a compute node to avoid clogging up the login
node.</p>
<hr />
</div>
<div id="avoid-connection-issues" class="section level2">
<h2>Avoid connection issues</h2>
<p>The pipeline can take hours for certain tasks, so if you are running
the Snakemake command using interactive session on your HPC, you will
likely run into issues due to your connection dropping out, leading to
the Snakemake analysis to end.</p>
<p>To avoid this, I use a terminal multiplexer, either <code>tmux</code>
or <code>screen</code>. When you are on the login node, start one of
these multiplexers. Once inside the multiplexer, start your interactive
session. The main reason for using a multiplexer here is that you can
reconnect to the session even if your connection stops. There are
several other advantages as well. They are really easy to use and will
make your life a lot better.</p>
<div class="note-box">
<p><strong>Note:</strong> If you have multiple login nodes on your HPC,
you will need to log in to the same login node to find your running tmux
session.</p>
</div>
<p>tmux documentation: <a href="https://github.com/tmux/tmux/wiki"
class="uri">https://github.com/tmux/tmux/wiki</a></p>
<hr />
</div>
<div id="managing-module-conflicts" class="section level2">
<h2>Managing Module Conflicts</h2>
<p>When using HPC systems, software conflicts often occur due to
pre-installed modules. This is particularly relevant when running
software like GenoPred, which requires a specific environment setup to
function correctly.</p>
<p>Before launching GenoPred, ensure your environment is clean by not
loading any unnecessary modules, especially those that can interfere
with software dependencies, such as R. You can check whether any modules
are loaded using the command <code>module list</code>, and unload any
loaded module using the command
<code>module unload &lt;module name&gt;</code>.</p>
<hr />
</div>
</div>
<div id="requesting-outputs" class="section level1">
<h1>Requesting outputs</h1>
<p>The GenoPred pipeline has many potential outputs. Here is a detailed
schematic diagram illustrating the inputs, outputs and processes of the
GenoPred pipeline.</p>
<div class="centered-container">
<div class="rounded-image-container">
<p><img src="Images/pipeline_readme/pipeline_schematic_lowdef.png"></p>
</div>
</div>
<div class="note-box">
<p><strong>Note:</strong> To see this image more clearly, right click
and open in a new tab.</p>
</div>
<hr />
<div id="main-rules" class="section level2">
<h2>Main rules</h2>
<p>Each of the key outputs from the pipeline can be requested using the
corresponding Snakemake rule. For example, if I just wanted to obtain
QC’d GWAS summary statistics I could run the <code>sumstat_prep</code>
rule.</p>
<pre class="bash"><code>snakemake -j1 --use-conda sumstat_prep</code></pre>
<details>
<summary>
Show table of rules for key outputs
</summary>
<table>
<colgroup>
<col width="5%" />
<col width="10%" />
<col width="84%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Type</th>
<th align="left">Rule</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Target</td>
<td align="left">output_all</td>
<td align="left">Generates both sample-level and individual-level .html
reports</td>
</tr>
<tr class="even">
<td align="left">Target</td>
<td align="left">sample_report</td>
<td align="left">Generates sample-level .html reports for target
datasets with <code>format</code> = ‘plink1’, ‘plink2’, ‘bgen’, or
‘vcf’.</td>
</tr>
<tr class="odd">
<td align="left">Target</td>
<td align="left">indiv_report</td>
<td align="left">Generates individual-level .html reports for all
individuals in target datasets with <code>indiv_report = T</code></td>
</tr>
<tr class="even">
<td align="left">Target</td>
<td align="left">ancestry_inference</td>
<td align="left">Perform ancestry inference for all target
datasets.</td>
</tr>
<tr class="odd">
<td align="left">Target</td>
<td align="left">target_pgs</td>
<td align="left">Calculates all polygenic scores in all target
datasets.</td>
</tr>
<tr class="even">
<td align="left">Target</td>
<td align="left">pc_projection</td>
<td align="left">Projects reference genetic PCs into all target
datasets</td>
</tr>
<tr class="odd">
<td align="left">Target</td>
<td align="left">format_target</td>
<td align="left">Harmonises all target datasets with the reference.</td>
</tr>
<tr class="even">
<td align="left">Target</td>
<td align="left">outlier_detection</td>
<td align="left">Perform QC within the target datasets, seperately for
each population with N &gt; 100. Includes relatedness estimation, PCA,
and population outlier detection.</td>
</tr>
<tr class="odd">
<td align="left">Target</td>
<td align="left">impute_23andme</td>
<td align="left">Perform genotype imputation of target datasets with
<code>format</code> = ‘23andMe’.</td>
</tr>
<tr class="even">
<td align="left">Reference</td>
<td align="left">sumstat_prep</td>
<td align="left">Performs quality control of all GWAS summary
statistics.</td>
</tr>
<tr class="odd">
<td align="left">Reference</td>
<td align="left">pgs_prep</td>
<td align="left">Prepares scoring files for all GWAS using all PGS
methods.</td>
</tr>
<tr class="even">
<td align="left">Reference</td>
<td align="left">ref_pca</td>
<td align="left">Performs PCA using reference genotype data.</td>
</tr>
</tbody>
</table>
</details>
<p></br></p>
<hr />
</div>
<div id="specific-outputs" class="section level2">
<h2>Specific outputs</h2>
<p>The rules above trigger sets of outputs to be created. For example
the <code>sumstat_prep</code> rule performs QC of all GWAS in the
<code>gwas_list</code>. However, it is also possible to request more
specific outputs, such as QC’d sumstats for just one of the GWAS in the
<code>gwas_list</code>. If we had a GWAS with the name
<code>COAD01</code>, we could request QC’d sumstats for just that GWAS
like this:</p>
<pre class="bash"><code># Create variables indicating the desired GWAS and the outdir parameter in the config file (by default Snakemake reads uses config.yaml)
gwas = COAD01
outdir = test_data/output/test1

# Run Snakemake command
snakemake -j1 --use-conda ${outdir}/reference/gwas_sumstat/${gwas}/${gwas}-cleaned.gz</code></pre>
<details>
<summary>
Show table of all available outputs
</summary>
<table>
<colgroup>
<col width="5%" />
<col width="11%" />
<col width="38%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">type</th>
<th align="left">group</th>
<th align="left">output</th>
<th align="left">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">target</td>
<td align="left">QC’d genotype</td>
<td
align="left">{outdir}/reference/target_checks/{name}/format_target.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="even">
<td align="left">target</td>
<td align="left">Imputed genotype</td>
<td
align="left">{outdir}/reference/target_checks/{name}/impute_23andme.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="odd">
<td align="left">target</td>
<td align="left">Ancestry Inference</td>
<td
align="left">{outdir}/reference/target_checks/{name}/ancestry_inference.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="even">
<td align="left">target</td>
<td align="left">Within-target QC</td>
<td
align="left">{outdir}/reference/target_checks/{name}/outlier_detection.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="odd">
<td align="left">target</td>
<td align="left">Projected PCs</td>
<td
align="left">{outdir}/reference/target_checks/{name}/pc_projection.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="even">
<td align="left">target</td>
<td align="left">Target PGS</td>
<td
align="left">{outdir}/reference/target_checks/{name}/target_pgs.done</td>
<td align="left">Specific target dataset</td>
</tr>
<tr class="odd">
<td align="left">reference</td>
<td align="left">QC’d sumstats</td>
<td
align="left">{outdir}/reference/gwas_sumstat/{gwas}/{gwas}-cleaned.gz</td>
<td align="left">Specific GWAS</td>
</tr>
<tr class="even">
<td align="left">reference</td>
<td align="left">PGS score file</td>
<td
align="left">{outdir}/reference/target_checks/prep_pgs_{method}_i-{gwas}.done</td>
<td align="left">Specific GWAS/score file using specific PGS method</td>
</tr>
<tr class="odd">
<td align="left">reference</td>
<td align="left">Reports</td>
<td
align="left">{outdir}/reference/target_checks/{name}/sample_report.done</td>
<td align="left">Sample-level report for specific target dataset</td>
</tr>
<tr class="even">
<td align="left">reference</td>
<td align="left">Reports</td>
<td
align="left">{outdir}/reference/target_checks/{name}/indiv_report.done</td>
<td align="left">Individual-level report for all individuals in a
specific target dataset</td>
</tr>
</tbody>
</table>
</details>
<hr />
</div>
<div id="output-structure" class="section level2">
<h2>Output structure</h2>
<p>Outputs specific to the configuration used are stored in the
<code>outdir</code> specified in the configfile:</p>
<pre><code>[outdir]
  ├── [target name] (results for each target dataset)
  │   ├── ancestry (ancestry inference results)
  │   │   ├── [target_name].Ancestry.model_pred (population probabilities)
  │   │   ├── [target_name].Ancestry.pc_plot.png (plot of target and reference pcs)
  │   │   └── keep_files (files listing individuals assigned to each population)
  │   ├── geno (harmonised genotype data)
  │   ├── pgs (polygenic scores)
  │   │   └── [population] (pgs for each target population)
  │   │       └── [pgs method] (pgs for each pgs method)
  │   │           └── [gwas/score name] (pgs for each gwas or score file)
  │   └── reports (polygenic scores)
  │       ├── [target_name]-report.html (sample-level report)
  │       └── individual (individual-level reports)
  │    
  └── reference
      ├── gwas_sumstat (processed gwas sumstats)
      │   └── [gwas name] (pgs for each gwas or score file)
      ├── pgs_score_files (score files for polygenic scoring)
      │   └── [pgs method] (pgs for each pgs method)
      │       └── [gwas/score name] (pgs for each GWAS or score file)
      ├── benchmarks (pipeline benchmark data)
      └── target_checks (pipeline logs)</code></pre>
<p>Some additional outputs that are independent of the configuration
used, are store in the resources folder of the
<code>GenoPred/pipeline</code> folder:</p>
<pre><code>GenoPred/pipeline
  └── resources
      ├── data (downloaded data)
      │   ├── target_checks (pipeline logs)
      │   ├── benchmarks (pipeline benchmark data)      
      │   └── ref (default reference data)
      │       └── pc_score_files (score files for reference pcs)
      └── software (downloaded software)</code></pre>
<hr />
</div>
</div>
<div id="reading-outputs-into-r" class="section level1">
<h1>Reading outputs into R</h1>
<p>I have included some handy R functions for reading in the outputs of
the pipeline. You just need to set your working directory to the
<code>GenoPred/pipeline</code> folder, and <code>source</code> the file
<code>GenoPred/functions/pipeline.R</code>.</p>
<p>For example:</p>
<pre class="r"><code>setwd(&#39;~/GenoPred/pipeline&#39;)
source(&#39;../functions/pipeline.R&#39;)</code></pre>
<p>Here is a list of useful R functions:</p>
<hr />
<div id="read_param" class="section level2">
<h2><code>read_param</code></h2>
<p>Reads in parameters from a configuration file.</p>
<ul>
<li><strong>Parameters</strong>
<ul>
<li><code>config</code>: Path to the configuration file.</li>
<li><code>param</code>: The name of the parameter to read.</li>
<li><code>return_obj</code> (optional): Boolean indicating whether to
return the parameter as an object (if possible) or as a file path.
Default is TRUE.</li>
</ul></li>
<li><strong>Returns</strong>
<ul>
<li>The value of the requested parameter if
<code>return_obj == F</code>, or as a data.table if
<code>return_obj == T</code>.</li>
</ul></li>
</ul>
<details>
<summary>
See usage
</summary>
<pre class="r"><code># Read in gwas_list
gwas_list &lt;-
  read_param(config = &#39;example_input/config.yaml&#39;, 
             param = &#39;gwas_list&#39;)

# Read in outdir
outdir &lt;-
  read_param(config = &#39;example_input/config.yaml&#39;, 
             param = &#39;gwas_list&#39;,
             return_obj = F)</code></pre>
</details>
<hr />
</div>
<div id="read_pgs" class="section level2">
<h2><code>read_pgs</code></h2>
<p>Reads in polygenic scores (PGS) based on the provided configuration
and filters.</p>
<ul>
<li><strong>Parameters</strong>
<ul>
<li><code>config</code>: Configuration file specifying paths and
parameters.</li>
<li><code>name</code> (optional): A vector of names to filter the target
list. Default is NULL.</li>
<li><code>pgs_methods</code> (optional): A vector of PGS methods to
include. Default is NULL.</li>
<li><code>gwas</code> (optional): A vector of GWAS to include. Default
is NULL.</li>
<li><code>pop</code> (optional): A vector of populations to include.
Default is NULL.</li>
</ul></li>
<li><strong>Returns</strong>
<ul>
<li>A list containing the filtered PGS data structured by target name,
population, GWAS, and PGS method.</li>
</ul></li>
</ul>
<details>
<summary>
See usage
</summary>
<pre class="r"><code># All PGS for all target datasets
pgs &lt;- read_pgs(config = &#39;example_input/config.yaml&#39;)

# All PGS for specific dataset
pgs &lt;-
  read_pgs(config = &#39;example_input/config.yaml&#39;, name = &#39;example_plink1&#39;)

# PGS for specific dataset, using a specific PGS method
pgs &lt;-
  read_pgs(config = &#39;example_input/config.yaml&#39;,
           name = &#39;example_plink1&#39;,
           pgs_method = &#39;dbslmm&#39;)

# PGS for specific dataset, using specific PGS method, and specific GWAS
pgs &lt;-
  read_pgs(
    config = &#39;example_input/config.yaml&#39;,
    name = &#39;example_plink1&#39;,
    pgs_method = &#39;dbslmm&#39;,
    gwas = &#39;COAD01&#39;
  )

# PGS for specific target population in a specific dataset, using specific PGS method, and specific GWAS
pgs &lt;-
  read_pgs(
    config = &#39;example_input/config.yaml&#39;,
    name = &#39;example_plink1&#39;,
    pgs_method = &#39;dbslmm&#39;,
    gwas = &#39;COAD01&#39;,
    pop = &#39;EUR&#39;
  )

# PGS for a specific dataset, using based on external score files only
pgs &lt;-
  read_pgs(
    config = &#39;example_input/config.yaml&#39;,
    name = &#39;example_plink1&#39;,
    pgs_method = &#39;external&#39;
  )</code></pre>
</details>
<hr />
</div>
<div id="read_ancestry" class="section level2">
<h2><code>read_ancestry</code></h2>
<p>Reads in ancestry inference results for a given target_dataset.</p>
<ul>
<li><strong>Parameters</strong>
<ul>
<li><code>config</code>: Configuration file specifying paths and
parameters.</li>
<li><code>name</code>: Name identifier for which to read ancestry
data.</li>
</ul></li>
<li><strong>Returns</strong>
<ul>
<li>A list containing ancestry inference outputs, including keep lists
indicating population classifications, population probabilities model,
and the ancestry inference log file.</li>
</ul></li>
</ul>
<details>
<summary>
See usage
</summary>
<pre class="r"><code>ancestry_info &lt;-
  read_ancestry(config = &#39;example_input/config.yaml&#39;, 
                name = &#39;example_plink1&#39;)</code></pre>
</details>
<hr />
</div>
<div id="find_pseudo" class="section level2">
<h2><code>find_pseudo</code></h2>
<p>Determines the pseudovalidation parameter for a given GWAS and PGS
method. See <a href="pipeline_technical.html#pseudovalidation">here</a>
for more information on pseudovalidation.</p>
<ul>
<li><strong>Parameters</strong>
<ul>
<li><code>config</code>: Configuration file specifying paths and
parameters.</li>
<li><code>gwas</code>: A single GWAS identifier.</li>
<li><code>pgs_method</code>: A single PGS method identifier.</li>
</ul></li>
<li><strong>Returns</strong>
<ul>
<li>A string representing the pseudovalidation parameter.</li>
</ul></li>
<li><strong>Note</strong>
<ul>
<li><code>ptclump</code> has no pseudovalidation approach, so this
function will return the PGS based on a p-value threshold of 1.</li>
</ul></li>
</ul>
<details>
<summary>
See usage
</summary>
<pre class="r"><code>pseudo_param &lt;-
  find_pseudo(config = &#39;example_input/config.yaml&#39;,
              gwas = &#39;COAD01&#39;,
              pgs_method = &#39;ptclump&#39;)</code></pre>
</details>
<hr />
</div>
<div id="read_pseudo_r" class="section level2">
<h2><code>read_pseudo_r</code></h2>
<p>Reads correlation (R) value from the lassosum pseudovalidation
results for a specified GWAS.</p>
<ul>
<li><strong>Parameters</strong>
<ul>
<li><code>config</code>: Configuration file specifying paths and
parameters.</li>
<li><code>gwas</code>: A single GWAS identifier.</li>
</ul></li>
<li><strong>Returns</strong>
<ul>
<li>A numeric value representing the R value from lassosum
pseudovalidation.</li>
</ul></li>
</ul>
<details>
<summary>
See usage
</summary>
<pre class="r"><code>pseudo_r &lt;-
  read_pseudo_r(
    config = &#39;example_input/config.yaml&#39;, 
    gwas = &#39;COAD01&#39;)</code></pre>
</details>
<hr />
</div>
</div>
<div id="computational-resources" class="section level1">
<h1>Computational resources</h1>
<p>Don’t worry too much about this, as the pipeline will adjust
according to the resources available. The requirements of the pipeline
vary depending on the rules applied and the input data provided. I would
suggest providing a minimum of 8GB RAM per core when using the pipeline.
Ideally you would have access to more cores, so more intensive PGS
methods run in a timely manner. We have performed a benchmark of time
and memory used by each rule in the pipeline (<a
href="pipeline_benchmark.html">link</a>).</p>
<p>When running the pipeline using the <code>--profile</code> flag, PGS
methods (except pT+clump) are run using the number of cores specified by
the <code>cores_prep_pgs</code> parameter in the config file (by default
10). When running SBayesR and PRS-CS in parallel, more memory is
required, with the pipeline requesting 4Gb x n_cores and 2Gb x n_cores
respectively. If you are running the pipeline in your current session,
using the <code>-j</code> parameter, PGS methods will be restricted
accordingly. For example, if <code>-j 2</code>, then PGS methods would
be restricted to 2 cores.</p>
<p>Required storage space will also vary depending on the input data and
configuration. This is also shown on the pipeline benchmark page (<a
href="pipeline_benchmark.html">link</a>).</p>
<div class="note-box">
<p><strong>Note.</strong> The pipeline will create a subset version of
the target genotype data, restricted to HapMap3 variants in PLINK1
binary format. This can require significant storage space. For example,
UK Biobank is ~140Gb in this format.</p>
</div>
<hr />
</div>
<div id="additional-parameters" class="section level1">
<h1>Additional parameters</h1>
<hr />
<div id="using-your-own-reference" class="section level2">
<h2>Using your own reference</h2>
<p>The default reference genotype data used by GenoPred is a previously
prepared dataset, which is based on the 1000 Genomes Phase 3 (1KG) and
Human Genome Diversity Project (HGDP) sample, restricted HapMap3
variants. This dataset contains 1204449 variants for 3313
individuals.</p>
<p>Users can provide their own reference data using the
<code>refdir</code> parameter in the <code>configfile</code>. For
example, if the reference data was in <code>~/data/private_ref</code>, I
would include <code>refdir: ~/data/private_ref</code> in the
<code>configfile</code>. The reference data folder must have the
following structure:</p>
<pre><code>[refdir]
  ├── ref.chr[1-22].[pgen/pvar/psam] (plink2 genotype data with RSIDs in SNP column)
  ├── ref.chr[1-22].rds (SNP data - refer to default ref data for format)
  ├── ref.pop.txt (Population data for reference individuals - with header)
  ├── ref.keep.list (lists keep files for each population - columns pop and path - no header)
  ├── keep_files
  │   └──[pop].keep (keep files for each population - no header)
  └── freq_files
      └──[pop]
          └──ref.[pop].chr[1-22].frq (plink1 .frq format)</code></pre>
<div class="note-box">
<p><strong>Note:</strong> .psam, ref.pop.txt and keep_files must contain
IID, and can optionally include FID information. The ID information must
be consistent across these files.</p>
</div>
<hr />
</div>
<div id="altering-pgs-method-parameters" class="section level2">
<h2>Altering PGS method parameters</h2>
<p>It is possible to alter parameters for certain PGS methods by setting
the following parameters in the configfile:</p>
<ul>
<li><code>ptclump_pts</code>: list of p-value thresholds for
ptclump</li>
<li><code>dbslmm_h2f</code>: list SNP-h2 folds for DBSLMM - use
<code>1</code> for the default model</li>
<li><code>prscs_phi</code>: list phi parameters for PRS-CS - use
<code>auto</code> for the auto model</li>
<li><code>prscs_ldef</code>: Selected whether PRS-CS ld reference is
derived from <code>1kg</code> (default) or <code>ukb</code> (UK
Biobank).</li>
<li><code>ldpred2_model</code>: list models for LDpred2 -
<code>grid</code>, <code>auto</code>, <code>inf</code></li>
</ul>
<p>See the default <a
href="https://github.com/opain/GenoPred/blob/master/pipeline/config.yaml">configfile</a>
for examples of these parameters being set.</p>
<hr />
</div>
<div id="specifying-unrelated-target-individuals"
class="section level2">
<h2>Specifying unrelated target individuals</h2>
<p>Relatedness estimation is one part of the within-sample QC (requested
using the <code>outlier_detection</code> rule). A list of unrelated
individuals is then used for downstream PCA. However, relatedness
estimation can be computationally intensive for large samples, and often
relatedness has already been estimated for such samples. For example, UK
Biobank genetic data comes with precomputed kinship data. To avoid
unnecessarily estimating relatedness within the GenoPred pipeline, there
is an optional <code>unrel</code> column in the
<code>target_list</code>, where the user can specify a file listing
unrelated individuals in each target sample. If this column is not
<code>NA</code> for a given target sample, the within-sample QC script
skips the relatedness estimation, and uses the precomputed list of
unrelated individuals for downstream PCA.</p>
<hr />
</div>
<div id="altering-ancestry-threshold" class="section level2">
<h2>Altering ancestry threshold</h2>
<p>By default, individuals are assigned to a reference super population
if the probability is &gt;0.95. However, users can alter this threshold
as desired using the <code>ancestry_prob_thresh</code> parameter in the
config file.</p>
<hr />
</div>
<div id="control-computational-resources" class="section level2">
<h2>Control computational resources</h2>
<p>The user can control the cores and memory allocated to certain tasks
in the pipeline to fit their needs.</p>
<p>By default, the pipeline allocates 10 cores running polygenic scoring
methods (except <code>ptclump</code>). The number of cores allocated to
polygenic scoring methods can be altered using the
<code>cores_prep_pgs</code> parameter in the config file.</p>
<p>By default, the pipeline allocates 10 cores and 10Gb memory when
performing target scoring. The number of cores and memory allocated to
target scoring can be altered using the <code>cores_target_pgs</code>
and <code>mem_target_pgs</code> parameters respectively.</p>
<p>By default, the pipeline allocates 10 cores when imputing 23andMe
target datasets. The number of cores can be altered using the
<code>cores_impute_23andme</code> parameters in the config file.</p>
<p>By default, the pipeline allocates 5 cores when running the
outlier_detection rule (estimating relatedness and within sample PCs).
The number of cores can be altered using the
<code>cores_outlier_detection</code> parameters in the config file.</p>
<hr />
</div>
</div>
<div id="running-in-offline-environment" class="section level1">
<h1>Running in offline environment</h1>
<p>See <a href="running_offline.html">here</a> if you would like to run
the GenoPred pipeline in an environment that does not have access to the
internet. In brief the user must download the resources required by
GenoPred, transfer them to their offline environment.</p>
<hr />
</div>
<div id="troubleshooting" class="section level1">
<h1>Troubleshooting</h1>
<p>Please post questions as an issue on the GenoPred GitHub repo <a
href="https://github.com/opain/GenoPred/issues">here</a>. If errors
occur while running the pipeline, log files will be saved in the
<code>GenoPred/pipeline/logs</code> folder. If running interactively
(i.e. -j1), the error should be printed on the screen.</p>
<p>If there is an unclear error message, feel free to post an issue. A
good approach for understanding the issue, is running the failed job
interactively, by using the <code>-p</code> parameter to print the
failed command, and then running interactively to understand the cause
of the error.</p>
</div>

<!-- footer.html -->
<hr/>

<div class="centered-container">
<div class="rounded-image-container" style="width: 500px;">
<img src="Images/logo/sponsors.png">
</div>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
