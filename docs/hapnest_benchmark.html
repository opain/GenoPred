<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>HapNest Benchmark</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />
<link rel="shortcut icon" href="Images/logo/favicon.ico">

<link rel="stylesheet" href="styles/night-mode.css" id="nightModeStylesheet">

<script>
function toggleNightMode() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (stylesheet.disabled) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
}
</script>

<label class="switch">
  <input type="checkbox" id="toggleNightMode" checked>
  <span class="slider round"></span>
</label>

<script>
document.getElementById('toggleNightMode').addEventListener('change', function() {
    var stylesheet = document.getElementById('nightModeStylesheet');
    if (this.checked) {
        stylesheet.disabled = false;
    } else {
        stylesheet.disabled = true;
    }
});
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YR18ZB3PR3"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YR18ZB3PR3');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>






<link rel="stylesheet" href="styles/styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"><img class="logo-img" src="Images/logo/Horizontal_white.png" style="height: 42px;" /></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Pipeline
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="pipeline_overview.html">Overview</a>
    </li>
    <li>
      <a href="pipeline_readme.html">Instructions</a>
    </li>
    <li>
      <a href="pipeline_technical.html">Technical documentation</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Research
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="research_index.html">Overview</a>
    </li>
    <li>
      <a href="comparison_of_methods_summary.html">Polygenic Scoring Methods Comparison</a>
    </li>
    <li>
      <a href="Functionally_informed_prediction.html">Quantifying Polygenic Signal Mediated by Altered Gene Expression</a>
    </li>
    <li>
      <a href="Absolute_Conversion.html">Translating Polygenic Scores onto the Absolute Scale</a>
    </li>
  </ul>
</li>
<li>
  <a href="more_index.html">More</a>
</li>
<li>
  <a href="https://github.com/opain/GenoPred">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">HapNest Benchmark</h1>

</div>


<hr />
<p>Here will use simulated genetic data to benchmark GenoPred. We will
simulate the genetic data using <a
href="https://github.com/intervene-EU-H2020/synthetic_data">HAPNEST</a>.</p>
<hr />
<div id="set-up-hapnest" class="section level1">
<h1>Set up HAPNEST</h1>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/HAPNEST
cd /users/k1806347/oliverpainfel/HAPNEST

# Step 1: Download container
singularity pull docker://sophiewharrie/intervene-synthetic-data

# Step 2: Set up workspace
mkdir -p /users/k1806347/oliverpainfel/HAPNEST/containers
mv intervene-synthetic-data_latest.sif /users/k1806347/oliverpainfel/HAPNEST/containers/
mkdir -p /users/k1806347/oliverpainfel/HAPNEST/data

# Step 3: Initiate HAPNEST (download dependencies)
export TMPDIR=/tmp
singularity exec --bind data/:/data/ containers/intervene-synthetic-data_latest.sif init

# Step 4: Download reference data
singularity exec --bind data/:/data/ containers/intervene-synthetic-data_latest.sif fetch
</code></pre>
</details>
<hr />
</div>
<div id="test-run-using-default-config" class="section level1">
<h1>Test run using default config</h1>
<p>Generates data for chromosome 1, for 6 populations, HapMap3 SNPs, and
1 phenotype.</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code># Step 5: Generate genotype and phenotype data
singularity exec --bind data/:/data/ containers/intervene-synthetic-data_latest.sif generate_geno 1 data/config.yaml
singularity exec --bind data/:/data/ containers/intervene-synthetic-data_latest.sif generate_pheno data/config.yaml

# Step 6: Evaluate simulation (optional and slow)
singularity exec --bind data/:/data/ containers/intervene-synthetic-data_latest.sif validate data/config.yaml</code></pre>
</details>
<p>The data simulation took about 1 minute. Evaluation takes &gt;2
hours.</p>
<hr />
</div>
<div id="hapnest-released-genotype-and-phenotype-data"
class="section level1">
<h1>HAPNEST released genotype and phenotype data</h1>
<p>It would probably be easier, and more reproducible to use the
released version of simulated data from the HAPNEST paper. The files are
very large as they are for 6.8M variants and 1M individuals. Let’s start
with chromosome 22 to testing things out. We can subset the files to
HapMap3 variants as we download them to avoid storing so much data in
first instance.</p>
<hr />
<div id="download-genotype-and-phenotype" class="section level2">
<h2>Download genotype and phenotype</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir -p /users/k1806347/oliverpainfel/HAPNEST/released/full
mkdir -p /users/k1806347/oliverpainfel/HAPNEST/released/subset
module load plink2
cd /users/k1806347/oliverpainfel/HAPNEST/released/full

# Download genotype data
# Subset the data to HapMap3 variants to save storage space
# Might as well convert to plink2 format for efficiency
for chr in $(seq 22 22); do
  for file in $(echo bed bim fam); do
    wget https://ftp.ebi.ac.uk/biostudies/fire/S-BSST/936/S-BSST936/Files/genotypes/synthetic_v1_chr-${chr}.${file}
  done
  
  wget https://ftp.ebi.ac.uk/biostudies/fire/S-BSST/936/S-BSST936/Files/rsids/rsid_variant_map_list_chr22.txt
  wget https://ftp.ebi.ac.uk/biostudies/fire/S-BSST/936/S-BSST936/Files/example/synthetic_small_v1_chr-22.bim
  
  awk &#39;NR==FNR {snp[$1]; next} $2 in snp&#39; /users/k1806347/oliverpainfel/GenoPred/pipeline/resources/data/hm3_snplist/w_hm3.snplist rsid_variant_map_list_chr22.txt &gt; matched_rows.txt

  plink2 \
    --bfile synthetic_v1_chr-${chr} \
    --make-pgen \
    --extract matched_rows.txt \
    --out /users/k1806347/oliverpainfel/HAPNEST/released/subset/synthetic_v1_hm3_chr${chr}

  rm synthetic_v1_chr-${chr}.*
  rm matched_rows.txt
  rm rsid_variant_map_list_chr${chr}.txt
done

# Download phenotype data
mkdir -p /users/k1806347/oliverpainfel/HAPNEST/released/phenotype
cd /users/k1806347/oliverpainfel/HAPNEST/released/phenotype
wget https://ftp.ebi.ac.uk/biostudies/fire/S-BSST/936/S-BSST936/Files/synthetic_v1.sample
for i in $(seq 1 9); do
  wget https://ftp.ebi.ac.uk/biostudies/fire/S-BSST/936/S-BSST936/Files/phenotypes/synthetic_v1.pheno${i}
done
</code></pre>
</details>
<p>Note. For some reason there only about 65% of HapMap3 variants
available in the synthetic data. This will cause an error when using
GenoPred as it requires a certain overlap with the default reference
data. Given we are going to generate the GWAS using this data, this
wouldn’t actually cause any issues of SNP overlap, but there would be
poor coverage of the genome which will decrease the PGS R2 values. This
is not a big issue, but given it is so fast to simulate data, it is
making me think we should simulate our own so we can make it exactly
what we want (sample size, genetic architecture, snplist).</p>
<hr />
</div>
</div>
<div id="full-simulation" class="section level1">
<h1>Full simulation</h1>
<p>Lets modify the quickstart config.yaml to simulate data for
chromosome 22, 40k individuals, EUR, EAS and AFR population, 9
phenotypes with same genetic architecture as HAPNEST paper.</p>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>cd /users/k1806347/oliverpainfel/HAPNEST

# Generate genotype and phenotype data
singularity exec \
  --bind data/:/data/ \
  --bind /users/k1806347/oliverpainfel/GenoPred/pipeline/misc/hapnest/config.synth_1.yaml:/data/config.synth_1.yaml \
  containers/intervene-synthetic-data_latest.sif \
  generate_geno \
  8 \
  data/config.synth_1.yaml
  
# Note this only worked when allocating 100G RAM when using 8 threads. This is a lot more than expected based on the HAPNEST paper.

singularity exec \
  --bind data/:/data/ \
  --bind /users/k1806347/oliverpainfel/GenoPred/pipeline/misc/hapnest/config.synth_1.yaml:/data/config.synth_1.yaml \
  containers/intervene-synthetic-data_latest.sif \
  generate_pheno \
  data/config.synth_1.yaml
  </code></pre>
</details>
<hr />
</div>
<div id="identify-unrelated-individuals" class="section level1">
<h1>Identify unrelated individuals</h1>
<p>We need to identify a group of unrelated individuals, to avoid bias
in the GWAS and sample overlap between GWAS and target sample when
evaluating PGS. Idenitfy unrelated individuals within each
population.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># Subset simulated data by population
library(data.table)
sample &lt;-
  fread(
    &#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-22.sample&#39;,
    header = F
  )$V1

pops&lt;-unique(sample)
fam &lt;- fread(&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-22.fam&#39;)
fam$pop &lt;- sample

for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  fam_i &lt;- fam[fam$pop == i,]
  fam_i &lt;- fam_i[, c(&#39;V1&#39;,&#39;V2&#39;), with=F]
  
  write.table(
    fam_i,
    paste0(
      &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/&#39;, i,&#39;.keep&#39;),
    col.names = F,
    row.names = F,
    quote = F
  )
}</code></pre>
<pre class="r"><code># Identify unrelated individuals
# conda activate .snakemake/conda/ea13b6c549c70695534894feeeecf0b3_
setwd(&#39;~/oliverpainfel/GenoPred/pipeline/&#39;)
dir.create(&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1&#39;, recursive = T)

library(&quot;optparse&quot;)
library(GenoUtils)
library(data.table)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Create temp directory
tmp_dir&lt;-tempdir()

option_list = list(
  make_option(&quot;--target_plink_chr&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;Path to per chromosome target PLINK files [required]&quot;),
  make_option(&quot;--maf&quot;, action=&quot;store&quot;, default=0.05, type=&#39;numeric&#39;,
              help=&quot;Minor allele frequency threshold [optional]&quot;),
  make_option(&quot;--geno&quot;, action=&quot;store&quot;, default=0.02, type=&#39;numeric&#39;,
              help=&quot;Variant missingness threshold [optional]&quot;),
  make_option(&quot;--hwe&quot;, action=&quot;store&quot;, default=1e-6, type=&#39;numeric&#39;,
              help=&quot;Hardy Weinberg p-value threshold. [optional]&quot;),
  make_option(&quot;--n_pcs&quot;, action=&quot;store&quot;, default=10, type=&#39;numeric&#39;,
              help=&quot;Number of PCs (min=4) [optional]&quot;),
  make_option(&quot;--plink2&quot;, action=&quot;store&quot;, default=&#39;plink2&#39;, type=&#39;character&#39;,
              help=&quot;Path PLINK2 software binary [required]&quot;),
  make_option(&quot;--keep_list&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;File containing list of keep files and corresponding population code [optional]&quot;),
  make_option(&quot;--unrel&quot;, action=&quot;store&quot;, default=NA, type=&#39;character&#39;,
              help=&quot;File containing list of unrelated individuals [optional]&quot;),
  make_option(&quot;--n_cores&quot;, action=&quot;store&quot;, default=1, type=&#39;numeric&#39;,
              help=&quot;Number of cores for parallel computing [optional]&quot;),
  make_option(&quot;--test&quot;, action=&quot;store&quot;, default=NA, type=&#39;character&#39;,
              help=&quot;Specify test mode [optional]&quot;),
  make_option(&quot;--output&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;Path for output files [required]&quot;)
)

opt = parse_args(OptionParser(option_list=option_list))

opt$test&lt;-&#39;chr22&#39;
opt$target_plink_chr&lt;-&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-&#39;
opt$output&lt;-&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/relatedness/synth_1&#39;
opt$n_cores&lt;-20

# Create output directory
opt$output_dir &lt;- paste0(dirname(opt$output),&#39;/&#39;)
system(paste0(&#39;mkdir -p &#39;,opt$output_dir))

if(!is.na(opt$test)){
  CHROMS &lt;- as.numeric(gsub(&#39;chr&#39;,&#39;&#39;,opt$test))
}

for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){

  # Identify high quality variants
  target_qc_snplist&lt;-plink_qc_snplist(bfile = opt$target_plink_chr, chr = CHROMS, plink2 = opt$plink2, geno = opt$geno, maf = opt$maf, hwe = opt$hwe, keep = paste0(&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/&#39;, i,&#39;.keep&#39;))
  
  # Generate kinship matrix and list of unrelated individuals
  plink_king(bfile = opt$target_plink_chr, chr = CHROMS, extract = target_qc_snplist, plink2 = opt$plink2, out = paste0(opt$output, &#39;.&#39;, i), threads = opt$n_cores, keep = paste0(&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/&#39;, i,&#39;.keep&#39;))
  
}</code></pre>
</details>
<hr />
</div>
<div id="subsample-and-gwas" class="section level1">
<h1>Subsample and GWAS</h1>
<div id="subsample" class="section level2">
<h2>Subsample</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>library(data.table)

fam &lt;- NULL
for(i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  tmp &lt;- fread(paste0(&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/relatedness/synth_1.&#39;,i,&#39;.unrelated.keep&#39;), header = F)
  tmp$pop &lt;- i
  fam &lt;- rbind(fam, tmp)
}

set.seed(1)
for(pop_i in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
  fam_pop_i &lt;- fam[fam$pop == pop_i,]
  print(nrow(fam_pop_i))
  train_size &lt;- floor(0.9 * nrow(fam_pop_i))
  train_indices &lt;- sample(seq_len(nrow(fam_pop_i)), size = train_size)
  
  write.table(
    fam_pop_i[train_indices, c(&#39;V1&#39;, &#39;V2&#39;), with = F],
    paste0(
      &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/training.&#39;,
      pop_i,
      &#39;.txt&#39;
    ),
    col.names = F,
    row.names = F,
    quote = F
  )
  
  write.table(
    fam_pop_i[!(seq_len(nrow(fam_pop_i)) %in% train_indices), c(&#39;V1&#39;,&#39;V2&#39;), with=F],
    paste0(
      &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/testing.&#39;,
      pop_i,
      &#39;.txt&#39;
    ),
    col.names = F,
    row.names = F,
    quote = F
  )
}</code></pre>
</details>
<hr />
</div>
<div id="gwas" class="section level2">
<h2>GWAS</h2>
<div id="perform-pca" class="section level3">
<h3>Perform PCA</h3>
<details>
<summary>
Show code
</summary>
<pre class="r"><code># conda activate .snakemake/conda/ea13b6c549c70695534894feeeecf0b3_
setwd(&#39;~/oliverpainfel/GenoPred/pipeline/&#39;)

start.time &lt;- Sys.time()
library(&quot;optparse&quot;)

option_list = list(
  make_option(&quot;--target_plink_chr&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;Path to per chromosome target PLINK files [required]&quot;),
  make_option(&quot;--maf&quot;, action=&quot;store&quot;, default=0.05, type=&#39;numeric&#39;,
              help=&quot;Minor allele frequency threshold [optional]&quot;),
  make_option(&quot;--geno&quot;, action=&quot;store&quot;, default=0.02, type=&#39;numeric&#39;,
              help=&quot;Variant missingness threshold [optional]&quot;),
  make_option(&quot;--hwe&quot;, action=&quot;store&quot;, default=1e-6, type=&#39;numeric&#39;,
              help=&quot;Hardy Weinberg p-value threshold. [optional]&quot;),
  make_option(&quot;--n_pcs&quot;, action=&quot;store&quot;, default=10, type=&#39;numeric&#39;,
              help=&quot;Number of PCs (min=4) [optional]&quot;),
  make_option(&quot;--plink2&quot;, action=&quot;store&quot;, default=&#39;plink2&#39;, type=&#39;character&#39;,
              help=&quot;Path PLINK2 software binary [required]&quot;),
  make_option(&quot;--keep_list&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;File containing list of keep files and corresponding population code [optional]&quot;),
  make_option(&quot;--unrel&quot;, action=&quot;store&quot;, default=NA, type=&#39;character&#39;,
              help=&quot;File containing list of unrelated individuals [optional]&quot;),
  make_option(&quot;--n_cores&quot;, action=&quot;store&quot;, default=1, type=&#39;numeric&#39;,
              help=&quot;Number of cores for parallel computing [optional]&quot;),
  make_option(&quot;--test&quot;, action=&quot;store&quot;, default=NA, type=&#39;character&#39;,
              help=&quot;Specify test mode [optional]&quot;),
  make_option(&quot;--output&quot;, action=&quot;store&quot;, default=NULL, type=&#39;character&#39;,
              help=&quot;Path for output files [required]&quot;)
)

opt = parse_args(OptionParser(option_list=option_list))

opt$target_plink_chr&lt;-&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-&#39;
opt$output&lt;-&#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/pca/&#39;
opt$test&lt;-&#39;chr22&#39;

keep_list&lt;-data.frame(
  file = c(
    &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/training.EUR.txt&#39;,
    &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/training.EAS.txt&#39;,
    &#39;~/oliverpainfel/Analysis/HAPNEST/synth_1/training.AFR.txt&#39;),
  POP = c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
)

library(GenoUtils)
library(data.table)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)

# Create temp directory
tmp_dir&lt;-tempdir()

if(!is.na(opt$test)){
  CHROMS &lt;- as.numeric(gsub(&#39;chr&#39;,&#39;&#39;,opt$test))
}

############
# Create file listing variants in regions of long range LD
############

targ_pvar &lt;- read_bim(opt$target_plink_chr, chr = CHROMS)
targ_pvar &lt;- remove_regions(dat = targ_pvar, regions = long_ld_coord)

for(pop in keep_list$POP){
  # Read in keep file for population
  keep_file &lt;- fread(keep_list$file[keep_list$POP == pop], header=F)
  if(ncol(keep_file) == 1){
    keep_file &lt;- data.table(
      FID = keep_file$V1,
      IID = keep_file$V1)
  } else {
    keep_file &lt;- data.table(
      FID = keep_file$V1,
      IID = keep_file$V2)
  }

  ###########
  # Perform PCA on QC&#39;d and independent variants
  ###########

  # Create QC&#39;d SNP-list
  target_qc_snplist &lt;- plink_qc_snplist(bfile = opt$target_plink_chr, plink2 = opt$plink2, chr = CHROMS, keep = keep_file, maf = opt$maf, geno = opt$geno, hwe = opt$hwe, threads = opt$n_cores)

  # Remove high LD regions
  target_qc_snplist &lt;- target_qc_snplist[target_qc_snplist %in% targ_pvar$SNP]

  # Perform LD pruning
  ld_indep &lt;- plink_prune(bfile = opt$target_plink_chr, chr = CHROMS, keep = keep_file, plink2 = opt$plink2, extract = target_qc_snplist, threads = opt$n_cores)

  # To improve efficiency, derive PCs using random subset of 1000 individuals.
  keep_file_subset &lt;- keep_file[sample(1000, replace = T),]
  keep_file_subset &lt;- keep_file_subset[!duplicated(keep_file_subset),]

  # Run PCA
  snp_weights &lt;- plink_pca(bfile = opt$target_plink_chr, keep = keep_file_subset, chr = CHROMS, plink2 = opt$plink2, extract = ld_indep, n_pc = opt$n_pcs, threads = opt$n_cores)
  fwrite(snp_weights, paste0(tmp_dir,&#39;/ref.eigenvec.var&#39;), row.names = F, quote=F, sep=&#39; &#39;, na=&#39;NA&#39;)

  # Project into the full population
  target_pcs &lt;- plink_score(bfile = opt$target_plink_chr, keep = keep_file, chr = CHROMS, plink2 = opt$plink2, score = paste0(tmp_dir,&#39;/ref.eigenvec.var&#39;), threads = opt$n_cores)

  fwrite(target_pcs, paste0(opt$output, pop,&#39;.pcs.txt&#39;), quote=F, sep=&#39; &#39;, na=&#39;NA&#39;)
}</code></pre>
</details>
<hr />
</div>
<div id="perform-gwas" class="section level3">
<h3>Perform GWAS</h3>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>
module add plink2
for pheno in $(seq 1 1); do
    awk &#39;BEGIN {OFS=&quot;\t&quot;} NR==1 {print &quot;FID&quot;, &quot;IID&quot;, &quot;pheno&quot;} NR&gt;1 {print $1, $1, $NF}&#39; /users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr.pheno${pheno} &gt; /users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr.pheno${pheno}.plink
    
  for pop in $(echo EUR EAS AFR); do
  
    mkdir -p ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}
    for chr in $(seq 22 22); do
        sbatch -p neurohack_cpu --mem 20G -n 4 --wrap=&quot;plink2 \
          --bfile /users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-22 \
          --pheno /users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr.pheno${pheno}.plink \
          --1 \
          --covar ~/oliverpainfel/Analysis/HAPNEST/synth_1/pca/${pop}.pcs.txt \
          --covar-variance-standardize \
          --logistic omit-ref cols=+a1freq,+ax hide-covar \
          --maf 0.01 \
          --geno 0.05 \
          --out ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.chr${chr}&quot;
    done
  done
done

# Once complete, merge results across chromosomes
for pheno in $(seq 1 1); do
  for pop in $(echo EUR EAS AFR); do
    head -n 1 ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.chr22.pheno.glm.logistic.hybrid &gt; ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.GW.pheno.glm.logistic.hybrid
      for chr in $(seq 22 22); do
        tail -n +2 ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.chr22.pheno.glm.logistic.hybrid &gt;&gt; ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.GW.pheno.glm.logistic.hybrid
      done
      
      # Remove REF and ALT columns and rename AX column to A2
      cut -f 4,5 --complement ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.GW.pheno.glm.logistic.hybrid | awk &#39;BEGIN{FS=OFS=&quot;\t&quot;} NR==1 {$7=&quot;A2&quot;} 1&#39; &gt; temp.txt &amp;&amp; mv temp.txt ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.GW.pheno.glm.logistic.hybrid
  
      gzip ~/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno${pheno}/pheno${pheno}.${pop}.GW.pheno.glm.logistic.hybrid
  done
done
</code></pre>
</details>
<hr />
</div>
</div>
</div>
<div id="run-genopred" class="section level1">
<h1>Run GenoPred</h1>
<div id="subset-hapnest-testing-data" class="section level2">
<h2>Subset HAPNEST testing data</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>mkdir -p ~/oliverpainfel/Analysis/HAPNEST/synth_1/testing_subset

cat ~/oliverpainfel/Analysis/HAPNEST/synth_1/testing.*.txt &gt; ~/oliverpainfel/Analysis/HAPNEST/synth_1/testing.txt

for chr in $(seq 22 22); do
    plink2 \
      --bfile /users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-${chr} \
      --keep ~/oliverpainfel/Analysis/HAPNEST/synth_1/testing.txt \
      --make-bed \
      --out ~/oliverpainfel/Analysis/HAPNEST/synth_1/testing_subset/synth_1.chr${chr}
done</code></pre>
</details>
</div>
<div id="prepare-config" class="section level2">
<h2>Prepare config</h2>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>dir.create(&#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config&#39;, recursive = T)

# gwas_list
sample_file&lt;-fread(&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr-22.sample&#39;, header=F)$V1
gwas_list &lt;- NULL
for(pheno in 1:1){
  pheno_file &lt;- fread(paste0(&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr.pheno&#39;, pheno,&#39;.plink&#39;))
  for(pop in c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)){
    
    pheno_file_pop &lt;- pheno_file[sample_file == pop,]
    
    tmp &lt;- data.frame(
      name=paste0(&#39;pheno&#39;,pheno,&#39;_&#39;,pop),
      path=paste0(&#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/synth_1/gwas/pheno&#39;, pheno, &#39;/pheno&#39;, pheno, &#39;.&#39;, pop, &#39;.GW.pheno.glm.logistic.hybrid.gz&#39;),
      population=pop,
      n=NA,
      sampling=mean(pheno_file_pop$pheno),
      prevalence=0.5,
      mean=NA,
      sd=NA,
      label=paste0(&#39;&quot;pheno&#39;, pheno, &#39; (&#39;, pop, &#39;)&quot;&#39;)
    )
    
    gwas_list &lt;- rbind(gwas_list, tmp)
  }
}

write.table(gwas_list, &#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/gwas_list.txt&#39;, col.names = T, row.names = F, quote = F)

# target_list
target_list &lt;- data.frame(
  name=&#39;hapnest&#39;,
  path=&#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/synth_1/testing_subset/synth_1&#39;,
  type=&#39;plink1&#39;,
  indiv_report=F
)

write.table(target_list, &#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/target_list.txt&#39;, col.names = T, row.names = F, quote = F)

config&lt;-c(
  &quot;outdir: /users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/output&quot;,
  &quot;config_file: /users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/config.yaml&quot;,
  &quot;gwas_list: /users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/gwas_list.txt&quot;,
  &quot;target_list: /users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/target_list.txt&quot;,
  &quot;pgs_methods: [&#39;ptclump&#39;]&quot;,
  &quot;cores_prep_pgs: 1&quot;,
  &quot;cores_target_pgs: 10&quot;,
  &quot;testing: chr22&quot;,
  &quot;pgs_scaling: [&#39;continuous&#39;, &#39;discrete&#39;]&quot;
)

write.table(config, &#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/config.yaml&#39;, col.names = F, row.names = F, quote = F)</code></pre>
</details>
<hr />
</div>
<div id="run-pipeline" class="section level2">
<h2>Run pipeline</h2>
<details>
<summary>
Show code
</summary>
<pre class="bash"><code>snakemake --profile slurm --use-conda --configfile=/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/config.yaml output_all -n</code></pre>
</details>
<hr />
</div>
</div>
<div id="evaluate-pgs" class="section level1">
<h1>Evaluate PGS</h1>
<p>Evaluate PGS R2 within each population.</p>
<details>
<summary>
Show code
</summary>
<pre class="r"><code>setwd(&#39;~/oliverpainfel/GenoPred/pipeline/&#39;)
source(&#39;../functions/misc.R&#39;)
source_all(&#39;../functions&#39;)
library(data.table)

# Get some key variables from config
config&lt;-&#39;/users/k1806347/oliverpainfel/Analysis/HAPNEST/genopred/config/config.yaml&#39;
pgs_methods &lt;- read_param(config = config, param = &#39;pgs_methods&#39;, return_obj = F)
outdir &lt;- read_param(config = config, param = &#39;outdir&#39;, return_obj = F)

# Get a list of score files
scores &lt;- list_score_files(config)

# Read in PGS for each population
pop &lt;- c(&#39;EUR&#39;,&#39;EAS&#39;,&#39;AFR&#39;)
pgs &lt;- read_pgs(config = config)

# Read in phenotype data
pheno &lt;- fread(&#39;/users/k1806347/oliverpainfel/HAPNEST/data/outputs/synth_1/synth_1_chr.pheno1.plink&#39;)

# Evaluate PGS (without adjustment for reference PCs)
assoc&lt;-NULL
for(i in pop){
  for(j in 1:nrow(scores)){
    tmp &lt;- pgs$hapnest[[i]][[scores$name[j]]][[scores$method[j]]]
    tmp &lt;- merge(tmp, pheno, by = c(&#39;FID&#39;,&#39;IID&#39;))
    tmp_pheno &lt;- tmp$pheno
    tmp_pgs &lt;- tmp[, !(names(tmp) %in% c(&#39;FID&#39;,&#39;IID&#39;,&#39;pheno&#39;)), with = F]
    
    for(k in names(tmp_pgs)){
      mod &lt;- glm(tmp_pheno ~ scale(tmp_pgs[[k]]), family=&#39;binomial&#39;)
        obs_r2 &lt;- cor(predict(mod), as.numeric(tmp_pheno))^2
      sum_mod &lt;- summary(mod)

      assoc &lt;- rbind(
        assoc, 
        data.table(
            Predictor = k,
            BETA = coef(sum_mod)[2, 1],
            SE = coef(sum_mod)[2, 2],
            P = coef(sum_mod)[2, 4],
            Obs_R2 = obs_r2,
            N = length(tmp_pheno),
            gwas = scores$name[j],
            method = scores$method[j],
            pop = i,
            trans = F
        )
      )
      }
  }
}

# Evaluate PGS (without adjustment for reference PCs)
assoc_trans&lt;-NULL
for(i in pop){
  for(j in 1:nrow(scores)){
    tmp &lt;- pgs$hapnest[[i]][[scores$name[j]]][[scores$method[j]]]
    tmp2 &lt;- pgs$hapnest[[&#39;TRANS&#39;]][[scores$name[j]]][[scores$method[j]]]
    tmp2 &lt;- tmp2[tmp2$FID %in% tmp$FID,]
    tmp &lt;- merge(tmp2, pheno, by = c(&#39;FID&#39;,&#39;IID&#39;))
    tmp_pheno &lt;- tmp$pheno
    tmp_pgs &lt;- tmp[, !(names(tmp) %in% c(&#39;FID&#39;,&#39;IID&#39;,&#39;pheno&#39;)), with = F]
    
    for(k in names(tmp_pgs)){
      mod &lt;- glm(tmp_pheno ~ scale(tmp_pgs[[k]]), family=&#39;binomial&#39;)
        obs_r2 &lt;- cor(predict(mod), as.numeric(tmp_pheno))^2
      sum_mod &lt;- summary(mod)

      assoc_trans &lt;- rbind(
        assoc_trans, 
        data.table(
            Predictor = k,
            BETA = coef(sum_mod)[2, 1],
            SE = coef(sum_mod)[2, 2],
            P = coef(sum_mod)[2, 4],
            Obs_R2 = obs_r2,
            N = length(tmp_pheno),
            gwas = scores$name[j],
            method = scores$method[j],
            pop = i,
            trans = T
        )
      )
      }
  }
}

# Check the correlation between pheno and PGS, with and without adjustments for reference PCs
cor(assoc_trans$BETA, assoc$BETA) # 0.9996044

plot(assoc_trans$BETA, assoc$BETA)
abline(a = 0, b = 1, col = &quot;red&quot;, lwd = 2, lty = 2)
# The results are almost identical. This will vary depending on whether the phenotype varies according to ancestry. This simulation confirms that the PGS R2 is not impacted when there is no correlation between ancestry and the phenotype.

# Plot the results
assoc_both &lt;- rbind(assoc, assoc_trans)
library(ggplot2)
library(cowplot)

# Extract pT variable from Predictor
assoc_both$pT &lt;- gsub(&#39;e.&#39;,&#39;e-&#39;, gsub(&#39;.*0_&#39;, &#39;&#39;, assoc_both$Predictor))
assoc_both$pT &lt;- factor(assoc_both$pT, levels = unique(assoc_both$pT))

# Improve labelling for plot
assoc_both$pop &lt;- paste0(&#39;Target = &#39;, assoc_both$pop)
assoc_both$pop &lt;- factor(assoc_both$pop, levels = unique(assoc_both$pop))

assoc_both$gwas &lt;- gsub(&#39;.*_&#39;, &#39;&#39;, assoc_both$gwas)
assoc_both$gwas &lt;- paste0(&#39;Discovery = &#39;, assoc_both$gwas)
assoc_both$gwas &lt;- factor(assoc_both$gwas, levels = unique(assoc_both$gwas))

assoc_both$trans &lt;- ifelse(assoc_both$trans, &#39;Unadjusted&#39;, &#39;Adjusted&#39;)

setwd(&#39;/scratch_tmp/prj/oliverpainfel/GenoPred&#39;)
dir.create(&#39;docs/Images/hapnest&#39;)
png(&#39;docs/Images/hapnest/pgs_eval.png&#39;, res = 100, height = 700, width = 1000, units = &#39;px&#39;)

ggplot(assoc_both, aes(x = trans, y = BETA, fill = pT)) +
  geom_hline(yintercept = 0, colour = &#39;darkgrey&#39;) +
  geom_bar(stat=&quot;identity&quot;, position=position_dodge(preserve = &quot;single&quot;), width = 0.8) +
  geom_errorbar(aes(ymin=BETA-SE, ymax=BETA+SE), width=0, position=position_dodge(width = 0.8, preserve = &quot;single&quot;)) +
  labs(y=&quot;BETA (SE)&quot;, x=NULL) +
  theme_half_open() +
  background_grid() +
  panel_border() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  background_grid(major = &#39;y&#39;, minor = &#39;y&#39;) +
  scale_fill_manual(values = colorRampPalette(c(&quot;lightblue&quot;, &quot;darkblue&quot;))(length(unique(assoc_both$pT)))) +
  facet_grid(pop ~ gwas)

dev.off()</code></pre>
</details>
<p></br></p>
<div class="centered-container">
<div class="rounded-image-container" style="width: 100%;">
<div class="figure">
<img src="Images/hapnest/pgs_eval.png" alt="" />
<p class="caption">Performance of PGS when adjusted for ancestry</p>
</div>
</div>
</div>
<p></br></p>
<p>The results with and without reference-based correction for ancestry
are almost identical. This will vary depending on whether the phenotype
varies according to ancestry. This simulation confirms that the PGS R2
is not impacted when there is no correlation between ancestry and the
phenotype.</p>
<p>As expected the PGS derived using target-matched ancestry GWAS,
perform slightly better. The difference isn’t huge, due to same GWAS
sample size, and cross population rG of 1.</p>
</div>

<!-- footer.html -->
<hr/>

<div class="centered-container">
<div class="rounded-image-container" style="width: 500px;">
<img src="Images/logo/sponsors.png">
</div>
</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
