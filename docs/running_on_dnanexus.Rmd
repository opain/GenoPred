---
title: Running GenoPred on DNAnexus
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_float: true
    toc_depth: 2
    css: styles/styles.css
    includes:
      in_header: header.html
      after_body: footer.html

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

```{css, echo=F}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
```

***

# Introduction

The UK Biobank (UKB) has recently updated its data access policy, requiring researchers to access and analyze UKB data exclusively via the UKB Research Analysis Platform (UKB-RAP), hosted by DNAnexus. This represents a significant shift in workflows, moving from institutional servers to a cloud-computing environment. DNAnexus and similar cloud-computing systems are likely to become standard for future datasets, so this guide aims to provide instructions on running GenoPred on DNAnexus, with a particular focus on analyzing UKB data. The UKB dataset presents unique challenges due to its size, making efficient analysis essential.

Cloud computing involves requesting access to an instance (or virtual machine) with a specified amount of resources, such as disk space, RAM, and the number of CPU cores. Once access is granted, users must create the required software and data environment within the instance—a step that is often unfamiliar to many. After completing the desired analyses, users must export any outputs they wish to retain, as any data or software left on the instance will be deleted once it is terminated.

This process of transferring software and data into and out of the instance is a significant departure from the experience of working on personal computers or institutional servers, where you can resume work seamlessly each time you log in. 

***

# RStudio vs. Cloud Workstation

Currently, the easiest way to run GenoPred on DNAnexus is interactively, using either RStudio or a Cloud Workstation with the GenoPred software container. Each approach offers unique advantages.

RStudio mounts files directly from a DNAnexus project, eliminating the need to import data. This feature saves time and disk space, particularly with large datasets like UKB genetic data.

Unlike RStudio, the cloud workstation requires input data to be manually imported using dx download, which can be time-consuming and requires additional storage space. While dxfuse allows project folders to be mounted (even across projects), it is prone to instability during long analyses, such as when using UKB.

Another distinction is that cloud workstations can be connected to via VScode, which some people may prefer to Rstudio.

Given the advantage of stable project folder mounting in RStudio, I will demonstrate the workflow in that context. For the demo, minimal resources are required, so I will request an `mem1_ssd1_v2_x2` instance type. A similar workflow can also be applied in the Cloud Workstation, substituting the Singularity container with the GenoPred Docker container.

***

# Demonstration using Rstudio

***

## Step 0: Prepare test data

To make the demonstration as similar as possible to working with UKB data, I will first upload a version of the GenoPred test data into a DNAnexus project. While it would be simpler to download the test data directly into the instance, this approach will better mimic the set up when working with UKB data.

```{bash}
# Step 1: Download the GenoPred test data from Zenodo
wget -O test_data.tar.gz https://zenodo.org/records/10640650/files/test_data.tar.gz?download=1

# Step 2: Decompress the downloaded file
tar -xf test_data.tar.gz

# Step 3: Extract only the necessary files for the demonstration
mkdir genopred_test_data
mv test_data/target/imputed_sample_plink2/example.chr22* genopred_test_data/
mv test_data/reference/gwas_sumstats/BODY04.gz genopred_test_data/

# Step 4: Load the Conda environment with dxpy installed
# The Conda environment file for installing dxpy is available in the GenoPred repository
# Path: GenoPred/pipeline/misc/dnanexus/dxpy_env.yml
conda activate dxpy_env

# Step 5: Log in to DNAnexus using an API token, if not already logged in
# API tokens can be created on the DNAnexus website (https://platform.dnanexus.com/)
dx login --token <token>

# Step 6: Select the desired DNAnexus project
dx select genopred_demo

# Step 7: Upload the prepared data to DNAnexus
dx upload -r genopred_test_data

# Step 8: Clean up temporary files to save space
rm -r test_data test_data.tar.gz genopred_test_data
```

***

## Step 1. Install Singularity and Download the GenoPred Container

Once your RStudio session has started, install Singularity via the terminal. Follow the commands below to set up Singularity, along with other essential tools:

```{bash}
# Configure keyboard layout (optional step to avoid prompts)
echo 'keyboard-configuration keyboard-configuration/layout select us' | sudo debconf-set-selections
echo 'keyboard-configuration keyboard-configuration/variant select English (US)' | sudo debconf-set-selections

# Install required dependencies (e.g., tmux, build tools, and libraries for Singularity)
sudo DEBIAN_FRONTEND=noninteractive apt update && \
sudo DEBIAN_FRONTEND=noninteractive apt install -y build-essential libseccomp-dev pkg-config squashfs-tools cryptsetup golang tmux

# Set the Singularity version to install
export VERSION=3.11.0

# Download and extract the Singularity source code
wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz
tar -xvzf singularity-ce-${VERSION}.tar.gz
cd singularity-ce-${VERSION}

# Configure and build Singularity without SUID
./mconfig --without-suid
make -C builddir

# Install Singularity system-wide
sudo make -C builddir install

# Return to the home directory
cd ~
```

After installing Singularity, download the GenoPred container using the following command:

```{bash}
# Pull the GenoPred container
singularity pull library://opain/genopred/genopred_pipeline:latest
```

<div class="note-box">

**Note:** To make your workflow more efficient and reproducible, consider saving the downloaded container file in your project folder. This allows you to re-use the container in future analyses without needing to download it again.

</div>

***

## Step 2. Import input data

In a DNAnexus project, data is automatically mounted within the RStudio session and can be accessed from the /mnt/project directory. However, if the data you need is not located in the project folder, you will need to import it manually using the dx download command.

For this demonstration, we are working with the small test dataset, so I will show how to import it. When working with larger datasets, such as UKB genetic data, it is often more efficient to use the mounted version of the dispensed data. This approach saves time and disk space by avoiding the need to download and store large files within the RStudio instance.

```{bash}
# View the files in your current project folder
dx ls

# More instructions on using the dx commands can be found here:
# https://documentation.dnanexus.com/getting-started/cli-quickstart

# Import the test data into the instance
dx download -r genopred_test_data
```

***

## Step 3. Set up pipeline configuration

Now, we will create the configuration files required to run the GenoPred pipeline. Note that the `outdir` and `resdir` must be set to directories located outside the container to ensure proper access and storage.

```{r}

# Create directories for configuration and output files
dir.create('/home/rstudio-server/genopred/config', recursive = TRUE)
dir.create('/home/rstudio-server/genopred/output', recursive = TRUE)

# Create gwas_list configuration
gwas_list <- data.frame(
  name = 'BODY04', 
  path = '/home/rstudio-server/genopred_test_data/BODY04.gz',
  population = 'EUR',
  n = NA,
  sampling = NA,
  prevalence = NA,
  mean = 0,
  sd = 1,
  label = '"Body Mass Index"'
)

write.table(
  gwas_list, 
  '/home/rstudio-server/genopred/config/gwas_list.txt', 
  col.names = TRUE, 
  row.names = FALSE, 
  quote = FALSE, 
  sep = ' '
)

# Create target_list configuration
target_list <- data.frame(
  name = 'example_plink1',
  path = '/home/rstudio-server/genopred_test_data/example',
  type = 'plink2',
  indiv_report = FALSE
)

write.table(
  target_list, 
  '/home/rstudio-server/genopred/config/target_list.txt', 
  col.names = TRUE, 
  row.names = FALSE, 
  quote = FALSE, 
  sep = ' '
)

# Create main configuration file
conf <- c(
  'outdir: /home/rstudio-server/genopred/output',
  'resdir: /home/rstudio-server/genopred/resources',
  'config_file: /home/rstudio-server/genopred/config/config.yaml',
  'gwas_list: /home/rstudio-server/genopred/config/gwas_list.txt',
  'target_list: /home/rstudio-server/genopred/config/target_list.txt',
  "pgs_methods: ['ptclump']",
  'testing: chr22'
)

writeLines(
  conf, 
  '/home/rstudio-server/genopred/config/config.yaml'
)

```

***

## Step 4. Run the pipeline in the container

Now we can run the GenoPred pipeline. This can be done either interactively within the container or by executing the desired commands directly. Running the pipeline interactively is often more convenient for performing a dry run before launching the full analysis.

***

### Start an Interactive Session in the Container

To ensure that your analysis persists even when the RStudio server tab is closed, it is recommended to start the container within a tmux session. This will allow you to detach and reattach to the session as needed.

Start a tmux session within the terminal by running:

```{bash}
tmux
```

This will take you into a `tmux` session. You can 'detach' from the `tmux` session by pressing `Ctrl+b d`, and reattach to the session in the future by typing:

```{bash}
tmux attach
```

Further instructions on using `tmux` can be found [here](https://www.redhat.com/en/blog/introduction-tmux-linux).

To begin, start an interactive session within the Singularity container. Make sure to mount the home directory within the RStudio session to store the outputs:

```{bash}
singularity shell \
  --bind /home/rstudio-server:/home/rstudio-server \
  --writable-tmpfs \
  /home/rstudio-server/genopred_pipeline_latest.sif
```

***

### Run GenoPred Inside the Container

Once inside the container, you can use the GenoPred pipeline as usual:

```{bash}
# Activate the GenoPred Environment:
source /opt/mambaforge/etc/profile.d/conda.sh
conda activate genopred

# Navigate to the Pipeline Folder:
cd /tools/GenoPred/pipeline

# Perform a Dry Run: 
# A dry run checks the pipeline's steps without executing them, helping you identify any missing dependencies or issues:
snakemake -n --use-conda --configfile=/home/rstudio-server/genopred/config/config.yaml output_all

# Run the Pipeline: 
# Once satisfied with the dry run, execute the pipeline:
snakemake -j1 --use-conda --configfile=/home/rstudio-server/genopred/config/config.yaml output_all
```

While this analysis is running, you can detach from the `tmux` session, close the RStudio tab, and close your browser. When you reopen the RStudio app, you may see that your session appears suspended. Do not worry—your analysis will continue running in the background.

By using `tmux`, your analysis will continue to run even if the terminal session or RStudio server tab is closed.

After the analysis is complete, you can leave the container by typing:

```{bash}
exit
```

***

## Step 5. Export ouputs to the project folder

To avoid losing the outputs of your analysis when the RStudio session is terminated, you need to export the results to your DNAnexus project folder. Both the resdir (resources) and outdir (outputs) should be saved for future analyses.

For simplicity and efficiency, we will compress the outputs and resources into a single tar file and then upload it to the DNAnexus project. If you plan to reuse the resources (e.g., for different pipeline configurations), you may choose to store them in separate tar files.

```{bash}
# Compress the GenoPred working directory
cd /home/rstudio-server
tar -cvf test_run_genopred.tar genopred

# Upload the GenoPred container
dx upload genopred_pipeline_latest.sif

# Upload the tar file containing pipeline resources and outputs
dx upload test_run_genopred.tar
```

Once the files are uploaded, you can safely terminate the RStudio session. Ensure the session is fully terminated by checking the Monitor tab in your DNAnexus project folder.

***

# Extending your analysis in the future

If you want to extend your analysis without rerunning steps that have already completed, you can start a new RStudio session, import the outputs from a previous run, and resume the pipeline from within the container. Note that you will also need to import the input data used in the previous analysis.

```{bash}
# Download the Outputs from the Previous Run:
dx download test_run_genopred.tar
tar -xvf test_run_genopred.tar

# Download the Singularity Container:
dx download genopred_pipeline_latest.sif

# Download the Input Data:
dx download -r genopred_test_data
```

When using dx download for files that are not part of a tar archive, the original timestamps are lost. This may confuse GenoPred, as it will interpret the files as being updated. To fix this, reset the timestamps of the input files:

```{bash}
find /home/rstudio-server/genopred_test_data/ -type f -exec touch -t 200001010101.01 {} +
```

If the input data is accessed via the automatic mount in /mnt/project, this step is unnecessary, as the timestamps are preserved. This another advantage of mounting the input data.

```{bash}
# Start an Interactive Session in the Container:
singularity shell \
  --bind /home/rstudio-server:/home/rstudio-server \
  --writable-tmpfs \
  /home/rstudio-server/genopred_pipeline_latest.sif

# Activate the GenoPred Environment:
source /opt/mambaforge/etc/profile.d/conda.sh
conda activate genopred

# Navigate to the Pipeline Folder:
cd /tools/GenoPred/pipeline

### Check the Pipeline State: Run a dry run to verify the current state of the pipeline:
snakemake -n --use-conda --configfile=/home/rstudio-server/genopred/config/config.yaml output_all
```

The pipeline will indicate that there is nothing to be done if the configuration has not changed and all outputs are up to date.

If an input file is updated (e.g., by changing its timestamp), the pipeline will automatically rerun only the necessary steps:

```{bash}
touch /home/rstudio-server/genopred_test_data/BODY04.gz
snakemake -n --use-conda --configfile=/home/rstudio-server/genopred/config/config.yaml output_all
```

This dry run will show which steps need to be re-executed due to the update.

***

# Running GenoPred with UK Biobank

The UKB imputed genetic data is provided without post-imputation QC, resulting in large files. The `format_target` step of GenoPred, which reformats the target genetic data, is time-intensive but reduces file size to ~86GB, making future analyses faster and cheaper. Storing this output for reuse is highly recommended. Additionally, selecting instances with appropriate resources for each pipeline stage ensures cost efficiency, as some steps utilize multiple cores while others do not.

***

## Key Adjustments for UKB Data

- Mounted UKB Data: Avoid duplicating the large UKB data files by using a mounted version to save time and disk space.
- File Naming with Symbolic Links: Update file names as required by GenoPred using symbolic links to avoid duplicating data.
- High-Resource Instance for `format_target`: Use a `mem3_ssd2_v2_x8` instance, which supports 8 processes and provides sufficient RAM and disk space for processing the large UKB files efficiently. Other steps of the pipeline will have other resources requirements.

***

## Workflow

- Run `format_target` on a High-Resource Instance: Use the `mem3_ssd2_v2_x8` instance to efficiently complete the `format_target` step. 
- Export and Store Processed Data: Save the reformatted data for future use, avoiding repeated processing.
- Terminate the High-Resource Instance: After completing `format_target`, terminate the instance to minimize costs.
- Continue Analysis on Cost-Effective Instances: For downstream steps, switch to an instance with resources tailored to those stages.
- This approach balances efficiency and cost when working with large-scale UKB genetic data in the GenoPred pipeline.

***

## Step 1. Install Singularity

Once your RStudio session has started, install Singularity via the terminal. Follow the commands below to set up Singularity, along with other essential tools:

```{bash}
# Configure keyboard layout (optional step to avoid prompts)
echo 'keyboard-configuration keyboard-configuration/layout select us' | sudo debconf-set-selections
echo 'keyboard-configuration keyboard-configuration/variant select English (US)' | sudo debconf-set-selections

# Install required dependencies (e.g., tmux, build tools, and libraries for Singularity)
sudo DEBIAN_FRONTEND=noninteractive apt update && \
sudo DEBIAN_FRONTEND=noninteractive apt install -y build-essential libseccomp-dev pkg-config squashfs-tools cryptsetup golang tmux

# Set the Singularity version to install
export VERSION=3.11.0

# Download and extract the Singularity source code
wget https://github.com/sylabs/singularity/releases/download/v${VERSION}/singularity-ce-${VERSION}.tar.gz
tar -xvzf singularity-ce-${VERSION}.tar.gz
cd singularity-ce-${VERSION}

# Configure and build Singularity without SUID
./mconfig --without-suid
make -C builddir

# Install Singularity system-wide
sudo make -C builddir install

# Return to the home directory
cd ~
```

***

## Step 2: Prepare input data

We will use a mounted version of the UKB genetic data to save time and disk space. To meet GenoPred's file name requirements without duplicating data, we will create symbolic links. Given the size of the UKB genetic data, we will also request an instance with sufficient resources.

```{bash}
# Create symlinks to the dispensed imputed genetic data
mkdir -p /home/rstudio-server/ukb/ukb_symlinks

# Link bgen and bgen.bgi files for all chromosomes
for chr in $(seq 1 22); do
  for file in $(echo bgen bgen.bgi); do
    ln -s /mnt/project/Bulk/Imputation/UKB\ imputation\ from\ genotype/ukb22828_c${chr}_b0_v3.${file} /home/rstudio-server/ukb/ukb_symlinks/ukb_imp.chr${chr}.${file}
  done
done

# Link the sample file (same for all chromosomes)
ln -s /mnt/project/Bulk/Imputation/UKB\ imputation\ from\ genotype/ukb22828_c1_b0_v3.sample /home/rstudio-server/ukb/ukb_symlinks/ukb_imp.sample
```

***

## Step 3. Set up pipeline configuration

Next, create the configuration files required to run the GenoPred pipeline. Ensure that `outdir` and `resdir` are set to directories outside the container for proper access and storage.

```{r}
# Create directories for configuration and output files
dir.create('/home/rstudio-server/genopred/config/ukb/basic', recursive = T)
dir.create('/home/rstudio-server/genopred/output', recursive = T)

# Create target list
# We are specifying the symbolic links we made for the UKB data
target_list <- data.frame(
  name='ukb',
  path='/home/rstudio-server/ukb/ukb_symlinks/ukb_imp',
  type='bgen',
  indiv_report=F
)

write.table(
  target_list,
  '/home/rstudio-server/genopred/config/ukb/basic/target_list.txt',
  col.names = T,
  row.names = F,
  quote = F
)

# Create config file
conf <- c(
  'outdir: /home/rstudio-server/genopred/output',
  'config_file: /home/rstudio-server/genopred/config/ukb/basic/config.yaml',
  'resdir: /home/rstudio-server/genopred/resources',
  'target_list: /home/rstudio-server/genopred/config/ukb/basic/target_list.txt'
)

write.table(
  conf,
  '/home/rstudio-server/genopred/config/ukb/basic/config.yaml',
  col.names = F,
  row.names = F,
  quote = F
)
```

***

## Step 4. Run the pipeline in the container

Now we can run the GenoPred pipeline. This can be done either interactively within the container or by executing the desired commands directly. Running the pipeline interactively is often more convenient for performing a dry run before launching the full analysis.

***

### Start an Interactive Session in the Container

To ensure that your analysis persists even when the RStudio server tab is closed, it is recommended to start the container within a tmux session. This will allow you to detach and reattach to the session as needed.

Start a tmux session within the terminal by running:

```{bash}
tmux
```

This will take you into a `tmux` session. You can 'detach' from the `tmux` session by pressing `Ctrl+b d`, and reattach to the session in the future by typing:

```{bash}
tmux attach
```

Further instructions on using `tmux` can be found [here](https://www.redhat.com/en/blog/introduction-tmux-linux).

To begin, start an interactive session within the Singularity container. Make sure to mount the home directory within the RStudio session and the directory that the symbolic links point to, to store the pipeline outputs and access the input data within the container.

```{bash}
singularity shell \
  --bind /home/rstudio-server:/home/rstudio-server \
  --bind /mnt/project/Bulk/Imputation/UKB\ imputation\ from\ genotype:/mnt/project/Bulk/Imputation/UKB\ imputation\ from\ genotype \
  --writable-tmpfs \
  /mnt/project/genopred_pipeline_latest.sif
```

***

### Run GenoPred Inside the Container

Once inside the container, you can use the GenoPred pipeline as usual. The resources provided by this instance (`mem3_ssd2_v2_x8`) will not be required for all steps in the GenoPred workflow, so to be cost efficient, I am just carrying out the `format_target` step within this instance. I will then export the data, terminate this instance, continue my analysis using a new instance with appropriate resources for downstream steps.

```{bash}
# Activate the GenoPred Environment:
source /opt/mambaforge/etc/profile.d/conda.sh
conda activate genopred

# Navigate to the Pipeline Folder:
cd /tools/GenoPred/pipeline

# Perform a Dry Run: 
# A dry run checks the pipeline's steps without executing them, helping you identify any missing dependencies or issues:
snakemake -n --use-conda --configfile=/home/rstudio-server/genopred/config/ukb/basic/config.yaml format_target

# Run the Pipeline: 
# Once satisfied with the dry run, execute the pipeline:
snakemake -j8 --use-conda --configfile=/home/rstudio-server/genopred/config/ukb/basic/config.yaml format_target
```

<div class="note-box">

**Note:** Since the instance has 8 cores available, I use the `-j8` parameter when running `snakemake` to ensure it utilizes all 8 cores efficiently.

</div>

After the analysis is complete, you can leave the container by typing:

```{bash}
exit
```

In total, this analysis took ~18 hours, costing ~£6.

***

## Step 5. Export ouputs to the project folder

To avoid losing the outputs of your analysis when the RStudio session is terminated, you need to export the results to your DNAnexus project folder. Both the resdir (resources) and outdir (outputs) should be saved for future analyses.

For simplicity and efficiency, we will compress the outputs and resources into a single tar file and then upload it to the DNAnexus project. If you plan to reuse the resources (e.g., for different pipeline configurations), you may choose to store them in separate tar files.

```{bash}
# Compress and upload the GenoPred working directory
cd /home/rstudio-server
tar -cvf ukb_genopred.tar genopred
dx upload ukb_genopred.tar
```

I will also tar and upload the symlinks created for the UKB data. While these could be recreated, this approach conveniently preserves the timestamps, making it easier to resume the analysis seamlessly when extending it in the future.

```{bash}
# Compress and upload the ukb directory containing symlinks
cd /home/rstudio-server
tar -cvf ukb_symlinks.tar ukb
dx upload ukb_symlinks.tar
```

Once the files are uploaded, you can safely terminate the RStudio session. Ensure the session is fully terminated by checking the Monitor tab in your DNAnexus project folder.

***

# Troubleshooting

Please post questions as an issue on the GenoPred GitHub repo [here](https://github.com/opain/GenoPred/issues).
